{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:21<?, ?it/s]\n",
      "  0%|          | 0/50 [01:04<?, ?it/s]\n",
      "  0%|          | 0/50 [00:59<?, ?it/s]\n",
      "  0%|          | 0/50 [00:58<?, ?it/s]\n",
      "  0%|          | 0/50 [00:56<?, ?it/s]\n",
      "  0%|          | 0/50 [00:55<?, ?it/s]\n",
      "  0%|          | 0/50 [00:53<?, ?it/s]\n",
      "  0%|          | 0/50 [00:51<?, ?it/s]\n",
      "  0%|          | 0/50 [00:49<?, ?it/s]\n",
      "  0%|          | 0/50 [00:44<?, ?it/s]\n",
      "  0%|          | 0/50 [00:39<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from libsvm.svmutil import svm_read_problem # https://blog.csdn.net/u013630349/article/details/47323883\n",
    "from time import time\n",
    "\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import scipy as sp\n",
    "from scipy.linalg import hessenberg\n",
    "def read_data(path):\n",
    "    b, A = svm_read_problem(path)\n",
    "    rows = len(b)   # 矩阵行数, i.e. sample 数\n",
    "    cols = max([max(row.keys()) if len(row)>0 else 0 for row in A])  # 矩阵列数, i.e. feature 数\n",
    "    b = np.array(b)\n",
    "    A_np = np.zeros((rows,cols))\n",
    "    for r in range(rows):\n",
    "        for c in A[r].keys():\n",
    "            # MatLab 是 1-index, python 则是 0-index\n",
    "            A_np[r,c-1] = A[r][c]\n",
    "    # 清楚全 0 features\n",
    "    effective_row_ids = []\n",
    "    for idx, row in enumerate(A_np):\n",
    "        if   True or np.sum(row) > 1e-3:\n",
    "            effective_row_ids.append(idx)\n",
    "    return b[effective_row_ids], A_np[effective_row_ids]\n",
    "\n",
    "\n",
    "def solve_tridiagonal_system(diag: np.ndarray, subdiag: np.ndarray, tau: float, b: np.ndarray) -> np.ndarray:\n",
    "    n = diag.shape[0]\n",
    "    c = np.zeros(n - 1)\n",
    "    d = np.zeros(n)\n",
    "\n",
    "    c[0] = subdiag[0] / (diag[0] + tau)\n",
    "    d[0] = b[0] / (diag[0] + tau)\n",
    "    for i in range(1, n - 1):\n",
    "        w = diag[i] + tau - subdiag[i - 1] * c[i - 1]\n",
    "        c[i] = subdiag[i] / w\n",
    "        d[i] = (b[i] - subdiag[i - 1] * d[i - 1]) / w\n",
    "    d[n - 1] = (b[n - 1] - subdiag[n - 2] * d[n - 2]) / (diag[n - 1] + tau - subdiag[n - 2] * c[n - 2])\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        d[i] -= c[i] * d[i + 1]\n",
    "\n",
    "    return d\n",
    "lamda = 100\n",
    "def phi(x,D):\n",
    "    return -np.log(D/2-np.linalg.norm(x,ord=2))\n",
    "\n",
    "def phi_grad(x,D):\n",
    "    x_norm = np.linalg.norm(x,ord=2)\n",
    "    return x/(x_norm*(D/2-x_norm))\n",
    " \n",
    "def phi_hessian(x,D):\n",
    "    x_norm = np.linalg.norm(x,ord=2)\n",
    "    # print(x_norm)\n",
    "    xxT = np.matmul(x[:,None],x[None,:])    # x * xT\n",
    "    return np.eye(x.size)/(x_norm*(D/2-x_norm)) + (2*x_norm-D/2)/(x_norm**3 * (D/2-x_norm)**2)*xxT\n",
    "def f(x,params):\n",
    "    b=params['b']\n",
    "    A=params['A_o']\n",
    "    m=A.shape[0]\n",
    "    bAx = b*(A@x)\n",
    "    exp_mbAx = np.exp(-bAx)\n",
    "    log1p_exp = np.log(1+exp_mbAx)\n",
    "    overflow_idxs = np.where(exp_mbAx==float('inf'))\n",
    "    log1p_exp[overflow_idxs] = -bAx[overflow_idxs]\n",
    "    return log1p_exp.mean() + 1/(lamda*m)* x.T@x\n",
    "\n",
    "def f_grad(x,params):\n",
    "    b=params['b']\n",
    "    A=params['A_o']\n",
    "    m=A.shape[0]\n",
    "    return np.ones(m)@(np.expand_dims((-b)/(1+np.exp(b*(A@x))), axis=1)*A)/m + 2/(lamda*m)*x\n",
    "\n",
    "def f_hessian(x,params):\n",
    "    b=params['b']\n",
    "    A=params['A_o']\n",
    "    m=A.shape[0]\n",
    "    Ax = A@x\n",
    "    exp_bAx = np.exp(b*Ax)\n",
    "    return (A.T @ (np.expand_dims(b*b*exp_bAx/(1+exp_bAx)**2, axis=1)*A) )/m + 2/(lamda*m)*np.eye(x.size)\n",
    "def f_int(x,params,x_k,gamma_k):\n",
    "    return f_grad(x_k,params).dot(x-x_k)+gamma_k/2*(f_hessian(x_k,params)@(x-x_k)).dot(x-x_k)\n",
    "def f_int_grad(x,params,x_k,gamma_k):\n",
    "    return f_grad(x_k,params)+gamma_k*f_hessian(x_k,params)@(x-x_k)\n",
    "def f_int_hess(x,params,x_k,gamma_k):\n",
    "    return gamma_k*f_hessian(x_k,params)\n",
    "def barrier_method(t_init, f, f_grad, f_hessian, phi, phi_grad, phi_hessian, A, b, x0, D, num_constraints, mu,\n",
    "                        method='newton', epsilon=1e-6, maxIter=20):\n",
    "    xt = x0\n",
    "    t = t_init\n",
    "    duality_gaps = []\n",
    "    func_val_record = []\n",
    "    t_s = time()\n",
    "    for i in range(maxIter):\n",
    "        xt,num_newton_step, fvals = solve_central(objective=f,\n",
    "                                f=lambda x:t*f(x)+phi(x,D), \n",
    "                                f_grad=lambda x:t*f_grad(x)+phi_grad(x,D), \n",
    "                                f_hessian=lambda x:t*f_hessian(x)+phi_hessian(x,D),\n",
    "                                x0=xt, D=D, method=method, epsilon=epsilon*1e3)\n",
    "        duality_gaps.extend([num_constraints/t]*num_newton_step)\n",
    "        func_val_record.extend(fvals)\n",
    "        if num_constraints/t < epsilon:\n",
    "            break\n",
    "        t *= mu\n",
    "    t_e = time()\n",
    "    return xt, t_e-t_s, np.array(duality_gaps), np.array(func_val_record)\n",
    "def armijo_search(f, f_grad, xk, t_hat, alpha, beta, D, isNewton=False, dk=None):\n",
    "    if isNewton:\n",
    "        assert dk is not None\n",
    "    tk = t_hat*1\n",
    "    grad = f_grad(xk)\n",
    "    while True:\n",
    "        if isNewton:\n",
    "            if np.linalg.norm(xk+tk*dk,ord=2)<=D/2 and f(xk+tk*dk) <= f(xk) + alpha*tk*grad.T@dk:\n",
    "                break\n",
    "        else:\n",
    "            # if np.linalg.norm(xk-tk*grad,ord=2)<=D/2 and f(xk-tk*grad) <= f(xk)-alpha*tk*grad.T@grad:\n",
    "            if f(xk-tk*grad) <= f(xk)-alpha*tk*grad.T@grad:\n",
    "                break\n",
    "        tk *= beta\n",
    "    return tk\n",
    "\n",
    "def solve_central(objective, f, f_grad, f_hessian, x0, D, method='newton', epsilon=1e-6, max_iter=50):\n",
    "    if method == 'newton':\n",
    "        return damped_newton(objective, f=f, f_grad=f_grad, f_hessian=f_hessian, x0=x0, D=D, epsilon=epsilon, max_iter=max_iter)\n",
    "    if method == 'bfgs':\n",
    "        return bfgs(objective, f=f, f_grad=f_grad, f_hessian=f_hessian, x0=x0, D=D, epsilon=epsilon, max_iter=max_iter)\n",
    "#* 阻尼牛顿\n",
    "def damped_newton(objective, f, f_grad, f_hessian, x0, D, epsilon=1e-6, max_iter=50):\n",
    "    xk = x0\n",
    "    iter_cnt = 0\n",
    "    fvals = []\n",
    "    for idx in range(max_iter):\n",
    "        iter_cnt += 1\n",
    "        fvals.append(objective(xk))\n",
    "        grad = f_grad(xk)\n",
    "        hessian = f_hessian(xk)\n",
    "        dk = -np.linalg.inv(hessian)@grad\n",
    "        decrement = (-grad@dk)**0.5\n",
    "        if decrement**2/2 <= epsilon:\n",
    "            # print('** End The Loop - Iter Cnt.:',iter_cnt, 'Decrement:',decrement, 'fval:',f(xk))\n",
    "            return xk, iter_cnt, fvals\n",
    "        tk = armijo_search(f, f_grad, xk, t_hat=1, alpha=0.1, beta=0.5, D=D, isNewton=True, dk=dk)\n",
    "        # print('Iter Cnt.:',iter_cnt, 'Decrement:',decrement, 'fval:',f(xk), 'tk:',tk)\n",
    "        xk += tk*dk\n",
    "    return xk, iter_cnt, fvals\n",
    "def update_approximation_bfgs(mat, sk, yk, mat_type='H'):\n",
    "    rhok = 1/(yk@sk)\n",
    "    if mat_type == 'H':\n",
    "        Hkyk = mat@yk\n",
    "        ykTHkyk = yk@Hkyk\n",
    "        HkykskT = Hkyk[:,None]@sk[None,:]\n",
    "        skskT = sk[:,None]@sk[None,:]\n",
    "        mat_new = mat + rhok*((rhok*ykTHkyk+1)*skskT - HkykskT - HkykskT.T)\n",
    "    else:\n",
    "        Bksk = mat@sk\n",
    "        skTBksk = sk@Bksk\n",
    "        mat_new = mat - Bksk[:,None]@Bksk[None,:]/skTBksk + yk[:,None]@yk[None,:]*rhok\n",
    "    return mat_new\n",
    "\n",
    "#* 拟牛顿方法 - 选择步长\n",
    "def wolfe_condition(f, f_grad, xk, pk, D, c1=1e-4, c2=0.9, multiplier=1.2, t0=0, tmax=2):\n",
    "    ### \n",
    "    while (np.linalg.norm(xk+tmax*pk)>=D/2):\n",
    "        tmax /= 2\n",
    "        # print('tmax:',tmax)\n",
    "        if tmax<1e-6:\n",
    "            # print('too small stepsize')\n",
    "            return -1\n",
    "    ###\n",
    "    ti = tmax/2\n",
    "    tprev = t0\n",
    "    i = 1\n",
    "    fval_cur = f(xk)\n",
    "    grad_cur = f_grad(xk)\n",
    "    while True:\n",
    "        xk_next = xk+ti*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if (fval_next > fval_cur + c1*ti*grad_cur@pk) or (fval_next >= fval_cur and i>1):\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, tprev, ti)\n",
    "        grad_next = f_grad(xk_next)\n",
    "        grad_next_T_pk = grad_next@pk\n",
    "        if np.abs(grad_next_T_pk) <= -c2*grad_cur@pk:\n",
    "            return ti\n",
    "        if grad_next_T_pk >= 0:\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, ti, tprev)\n",
    "        tprev = ti\n",
    "        ti = tprev*multiplier\n",
    "        i += 1\n",
    "def zoom(f, f_grad, xk, pk, fval, grad, c1, c2, t_lo, t_hi):\n",
    "    while True:\n",
    "        # print(f\"t_lo: {t_lo}\\tt_hi: {t_hi}\")\n",
    "        t = (t_lo+t_hi)/2\n",
    "        xk_next = xk + t*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if fval_next > fval + c1*t*grad@pk or fval_next >= f(xk+t_lo*pk):\n",
    "            t_hi = t\n",
    "        else:\n",
    "            grad_next = f_grad(xk_next)\n",
    "            grad_next_T_pk = grad_next@pk\n",
    "            if np.abs(grad_next_T_pk) <= -c2*grad@pk:\n",
    "                return t\n",
    "            if grad_next_T_pk*(t_hi-t_lo)>=0:\n",
    "                t_hi = t_lo\n",
    "            t_lo = t\n",
    "        if t_lo == t_hi: # 死循环\n",
    "            return -1\n",
    "#* 拟牛顿\n",
    "def bfgs(objective, f, f_grad, f_hessian, x0, D, alpha=0.1, beta=0.5, epsilon=1e-6, max_iter=500):\n",
    "    xk = x0\n",
    "    hessian = f_hessian(x0)\n",
    "    mat_k = np.linalg.inv(hessian) \n",
    "    # mat_k = np.eye(n) \n",
    "    iter_cnt = 0\n",
    "    fvals = []\n",
    "    # pbar=tqdm(range(max_iter))\n",
    "    for idx in range(max_iter):\n",
    "        iter_cnt += 1\n",
    "        grad_k = f_grad(xk)\n",
    "        dk = -mat_k@grad_k \n",
    "        tk = wolfe_condition(f, f_grad, xk, dk, D, c1=1e-4, c2=0.9)\n",
    "        if tk<0:\n",
    "            return xk, iter_cnt-1, fvals\n",
    "        fvals.append(objective(xk))\n",
    "        sk = tk*dk\n",
    "        xk_next = xk + sk\n",
    "        grad_next = f_grad(xk_next)\n",
    "        # if np.linalg.norm(grad_next, ord=2) <= epsilon:\n",
    "        if np.linalg.norm(grad_next, ord=2) <= epsilon or np.linalg.norm(xk_next)>=D/2-1e-2:\n",
    "            print(f'Iteration {iter_cnt} - grad_norm: {np.linalg.norm(grad_next)}, tk: {tk}, x_norm:{np.linalg.norm(xk_next)}')\n",
    "            return xk_next, iter_cnt, fvals\n",
    "        else:\n",
    "            print(f'Iteration {iter_cnt} - grad_norm: {np.linalg.norm(grad_next)}, tk: {tk}, x_norm:{np.linalg.norm(xk_next)}')\n",
    "        # mat_k = np.linalg.inv(f_hessian(xk_next))\n",
    "        mat_k = update_approximation_bfgs(mat=mat_k, sk=sk, yk=grad_next-grad_k)\n",
    "        xk = xk_next\n",
    "    return xk_next, iter_cnt, fvals\n",
    "\n",
    "\n",
    "def minimize_quadratic_on_l2_ball(g: np.ndarray, H: np.ndarray, R: float, inner_eps: float, params: dict,x_k: np.ndarray,gamma_k: float) -> np.ndarray:\n",
    "    n = g.shape[0]\n",
    "    x_opt_ipm_damped, t_ipm_damped, duality_gaps_damped, fvals_damped = barrier_method(t_init=params['t_init'], f=lambda x:f_int(x,params,x_k,gamma_k),\n",
    "                            f_grad=lambda x:f_int_grad(x,params,x_k,gamma_k), f_hessian=lambda x:f_int_hess(x,params,x_k,gamma_k), phi=phi, phi_grad=phi_grad,\n",
    "                            phi_hessian=phi_hessian, \n",
    "                A=params['A_o'], b=params['b'], x0=x_k, D=2*params['R'], num_constraints=1, method='bfgs', mu=10, epsilon=params['inner_eps'], maxIter=20)\n",
    "    return x_opt_ipm_damped\n",
    "\n",
    "\n",
    "def contracting_newton(params, c_0, decrease_gamma, history):\n",
    "    # start_time = time.perf_counter()\n",
    "    # last_logging_time = start_time\n",
    "    # last_display_time = start_time\n",
    "\n",
    "    n = params['A'].shape[1]\n",
    "    m = params['A'].shape[0]\n",
    "    inv_m = 1.0 / m\n",
    "    data_accesses = m\n",
    "\n",
    "    x_k = params['x_0'].copy()\n",
    "    # Ax = params['A'].dot(x_k)\n",
    "    Ax = params['A']@x_k\n",
    "    g_k = np.zeros(n)\n",
    "    H_k = np.zeros((n, n))\n",
    "    v_k = np.zeros(n)\n",
    "\n",
    "    gamma_str = f\"gamma_k = {c_0}\"\n",
    "    if decrease_gamma:\n",
    "        gamma_str += \" / (3 + k)\"\n",
    "    print(f\"Contracting Newton Method, {gamma_str}\")\n",
    "    pbar=tqdm(range(params['n_iters'] ))\n",
    "    for k in pbar:\n",
    "        to_finish = False\n",
    "        # update_history(\n",
    "        #     params,\n",
    "        #     start_time,\n",
    "        #     k,\n",
    "        #     data_accesses,\n",
    "        #     lambda: float('inf') if x_k.norm() > params['R'] + 1e-5 else inv_m * np.logaddexp(Ax, 0).sum(),\n",
    "        #     last_logging_time,\n",
    "        #     last_display_time,\n",
    "        #     history,\n",
    "        #     to_finish\n",
    "        # )\n",
    "        # print(np.linalg.norm(g_k))\n",
    "        if to_finish or (k>=1 and np.linalg.norm(g_k)<params['outer_eps']):\n",
    "            break\n",
    "\n",
    "        gamma_k = c_0\n",
    "        if decrease_gamma:\n",
    "            gamma_k /= 3.0 + k\n",
    "            # gamma_k=c_0*(1-(k/(k+1))**3)\n",
    "            # print(\"Gamma_k=\",gamma_k)\n",
    "        # print(\"Round:\",k,flush=True)\n",
    "        g_k = inv_m * (params['A'].T.dot(1 / (1 + np.exp(-Ax)))+2*params['lambda']*x_k) \n",
    "        H_k = (inv_m ) * (params['A'].T.dot(((1 / (1 + np.exp(-Ax))) * (1 - 1 / (1 + np.exp(-Ax))))[:, np.newaxis] * params['A'])) + inv_m*2*params['lambda']*np.diag([1.0]*x_k.size)\n",
    "        # g_k -= H_k.dot(x_k)\n",
    "\n",
    "        v_k = minimize_quadratic_on_l2_ball(g_k, H_k, params['R'], params['inner_eps'],params,x_k,gamma_k)\n",
    "\n",
    "        x_k += gamma_k * (v_k - x_k)\n",
    "        Ax = params['A'].dot(x_k)\n",
    "        data_accesses += m\n",
    "        pbar.set_description('Function value: %.8f / Grad norm: %.8f'%(np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k))))+inv_m*params['lambda']*np.linalg.norm(x_k)**2,np.linalg.norm(g_k)))\n",
    "        # print(\"function value:\",np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k))))+inv_m*params['lambda']*np.linalg.norm(x_k)**2)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49749 300\n",
      "14910962\n",
      "Contracting Newton Method, gamma_k = 3.0 / (3 + k)\n",
      "Iteration 1 - grad_norm: 0.22929800830210337, tk: 1.0, x_norm:1.9281132026839376\n",
      "Iteration 2 - grad_norm: 0.1259083540499028, tk: 1.0, x_norm:1.2208181153545434\n",
      "Iteration 3 - grad_norm: 0.15153596655678273, tk: 1.0, x_norm:0.618938493164876\n",
      "Iteration 4 - grad_norm: 0.11446979685446487, tk: 1.0, x_norm:0.61643300379609\n",
      "Iteration 5 - grad_norm: 0.0247493789669156, tk: 1.0, x_norm:0.8134796017482979\n",
      "Iteration 6 - grad_norm: 0.020076785584696014, tk: 1.0, x_norm:0.827897387793117\n",
      "Iteration 7 - grad_norm: 0.012280949732820423, tk: 1.0, x_norm:0.8519762166108459\n",
      "Iteration 8 - grad_norm: 0.005443269954289677, tk: 1.0, x_norm:0.8676745661768795\n",
      "Iteration 9 - grad_norm: 0.0020284932019427053, tk: 1.0, x_norm:0.8717157819025817\n",
      "Iteration 10 - grad_norm: 0.0014664498213446213, tk: 1.0, x_norm:0.8707840861089593\n",
      "Iteration 11 - grad_norm: 0.0011727823095993648, tk: 1.0, x_norm:0.8701104871419868\n",
      "Iteration 1 - grad_norm: 0.042870727121108426, tk: 1.0, x_norm:1.6206423912264147\n",
      "Iteration 2 - grad_norm: 0.012655659665792868, tk: 1.0, x_norm:1.7513921702187885\n",
      "Iteration 3 - grad_norm: 0.0024867600495064976, tk: 1.0, x_norm:1.8026199592274421\n",
      "Iteration 1 - grad_norm: 0.054926503816321984, tk: 1.0, x_norm:3.606591745582643\n",
      "Iteration 2 - grad_norm: 0.017899241075810268, tk: 1.0, x_norm:4.065104637924016\n",
      "Iteration 3 - grad_norm: 0.002601916689232325, tk: 1.0, x_norm:4.171874119690447\n",
      "Iteration 1 - grad_norm: 0.7490492486053903, tk: 0.5, x_norm:6.05060619548512\n",
      "Iteration 2 - grad_norm: 0.33612955522945226, tk: 0.5, x_norm:7.042014092637948\n",
      "Iteration 3 - grad_norm: 0.0488662850646834, tk: 1.0, x_norm:7.765522116770513\n",
      "Iteration 4 - grad_norm: 0.005418953430503269, tk: 1.0, x_norm:7.621502308136385\n",
      "Iteration 1 - grad_norm: 1.7255164274328894, tk: 0.5, x_norm:8.744193652501735\n",
      "Iteration 2 - grad_norm: 0.5718256182425367, tk: 0.5, x_norm:9.194876491509099\n",
      "Iteration 3 - grad_norm: 0.16096018233668977, tk: 1.0, x_norm:9.34558920386546\n",
      "Iteration 4 - grad_norm: 0.010624551203105466, tk: 1.0, x_norm:9.310758770724073\n",
      "Iteration 5 - grad_norm: 0.014364826436198542, tk: 1.0, x_norm:9.30753172688501\n",
      "Iteration 6 - grad_norm: 0.0018840229680020556, tk: 1.0, x_norm:9.311886054768296\n",
      "Iteration 1 - grad_norm: 9.398892195722903, tk: 0.25, x_norm:9.585439577036182\n",
      "Iteration 2 - grad_norm: 5.809998041611232, tk: 0.25, x_norm:9.7650278663238\n",
      "Iteration 3 - grad_norm: 3.3703899495409906, tk: 0.25, x_norm:9.83053179586325\n",
      "Iteration 4 - grad_norm: 0.9012712982894149, tk: 0.5, x_norm:9.869038747766481\n",
      "Iteration 5 - grad_norm: 0.1930248958307469, tk: 1.0, x_norm:9.879764614601088\n",
      "Iteration 6 - grad_norm: 0.006397704935474048, tk: 1.0, x_norm:9.877816468285163\n",
      "Iteration 7 - grad_norm: 0.0027868619414772376, tk: 1.0, x_norm:9.877849119513398\n",
      "Iteration 1 - grad_norm: 65.18883806250777, tk: 0.09, x_norm:9.92377438480224\n",
      "Iteration 2 - grad_norm: 58.134282180357545, tk: 0.0625, x_norm:9.945758773690082\n",
      "Iteration 3 - grad_norm: 43.324804774096854, tk: 0.125, x_norm:9.968100791279221\n",
      "Iteration 4 - grad_norm: 32.04910729779065, tk: 0.125, x_norm:9.976075499512566\n",
      "Iteration 5 - grad_norm: 5.281224514075718, tk: 0.5, x_norm:9.987092415131531\n",
      "Iteration 6 - grad_norm: 3.6783128412431214, tk: 1.0, x_norm:9.985292413735968\n",
      "Iteration 7 - grad_norm: 0.3969139659320117, tk: 1.0, x_norm:9.98599186976255\n",
      "Iteration 8 - grad_norm: 0.3064724451456903, tk: 1.0, x_norm:9.986129748487068\n",
      "Iteration 9 - grad_norm: 0.006115412956462904, tk: 1.0, x_norm:9.986070233338284\n",
      "Iteration 10 - grad_norm: 0.0016013516238921252, tk: 1.0, x_norm:9.986070793401383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.31470173 / Grad norm: 0.59389792:   0%|          | 1/10000 [01:26<239:05:46, 86.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 70.72772818638094, tk: 1.0, x_norm:9.98586498202115\n",
      "Iteration 2 - grad_norm: 47.17037097436463, tk: 1.0, x_norm:9.978808559283614\n",
      "Iteration 3 - grad_norm: 28.324695208812763, tk: 1.0, x_norm:9.964717995241402\n",
      "Iteration 4 - grad_norm: 17.72470141207779, tk: 1.0, x_norm:9.943639354879387\n",
      "Iteration 5 - grad_norm: 10.931615731824408, tk: 1.0, x_norm:9.908671412237467\n",
      "Iteration 6 - grad_norm: 6.7945988501286605, tk: 1.0, x_norm:9.853198748772765\n",
      "Iteration 7 - grad_norm: 4.230624912941775, tk: 1.0, x_norm:9.764538920132294\n",
      "Iteration 8 - grad_norm: 2.6605585042888253, tk: 1.0, x_norm:9.626137621501474\n",
      "Iteration 9 - grad_norm: 1.7097277395208146, tk: 1.0, x_norm:9.41796955926857\n",
      "Iteration 10 - grad_norm: 1.1595886843693761, tk: 1.0, x_norm:9.13121774242734\n",
      "Iteration 11 - grad_norm: 0.8822327752972542, tk: 1.0, x_norm:8.8003412457135\n",
      "Iteration 12 - grad_norm: 0.7801932999113491, tk: 1.0, x_norm:8.516931350027818\n",
      "Iteration 13 - grad_norm: 0.751488641603401, tk: 1.0, x_norm:8.338829735355494\n",
      "Iteration 14 - grad_norm: 0.7346639878637393, tk: 1.0, x_norm:8.195814211423274\n",
      "Iteration 15 - grad_norm: 0.7066341720450974, tk: 1.0, x_norm:7.933852579636283\n",
      "Iteration 16 - grad_norm: 0.6604575177290785, tk: 1.0, x_norm:7.43122009726818\n",
      "Iteration 17 - grad_norm: 0.5826199309262907, tk: 1.0, x_norm:6.437288527816165\n",
      "Iteration 18 - grad_norm: 0.4476032375775308, tk: 1.0, x_norm:4.753418123120265\n",
      "Iteration 19 - grad_norm: 0.25469523136586475, tk: 1.0, x_norm:3.3996566592531017\n",
      "Iteration 20 - grad_norm: 0.1624023784433917, tk: 1.0, x_norm:3.109057706783132\n",
      "Iteration 21 - grad_norm: 0.12252316609495272, tk: 1.0, x_norm:2.769853012465931\n",
      "Iteration 22 - grad_norm: 0.11887746277707575, tk: 1.0, x_norm:2.639128245443549\n",
      "Iteration 23 - grad_norm: 0.11761769847326214, tk: 1.0, x_norm:2.640974965816115\n",
      "Iteration 24 - grad_norm: 0.11179377962898816, tk: 1.0, x_norm:2.633385639673899\n",
      "Iteration 25 - grad_norm: 0.10521370560841965, tk: 1.0, x_norm:2.5805073806003365\n",
      "Iteration 26 - grad_norm: 0.093430873880207, tk: 1.0, x_norm:2.379569631411213\n",
      "Iteration 27 - grad_norm: 0.07874431091040637, tk: 1.0, x_norm:1.983465760235292\n",
      "Iteration 28 - grad_norm: 0.05487407236335212, tk: 1.0, x_norm:1.5137339633303477\n",
      "Iteration 29 - grad_norm: 0.025740539294637425, tk: 1.0, x_norm:1.3357820702135237\n",
      "Iteration 30 - grad_norm: 0.021772417936290322, tk: 1.0, x_norm:1.3247401038471125\n",
      "Iteration 31 - grad_norm: 0.021591891727469854, tk: 1.0, x_norm:1.3241942101351645\n",
      "Iteration 32 - grad_norm: 0.021241995283413986, tk: 1.0, x_norm:1.3219478956969133\n",
      "Iteration 33 - grad_norm: 0.020421553165487532, tk: 1.0, x_norm:1.3158963064984424\n",
      "Iteration 34 - grad_norm: 0.018526127259245236, tk: 1.0, x_norm:1.3033145526327292\n",
      "Iteration 35 - grad_norm: 0.014221758992452305, tk: 1.0, x_norm:1.2845955050420301\n",
      "Iteration 36 - grad_norm: 0.007513687541968146, tk: 1.0, x_norm:1.2704285522727037\n",
      "Iteration 37 - grad_norm: 0.0024753840694931454, tk: 1.0, x_norm:1.2669448484360364\n",
      "Iteration 38 - grad_norm: 0.0014100591317749711, tk: 1.0, x_norm:1.2670046744742052\n",
      "Iteration 39 - grad_norm: 0.0013617169613818745, tk: 1.0, x_norm:1.2669960892767391\n",
      "Iteration 40 - grad_norm: 0.0013440931250463428, tk: 1.0, x_norm:1.2669771026439183\n",
      "Iteration 41 - grad_norm: 0.001265066332225253, tk: 1.0, x_norm:1.2669019924652183\n",
      "Iteration 42 - grad_norm: 0.001130385301249208, tk: 1.0, x_norm:1.2667995600520259\n",
      "Iteration 1 - grad_norm: 0.0527351630656891, tk: 1.0, x_norm:2.729398336084919\n",
      "Iteration 2 - grad_norm: 0.01595719471017058, tk: 1.0, x_norm:2.96761694393249\n",
      "Iteration 3 - grad_norm: 0.002967377890316952, tk: 1.0, x_norm:3.051107477708701\n",
      "Iteration 1 - grad_norm: 0.025539238110724533, tk: 1.0, x_norm:5.800511386529072\n",
      "Iteration 2 - grad_norm: 0.004099445092718252, tk: 1.0, x_norm:5.9443506368115235\n",
      "Iteration 1 - grad_norm: 1.61985442529613, tk: 0.25, x_norm:7.248686142245978\n",
      "Iteration 2 - grad_norm: 1.1032793755721633, tk: 0.25, x_norm:8.238174205085691\n",
      "Iteration 3 - grad_norm: 0.2686061024043593, tk: 0.5, x_norm:9.096592053061217\n",
      "Iteration 4 - grad_norm: 0.08089102579133636, tk: 1.0, x_norm:9.02490865483707\n",
      "Iteration 5 - grad_norm: 0.01938802237346195, tk: 1.0, x_norm:9.069513952183936\n",
      "Iteration 6 - grad_norm: 0.012506599816715928, tk: 1.0, x_norm:9.070779331467282\n",
      "Iteration 7 - grad_norm: 0.0034083939785245344, tk: 1.0, x_norm:9.06763833631005\n",
      "Iteration 1 - grad_norm: 8.561561606324654, tk: 0.09, x_norm:9.407186038618459\n",
      "Iteration 2 - grad_norm: 7.667171712506856, tk: 0.0625, x_norm:9.572472597157109\n",
      "Iteration 3 - grad_norm: 5.817514989544245, tk: 0.125, x_norm:9.743518399045424\n",
      "Iteration 4 - grad_norm: 1.7053007173493067, tk: 0.25, x_norm:9.870715818610515\n",
      "Iteration 5 - grad_norm: 0.17031789782790424, tk: 0.5, x_norm:9.891200610563887\n",
      "Iteration 6 - grad_norm: 0.0694802569464798, tk: 0.5, x_norm:9.890228465796923\n",
      "Iteration 7 - grad_norm: 0.0680604084331832, tk: 0.5, x_norm:9.88865587726166\n",
      "Iteration 8 - grad_norm: 0.036664178796409264, tk: 1.0, x_norm:9.889079127230625\n",
      "Iteration 9 - grad_norm: 0.025428426529613364, tk: 0.5, x_norm:9.889739484726197\n",
      "Iteration 10 - grad_norm: 0.024720474440619047, tk: 0.5, x_norm:9.889830829031\n",
      "Iteration 11 - grad_norm: 0.006214959554883538, tk: 0.5, x_norm:9.889569654597187\n",
      "Iteration 12 - grad_norm: 0.008812278142240655, tk: 0.5, x_norm:9.889417815668788\n",
      "Iteration 13 - grad_norm: 0.006463363689824461, tk: 0.5, x_norm:9.889433590932107\n",
      "Iteration 14 - grad_norm: 0.0014101696969070657, tk: 0.5, x_norm:9.889515170613057\n",
      "Iteration 15 - grad_norm: 0.0017610746525555496, tk: 0.5, x_norm:9.8895328465308\n",
      "Iteration 1 - grad_norm: 72.10412982513243, tk: 0.0625, x_norm:9.943609624200246\n",
      "Iteration 2 - grad_norm: 56.58463667069893, tk: 0.0625, x_norm:9.969608173908346\n",
      "Iteration 3 - grad_norm: 35.621491104757574, tk: 0.125, x_norm:9.981354550401711\n",
      "Iteration 4 - grad_norm: 16.098723592862303, tk: 0.25, x_norm:9.986291291949579\n",
      "Iteration 5 - grad_norm: 3.3678988282719704, tk: 0.5, x_norm:9.988299683306403\n",
      "Iteration 6 - grad_norm: 1.567055719802821, tk: 0.25, x_norm:9.988535850348025\n",
      "Iteration 7 - grad_norm: 0.9727740040531525, tk: 1.0, x_norm:9.988845232775233\n",
      "Iteration 8 - grad_norm: 1.0248085518597942, tk: 0.25, x_norm:9.9888508012501\n",
      "Iteration 9 - grad_norm: 0.40014644072365047, tk: 1.0, x_norm:9.988677810099043\n",
      "Iteration 10 - grad_norm: 0.574044586865672, tk: 0.25, x_norm:9.988656174398995\n",
      "Iteration 11 - grad_norm: 0.21117793259384063, tk: 0.5, x_norm:9.988700945980387\n",
      "Iteration 12 - grad_norm: 0.04490270097219823, tk: 0.25, x_norm:9.988721426854914\n",
      "Iteration 13 - grad_norm: 0.007218878003892955, tk: 0.25, x_norm:9.988726079931839\n",
      "Iteration 14 - grad_norm: 0.0025138329989804202, tk: 0.25, x_norm:9.988726656402596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.21920524 / Grad norm: 0.16492101:   0%|          | 2/10000 [04:18<379:18:46, 136.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 2.098293950661454, tk: 1.0, x_norm:9.526489016691775\n",
      "Iteration 2 - grad_norm: 1.399541572026269, tk: 1.0, x_norm:9.292318182360964\n",
      "Iteration 3 - grad_norm: 0.8407593714835254, tk: 1.0, x_norm:8.829359592187693\n",
      "Iteration 4 - grad_norm: 0.5268941812369141, tk: 1.0, x_norm:8.149576945219003\n",
      "Iteration 5 - grad_norm: 0.32672893786662754, tk: 1.0, x_norm:7.06249064047081\n",
      "Iteration 6 - grad_norm: 0.20726332824913696, tk: 1.0, x_norm:5.4783210909967375\n",
      "Iteration 7 - grad_norm: 0.14037084575490064, tk: 1.0, x_norm:3.5447654605630836\n",
      "Iteration 8 - grad_norm: 0.11614675785681412, tk: 1.0, x_norm:2.633815160057773\n",
      "Iteration 9 - grad_norm: 0.09920651484249922, tk: 1.0, x_norm:2.379704941439295\n",
      "Iteration 10 - grad_norm: 0.03425130328439572, tk: 1.0, x_norm:0.8828484477406766\n",
      "Iteration 11 - grad_norm: 0.028535680263074976, tk: 1.0, x_norm:0.7862864402981002\n",
      "Iteration 12 - grad_norm: 0.006134525488445054, tk: 1.0, x_norm:0.6250192223617279\n",
      "Iteration 13 - grad_norm: 0.0020698866938691734, tk: 1.0, x_norm:0.6984711643833289\n",
      "Iteration 1 - grad_norm: 0.10542690348655058, tk: 1.0, x_norm:3.0593844638030574\n",
      "Iteration 2 - grad_norm: 0.059613645854354434, tk: 1.0, x_norm:3.400493653165816\n",
      "Iteration 3 - grad_norm: 0.012056512090598543, tk: 1.0, x_norm:3.745412226426704\n",
      "Iteration 4 - grad_norm: 0.007496418306768014, tk: 1.0, x_norm:3.780960045893312\n",
      "Iteration 5 - grad_norm: 0.0020572199130281786, tk: 1.0, x_norm:3.7991750452620376\n",
      "Iteration 1 - grad_norm: 0.7150691863585331, tk: 0.5, x_norm:5.485581741652929\n",
      "Iteration 2 - grad_norm: 0.11978597742012392, tk: 1.0, x_norm:7.62457354702963\n",
      "Iteration 3 - grad_norm: 0.028863724403552865, tk: 1.0, x_norm:6.99087698894415\n",
      "Iteration 4 - grad_norm: 0.004718938866374187, tk: 1.0, x_norm:7.131834484810945\n",
      "Iteration 1 - grad_norm: 2.73589877800697, tk: 0.125, x_norm:7.812023268461377\n",
      "Iteration 2 - grad_norm: 2.3193903915165293, tk: 0.125, x_norm:8.386901596158353\n",
      "Iteration 3 - grad_norm: 1.4152182235367115, tk: 0.25, x_norm:9.142938134771942\n",
      "Iteration 4 - grad_norm: 0.8397133929240483, tk: 0.25, x_norm:9.351119214456315\n",
      "Iteration 5 - grad_norm: 0.3367688022700657, tk: 1.0, x_norm:9.539742553072427\n",
      "Iteration 6 - grad_norm: 0.04605268766689886, tk: 1.0, x_norm:9.47606679063111\n",
      "Iteration 7 - grad_norm: 0.046205445259977405, tk: 1.0, x_norm:9.477854688958388\n",
      "Iteration 8 - grad_norm: 0.017472193019901324, tk: 1.0, x_norm:9.488666391192668\n",
      "Iteration 9 - grad_norm: 0.014822361817685264, tk: 0.5, x_norm:9.489019291883283\n",
      "Iteration 10 - grad_norm: 0.010781477131875015, tk: 1.0, x_norm:9.482683835124265\n",
      "Iteration 11 - grad_norm: 0.003993761403115313, tk: 1.0, x_norm:9.484796114560359\n",
      "Iteration 12 - grad_norm: 0.001875965371018957, tk: 0.5, x_norm:9.48604990410624\n",
      "Iteration 1 - grad_norm: 15.526470833096417, tk: 0.075, x_norm:9.70780230130378\n",
      "Iteration 2 - grad_norm: 13.23012782461927, tk: 0.0625, x_norm:9.81681339635883\n",
      "Iteration 3 - grad_norm: 9.168057578829144, tk: 0.125, x_norm:9.891977875274067\n",
      "Iteration 4 - grad_norm: 3.429727794503593, tk: 0.25, x_norm:9.932082594495538\n",
      "Iteration 5 - grad_norm: 0.47122649654917076, tk: 0.5, x_norm:9.942580615011474\n",
      "Iteration 6 - grad_norm: 0.2228774383957768, tk: 0.25, x_norm:9.943249232666966\n",
      "Iteration 7 - grad_norm: 0.03757942054508685, tk: 0.5, x_norm:9.943560372941883\n",
      "Iteration 8 - grad_norm: 0.022317537395832414, tk: 0.25, x_norm:9.94351309880834\n",
      "Iteration 9 - grad_norm: 0.016947964226657335, tk: 0.5, x_norm:9.943483431622333\n",
      "Iteration 10 - grad_norm: 0.008361481476908265, tk: 0.5, x_norm:9.943543093646198\n",
      "Iteration 11 - grad_norm: 0.020342530934919084, tk: 0.5, x_norm:9.943607089808213\n",
      "Iteration 12 - grad_norm: 0.008006399606869634, tk: 0.5, x_norm:9.943568900691902\n",
      "Iteration 13 - grad_norm: 0.001974651310231146, tk: 0.25, x_norm:9.943542252481384\n",
      "Iteration 14 - grad_norm: 0.004114122506947852, tk: 0.5, x_norm:9.943529018722366\n",
      "Iteration 15 - grad_norm: 0.0023408334299746727, tk: 0.5, x_norm:9.943533999462213\n",
      "Iteration 1 - grad_norm: 137.15699418983294, tk: 0.0648, x_norm:9.974586765642853\n",
      "Iteration 2 - grad_norm: 102.05541439937139, tk: 0.0625, x_norm:9.986517395674726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.17321519 / Grad norm: 0.06716901:   0%|          | 3/10000 [06:04<340:39:49, 122.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 1.4393415355526982, tk: 1.0, x_norm:9.309930119342328\n",
      "Iteration 2 - grad_norm: 0.958298308849638, tk: 1.0, x_norm:8.967309897861819\n",
      "Iteration 3 - grad_norm: 0.5733042220833567, tk: 1.0, x_norm:8.287456849843128\n",
      "Iteration 4 - grad_norm: 0.3564438647399909, tk: 1.0, x_norm:7.283340096742866\n",
      "Iteration 5 - grad_norm: 0.21668325674607988, tk: 1.0, x_norm:5.665403054251642\n",
      "Iteration 6 - grad_norm: 0.12869361730047166, tk: 1.0, x_norm:3.331887220681918\n",
      "Iteration 7 - grad_norm: 0.09033060998749176, tk: 1.0, x_norm:1.6828492601339768\n",
      "Iteration 8 - grad_norm: 0.07802552534678095, tk: 1.0, x_norm:1.4558705927008473\n",
      "Iteration 9 - grad_norm: 0.0664590000942518, tk: 1.0, x_norm:1.035539426689138\n",
      "Iteration 10 - grad_norm: 0.06825260229174632, tk: 0.4375, x_norm:0.16361785605739368\n",
      "Iteration 11 - grad_norm: 0.07996718283763576, tk: 0.0625, x_norm:0.07115054928690225\n",
      "Iteration 12 - grad_norm: 0.08499427932076346, tk: 0.03125, x_norm:0.028149528658074918\n",
      "Iteration 13 - grad_norm: 0.12224157839229637, tk: 0.03125, x_norm:0.010570696447957087\n",
      "Iteration 14 - grad_norm: 0.1149181303978368, tk: 0.0625, x_norm:0.008775827517734423\n",
      "Iteration 15 - grad_norm: 0.10177870000941387, tk: 0.5, x_norm:0.009941358125159807\n",
      "Iteration 16 - grad_norm: 0.09385009828498657, tk: 0.0625, x_norm:0.008211510941137206\n",
      "Iteration 17 - grad_norm: 0.043487185468975925, tk: 0.25, x_norm:0.01181779372230431\n",
      "Iteration 18 - grad_norm: 0.04963786252041434, tk: 0.5, x_norm:0.009028831128088732\n",
      "Iteration 19 - grad_norm: 0.07023266432987321, tk: 0.0625, x_norm:0.00406894316746934\n",
      "Iteration 20 - grad_norm: 0.0827920078839948, tk: 0.25, x_norm:0.0022856608238017474\n",
      "Iteration 21 - grad_norm: 0.09983058891194889, tk: 0.0078125, x_norm:0.00153024375677072\n",
      "Iteration 22 - grad_norm: 0.10245033094241886, tk: 0.125, x_norm:0.0008794832256094633\n",
      "Iteration 23 - grad_norm: 0.10296531241015838, tk: 0.00390625, x_norm:0.0008527378957393693\n",
      "Iteration 24 - grad_norm: 0.12329248471828184, tk: 0.125, x_norm:0.00036278195937747564\n",
      "Iteration 25 - grad_norm: 0.1212153662960418, tk: 0.00390625, x_norm:0.0003658832073162423\n",
      "Iteration 26 - grad_norm: 0.0776965071851345, tk: 0.03125, x_norm:0.0005027964327802413\n",
      "Iteration 27 - grad_norm: 0.0772100438132037, tk: 0.03125, x_norm:0.000494033804832543\n",
      "Iteration 28 - grad_norm: 0.0711161373518562, tk: 0.015625, x_norm:0.00040177310574750566\n",
      "Iteration 29 - grad_norm: 0.07864728146325288, tk: 0.0625, x_norm:0.0003438248888910009\n",
      "Iteration 30 - grad_norm: 0.08171178543708378, tk: 0.001953125, x_norm:0.00029687748362389893\n",
      "Iteration 31 - grad_norm: 0.08584047948607607, tk: 0.125, x_norm:0.0002350055849871883\n",
      "Iteration 32 - grad_norm: 0.08647036616123556, tk: 0.0009765625, x_norm:0.00021574606504974768\n",
      "Iteration 33 - grad_norm: 0.08148753754233147, tk: 0.0625, x_norm:0.00019353963276205318\n",
      "Iteration 34 - grad_norm: 0.08127242258393894, tk: 0.0009765625, x_norm:0.00019284896757394576\n",
      "Iteration 35 - grad_norm: 0.06412103970009035, tk: 0.25, x_norm:0.00019778333828752808\n",
      "Iteration 36 - grad_norm: 0.06360380938811232, tk: 0.0009765625, x_norm:0.00019791348592382966\n",
      "Iteration 37 - grad_norm: 0.05916596586473207, tk: 0.5, x_norm:0.00015995466381167465\n",
      "Iteration 38 - grad_norm: 0.05967506573113078, tk: 0.0009765625, x_norm:0.00015728251681485937\n",
      "Iteration 39 - grad_norm: 0.06140825024659469, tk: 0.25, x_norm:0.00013731651929618845\n",
      "Iteration 40 - grad_norm: 0.07483953627558909, tk: 0.001953125, x_norm:7.974742608318765e-05\n",
      "Iteration 41 - grad_norm: 0.0751726730704521, tk: 0.0078125, x_norm:7.918341643249106e-05\n",
      "Iteration 42 - grad_norm: 0.07986613710539275, tk: 0.015625, x_norm:4.179192556760719e-05\n",
      "Iteration 43 - grad_norm: 0.07999101027268617, tk: 0.000244140625, x_norm:4.1638955342794135e-05\n",
      "Iteration 44 - grad_norm: 0.09726552584319476, tk: 0.0625, x_norm:2.1046471234306172e-05\n",
      "Iteration 45 - grad_norm: 0.09782331221762473, tk: 0.0001220703125, x_norm:2.0866988818035807e-05\n",
      "Iteration 46 - grad_norm: 0.10099306146354077, tk: 0.0625, x_norm:1.8365027634509638e-05\n",
      "Iteration 47 - grad_norm: 0.10100807801773197, tk: 6.103515625e-05, x_norm:1.8102698608184906e-05\n",
      "Iteration 48 - grad_norm: 0.09328670158511869, tk: 0.03125, x_norm:1.8972173209455636e-05\n",
      "Iteration 49 - grad_norm: 0.07505283785339062, tk: 0.000244140625, x_norm:2.152463568450393e-05\n",
      "Iteration 50 - grad_norm: 0.07514248335503487, tk: 0.00390625, x_norm:2.1443303283363302e-05\n",
      "Iteration 1 - grad_norm: 0.20800342774137381, tk: 1.0, x_norm:4.650228548108572\n",
      "Iteration 2 - grad_norm: 0.23089777040480525, tk: 1.0, x_norm:4.1021216209377345\n",
      "Iteration 3 - grad_norm: 0.22668744963283788, tk: 1.0, x_norm:4.184005995159784\n",
      "Iteration 4 - grad_norm: 0.2264779824291052, tk: 1.0, x_norm:4.188043455524477\n",
      "Iteration 5 - grad_norm: 0.22476469946881933, tk: 1.0, x_norm:4.220086315722245\n",
      "Iteration 6 - grad_norm: 0.22275963816063268, tk: 1.0, x_norm:4.25556813871548\n",
      "Iteration 7 - grad_norm: 0.2187818818191083, tk: 1.0, x_norm:4.3204685146131245\n",
      "Iteration 8 - grad_norm: 0.21226553675867882, tk: 1.0, x_norm:4.414064441662915\n",
      "Iteration 9 - grad_norm: 0.20060785740493395, tk: 1.0, x_norm:4.552118119821917\n",
      "Iteration 10 - grad_norm: 0.18076593314894523, tk: 1.0, x_norm:4.725124522279863\n",
      "Iteration 11 - grad_norm: 0.15018334170567893, tk: 1.0, x_norm:4.873194269877991\n",
      "Iteration 12 - grad_norm: 0.11668181523300132, tk: 1.0, x_norm:4.824176985029016\n",
      "Iteration 13 - grad_norm: 0.09171925438618593, tk: 1.0, x_norm:4.437202627973216\n",
      "Iteration 14 - grad_norm: 0.062218288691164664, tk: 1.0, x_norm:3.9561366364417023\n",
      "Iteration 15 - grad_norm: 0.04263043832152899, tk: 1.0, x_norm:3.7008234820786168\n",
      "Iteration 16 - grad_norm: 0.03933978050512101, tk: 1.0, x_norm:3.6561325754265175\n",
      "Iteration 17 - grad_norm: 0.03918116553407309, tk: 1.0, x_norm:3.6565290894974503\n",
      "Iteration 18 - grad_norm: 0.039172555656675524, tk: 1.0, x_norm:3.6569104774348475\n",
      "Iteration 19 - grad_norm: 0.03912883185629655, tk: 1.0, x_norm:3.6589886896317543\n",
      "Iteration 20 - grad_norm: 0.03907459162768665, tk: 1.0, x_norm:3.6614713342761194\n",
      "Iteration 21 - grad_norm: 0.03896617067080743, tk: 1.0, x_norm:3.666132817256315\n",
      "Iteration 22 - grad_norm: 0.03877885276263633, tk: 1.0, x_norm:3.6734813696666078\n",
      "Iteration 23 - grad_norm: 0.03841883781340098, tk: 1.0, x_norm:3.6859614724946486\n",
      "Iteration 24 - grad_norm: 0.03771804593884772, tk: 1.0, x_norm:3.7066385710186722\n",
      "Iteration 25 - grad_norm: 0.03630665774098273, tk: 1.0, x_norm:3.7405221368179733\n",
      "Iteration 26 - grad_norm: 0.03349329772230724, tk: 1.0, x_norm:3.791342634777447\n",
      "Iteration 27 - grad_norm: 0.028192124333121505, tk: 1.0, x_norm:3.8507547368231196\n",
      "Iteration 28 - grad_norm: 0.019732169446851456, tk: 1.0, x_norm:3.88265094044295\n",
      "Iteration 29 - grad_norm: 0.011224666558161848, tk: 1.0, x_norm:3.8589564383813113\n",
      "Iteration 30 - grad_norm: 0.008080102145003423, tk: 1.0, x_norm:3.8232984282038047\n",
      "Iteration 31 - grad_norm: 0.007679719459798616, tk: 1.0, x_norm:3.8110510197497627\n",
      "Iteration 32 - grad_norm: 0.007631889907714365, tk: 1.0, x_norm:3.8097928023541106\n",
      "Iteration 33 - grad_norm: 0.0076284665047470996, tk: 1.0, x_norm:3.8097667462032465\n",
      "Iteration 34 - grad_norm: 0.0076200241538967395, tk: 1.0, x_norm:3.809712487224611\n",
      "Iteration 35 - grad_norm: 0.007608097633194595, tk: 1.0, x_norm:3.809638551809976\n",
      "Iteration 36 - grad_norm: 0.0075864690452586364, tk: 1.0, x_norm:3.809510014269995\n",
      "Iteration 37 - grad_norm: 0.007549830078023235, tk: 1.0, x_norm:3.809305608986604\n",
      "Iteration 38 - grad_norm: 0.007483661028010622, tk: 1.0, x_norm:3.808968449450372\n",
      "Iteration 39 - grad_norm: 0.007361807977975247, tk: 1.0, x_norm:3.8084203885443793\n",
      "Iteration 40 - grad_norm: 0.007130476325080396, tk: 1.0, x_norm:3.8075372318494227\n",
      "Iteration 41 - grad_norm: 0.006693134332926502, tk: 1.0, x_norm:3.8061902209644507\n",
      "Iteration 42 - grad_norm: 0.005914904256739893, tk: 1.0, x_norm:3.8044593697570854\n",
      "Iteration 43 - grad_norm: 0.004714311349819489, tk: 1.0, x_norm:3.8032508732116033\n",
      "Iteration 44 - grad_norm: 0.003232806122566852, tk: 1.0, x_norm:3.804159735523667\n",
      "Iteration 45 - grad_norm: 0.002127737948854577, tk: 1.0, x_norm:3.806322259269761\n",
      "Iteration 46 - grad_norm: 0.0018216356268514439, tk: 1.0, x_norm:3.8072919871832007\n",
      "Iteration 47 - grad_norm: 0.0017789259392986898, tk: 1.0, x_norm:3.8073780318723527\n",
      "Iteration 48 - grad_norm: 0.00177489414443123, tk: 1.0, x_norm:3.807366764380324\n",
      "Iteration 49 - grad_norm: 0.0017742042407905023, tk: 1.0, x_norm:3.8073635159812103\n",
      "Iteration 50 - grad_norm: 0.0017708172125820393, tk: 1.0, x_norm:3.8073476828629675\n",
      "Iteration 1 - grad_norm: 0.6914573151281697, tk: 0.5, x_norm:6.30042944603489\n",
      "Iteration 2 - grad_norm: 0.2713239372801255, tk: 0.5, x_norm:7.590413155996093\n",
      "Iteration 3 - grad_norm: 0.050837167916874745, tk: 1.0, x_norm:8.0397679998006\n",
      "Iteration 4 - grad_norm: 0.008351512462731948, tk: 1.0, x_norm:7.896435317779114\n",
      "Iteration 5 - grad_norm: 0.002297549793127352, tk: 1.0, x_norm:7.926607063667863\n",
      "Iteration 1 - grad_norm: 3.707930102449646, tk: 0.125, x_norm:8.615419164440654\n",
      "Iteration 2 - grad_norm: 2.9816012790588657, tk: 0.125, x_norm:9.138415053263286\n",
      "Iteration 3 - grad_norm: 2.3750527305121505, tk: 0.125, x_norm:9.368138935987588\n",
      "Iteration 4 - grad_norm: 1.4483655513537324, tk: 0.25, x_norm:9.557077333063587\n",
      "Iteration 5 - grad_norm: 0.3002955335814053, tk: 0.5, x_norm:9.680914211699342\n",
      "Iteration 6 - grad_norm: 0.06334591125676724, tk: 1.0, x_norm:9.688308903514544\n",
      "Iteration 7 - grad_norm: 0.07186123695764736, tk: 0.5, x_norm:9.696159569668998\n",
      "Iteration 8 - grad_norm: 0.030211036464226144, tk: 0.5, x_norm:9.695779540109715\n",
      "Iteration 9 - grad_norm: 0.009377132968386416, tk: 0.5, x_norm:9.6931252623384\n",
      "Iteration 10 - grad_norm: 0.011551959912542936, tk: 0.5, x_norm:9.692740689876567\n",
      "Iteration 11 - grad_norm: 0.004183851502829916, tk: 0.5, x_norm:9.693242902688228\n",
      "Iteration 12 - grad_norm: 0.0010527130958121955, tk: 0.5, x_norm:9.693620473749109\n",
      "Iteration 13 - grad_norm: 0.001299357967962578, tk: 0.5, x_norm:9.693657920789198\n",
      "Iteration 1 - grad_norm: 26.464220749423117, tk: 0.0625, x_norm:9.82501811108251\n",
      "Iteration 2 - grad_norm: 21.953602721092107, tk: 0.0625, x_norm:9.899358347142115\n",
      "Iteration 3 - grad_norm: 14.02759349669905, tk: 0.125, x_norm:9.943110658948465\n",
      "Iteration 4 - grad_norm: 5.217562955331928, tk: 0.25, x_norm:9.961685473569924\n",
      "Iteration 5 - grad_norm: 0.9148674852214294, tk: 0.5, x_norm:9.96680778264646\n",
      "Iteration 6 - grad_norm: 0.129724586627442, tk: 0.25, x_norm:9.967766011968122\n",
      "Iteration 7 - grad_norm: 0.11463987089396961, tk: 1.0, x_norm:9.967712269032976\n",
      "Iteration 8 - grad_norm: 0.07031460161997681, tk: 0.25, x_norm:9.967645063697962\n",
      "Iteration 9 - grad_norm: 0.040192172646969365, tk: 0.5, x_norm:9.967609698771733\n",
      "Iteration 10 - grad_norm: 0.054888889324861245, tk: 0.5, x_norm:9.96759341578579\n",
      "Iteration 11 - grad_norm: 0.023542586404504934, tk: 0.5, x_norm:9.967637477311147\n",
      "Iteration 12 - grad_norm: 0.0355239214437803, tk: 0.5, x_norm:9.967682328753213\n",
      "Iteration 13 - grad_norm: 0.020818623589009547, tk: 0.5, x_norm:9.967660645904306\n",
      "Iteration 14 - grad_norm: 0.019217401321523164, tk: 0.5, x_norm:9.967618716473423\n",
      "Iteration 15 - grad_norm: 0.018596526889303376, tk: 0.5, x_norm:9.967620022685646\n",
      "Iteration 16 - grad_norm: 0.0042210905527919635, tk: 0.5, x_norm:9.967644263829651\n",
      "Iteration 17 - grad_norm: 0.01315569174443798, tk: 0.5, x_norm:9.967657000762992\n",
      "Iteration 18 - grad_norm: 0.005970789815330351, tk: 0.5, x_norm:9.967648391310503\n",
      "Iteration 1 - grad_norm: 250.15308568569685, tk: 0.054, x_norm:9.98287458282157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.15310140 / Grad norm: 0.02741626:   0%|          | 4/10000 [10:54<524:00:05, 188.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 1.083190121011557, tk: 1.0, x_norm:9.08261275614477\n",
      "Iteration 2 - grad_norm: 0.7208138292642399, tk: 1.0, x_norm:8.626383281467824\n",
      "Iteration 3 - grad_norm: 0.430662076597366, tk: 1.0, x_norm:7.719638082453804\n",
      "Iteration 4 - grad_norm: 0.267031889146807, tk: 1.0, x_norm:6.376436262290956\n",
      "Iteration 5 - grad_norm: 0.16120864566622745, tk: 1.0, x_norm:4.198295812616076\n",
      "Iteration 6 - grad_norm: 0.09100443044418517, tk: 1.0, x_norm:1.0949468486764866\n",
      "Iteration 7 - grad_norm: 0.08506483114414676, tk: 0.25, x_norm:0.6642443844554293\n",
      "Iteration 8 - grad_norm: 0.10190348730062619, tk: 1.0, x_norm:0.3264057935473885\n",
      "Iteration 9 - grad_norm: 0.11380079406100164, tk: 0.5, x_norm:0.09042419427552668\n",
      "Iteration 10 - grad_norm: 0.1255403014998628, tk: 0.03125, x_norm:0.031000871465936195\n",
      "Iteration 11 - grad_norm: 0.08682974798397416, tk: 0.25, x_norm:0.03543205903947659\n",
      "Iteration 12 - grad_norm: 0.0839750414933206, tk: 1.0, x_norm:0.027293337003389585\n",
      "Iteration 13 - grad_norm: 0.09079440408235503, tk: 0.25, x_norm:0.022387281419789514\n",
      "Iteration 14 - grad_norm: 0.09220675431376056, tk: 0.25, x_norm:0.008348869710103518\n",
      "Iteration 15 - grad_norm: 0.10292226304002115, tk: 0.125, x_norm:0.006113504274014292\n",
      "Iteration 16 - grad_norm: 0.10831945621129453, tk: 0.03125, x_norm:0.0048226504492948725\n",
      "Iteration 17 - grad_norm: 0.08528944092008921, tk: 0.5, x_norm:0.004506054565968094\n",
      "Iteration 18 - grad_norm: 0.08464066140850854, tk: 0.03125, x_norm:0.00448968536599488\n",
      "Iteration 19 - grad_norm: 0.10192113216160885, tk: 0.25, x_norm:0.0027379810011783265\n",
      "Iteration 20 - grad_norm: 0.10130971177586338, tk: 0.125, x_norm:0.0025034029559563124\n",
      "Iteration 21 - grad_norm: 0.09648740506188039, tk: 0.03125, x_norm:0.002098750890741731\n",
      "Iteration 22 - grad_norm: 0.09531725972567229, tk: 0.5, x_norm:0.0015014380972124574\n",
      "Iteration 23 - grad_norm: 0.09551124655303203, tk: 0.0078125, x_norm:0.0013093941821401625\n",
      "Iteration 24 - grad_norm: 0.0851950149619222, tk: 0.5, x_norm:0.0011396366111844337\n",
      "Iteration 25 - grad_norm: 0.08329120373042571, tk: 0.00390625, x_norm:0.0011013775146467605\n",
      "Iteration 26 - grad_norm: 0.10049401360380558, tk: 0.5, x_norm:0.0005628178982790324\n",
      "Iteration 27 - grad_norm: 0.10184758445364495, tk: 0.001953125, x_norm:0.0005437678282241878\n",
      "Iteration 28 - grad_norm: 0.09821493774859294, tk: 0.5, x_norm:0.0003642987391125084\n",
      "Iteration 29 - grad_norm: 0.09801319463371533, tk: 0.0009765625, x_norm:0.00035557048979037887\n",
      "Iteration 30 - grad_norm: 0.09742909842975007, tk: 0.25, x_norm:0.00021793471949141892\n",
      "Iteration 31 - grad_norm: 0.09764895240117744, tk: 0.0009765625, x_norm:0.00021499450799939462\n",
      "Iteration 32 - grad_norm: 0.08532876173266829, tk: 0.25, x_norm:0.00022249590519330865\n",
      "Iteration 33 - grad_norm: 0.0839365470758107, tk: 0.0009765625, x_norm:0.00022205137667015673\n",
      "Iteration 34 - grad_norm: 0.08742178712733707, tk: 0.125, x_norm:0.00017384404113017957\n",
      "Iteration 35 - grad_norm: 0.08756378126470768, tk: 0.00048828125, x_norm:0.00017212868346134515\n",
      "Iteration 36 - grad_norm: 0.09336360595557601, tk: 0.25, x_norm:0.00013807556139147355\n",
      "Iteration 37 - grad_norm: 0.09356257509751077, tk: 0.00048828125, x_norm:0.0001369556978931594\n",
      "Iteration 38 - grad_norm: 0.10292443493762739, tk: 0.0625, x_norm:0.00011001908119613767\n",
      "Iteration 39 - grad_norm: 0.10335795052357594, tk: 0.00048828125, x_norm:0.00010916708430770953\n",
      "Iteration 40 - grad_norm: 0.10701686981749886, tk: 0.0625, x_norm:7.040927495342369e-05\n",
      "Iteration 41 - grad_norm: 0.1070797979553589, tk: 0.000244140625, x_norm:7.007655476729014e-05\n",
      "Iteration 42 - grad_norm: 0.1096586801190684, tk: 0.03125, x_norm:5.4639054958896046e-05\n",
      "Iteration 43 - grad_norm: 0.10966357741559886, tk: 0.000244140625, x_norm:5.458106156259265e-05\n",
      "Iteration 44 - grad_norm: 0.10599263337427281, tk: 0.125, x_norm:4.4621463627759e-05\n",
      "Iteration 45 - grad_norm: 0.10597923009811794, tk: 0.0001220703125, x_norm:4.453581329488497e-05\n",
      "Iteration 46 - grad_norm: 0.10619131709129438, tk: 0.0625, x_norm:3.878396865489391e-05\n",
      "Iteration 47 - grad_norm: 0.10618672820031952, tk: 0.0001220703125, x_norm:3.871867049781209e-05\n",
      "Iteration 48 - grad_norm: 0.08488517104093395, tk: 0.25, x_norm:3.9300609686405745e-05\n",
      "Iteration 49 - grad_norm: 0.08283453899045283, tk: 0.0001220703125, x_norm:3.907016196318238e-05\n",
      "Iteration 50 - grad_norm: 0.07896172701365736, tk: 0.0625, x_norm:3.4524995654524603e-05\n",
      "Iteration 1 - grad_norm: 0.10166503411580743, tk: 1.0, x_norm:2.8229698313298393\n",
      "Iteration 2 - grad_norm: 0.10506182356631638, tk: 1.0, x_norm:2.597329277281805\n",
      "Iteration 3 - grad_norm: 0.10468567215953271, tk: 1.0, x_norm:2.6173986285744584\n",
      "Iteration 4 - grad_norm: 0.10461425724922639, tk: 1.0, x_norm:2.62110049985645\n",
      "Iteration 5 - grad_norm: 0.10417359945249381, tk: 1.0, x_norm:2.6431833419633066\n",
      "Iteration 6 - grad_norm: 0.10363385503057909, tk: 1.0, x_norm:2.6686673577671853\n",
      "Iteration 7 - grad_norm: 0.10256294670589815, tk: 1.0, x_norm:2.7151427565127784\n",
      "Iteration 8 - grad_norm: 0.1007627472126101, tk: 1.0, x_norm:2.7841446501860365\n",
      "Iteration 9 - grad_norm: 0.09746989184387794, tk: 1.0, x_norm:2.890396705897788\n",
      "Iteration 10 - grad_norm: 0.09165272941808335, tk: 1.0, x_norm:3.038037419446792\n",
      "Iteration 11 - grad_norm: 0.08183338594288816, tk: 1.0, x_norm:3.211156905928863\n",
      "Iteration 12 - grad_norm: 0.06725265238505408, tk: 1.0, x_norm:3.3263380971968104\n",
      "Iteration 13 - grad_norm: 0.04899540450623292, tk: 1.0, x_norm:3.240726260630452\n",
      "Iteration 14 - grad_norm: 0.032780198627567474, tk: 1.0, x_norm:2.984906534768203\n",
      "Iteration 15 - grad_norm: 0.024527857756976853, tk: 1.0, x_norm:2.800434728141217\n",
      "Iteration 16 - grad_norm: 0.02200345048713213, tk: 1.0, x_norm:2.7334764762324975\n",
      "Iteration 17 - grad_norm: 0.021860957282422176, tk: 1.0, x_norm:2.730495010943027\n",
      "Iteration 18 - grad_norm: 0.02185662905933779, tk: 1.2, x_norm:2.730589868872939\n",
      "Iteration 19 - grad_norm: 0.02182283733918265, tk: 1.0, x_norm:2.7314399320977367\n",
      "Iteration 20 - grad_norm: 0.021778096424000016, tk: 1.0, x_norm:2.732484814480213\n",
      "Iteration 21 - grad_norm: 0.021676460621629406, tk: 1.0, x_norm:2.734632365418698\n",
      "Iteration 22 - grad_norm: 0.021476980296855977, tk: 1.0, x_norm:2.738376320490584\n",
      "Iteration 23 - grad_norm: 0.021038832248333816, tk: 1.0, x_norm:2.7456363428501853\n",
      "Iteration 24 - grad_norm: 0.02009052723272904, tk: 1.0, x_norm:2.759492402480326\n",
      "Iteration 25 - grad_norm: 0.01810012508768325, tk: 1.0, x_norm:2.7849918144500547\n",
      "Iteration 26 - grad_norm: 0.014494118347338153, tk: 1.0, x_norm:2.8238910103470842\n",
      "Iteration 27 - grad_norm: 0.009662279798590181, tk: 1.0, x_norm:2.861319602715695\n",
      "Iteration 28 - grad_norm: 0.00580876461723031, tk: 1.0, x_norm:2.8716713520224744\n",
      "Iteration 29 - grad_norm: 0.004466050959281316, tk: 1.0, x_norm:2.862698766258902\n",
      "Iteration 30 - grad_norm: 0.004251861941794059, tk: 1.0, x_norm:2.857035658651869\n",
      "Iteration 31 - grad_norm: 0.0042247223266615175, tk: 1.0, x_norm:2.856024955434429\n",
      "Iteration 32 - grad_norm: 0.004222550037890362, tk: 1.0, x_norm:2.855946389674008\n",
      "Iteration 33 - grad_norm: 0.004216355388989084, tk: 1.0, x_norm:2.855731707187269\n",
      "Iteration 34 - grad_norm: 0.0042075709715738655, tk: 1.0, x_norm:2.8554484112810767\n",
      "Iteration 35 - grad_norm: 0.004190565460361289, tk: 1.0, x_norm:2.8549541556553217\n",
      "Iteration 36 - grad_norm: 0.0041598668087094, tk: 1.0, x_norm:2.8541871299269825\n",
      "Iteration 37 - grad_norm: 0.004099525733025462, tk: 1.0, x_norm:2.8529624661052018\n",
      "Iteration 38 - grad_norm: 0.003978302327652993, tk: 1.0, x_norm:2.851100010876872\n",
      "Iteration 39 - grad_norm: 0.0037305874130097874, tk: 1.0, x_norm:2.8484777537205894\n",
      "Iteration 40 - grad_norm: 0.0032514084897880017, tk: 1.0, x_norm:2.8455714153468223\n",
      "Iteration 41 - grad_norm: 0.00247560685871991, tk: 1.0, x_norm:2.844491448727968\n",
      "Iteration 42 - grad_norm: 0.00159272137365486, tk: 1.0, x_norm:2.8483728742486076\n",
      "Iteration 1 - grad_norm: 0.9406369604257435, tk: 0.25, x_norm:4.478792301079099\n",
      "Iteration 2 - grad_norm: 0.6811679049875404, tk: 0.25, x_norm:5.898113843486062\n",
      "Iteration 3 - grad_norm: 0.23588371419678042, tk: 0.5, x_norm:7.823120012413292\n",
      "Iteration 4 - grad_norm: 0.07330351642588037, tk: 1.0, x_norm:8.278403669167195\n",
      "Iteration 5 - grad_norm: 0.021895716226297886, tk: 1.0, x_norm:8.033301391101135\n",
      "Iteration 6 - grad_norm: 0.0049290284539924316, tk: 1.0, x_norm:8.096527768424751\n",
      "Iteration 1 - grad_norm: 3.9562427410411036, tk: 0.125, x_norm:8.937652374737512\n",
      "Iteration 2 - grad_norm: 2.8094209548927056, tk: 0.125, x_norm:9.459951737005227\n",
      "Iteration 3 - grad_norm: 2.072117668996084, tk: 0.125, x_norm:9.594215236563084\n",
      "Iteration 4 - grad_norm: 0.1523533295387066, tk: 0.5, x_norm:9.764156410856087\n",
      "Iteration 5 - grad_norm: 0.09933820613650378, tk: 0.25, x_norm:9.760095216828294\n",
      "Iteration 6 - grad_norm: 0.057949170934377514, tk: 0.5, x_norm:9.756078906569442\n",
      "Iteration 7 - grad_norm: 0.015166862452248334, tk: 0.5, x_norm:9.758489648569524\n",
      "Iteration 8 - grad_norm: 0.019955251614940717, tk: 0.5, x_norm:9.75979104045706\n",
      "Iteration 9 - grad_norm: 0.007560853374677595, tk: 0.5, x_norm:9.759190692501226\n",
      "Iteration 10 - grad_norm: 0.003522959678812714, tk: 0.5, x_norm:9.758779223498559\n",
      "Iteration 11 - grad_norm: 0.0023809549532542414, tk: 0.5, x_norm:9.758831553542203\n",
      "Iteration 12 - grad_norm: 0.0010462630342885264, tk: 0.5, x_norm:9.75889977065527\n",
      "Iteration 1 - grad_norm: 33.228873979210675, tk: 0.0625, x_norm:9.872797278851682\n",
      "Iteration 2 - grad_norm: 26.562421962294177, tk: 0.0625, x_norm:9.930077283764232\n",
      "Iteration 3 - grad_norm: 16.830032668270775, tk: 0.125, x_norm:9.95804273567106\n",
      "Iteration 4 - grad_norm: 7.208469576847486, tk: 0.25, x_norm:9.969943616880515\n",
      "Iteration 5 - grad_norm: 0.9442578386239974, tk: 0.5, x_norm:9.974617124028365\n",
      "Iteration 6 - grad_norm: 1.851922405402049, tk: 0.25, x_norm:9.97624465803079\n",
      "Iteration 7 - grad_norm: 0.8003245425180847, tk: 0.5, x_norm:9.97563472465679\n",
      "Iteration 8 - grad_norm: 0.8254125672706557, tk: 0.5, x_norm:9.974636410860091\n",
      "Iteration 9 - grad_norm: 0.5519282408608296, tk: 0.5, x_norm:9.974815493344812\n",
      "Iteration 10 - grad_norm: 0.11872486727732626, tk: 0.5, x_norm:9.975232641355834\n",
      "Iteration 11 - grad_norm: 0.34144775484461537, tk: 0.5, x_norm:9.975366961624273\n",
      "Iteration 12 - grad_norm: 0.16431870676432808, tk: 0.5, x_norm:9.975256828244618\n",
      "Iteration 13 - grad_norm: 0.097185186866246, tk: 0.5, x_norm:9.975097452387985\n",
      "Iteration 14 - grad_norm: 0.09225297464685091, tk: 0.25, x_norm:9.97510085137007\n",
      "Iteration 15 - grad_norm: 0.028814699036747216, tk: 0.5, x_norm:9.975140742247955\n",
      "Iteration 16 - grad_norm: 0.002776178969336495, tk: 0.25, x_norm:9.975159278571235\n",
      "Iteration 17 - grad_norm: 0.009479111024284054, tk: 0.25, x_norm:9.975164176073527\n",
      "Iteration 18 - grad_norm: 0.006206115949313271, tk: 0.5, x_norm:9.97516201405173\n",
      "Iteration 1 - grad_norm: 325.23505757951636, tk: 0.054, x_norm:9.986999201979733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.14704785 / Grad norm: 0.01106030:   0%|          | 5/10000 [15:58<639:22:01, 230.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 1.1326235983713813, tk: 1.0, x_norm:9.121026096419655\n",
      "Iteration 2 - grad_norm: 0.7540470405884389, tk: 1.0, x_norm:8.683122877307794\n",
      "Iteration 3 - grad_norm: 0.45098483826303815, tk: 1.0, x_norm:7.810980637327997\n",
      "Iteration 4 - grad_norm: 0.28019958557743097, tk: 1.0, x_norm:6.513416203309818\n",
      "Iteration 5 - grad_norm: 0.17018141204418052, tk: 1.0, x_norm:4.38612156030248\n",
      "Iteration 6 - grad_norm: 0.10108207046468434, tk: 1.0, x_norm:1.1244893825620323\n",
      "Iteration 7 - grad_norm: 0.09541841244254609, tk: 0.25, x_norm:0.2799549664630795\n",
      "Iteration 8 - grad_norm: 0.09580212341318725, tk: 1.0, x_norm:0.06737041947334788\n",
      "Iteration 9 - grad_norm: 0.10701983647663872, tk: 0.125, x_norm:0.04329887028333995\n",
      "Iteration 10 - grad_norm: 0.11314007740625641, tk: 0.125, x_norm:0.020106675971924018\n",
      "Iteration 11 - grad_norm: 0.09231861937476223, tk: 0.5, x_norm:0.011092821659578067\n",
      "Iteration 12 - grad_norm: 0.08791096880362552, tk: 0.0625, x_norm:0.010794582341382223\n",
      "Iteration 13 - grad_norm: 0.0861721937699314, tk: 0.25, x_norm:0.007104867563014549\n",
      "Iteration 14 - grad_norm: 0.09268384510974961, tk: 0.25, x_norm:0.004752798220032315\n",
      "Iteration 15 - grad_norm: 0.10182122950224029, tk: 0.015625, x_norm:0.0030030552102289533\n",
      "Iteration 16 - grad_norm: 0.11130040596841263, tk: 0.25, x_norm:0.001514257028683974\n",
      "Iteration 17 - grad_norm: 0.11411404721515418, tk: 0.00390625, x_norm:0.0013153772903791393\n",
      "Iteration 18 - grad_norm: 0.10942486013305197, tk: 0.25, x_norm:0.00080797862418261\n",
      "Iteration 19 - grad_norm: 0.10908788746478827, tk: 0.00390625, x_norm:0.0008009425289484669\n",
      "Iteration 20 - grad_norm: 0.09029023303099919, tk: 0.25, x_norm:0.000911863372094861\n",
      "Iteration 21 - grad_norm: 0.09018594684814651, tk: 0.03125, x_norm:0.0008978856703842806\n",
      "Iteration 22 - grad_norm: 0.0899179997546979, tk: 0.03125, x_norm:0.0007375313973166386\n",
      "Iteration 23 - grad_norm: 0.08892037081914138, tk: 0.125, x_norm:0.0006200684857353058\n",
      "Iteration 24 - grad_norm: 0.08964644467776745, tk: 0.00390625, x_norm:0.000589191984032026\n",
      "Iteration 25 - grad_norm: 0.09573676086333277, tk: 0.25, x_norm:0.0003357934616315833\n",
      "Iteration 26 - grad_norm: 0.09825516990369065, tk: 0.0009765625, x_norm:0.0003016825031403497\n",
      "Iteration 27 - grad_norm: 0.10734748129238088, tk: 0.25, x_norm:0.00017768986865559502\n",
      "Iteration 28 - grad_norm: 0.11041756787184123, tk: 0.00048828125, x_norm:0.00015469900954135014\n",
      "Iteration 29 - grad_norm: 0.10508226461245591, tk: 0.25, x_norm:0.0001352503667933019\n",
      "Iteration 30 - grad_norm: 0.0988126327347202, tk: 0.0009765625, x_norm:0.0001333606034739924\n",
      "Iteration 31 - grad_norm: 0.09877898053385899, tk: 0.125, x_norm:0.00012411333930887881\n",
      "Iteration 32 - grad_norm: 0.09858880316595542, tk: 0.0009765625, x_norm:0.00010402245983500127\n",
      "Iteration 33 - grad_norm: 0.09769643820038901, tk: 0.0625, x_norm:9.977955641679721e-05\n",
      "Iteration 34 - grad_norm: 0.09103346320680306, tk: 0.001953125, x_norm:7.585678823142593e-05\n",
      "Iteration 35 - grad_norm: 0.09127560399379177, tk: 0.015625, x_norm:7.543734625515958e-05\n",
      "Iteration 36 - grad_norm: 0.09239195517602038, tk: 0.00390625, x_norm:5.724097170489235e-05\n",
      "Iteration 37 - grad_norm: 0.0924852006311755, tk: 0.00390625, x_norm:5.6868956595608774e-05\n",
      "Iteration 38 - grad_norm: 0.09756130497661425, tk: 0.0078125, x_norm:3.129977884553299e-05\n",
      "Iteration 39 - grad_norm: 0.09756920390732024, tk: 0.000244140625, x_norm:3.127994255331057e-05\n",
      "Iteration 40 - grad_norm: 0.09894595231821271, tk: 0.0625, x_norm:2.3711126676537387e-05\n",
      "Iteration 41 - grad_norm: 0.09896177154909466, tk: 0.0001220703125, x_norm:2.369169649184222e-05\n",
      "Iteration 42 - grad_norm: 0.10355771665492494, tk: 0.03125, x_norm:1.851751219428171e-05\n",
      "Iteration 43 - grad_norm: 0.10361819461614263, tk: 6.103515625e-05, x_norm:1.848039205652965e-05\n",
      "Iteration 44 - grad_norm: 0.10291158532769966, tk: 0.125, x_norm:1.4317129373684448e-05\n",
      "Iteration 45 - grad_norm: 0.1025980314028835, tk: 6.103515625e-05, x_norm:1.4000629146862225e-05\n",
      "Iteration 46 - grad_norm: 0.1040106440820199, tk: 0.03125, x_norm:1.1585295254517406e-05\n",
      "Iteration 47 - grad_norm: 0.10524491543961279, tk: 6.103515625e-05, x_norm:1.0763521510474188e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function value: 0.14704785 / Grad norm: 0.01106030:   0%|          | 5/10000 [18:12<606:31:52, 218.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0e5a5fa6f563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdecrease_gamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mcontracting_newton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecrease_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mcontracting_newton\u001b[1;34m(params, c_0, decrease_gamma, history)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;31m# g_k -= H_k.dot(x_k)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[0mv_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize_quadratic_on_l2_ball\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'R'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inner_eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mx_k\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma_k\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv_k\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mminimize_quadratic_on_l2_ball\u001b[1;34m(g, H, R, inner_eps, params, x_k, gamma_k)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mminimize_quadratic_on_l2_ball\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_eps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m     x_opt_ipm_damped, t_ipm_damped, duality_gaps_damped, fvals_damped = barrier_method(t_init=params['t_init'], f=lambda x:f_int(x,params,x_k,gamma_k),\n\u001b[0m\u001b[0;32m    243\u001b[0m                             \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_int_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_int_hess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                             \u001b[0mphi_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi_hessian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mbarrier_method\u001b[1;34m(t_init, f, f_grad, f_hessian, phi, phi_grad, phi_hessian, A, b, x0, D, num_constraints, mu, method, epsilon, maxIter)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mt_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         xt,num_newton_step, fvals = solve_central(objective=f,\n\u001b[0m\u001b[0;32m     97\u001b[0m                                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                 \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphi_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36msolve_central\u001b[1;34m(objective, f, f_grad, f_hessian, x0, D, method, epsilon, max_iter)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdamped_newton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;31m#* 阻尼牛顿\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdamped_newton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mbfgs\u001b[1;34m(objective, f, f_grad, f_hessian, x0, D, alpha, beta, epsilon, max_iter)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mgrad_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mdk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmat_k\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mgrad_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwolfe_condition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_cnt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mwolfe_condition\u001b[1;34m(f, f_grad, xk, pk, D, c1, c2, multiplier, t0, tmax)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mxk_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mti\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfval_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk_next\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfval_next\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mfval_cur\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mti\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_cur\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfval_next\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mfval_cur\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtprev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         xt,num_newton_step, fvals = solve_central(objective=f,\n\u001b[1;32m---> 97\u001b[1;33m                                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                                 \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphi_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                                 \u001b[0mf_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphi_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mminimize_quadratic_on_l2_ball\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_eps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m     x_opt_ipm_damped, t_ipm_damped, duality_gaps_damped, fvals_damped = barrier_method(t_init=params['t_init'], f=lambda x:f_int(x,params,x_k,gamma_k),\n\u001b[0m\u001b[0;32m    243\u001b[0m                             \u001b[0mf_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_int_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mf_int_hess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                             \u001b[0mphi_hessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphi_hessian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mf_int\u001b[1;34m(x, params, x_k, gamma_k)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexp_bAx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp_bAx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf_int_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f4089af0910>\u001b[0m in \u001b[0;36mf_hessian\u001b[1;34m(x, params)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mAx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mexp_bAx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mAx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexp_bAx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp_bAx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgamma_k\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "b, A = read_data('w8a')\n",
    "# b, A = read_data('ijcnn1.test')\n",
    "# b, A = read_data('a9a.test')\n",
    "# b, A = read_data('CINA.test')\n",
    "m,n = A.shape\n",
    "print(m,n)\n",
    "# b=np.expand_dims(b, axis=1)\n",
    "params=dict()\n",
    "params['A']=-np.multiply(b,A.T).T\n",
    "params['A_o']=A\n",
    "params['b']=b\n",
    "# print(params['A'][0,:])\n",
    "print(np.sum(A==params['A']))\n",
    "params['x_0']=np.zeros(n)+0.005\n",
    "params['t_init']=1\n",
    "c_0 = 3.0\n",
    "params['R']=10\n",
    "params['inner_eps']=1e-6\n",
    "params['outer_eps']=1e-4\n",
    "params['n_iters']=10000\n",
    "params['lambda']=0.01\n",
    "history=None\n",
    "decrease_gamma=True\n",
    "contracting_newton(params, c_0, decrease_gamma, history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "734ab24b5d337aa3083f37141e45635523032b38e37867a0b0460a6855b4b5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
