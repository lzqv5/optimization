{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from time import time\n",
    "from scipy.interpolate import interp1d\n",
    "from libsvm.svmutil import svm_read_problem # https://blog.csdn.net/u013630349/article/details/47323883\n",
    "\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single(seq, xlabel='Iteration', ylabel='Gradient Norm', title=''):\n",
    "    plt.figure()\n",
    "    iterations = np.arange(len(seq))+1\n",
    "    plt.semilogy(iterations,seq)\n",
    "    plt.xticks(iterations)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "def plot_multi_seqs(seqs, xlabel='Iteration', ylabel='Gradient Norm', title='', xtick_step = 50):\n",
    "    plt.figure(figsize=(16,8), dpi=150)\n",
    "    maxLen = 0\n",
    "    for seq in seqs:\n",
    "        iterations = seq.index\n",
    "        if iterations.size > maxLen:\n",
    "            maxLen = iterations.size\n",
    "        plt.semilogy(iterations, seq, label=seq.name)\n",
    "    plt.xticks(np.arange(stop=maxLen,step=xtick_step)+1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45546, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path, rm_zeros=True):\n",
    "    b, A = svm_read_problem(path)\n",
    "    rows = len(b)   # 矩阵行数, i.e. sample 数\n",
    "    cols = max([max(row.keys()) if len(row)>0 else 0 for row in A])  # 矩阵列数, i.e. feature 数\n",
    "    b = np.array(b)\n",
    "    A_np = np.zeros((rows,cols))\n",
    "    for r in range(rows):\n",
    "        for c in A[r].keys():\n",
    "            # MatLab 是 1-index, python 则是 0-index\n",
    "            A_np[r,c-1] = A[r][c]\n",
    "    if rm_zeros:\n",
    "        # 清除全 0 features\n",
    "        effective_row_ids = []\n",
    "        for idx, row in enumerate(A_np):\n",
    "            if np.sum(np.abs(row)) > 1e-3:\n",
    "                effective_row_ids.append(idx)\n",
    "        return b[effective_row_ids], A_np[effective_row_ids]\n",
    "    return b, A_np\n",
    "\n",
    "b, A = read_data('w8a')\n",
    "# b, A = read_data('w8a',False)\n",
    "# b, A = read_data('gisette_scale')\n",
    "m,n = A.shape\n",
    "m,n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令 $g_i(x)=\\exp(b_i x^\\top a_i), i=1,2,...,m$\n",
    "\n",
    "所以可以得到目标函数为:\n",
    "$$\n",
    "f(x)=\\frac{1}{m}\\sum_{i=1}^{m}\\log\\left( 1+ \\frac{1}{g_i(x)}\\right) + \\frac{1}{100m}\\left\\|x\\right\\|^2\n",
    "$$\n",
    "进而可以得到梯度 $\\nabla f(x)$ 和 Hessian矩阵 $\\nabla^2 f(x)$ 的形式:\n",
    "$$\n",
    "\\nabla f(x) = \\frac{1}{m}\\sum_{i=1}^{m}\\left[ -b_i a_i (1+g_i(x))^{-1} \\right] + \\frac{1}{50m}x\n",
    "$$\n",
    "$$\n",
    "\\nabla^2 f(x) =  \\frac{1}{m}\\sum_{i=1}^{m}\\left( b_i^2 \\frac{g_i(x)}{(1+g_i(x))^2}a_i a_i^\\top \\right) + \\frac{1}{50m}I\n",
    "$$\n",
    "\n",
    "此处函数内的 $a_i,b_i$ 和数据本身相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 100\n",
    "\n",
    "def f(x):\n",
    "    bAx = b*(A@x)\n",
    "    exp_mbAx = np.exp(-bAx)\n",
    "    log1p_exp = np.log(1+exp_mbAx)\n",
    "    overflow_idxs = np.where(exp_mbAx==float('inf'))\n",
    "    log1p_exp[overflow_idxs] = -bAx[overflow_idxs]\n",
    "    return log1p_exp.mean() + 1/(lamda*m)* x.T@x\n",
    "\n",
    "def f_grad(x):\n",
    "    return np.ones(m)@(np.expand_dims((-b)/(1+np.exp(b*(A@x))), axis=1)*A)/m + 2/(lamda*m)*x\n",
    "\n",
    "def f_hessian(x):\n",
    "    Ax = A@x\n",
    "    exp_bAx = np.exp(b*Ax)\n",
    "    return (A.T @ (np.expand_dims(b*b*exp_bAx/(1+exp_bAx)**2, axis=1)*A) )/m + 2/(lamda*m)*np.eye(x.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Search (Armijo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Armijo rule \n",
    "def armijo_search(f, f_grad, xk, t_hat, alpha, beta, D, isNewton=False, dk=None):\n",
    "    if isNewton:\n",
    "        assert dk is not None\n",
    "    tk = t_hat*1\n",
    "    grad = f_grad(xk)\n",
    "    while True:\n",
    "        if isNewton:\n",
    "            if np.linalg.norm(xk+tk*dk,ord=2)<=D/2 and f(xk+tk*dk) <= f(xk) + alpha*tk*grad.T@dk:\n",
    "                break\n",
    "        else:\n",
    "            # if np.linalg.norm(xk-tk*grad,ord=2)<=D/2 and f(xk-tk*grad) <= f(xk)-alpha*tk*grad.T@grad:\n",
    "            if f(xk-tk*grad) <= f(xk)-alpha*tk*grad.T@grad:\n",
    "                break\n",
    "        tk *= beta\n",
    "    return tk\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton (Interior Point Methods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logarithmic barrier:\n",
    "$$\n",
    "\\phi(x)=-\\log(-g(x)),\\quad g(x)=\\left\\|x\\right\\|_2 - D/2\n",
    "$$\n",
    "$$\n",
    "\\nabla g(x) = x/\\left\\|x\\right\\|_2, \\quad \\nabla^2 g(x)= \\left\\|x\\right\\|_2^{-1}I-\\left\\|x\\right\\|_2^{-3}xx^\\top\n",
    "$$\n",
    "gradient and hessian:\n",
    "$$\n",
    "\\nabla \\phi(x) = \\frac{1}{-g(x)}\\nabla g(x)=\\frac{x/\\left\\|x\\right\\|_2}{D/2-\\left\\|x\\right\\|_2}=\\frac{x}{\\left\\|x\\right\\|_2(D/2-\\left\\|x\\right\\|_2)}\n",
    "$$\n",
    "$$\n",
    "\\nabla^2\\phi(x)=\\frac{1}{g(x)^2}\\nabla g(x)\\nabla g(x)^\\top + \\frac{1}{-g(x)}\\nabla^2 g(x) = \\frac{1}{\\left\\|x\\right\\|_2(D/2-\\left\\|x\\right\\|_2)}I+\\frac{2\\left\\|x\\right\\|_2-D/2}{\\left\\|x\\right\\|_2^3(D/2-\\left\\|x\\right\\|_2)^2}xx^\\top\n",
    "$$\n",
    "central path - for $t>0$:\n",
    "$$\n",
    "\\min_x tf(x)+\\phi(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x,D):\n",
    "    return -np.log(D/2-np.linalg.norm(x,ord=2))\n",
    "\n",
    "def phi_grad(x,D):\n",
    "    x_norm = np.linalg.norm(x,ord=2)\n",
    "    return x/(x_norm*(D/2-x_norm))\n",
    "\n",
    "def phi_hessian(x,D):\n",
    "    x_norm = np.linalg.norm(x,ord=2)\n",
    "    xxT = np.matmul(x[:,None],x[None,:])    # x * xT\n",
    "    return np.eye(x.size)/(x_norm*(D/2-x_norm)) + (2*x_norm-D/2)/(x_norm**3 * (D/2-x_norm)**2)*xxT\n",
    "\n",
    "\n",
    "#* 外部迭代\n",
    "def barrier_method(t_init, f, f_grad, f_hessian, phi, phi_grad, phi_hessian, A, b, x0, D, num_constraints, mu,\n",
    "                        method='newton', epsilon=1e-6, maxIter=20):\n",
    "    xt = x0\n",
    "    t = t_init\n",
    "    duality_gaps = []\n",
    "    func_val_record = []\n",
    "    t_s = time()\n",
    "    for i in range(maxIter):\n",
    "        xt,num_newton_step, fvals = solve_central(objective=f,\n",
    "                                f=lambda x:t*f(x)+phi(x,D), \n",
    "                                f_grad=lambda x:t*f_grad(x)+phi_grad(x,D), \n",
    "                                f_hessian=lambda x:t*f_hessian(x)+phi_hessian(x,D),\n",
    "                                x0=xt, D=D, method=method, epsilon=epsilon*1e3)\n",
    "        duality_gaps.extend([num_constraints/t]*num_newton_step)\n",
    "        func_val_record.extend(fvals)\n",
    "        if num_constraints/t < epsilon:\n",
    "            break\n",
    "        t *= mu\n",
    "    t_e = time()\n",
    "    return xt, t_e-t_s, np.array(duality_gaps), np.array(func_val_record)\n",
    "\n",
    "def solve_central(objective, f, f_grad, f_hessian, x0, D, method='newton', epsilon=1e-6, max_iter=50):\n",
    "    if method == 'newton':\n",
    "        return damped_newton(objective, f=f, f_grad=f_grad, f_hessian=f_hessian, x0=x0, D=D, epsilon=epsilon, max_iter=max_iter)\n",
    "    if method == 'bfgs':\n",
    "        return bfgs(objective, f=f, f_grad=f_grad, f_hessian=f_hessian, x0=x0, D=D, epsilon=epsilon, max_iter=max_iter)\n",
    "\n",
    "\n",
    "#* 阻尼牛顿\n",
    "def damped_newton(objective, f, f_grad, f_hessian, x0, D, epsilon=1e-6, max_iter=50):\n",
    "    xk = x0\n",
    "    iter_cnt = 0\n",
    "    fvals = []\n",
    "    for idx in range(max_iter):\n",
    "        iter_cnt += 1\n",
    "        fvals.append(objective(xk))\n",
    "        grad = f_grad(xk)\n",
    "        hessian = f_hessian(xk)\n",
    "        dk = -np.linalg.inv(hessian)@grad\n",
    "        decrement = (-grad@dk)**0.5\n",
    "        if decrement**2/2 <= epsilon:\n",
    "            print('** End The Loop - Iter Cnt.:',iter_cnt, 'Decrement:',decrement, 'fval:',f(xk))\n",
    "            return xk, iter_cnt, fvals\n",
    "        tk = armijo_search(f, f_grad, xk, t_hat=1, alpha=0.1, beta=0.5, D=D, isNewton=True, dk=dk)\n",
    "        print('Iter Cnt.:',iter_cnt, 'Decrement:',decrement, 'fval:',f(xk), 'tk:',tk)\n",
    "        xk += tk*dk\n",
    "    return xk, iter_cnt, fvals\n",
    "\n",
    "#* 拟牛顿\n",
    "def bfgs(objective, f, f_grad, f_hessian, x0, D, alpha=0.1, beta=0.5, epsilon=1e-6, max_iter=500):\n",
    "    xk = x0\n",
    "    hessian = f_hessian(x0)\n",
    "    mat_k = np.linalg.inv(hessian) \n",
    "    # mat_k = np.eye(n) \n",
    "    iter_cnt = 0\n",
    "    fvals = []\n",
    "    for idx in range(max_iter):\n",
    "        iter_cnt += 1\n",
    "        grad_k = f_grad(xk)\n",
    "        dk = -mat_k@grad_k \n",
    "        tk = wolfe_condition(f, f_grad, xk, dk, D, c1=1e-4, c2=0.9)\n",
    "        if tk<0:\n",
    "            return xk, iter_cnt-1, fvals\n",
    "        fvals.append(objective(xk))\n",
    "        sk = tk*dk\n",
    "        xk_next = xk + sk\n",
    "        grad_next = f_grad(xk_next)\n",
    "        # if np.linalg.norm(grad_next, ord=2) <= epsilon:\n",
    "        if np.linalg.norm(grad_next, ord=2) <= epsilon or np.linalg.norm(xk_next)>=D/2-1e-2:\n",
    "            return xk_next, iter_cnt, fvals\n",
    "        else:\n",
    "            print(f'Iteration {iter_cnt} - grad_norm:',np.linalg.norm(grad_next),\"tk:\",tk, \"x_norm:\",np.linalg.norm(xk_next))\n",
    "        # mat_k = np.linalg.inv(f_hessian(xk_next))\n",
    "        mat_k = update_approximation_bfgs(mat=mat_k, sk=sk, yk=grad_next-grad_k)\n",
    "        xk = xk_next\n",
    "    return xk_next, iter_cnt, fvals\n",
    "        \n",
    "def update_approximation_bfgs(mat, sk, yk, mat_type='H'):\n",
    "    rhok = 1/(yk@sk)\n",
    "    if mat_type == 'H':\n",
    "        Hkyk = mat@yk\n",
    "        ykTHkyk = yk@Hkyk\n",
    "        HkykskT = Hkyk[:,None]@sk[None,:]\n",
    "        skskT = sk[:,None]@sk[None,:]\n",
    "        mat_new = mat + rhok*((rhok*ykTHkyk+1)*skskT - HkykskT - HkykskT.T)\n",
    "    else:\n",
    "        Bksk = mat@sk\n",
    "        skTBksk = sk@Bksk\n",
    "        mat_new = mat - Bksk[:,None]@Bksk[None,:]/skTBksk + yk[:,None]@yk[None,:]*rhok\n",
    "    return mat_new\n",
    "\n",
    "#* 拟牛顿方法 - 选择步长\n",
    "def wolfe_condition(f, f_grad, xk, pk, D, c1=1e-4, c2=0.9, multiplier=1.2, t0=0, tmax=2):\n",
    "    ### \n",
    "    while (np.linalg.norm(xk+tmax*pk)>=D/2):\n",
    "        tmax /= 2\n",
    "        # print('tmax:',tmax)\n",
    "        if tmax<1e-6:\n",
    "            # print('too small stepsize')\n",
    "            return -1\n",
    "    ###\n",
    "    ti = tmax/2\n",
    "    tprev = t0\n",
    "    i = 1\n",
    "    fval_cur = f(xk)\n",
    "    grad_cur = f_grad(xk)\n",
    "    while True:\n",
    "        xk_next = xk+ti*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if (fval_next > fval_cur + c1*ti*grad_cur@pk) or (fval_next >= fval_cur and i>1):\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, tprev, ti)\n",
    "        grad_next = f_grad(xk_next)\n",
    "        grad_next_T_pk = grad_next@pk\n",
    "        if np.abs(grad_next_T_pk) <= -c2*grad_cur@pk:\n",
    "            return ti\n",
    "        if grad_next_T_pk >= 0:\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, ti, tprev)\n",
    "        tprev = ti\n",
    "        ti = tprev*multiplier\n",
    "        i += 1\n",
    "\n",
    "def zoom(f, f_grad, xk, pk, fval, grad, c1, c2, t_lo, t_hi):\n",
    "    while True:\n",
    "        # print(f\"t_lo: {t_lo}\\tt_hi: {t_hi}\")\n",
    "        t = (t_lo+t_hi)/2\n",
    "        xk_next = xk + t*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if fval_next > fval + c1*t*grad@pk or fval_next >= f(xk+t_lo*pk):\n",
    "            t_hi = t\n",
    "        else:\n",
    "            grad_next = f_grad(xk_next)\n",
    "            grad_next_T_pk = grad_next@pk\n",
    "            if np.abs(grad_next_T_pk) <= -c2*grad@pk:\n",
    "                return t\n",
    "            if grad_next_T_pk*(t_hi-t_lo)>=0:\n",
    "                t_hi = t_lo\n",
    "            t_lo = t\n",
    "        if t_lo == t_hi: # 死循环\n",
    "            return -1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter Cnt.: 1 Decrement: 0.8181937689877108 fval: -4.796761076282368 tk: 1\n",
      "Iter Cnt.: 2 Decrement: 0.4311602474045324 fval: -5.18588281281812 tk: 1\n",
      "Iter Cnt.: 3 Decrement: 0.2882439952273807 fval: -5.304571735466875 tk: 1\n",
      "Iter Cnt.: 4 Decrement: 0.18771922818407033 fval: -5.357852773746775 tk: 1\n",
      "Iter Cnt.: 5 Decrement: 0.10403976891343639 fval: -5.379962815361623 tk: 1\n",
      "** End The Loop - Iter Cnt.: 6 Decrement: 0.03879841180285344 fval: -5.3864071146154515\n",
      "Iter Cnt.: 1 Decrement: 0.552576817172851 fval: -4.494618883305269 tk: 1\n",
      "Iter Cnt.: 2 Decrement: 0.3032427619530524 fval: -4.683557104688924 tk: 1\n",
      "Iter Cnt.: 3 Decrement: 0.13385553549217197 fval: -4.739144001937335 tk: 1\n",
      "** End The Loop - Iter Cnt.: 4 Decrement: 0.0417298329977352 fval: -4.749429753978426\n",
      "Iter Cnt.: 1 Decrement: 0.8241597281835419 fval: 1.0528272981041509 tk: 1\n",
      "Iter Cnt.: 2 Decrement: 0.4526555362093539 fval: 0.6826557809398608 tk: 0.5\n",
      "Iter Cnt.: 3 Decrement: 0.3058627241285678 fval: 0.6322861351049278 tk: 1\n",
      "Iter Cnt.: 4 Decrement: 0.2984579382174994 fval: 0.6062355142680387 tk: 0.25\n",
      "Iter Cnt.: 5 Decrement: 0.05185995772211527 fval: 0.5909893491014566 tk: 1\n",
      "** End The Loop - Iter Cnt.: 6 Decrement: 0.005571944590462866 fval: 0.5895714081084868\n",
      "Iter Cnt.: 1 Decrement: 0.5914788435090075 fval: 53.26093189489525 tk: 1\n",
      "Iter Cnt.: 2 Decrement: 0.10672446547287587 fval: 53.07207374714243 tk: 1\n",
      "** End The Loop - Iter Cnt.: 3 Decrement: 0.009515077681089622 fval: 53.06611040338589\n",
      "Iter Cnt.: 1 Decrement: 0.26061371790612853 fval: 577.6046721097124 tk: 1\n",
      "** End The Loop - Iter Cnt.: 2 Decrement: 0.011628791277949305 fval: 577.5699557649748\n",
      "Iter Cnt.: 1 Decrement: 0.10989601783377453 fval: 5822.580163152638 tk: 1\n",
      "** End The Loop - Iter Cnt.: 2 Decrement: 0.0009161470676423608 fval: 5822.574097008393\n",
      "** End The Loop - Iter Cnt.: 1 Decrement: 0.027446630067200807 fval: 58272.61303086815\n",
      "Iter Cnt.: 1 Decrement: 0.0947956606002755 fval: 582773.0023694658 tk: 1\n",
      "** End The Loop - Iter Cnt.: 2 Decrement: 5.224842105506943e-05 fval: 582772.9978750565\n",
      "最小值: 0.058278\t耗时: 3.369968s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "# D=20\n",
    "t_init = 1\n",
    "x0 = np.zeros(n)+0.005\n",
    "x_opt_ipm_damped, t_ipm_damped, duality_gaps_damped, fvals_damped = barrier_method(t_init=t_init, f=f, f_grad=f_grad, f_hessian=f_hessian, phi=phi, phi_grad=phi_grad, phi_hessian=phi_hessian, \n",
    "                A=A, b=b, x0=x0, D=500, num_constraints=1, method='newton', mu=10, epsilon=1e-6, maxIter=20)\n",
    "print(f'最小值: {f(x_opt_ipm_damped):>2f}\\t耗时: {t_ipm_damped:>2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 0.18720366392344154 tk: 1.0 x_norm: 1.3860693376355462\n",
      "Iteration 2 - grad_norm: 0.11175047388506208 tk: 1.0 x_norm: 1.9102213805470094\n",
      "Iteration 3 - grad_norm: 0.054347672400478636 tk: 1.0 x_norm: 2.8714839671840364\n",
      "Iteration 4 - grad_norm: 0.02856011084310909 tk: 1.0 x_norm: 3.9409963644117165\n",
      "Iteration 5 - grad_norm: 0.014770414944270489 tk: 1.0 x_norm: 5.208520985073693\n",
      "Iteration 6 - grad_norm: 0.008798965053306108 tk: 1.0 x_norm: 6.41936802895115\n",
      "Iteration 7 - grad_norm: 0.006720070227670148 tk: 1.0 x_norm: 7.415931535105996\n",
      "Iteration 8 - grad_norm: 0.006042372163109145 tk: 1.0 x_norm: 8.123375964740042\n",
      "Iteration 9 - grad_norm: 0.005620455731044583 tk: 1.0 x_norm: 8.683340851021015\n",
      "Iteration 10 - grad_norm: 0.005166600011131825 tk: 1.0 x_norm: 9.238726329789905\n",
      "Iteration 11 - grad_norm: 0.00463657976625041 tk: 1.0 x_norm: 9.678971862835711\n",
      "Iteration 12 - grad_norm: 0.0038900089061983108 tk: 1.0 x_norm: 9.795779066848262\n",
      "Iteration 13 - grad_norm: 0.003795057906650085 tk: 1.0 x_norm: 9.514672903884364\n",
      "Iteration 14 - grad_norm: 0.003846771605006583 tk: 1.0 x_norm: 9.180096937764114\n",
      "Iteration 15 - grad_norm: 0.0035013663629551513 tk: 1.0 x_norm: 8.739559217640476\n",
      "Iteration 16 - grad_norm: 0.0027997934171730926 tk: 1.0 x_norm: 8.638288141321889\n",
      "Iteration 17 - grad_norm: 0.002491113104558627 tk: 1.0 x_norm: 8.924525863224698\n",
      "Iteration 18 - grad_norm: 0.0022419765444360645 tk: 1.0 x_norm: 9.406205776660927\n",
      "Iteration 19 - grad_norm: 0.001908975875360254 tk: 1.0 x_norm: 9.671368083564756\n",
      "Iteration 20 - grad_norm: 0.0015506211041319642 tk: 1.0 x_norm: 9.834363894554059\n",
      "Iteration 21 - grad_norm: 0.0010223148158932328 tk: 1.0 x_norm: 9.971881163665643\n",
      "Iteration 1 - grad_norm: 0.016832724582396073 tk: 1.0 x_norm: 18.909958049202487\n",
      "Iteration 2 - grad_norm: 0.007665356785575178 tk: 1.0 x_norm: 23.65208238136139\n",
      "Iteration 3 - grad_norm: 0.0028788055469952984 tk: 1.0 x_norm: 28.308952081986213\n",
      "Iteration 4 - grad_norm: 0.0016073695144896603 tk: 1.0 x_norm: 30.472215667679652\n",
      "Iteration 5 - grad_norm: 0.0013849588245972118 tk: 1.0 x_norm: 31.30073497580074\n",
      "Iteration 6 - grad_norm: 0.0011262188159659934 tk: 1.0 x_norm: 31.617747004458437\n",
      "Iteration 1 - grad_norm: 0.055133678296803074 tk: 1.0 x_norm: 47.97795271307219\n",
      "Iteration 2 - grad_norm: 0.04364441158681248 tk: 1.0 x_norm: 53.46765824656404\n",
      "Iteration 3 - grad_norm: 0.013775146574397214 tk: 1.0 x_norm: 54.81544462687728\n",
      "Iteration 4 - grad_norm: 0.007040520522461845 tk: 1.0 x_norm: 56.12189126495801\n",
      "Iteration 5 - grad_norm: 0.0033098655004107588 tk: 1.0 x_norm: 56.889300109506635\n",
      "Iteration 6 - grad_norm: 0.001659591767936226 tk: 1.0 x_norm: 57.15615714288619\n",
      "Iteration 7 - grad_norm: 0.0015704816448218971 tk: 1.0 x_norm: 57.17733407030642\n",
      "Iteration 1 - grad_norm: 0.017950803944960687 tk: 1.0 x_norm: 64.58621121648251\n",
      "Iteration 2 - grad_norm: 0.00783677182835105 tk: 1.0 x_norm: 65.58647939043537\n",
      "Iteration 3 - grad_norm: 0.0018684337618932619 tk: 1.0 x_norm: 65.89800066368063\n",
      "Iteration 1 - grad_norm: 0.005454518038044822 tk: 1.0 x_norm: 67.1070838097371\n",
      "最小值: 0.058278\t耗时: 6.800518s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "# D=20\n",
    "t_init = 1\n",
    "x0 = np.zeros(n)+0.005\n",
    "x_opt_ipm_bfgs, t_ipm_bfgs, duality_gaps_bfgs, fvals_bfgs = barrier_method(t_init=t_init, f=f, f_grad=f_grad, f_hessian=f_hessian, phi=phi, phi_grad=phi_grad, phi_hessian=phi_hessian, \n",
    "                A=A, b=b, x0=x0, D=500, num_constraints=1, method='bfgs', mu=10, epsilon=1e-6, maxIter=20)\n",
    "print(f'最小值: {f(x_opt_ipm_bfgs):>2f}\\t耗时: {t_ipm_bfgs:>2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.565065812283219e-07"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_opt_ipm_bfgs)-f(x_opt_ipm_damped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure damped newton w/o constraints (D=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2077272/1792977231.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  exp_mbAx = np.exp(-bAx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_norm: 27.02283865218793 tk: 4.76837158203125e-07 x_norm: 0.8324634570299232\n",
      "grad_norm: 3.832027404717997 tk: 6.103515625e-05 x_norm: 7.925982391967798\n",
      "grad_norm: 5.440620584930539 tk: 0.0078125 x_norm: 54.730256541485794\n",
      "grad_norm: 2.681866285112544 tk: 0.03125 x_norm: 63.63377043483731\n",
      "grad_norm: 3.313336576783995 tk: 0.0625 x_norm: 82.46445930968093\n",
      "grad_norm: 2.1213332556568445 tk: 0.125 x_norm: 80.47618311495715\n",
      "grad_norm: 1.9850605438914468 tk: 0.25 x_norm: 90.08652498968195\n",
      "grad_norm: 1.3869801709695355 tk: 0.25 x_norm: 99.643349337717\n",
      "grad_norm: 1.1152780867135654 tk: 0.25 x_norm: 85.78640144871804\n",
      "grad_norm: 0.6516324083908752 tk: 0.5 x_norm: 95.22359837165743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2077272/1792977231.py:17: RuntimeWarning: overflow encountered in square\n",
      "  return (A.T @ (np.expand_dims(b*b*exp_bAx/(1+exp_bAx)**2, axis=1)*A) )/m + 2/(lamda*m)*np.eye(x.size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_norm: 0.44834087699060793 tk: 0.5 x_norm: 104.87453268620342\n",
      "grad_norm: 0.3214719685463408 tk: 0.5 x_norm: 83.02461482125388\n",
      "grad_norm: 0.2735461834919538 tk: 0.25 x_norm: 80.48477255151704\n",
      "grad_norm: 0.21961446281426147 tk: 0.25 x_norm: 68.0737411374543\n",
      "grad_norm: 0.08436563827210725 tk: 1 x_norm: 28.464941017827833\n",
      "grad_norm: 0.03235747086244582 tk: 1 x_norm: 41.99626687844988\n",
      "grad_norm: 0.012363367218947992 tk: 1 x_norm: 17.5100975608777\n",
      "grad_norm: 0.0047075999173327035 tk: 1 x_norm: 14.787796495808722\n",
      "grad_norm: 0.0018314542286906165 tk: 1 x_norm: 13.009387128759888\n",
      "grad_norm: 0.0007356807921560666 tk: 1 x_norm: 11.716237021349626\n",
      "grad_norm: 0.00030976054227505354 tk: 1 x_norm: 10.784310656536404\n",
      "grad_norm: 0.00013915688970614633 tk: 1 x_norm: 10.170475862154213\n",
      "grad_norm: 7.065474620639843e-05 tk: 1 x_norm: 9.770065573589214\n",
      "grad_norm: 2.9736287249017688e-05 tk: 1 x_norm: 9.574119260497067\n",
      "grad_norm: 8.531059090914392e-06 tk: 1 x_norm: 9.57024661495238\n",
      "grad_norm: 1.5252948898417579e-06 tk: 1 x_norm: 9.598945884937972\n",
      "grad_norm: 8.491076896495788e-08 tk: 1 x_norm: 9.606190496231651\n",
      "最小值: 0.000190\t耗时: 85.602795s\n"
     ]
    }
   ],
   "source": [
    "#* pure阻尼牛顿\n",
    "def pure_damped_newton(f, f_grad, f_hessian, x0, D, epsilon=1e-6, max_iters=100):\n",
    "    func_val_record = []\n",
    "    grad_norm_record = []\n",
    "    xk = x0\n",
    "    t_s = time()\n",
    "    # for idx in trange(max_iters):\n",
    "    for idx in range(max_iters):\n",
    "        grad = f_grad(xk)\n",
    "        # print(np.linalg.norm(grad))\n",
    "        hessian = f_hessian(xk)\n",
    "        # dk = -np.linalg.pinv(hessian)@grad\n",
    "        dk = -np.linalg.inv(hessian)@grad\n",
    "        tk = armijo_search(f, f_grad, xk, t_hat=1, alpha=0.1, beta=0.5, D=D, isNewton=True, dk=dk)\n",
    "        xk_next = xk + tk*dk\n",
    "        func_val_record.append(f(xk_next))\n",
    "        # grad_norm_record.append(np.linalg.norm(f_grad(xk_next),ord=2))\n",
    "        grad_next = np.linalg.norm(f_grad(xk_next),ord=2)\n",
    "        grad_norm_record.append(grad_next)\n",
    "        # termination criteria\n",
    "        if grad_next<=epsilon:\n",
    "            break\n",
    "        else:\n",
    "            print('grad_norm:',grad_next,\"tk:\",tk, \"x_norm:\",np.linalg.norm(xk_next))\n",
    "        xk = xk_next\n",
    "    t_e = time()\n",
    "    return xk_next, np.asarray(func_val_record), np.asarray(grad_norm_record), t_e-t_s\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "# init_x = np.zeros(n)+0.5\n",
    "init_x = np.zeros(n)+0.005\n",
    "\n",
    "# D=500 半径足够大，本质上是无约束\n",
    "x_opt_damped, _, _, t_damped = pure_damped_newton(f=f, f_grad=f_grad, f_hessian=f_hessian, x0=init_x, D=500, epsilon=1e-8, max_iters=50)\n",
    "print(f'最小值: {f(x_opt_damped):>2f}\\t耗时: {t_damped:>2f}s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure quasi newton w/o constraints (D=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 0.18017720987362976 tk: 1.0 x_norm: 11.165278301280532\n",
      "Iteration 2 - grad_norm: 0.11332750219773532 tk: 1.0 x_norm: 15.135338733342227\n",
      "Iteration 3 - grad_norm: 0.0588887609960591 tk: 1.0 x_norm: 21.533528580786278\n",
      "Iteration 4 - grad_norm: 0.03370457453496356 tk: 1.0 x_norm: 28.007182606015498\n",
      "Iteration 5 - grad_norm: 0.018882899036194684 tk: 1.0 x_norm: 35.87806759864599\n",
      "Iteration 6 - grad_norm: 0.010866841039356227 tk: 1.0 x_norm: 44.44864398760293\n",
      "Iteration 7 - grad_norm: 0.006490045202947455 tk: 1.0 x_norm: 53.327850892309826\n",
      "Iteration 8 - grad_norm: 0.004300271670796263 tk: 1.0 x_norm: 61.34159830918189\n",
      "Iteration 9 - grad_norm: 0.0033286798522448226 tk: 1.0 x_norm: 67.46185331330766\n",
      "Iteration 10 - grad_norm: 0.0029130781154975767 tk: 1.0 x_norm: 71.52202526197196\n",
      "Iteration 11 - grad_norm: 0.0026709621915537753 tk: 1.0 x_norm: 74.55496886554727\n",
      "Iteration 12 - grad_norm: 0.0024711794717667194 tk: 1.0 x_norm: 77.01301640920776\n",
      "Iteration 13 - grad_norm: 0.0022580722379469745 tk: 1.0 x_norm: 77.61081896031442\n",
      "Iteration 14 - grad_norm: 0.0019611305006011176 tk: 1.0 x_norm: 74.87516342684319\n",
      "Iteration 15 - grad_norm: 0.001815015621707459 tk: 1.0 x_norm: 69.7557515224829\n",
      "Iteration 16 - grad_norm: 0.0019063176832953225 tk: 1.0 x_norm: 64.42711104360677\n",
      "Iteration 17 - grad_norm: 0.0018763345697549107 tk: 1.0 x_norm: 61.94319651661975\n",
      "Iteration 18 - grad_norm: 0.0017208657496739978 tk: 1.0 x_norm: 61.616147745504676\n",
      "Iteration 19 - grad_norm: 0.001386078159312382 tk: 1.0 x_norm: 62.89409076494536\n",
      "Iteration 20 - grad_norm: 0.0011635196375529271 tk: 1.0 x_norm: 65.10222137327875\n",
      "Iteration 21 - grad_norm: 0.0010389973610115406 tk: 1.0 x_norm: 67.10553071463985\n",
      "Iteration 22 - grad_norm: 0.0009588307486315539 tk: 1.0 x_norm: 68.51480003888817\n",
      "Iteration 23 - grad_norm: 0.0008895651592463788 tk: 1.0 x_norm: 69.19359689165321\n",
      "Iteration 24 - grad_norm: 0.0008186623859286282 tk: 1.0 x_norm: 68.98677847889323\n",
      "Iteration 25 - grad_norm: 0.0007557517882971561 tk: 1.0 x_norm: 67.95288736419309\n",
      "Iteration 26 - grad_norm: 0.0007121398766398684 tk: 1.0 x_norm: 66.85210538322347\n",
      "Iteration 27 - grad_norm: 0.0006733727089787008 tk: 1.0 x_norm: 66.27575818961851\n",
      "Iteration 28 - grad_norm: 0.0006374724502729076 tk: 1.0 x_norm: 66.21837447067597\n",
      "Iteration 29 - grad_norm: 0.0006106643068685932 tk: 1.0 x_norm: 66.6604945874876\n",
      "Iteration 30 - grad_norm: 0.0005820467844169081 tk: 1.0 x_norm: 67.3594410816704\n",
      "Iteration 31 - grad_norm: 0.0005408033541224585 tk: 1.0 x_norm: 67.9537369898761\n",
      "Iteration 32 - grad_norm: 0.000496140086031849 tk: 1.0 x_norm: 68.26786077567732\n",
      "Iteration 33 - grad_norm: 0.00047270438200389266 tk: 1.0 x_norm: 68.15910372645311\n",
      "Iteration 34 - grad_norm: 0.00048387612497401426 tk: 1.0 x_norm: 67.58414815459903\n",
      "Iteration 35 - grad_norm: 0.0004949857444074271 tk: 1.0 x_norm: 66.8415994894382\n",
      "Iteration 36 - grad_norm: 0.0004830587107062824 tk: 1.0 x_norm: 66.2013133539269\n",
      "Iteration 37 - grad_norm: 0.00045357425432472284 tk: 1.0 x_norm: 65.76826874617754\n",
      "Iteration 38 - grad_norm: 0.00042773931332716576 tk: 1.0 x_norm: 65.70252926200358\n",
      "Iteration 39 - grad_norm: 0.0004186094679425927 tk: 1.0 x_norm: 65.99003723825544\n",
      "Iteration 40 - grad_norm: 0.00041343858748386523 tk: 1.0 x_norm: 66.35426551052815\n",
      "Iteration 41 - grad_norm: 0.0004022697535017772 tk: 1.0 x_norm: 66.55788455813193\n",
      "Iteration 42 - grad_norm: 0.00038180143129293043 tk: 1.0 x_norm: 66.47462204646745\n",
      "Iteration 43 - grad_norm: 0.0003565784345057724 tk: 1.0 x_norm: 66.05187093719077\n",
      "Iteration 44 - grad_norm: 0.00034110264322729904 tk: 1.0 x_norm: 65.52533249507341\n",
      "Iteration 45 - grad_norm: 0.0003426694582493172 tk: 1.0 x_norm: 65.08158142810443\n",
      "Iteration 46 - grad_norm: 0.0003684732813880633 tk: 1.0 x_norm: 64.85402514554046\n",
      "Iteration 47 - grad_norm: 0.00040412997955255087 tk: 1.0 x_norm: 64.88151195654284\n",
      "Iteration 48 - grad_norm: 0.00042213333317814175 tk: 1.0 x_norm: 65.14413768046361\n",
      "Iteration 49 - grad_norm: 0.00040287318633914587 tk: 1.0 x_norm: 65.44287737547742\n",
      "Iteration 50 - grad_norm: 0.0003666344055566153 tk: 1.0 x_norm: 65.62255594844466\n",
      "Iteration 51 - grad_norm: 0.00033128011177081985 tk: 1.0 x_norm: 65.62718310996702\n",
      "Iteration 52 - grad_norm: 0.00030289212583518816 tk: 1.0 x_norm: 65.45906510939469\n",
      "Iteration 53 - grad_norm: 0.00028180582867004176 tk: 1.0 x_norm: 65.20941241610925\n",
      "Iteration 54 - grad_norm: 0.00026894200452419345 tk: 1.0 x_norm: 65.00170960963544\n",
      "Iteration 55 - grad_norm: 0.00027781629094515296 tk: 1.0 x_norm: 64.95305740063749\n",
      "Iteration 56 - grad_norm: 0.0002967967177199764 tk: 1.0 x_norm: 65.02718560645997\n",
      "Iteration 57 - grad_norm: 0.00031281611824603167 tk: 1.0 x_norm: 65.17260428963303\n",
      "Iteration 58 - grad_norm: 0.00030969535289721744 tk: 1.0 x_norm: 65.28106275216449\n",
      "Iteration 59 - grad_norm: 0.00029124217321438797 tk: 1.0 x_norm: 65.28609374185417\n",
      "Iteration 60 - grad_norm: 0.0002709063017345956 tk: 1.0 x_norm: 65.1845188321373\n",
      "Iteration 61 - grad_norm: 0.00025693696164495684 tk: 1.0 x_norm: 65.03668367200459\n",
      "Iteration 62 - grad_norm: 0.00025143613901653023 tk: 1.0 x_norm: 64.90198743368664\n",
      "Iteration 63 - grad_norm: 0.00025720154144584034 tk: 1.0 x_norm: 64.8564570444718\n",
      "Iteration 64 - grad_norm: 0.0002721671706573624 tk: 1.0 x_norm: 64.95854253365678\n",
      "Iteration 65 - grad_norm: 0.00028435146169293856 tk: 1.0 x_norm: 65.16643596355497\n",
      "Iteration 66 - grad_norm: 0.00028290856587634823 tk: 1.0 x_norm: 65.3946086088038\n",
      "Iteration 67 - grad_norm: 0.00026580143747703433 tk: 1.0 x_norm: 65.53589472783098\n",
      "Iteration 68 - grad_norm: 0.00024012384964942608 tk: 1.0 x_norm: 65.53277574317818\n",
      "Iteration 69 - grad_norm: 0.00021757052632545988 tk: 1.0 x_norm: 65.37316764075369\n",
      "Iteration 70 - grad_norm: 0.0002061136369235042 tk: 1.0 x_norm: 65.13992753734306\n",
      "Iteration 71 - grad_norm: 0.000208200724182249 tk: 1.0 x_norm: 64.92712022591911\n",
      "Iteration 72 - grad_norm: 0.00022739214701570309 tk: 1.0 x_norm: 64.82108164299814\n",
      "Iteration 73 - grad_norm: 0.00025293698658785074 tk: 1.0 x_norm: 64.84510423938877\n",
      "Iteration 74 - grad_norm: 0.00027095668768186104 tk: 1.0 x_norm: 64.9423115506049\n",
      "Iteration 75 - grad_norm: 0.000271633251287112 tk: 1.0 x_norm: 65.03832823818831\n",
      "Iteration 76 - grad_norm: 0.0002553217488570924 tk: 1.0 x_norm: 65.06149701335129\n",
      "Iteration 77 - grad_norm: 0.00023183958088104114 tk: 1.0 x_norm: 64.9922623512936\n",
      "Iteration 78 - grad_norm: 0.00021097538776471464 tk: 1.0 x_norm: 64.87230843398723\n",
      "Iteration 79 - grad_norm: 0.000197107215238403 tk: 1.0 x_norm: 64.77244395746897\n",
      "Iteration 80 - grad_norm: 0.00019210223526650816 tk: 1.0 x_norm: 64.76963373929584\n",
      "Iteration 81 - grad_norm: 0.00019972055112803814 tk: 1.0 x_norm: 64.92306844224667\n",
      "Iteration 82 - grad_norm: 0.0002142167737529503 tk: 1.0 x_norm: 65.175004040805\n",
      "Iteration 83 - grad_norm: 0.00022406160302169143 tk: 1.0 x_norm: 65.42888040984931\n",
      "Iteration 84 - grad_norm: 0.00022310761362967336 tk: 1.0 x_norm: 65.6168710303731\n",
      "Iteration 85 - grad_norm: 0.00021105414748008206 tk: 1.0 x_norm: 65.69602435511749\n",
      "Iteration 86 - grad_norm: 0.00019287647373586965 tk: 1.0 x_norm: 65.66360448702385\n",
      "Iteration 87 - grad_norm: 0.00017796377473094094 tk: 1.0 x_norm: 65.5666691885147\n",
      "Iteration 88 - grad_norm: 0.00017126011443343236 tk: 1.0 x_norm: 65.50175304465651\n",
      "Iteration 89 - grad_norm: 0.00017215574140614422 tk: 1.0 x_norm: 65.53715261627754\n",
      "Iteration 90 - grad_norm: 0.00018277664694540675 tk: 1.0 x_norm: 65.68685059428456\n",
      "Iteration 91 - grad_norm: 0.00019827392391654535 tk: 1.0 x_norm: 65.90339209759593\n",
      "Iteration 92 - grad_norm: 0.00020989597979334277 tk: 1.0 x_norm: 66.13717475352544\n",
      "Iteration 93 - grad_norm: 0.00020955073909552577 tk: 1.0 x_norm: 66.29896973244166\n",
      "Iteration 94 - grad_norm: 0.0001973481278317285 tk: 1.0 x_norm: 66.31094391087183\n",
      "Iteration 95 - grad_norm: 0.000181264649539806 tk: 1.0 x_norm: 66.21111011098965\n",
      "Iteration 96 - grad_norm: 0.00016752563817009302 tk: 1.0 x_norm: 66.08169960137703\n",
      "Iteration 97 - grad_norm: 0.0001603997096920889 tk: 1.0 x_norm: 66.01364465386418\n",
      "Iteration 98 - grad_norm: 0.00016003278184955204 tk: 1.0 x_norm: 66.09693483692287\n",
      "Iteration 99 - grad_norm: 0.00016381451401201923 tk: 1.0 x_norm: 66.36677253938824\n",
      "Iteration 100 - grad_norm: 0.0001687814390948431 tk: 1.0 x_norm: 66.72061283286416\n",
      "Iteration 101 - grad_norm: 0.000173365873496343 tk: 1.0 x_norm: 67.05128008227862\n",
      "Iteration 102 - grad_norm: 0.0001775727859368129 tk: 1.0 x_norm: 67.28823194891385\n",
      "Iteration 103 - grad_norm: 0.0001805264634599637 tk: 1.0 x_norm: 67.34314446442674\n",
      "Iteration 104 - grad_norm: 0.00017867831009058305 tk: 1.0 x_norm: 67.20722814670413\n",
      "Iteration 105 - grad_norm: 0.00017039854943053852 tk: 1.0 x_norm: 66.97191825608355\n",
      "Iteration 106 - grad_norm: 0.00015945260180363937 tk: 1.0 x_norm: 66.75968437120379\n",
      "Iteration 107 - grad_norm: 0.0001505236267637822 tk: 1.0 x_norm: 66.64894059909466\n",
      "Iteration 108 - grad_norm: 0.0001468766374922231 tk: 1.0 x_norm: 66.71410581943866\n",
      "Iteration 109 - grad_norm: 0.0001453885181544397 tk: 1.0 x_norm: 66.93248852727353\n",
      "Iteration 110 - grad_norm: 0.00014195981830332103 tk: 1.0 x_norm: 67.18138011875712\n",
      "Iteration 111 - grad_norm: 0.00013763134239294766 tk: 1.0 x_norm: 67.34483620621606\n",
      "Iteration 112 - grad_norm: 0.000135115769356685 tk: 1.0 x_norm: 67.34182921580653\n",
      "Iteration 113 - grad_norm: 0.00013375848075421317 tk: 1.0 x_norm: 67.1772212318783\n",
      "Iteration 114 - grad_norm: 0.0001306595143205679 tk: 1.0 x_norm: 66.94785099106718\n",
      "Iteration 115 - grad_norm: 0.00012595780911159017 tk: 1.0 x_norm: 66.78731438671275\n",
      "Iteration 116 - grad_norm: 0.00012293008870478453 tk: 1.0 x_norm: 66.78700894681047\n",
      "Iteration 117 - grad_norm: 0.00012274225107835086 tk: 1.0 x_norm: 66.9732308878052\n",
      "Iteration 118 - grad_norm: 0.00012170517688985373 tk: 1.0 x_norm: 67.25023958962603\n",
      "Iteration 119 - grad_norm: 0.0001176972107543347 tk: 1.0 x_norm: 67.51083874275601\n",
      "Iteration 120 - grad_norm: 0.00011173988097871811 tk: 1.0 x_norm: 67.67862433600132\n",
      "Iteration 121 - grad_norm: 0.00010610875292069336 tk: 1.0 x_norm: 67.69274707104832\n",
      "Iteration 122 - grad_norm: 0.00010196793766571017 tk: 1.0 x_norm: 67.55101650273728\n",
      "BFGS - 迭代次数: 123\t最小值: 0.058483\t耗时: 15.513544s\n"
     ]
    }
   ],
   "source": [
    "#* 拟牛顿\n",
    "def quasi_newton_bfgs(f, f_grad, f_hessian, x0, mat_type='H', alpha=0.1, beta=0.5, epsilon=1e-6, max_iters=500):\n",
    "    assert mat_type in ['H','B']\n",
    "    xk = x0\n",
    "    hessian = f_hessian(x0)\n",
    "    mat_k = np.linalg.inv(hessian) if mat_type=='H' else hessian\n",
    "    iter_cnt = 0\n",
    "    t_s = time()\n",
    "    for idx in range(max_iters):\n",
    "        iter_cnt += 1\n",
    "        grad_k = f_grad(xk)\n",
    "        dk = -mat_k@grad_k if mat_type=='H' else -np.linalg.inv(mat_k)@grad_k\n",
    "        tk = wolfe_condition(f, f_grad, xk, dk, c1=1e-4, c2=0.9)\n",
    "        sk = tk*dk\n",
    "        xk_next = xk + sk\n",
    "        grad_next = f_grad(xk_next)\n",
    "        if np.linalg.norm(grad_next, ord=2) <= epsilon:\n",
    "            return xk_next, iter_cnt, time()-t_s\n",
    "        else:\n",
    "            print(f'Iteration {iter_cnt} - grad_norm:',np.linalg.norm(grad_next),\"tk:\",tk, \"x_norm:\",np.linalg.norm(xk_next))\n",
    "        # mat_k = np.linalg.inv(f_hessian(xk_next))\n",
    "        mat_k = update_approximation_bfgs(mat=mat_k, sk=sk, yk=grad_next-grad_k, mat_type=mat_type)\n",
    "        xk = xk_next\n",
    "    return xk_next, iter_cnt, time()-t_s\n",
    "\n",
    "def wolfe_condition(f, f_grad, xk, pk, c1=1e-4, c2=0.9, multiplier=1.25, t0=0, tmax=2):\n",
    "    ti = tmax/2\n",
    "    tprev = t0\n",
    "    i = 1\n",
    "    fval_cur = f(xk)\n",
    "    grad_cur = f_grad(xk)\n",
    "    while True:\n",
    "        xk_next = xk+ti*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if (fval_next > fval_cur + c1*ti*grad_cur@pk) or (fval_next >= fval_cur and i>1):\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, tprev, ti)\n",
    "        grad_next = f_grad(xk_next)\n",
    "        grad_next_T_pk = grad_next@pk\n",
    "        if np.abs(grad_next_T_pk) <= -c2*grad_cur@pk:\n",
    "            return ti\n",
    "        if grad_next_T_pk >= 0:\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, ti, tprev)\n",
    "        tprev = ti\n",
    "        ti = tprev*multiplier\n",
    "        i += 1\n",
    "\n",
    "np.random.seed(1000)\n",
    "init_x = np.zeros(n)+0.005\n",
    "\n",
    "# 使用 quasi-newton 求解无约束问题\n",
    "# quasi_newton_bfgs(f, f_grad, f_hessian, x0, mat_type='H', alpha=0.1, beta=0.5, epsilon=1e-6, maxIter=100):\n",
    "x_opt_bfgs, iter_cnt_bfgs, t_bfgs = quasi_newton_bfgs(f=f, f_grad=f_grad, f_hessian=f_hessian, x0=init_x, mat_type='H', epsilon=1e-4, max_iters=200)\n",
    "# x_opt_bfgs, iter_cnt_bfgs, t_bfgs = quasi_newton_bfgs(f=f, f_grad=f_grad, f_hessian=f_hessian, x0=init_x, mat_type='B', epsilon=1e-8, max_iters=200)\n",
    "print(f'BFGS - 迭代次数: {iter_cnt_bfgs}\\t最小值: {f(x_opt_bfgs):>2f}\\t耗时: {t_bfgs:>2f}s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure l-bfgs w/o constraints (D=500) ***aborted***\n",
    "\n",
    "Not very appropriate for IPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - grad_norm: 0.2874976403305301 tk: 1.0 x_norm: 0.6034130174696074\n",
      "Iteration 2 - grad_norm: 0.2838872583169178 tk: 1.25 x_norm: 0.6295060924456327\n",
      "Iteration 3 - grad_norm: 0.28242345968900984 tk: 3.0517578125 x_norm: 0.6542786523350346\n",
      "Iteration 4 - grad_norm: 0.28217543253346206 tk: 3.814697265625 x_norm: 0.6749511140438361\n",
      "Iteration 5 - grad_norm: 0.2821953930122363 tk: 5.9604644775390625 x_norm: 0.6953605998289375\n",
      "Iteration 6 - grad_norm: 0.28217480273736845 tk: 5.9604644775390625 x_norm: 0.7144840093383312\n",
      "Iteration 7 - grad_norm: 0.2821900982989895 tk: 7.450580596923828 x_norm: 0.7425670327511641\n",
      "Iteration 8 - grad_norm: 0.2820953597561407 tk: 11.641532182693481 x_norm: 0.782945591576831\n",
      "Iteration 9 - grad_norm: 0.28219147481740264 tk: 7.450580596923828 x_norm: 0.8100803607423993\n",
      "Iteration 10 - grad_norm: 0.282316987039029 tk: 1.5625 x_norm: 0.8507287723275746\n",
      "Iteration 11 - grad_norm: 0.2825591070321152 tk: 1.0 x_norm: 0.9281565145082193\n",
      "Iteration 12 - grad_norm: 0.28284588710723013 tk: 1.0 x_norm: 1.016427673000379\n",
      "Iteration 13 - grad_norm: 0.28318353701809906 tk: 1.0 x_norm: 1.1146069916278616\n",
      "Iteration 14 - grad_norm: 0.2835713586151958 tk: 1.0 x_norm: 1.2202781596444714\n",
      "Iteration 15 - grad_norm: 0.28400950195151586 tk: 1.0 x_norm: 1.3318416238473683\n",
      "L-BFGS - 迭代次数: 15\t最小值: 0.417851\t耗时: 11.990113s\n"
     ]
    }
   ],
   "source": [
    "class Container():\n",
    "    def __init__(self,numStore,dim) -> None:\n",
    "        self.ss = [np.zeros(dim) for i in range(numStore)]\n",
    "        self.ys = [np.zeros(dim) for i in range(numStore)]\n",
    "        self.cur_idx = 0\n",
    "        self.numStore = numStore\n",
    "        self.dim = dim\n",
    "    def update_container(self,sk,yk):\n",
    "        self.ss[self.cur_idx] = sk\n",
    "        self.ys[self.cur_idx] = yk\n",
    "        self.cur_idx = (self.cur_idx+1)%self.numStore\n",
    "    def cal_descent_direction(self,grad):\n",
    "        # self.cur_idx # last index\n",
    "        start_idx = self.cur_idx-1 # first index\n",
    "        for i in range(start_idx,start_idx-self.numStore,-1):\n",
    "            ysTss = self.ss[i]@self.ys[i]\n",
    "            alpha_i = (self.ss[i]@grad)/ysTss if ysTss != 0 else 0\n",
    "            grad -= alpha_i*self.ys[i]\n",
    "        r = np.eye(self.dim)@grad\n",
    "        for i in range(self.cur_idx, self.cur_idx+self.numStore):\n",
    "            trueId = i if i<self.numStore else i-self.numStore\n",
    "            ysTss = self.ss[trueId]@self.ys[trueId]\n",
    "            alpha_i = 0\n",
    "            beta = 0\n",
    "            if ysTss!=0:\n",
    "                alpha_i = (self.ss[trueId]@grad)/ysTss\n",
    "                beta = (self.ys[trueId]@r)/ysTss\n",
    "            r = r + (alpha_i-beta)*self.ss[trueId]\n",
    "        return r\n",
    "        \n",
    "\n",
    "#* 拟牛顿\n",
    "def quasi_newton_lbfgs(f, f_grad, f_hessian, x0, m=15, epsilon=1e-6, max_iters=500):\n",
    "    xk = x0\n",
    "    # hessian = f_hessian(x0)\n",
    "    # mat_k = np.linalg.inv(hessian) \n",
    "    # mat_k = np.eye(n)\n",
    "    dk = -f_grad(xk)\n",
    "    iter_cnt = 0\n",
    "    container = Container(numStore=m, dim=xk.size)\n",
    "    t_s = time()\n",
    "    for idx in range(max_iters):\n",
    "        iter_cnt += 1\n",
    "        grad_k = f_grad(xk)\n",
    "        # dk = -mat_k@grad_k \n",
    "        tk = wolfe_condition(f, f_grad, xk, dk, c1=1e-4, c2=0.9)\n",
    "        if tk<0:\n",
    "            return xk, iter_cnt-1, time()-t_s\n",
    "        sk = tk*dk\n",
    "        xk_next = xk + sk\n",
    "        grad_next = f_grad(xk_next)\n",
    "        if np.linalg.norm(grad_next, ord=2) <= epsilon:\n",
    "            return xk_next, iter_cnt, time()-t_s\n",
    "        else:\n",
    "            print(f'Iteration {iter_cnt} - grad_norm:',np.linalg.norm(grad_next),\"tk:\",tk, \"x_norm:\",np.linalg.norm(xk_next))\n",
    "        # mat_k = np.linalg.inv(f_hessian(xk_next))\n",
    "        # mat_k = update_approximation_lbfgs(mat=mat_k, sk=sk, yk=grad_next-grad_k)\n",
    "        container.update_container(sk=sk, yk=grad_next-grad_k)\n",
    "        dk = -container.cal_descent_direction(grad_next)\n",
    "        xk = xk_next\n",
    "    return xk_next, iter_cnt, time()-t_s\n",
    "\n",
    "def wolfe_condition(f, f_grad, xk, pk, c1=1e-4, c2=0.9, multiplier=1.25, t0=0, tmax=2):\n",
    "    ti = tmax/2\n",
    "    tprev = t0\n",
    "    i = 1\n",
    "    fval_cur = f(xk)\n",
    "    grad_cur = f_grad(xk)\n",
    "    while True:\n",
    "        xk_next = xk+ti*pk\n",
    "        fval_next = f(xk_next)\n",
    "        if (fval_next > fval_cur + c1*ti*grad_cur@pk) or (fval_next >= fval_cur and i>1):\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, tprev, ti)\n",
    "        grad_next = f_grad(xk_next)\n",
    "        grad_next_T_pk = grad_next@pk\n",
    "        if np.abs(grad_next_T_pk) <= -c2*grad_cur@pk:\n",
    "            return ti\n",
    "        if grad_next_T_pk >= 0:\n",
    "            return zoom(f, f_grad, xk, pk, fval_cur, grad_cur, c1, c2, ti, tprev)\n",
    "        tprev = ti\n",
    "        ti = tprev*multiplier\n",
    "        i += 1\n",
    "\n",
    "\n",
    "np.random.seed(1000)\n",
    "init_x = np.zeros(n)+0.005\n",
    "\n",
    "# 使用 quasi-newton 求解无约束问题\n",
    "x_opt_lbfgs, iter_cnt_lbfgs, t_lbfgs = quasi_newton_lbfgs(f=f, f_grad=f_grad, f_hessian=f_hessian, x0=init_x, m=15, epsilon=1e-3, max_iters=200)\n",
    "print(f'L-BFGS - 迭代次数: {iter_cnt_lbfgs}\\t最小值: {f(x_opt_lbfgs):>2f}\\t耗时: {t_lbfgs:>2f}s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected gradient methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_x \\quad \\frac{1}{m}\\sum_{i=1}^{m}&\\log\\left( 1 + \\exp(-b_i x^\\top a_i)\\right) + \\frac{1}{100m}\\left\\|x\\right\\|^2   \\\\\n",
    "\\text{subject to }\\quad\\quad &\\left\\|x\\right\\|_2 \\le D/2\n",
    "\\end{aligned}\n",
    "$$\n",
    "feasible set is a L2 ball $\\mathcal{X} = \\{x:\\left\\|x\\right\\|_2 \\le D/2\\}$\n",
    "\n",
    "projected gradient method\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{k+1} &= x_k - \\alpha_k p_k\\\\\n",
    "x_{k+1} &= \\Pi_\\mathcal{X}(y_{k+1})\\\\\n",
    "\\Pi_\\mathcal{X}(x) &= \\left\\{\\begin{matrix}\n",
    "x & \\left\\|x\\right\\|_2 \\le D/2  \\\\\n",
    "\\frac{D}{2\\left\\|x\\right\\|_2}x &  \\left\\|x\\right\\|_2 > D/2\\\\\n",
    "\\end{matrix}\\right.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Grad. Norm.: 0.052109680543728935 Norm. Diff.: 3.2435150931206587 tk: 5 x_norm: 3.1948158750857765\n",
      "Iteration 1 - Grad. Norm.: 0.03874538795695223 Norm. Diff.: 0.2605484027186447 tk: 5 x_norm: 3.3007664609434073\n",
      "Iteration 2 - Grad. Norm.: 0.03247236111795165 Norm. Diff.: 0.1937269397847612 tk: 5 x_norm: 3.39832364755234\n",
      "Iteration 3 - Grad. Norm.: 0.028707614758793267 Norm. Diff.: 0.16236180558975827 tk: 5 x_norm: 3.488927444461727\n",
      "Iteration 4 - Grad. Norm.: 0.026137955548665787 Norm. Diff.: 0.14353807379396633 tk: 5 x_norm: 3.573880284211031\n",
      "Iteration 5 - Grad. Norm.: 0.024238255924168794 Norm. Diff.: 0.13068977774332896 tk: 5 x_norm: 3.654164258131663\n",
      "Iteration 6 - Grad. Norm.: 0.02275515238979999 Norm. Diff.: 0.12119127962084399 tk: 5 x_norm: 3.730525846831219\n",
      "Iteration 7 - Grad. Norm.: 0.021550498078459098 Norm. Diff.: 0.11377576194899999 tk: 5 x_norm: 3.803544343824972\n",
      "Iteration 8 - Grad. Norm.: 0.02054217078675201 Norm. Diff.: 0.10775249039229548 tk: 5 x_norm: 3.873677891009221\n",
      "Iteration 9 - Grad. Norm.: 0.01967811317099874 Norm. Diff.: 0.10271085393376006 tk: 5 x_norm: 3.9412945794501484\n",
      "Iteration 10 - Grad. Norm.: 0.018923649545407387 Norm. Diff.: 0.09839056585499374 tk: 5 x_norm: 4.006694049320368\n",
      "Iteration 11 - Grad. Norm.: 0.018254755248512777 Norm. Diff.: 0.09461824772703696 tk: 5 x_norm: 4.070122926376995\n",
      "Iteration 12 - Grad. Norm.: 0.017654243223426912 Norm. Diff.: 0.09127377624256387 tk: 5 x_norm: 4.131786136275055\n",
      "Iteration 13 - Grad. Norm.: 0.017109485628512194 Norm. Diff.: 0.08827121611713455 tk: 5 x_norm: 4.1918553780763546\n",
      "Iteration 14 - Grad. Norm.: 0.01661099162910515 Norm. Diff.: 0.08554742814256094 tk: 5 x_norm: 4.250475586797769\n",
      "Iteration 15 - Grad. Norm.: 0.016151486504397905 Norm. Diff.: 0.08305495814552576 tk: 5 x_norm: 4.307769938849529\n",
      "Iteration 16 - Grad. Norm.: 0.015725296588775545 Norm. Diff.: 0.08075743252198951 tk: 5 x_norm: 4.3638437802112815\n",
      "Iteration 17 - Grad. Norm.: 0.015327927455063974 Norm. Diff.: 0.0786264829438777 tk: 5 x_norm: 4.41878774419224\n",
      "Iteration 18 - Grad. Norm.: 0.01495576795345957 Norm. Diff.: 0.07663963727531989 tk: 5 x_norm: 4.472680250221823\n",
      "Iteration 19 - Grad. Norm.: 0.014605878410723272 Norm. Diff.: 0.07477883976729786 tk: 5 x_norm: 4.525589523576644\n",
      "Iteration 20 - Grad. Norm.: 0.014275836426987468 Norm. Diff.: 0.07302939205361637 tk: 5 x_norm: 4.577575239960449\n",
      "Iteration 21 - Grad. Norm.: 0.013963622905490478 Norm. Diff.: 0.07137918213493735 tk: 5 x_norm: 4.628689873249136\n",
      "Iteration 22 - Grad. Norm.: 0.013667536698368668 Norm. Diff.: 0.0698181145274524 tk: 5 x_norm: 4.6789798061940004\n",
      "Iteration 23 - Grad. Norm.: 0.013386129933440693 Norm. Diff.: 0.0683376834918433 tk: 5 x_norm: 4.728486250282938\n",
      "Iteration 24 - Grad. Norm.: 0.013118158498739279 Norm. Diff.: 0.06693064966720347 tk: 5 x_norm: 4.777246010846559\n",
      "Iteration 25 - Grad. Norm.: 0.012862543774248811 Norm. Diff.: 0.06559079249369638 tk: 5 x_norm: 4.825292125878381\n",
      "Iteration 26 - Grad. Norm.: 0.012618342799414947 Norm. Diff.: 0.06431271887124403 tk: 5 x_norm: 4.872654401231959\n",
      "Iteration 27 - Grad. Norm.: 0.012384724827479992 Norm. Diff.: 0.06309171399707474 tk: 5 x_norm: 4.919359860382872\n",
      "Iteration 28 - Grad. Norm.: 0.01216095275544152 Norm. Diff.: 0.06192362413739998 tk: 5 x_norm: 4.9654331234576885\n",
      "Iteration 29 - Grad. Norm.: 0.01194636830344556 Norm. Diff.: 0.060804763777207595 tk: 5 x_norm: 5.010896727490012\n",
      "Iteration 30 - Grad. Norm.: 0.011740380096867469 Norm. Diff.: 0.05973184151722783 tk: 5 x_norm: 5.055771397686673\n",
      "Iteration 31 - Grad. Norm.: 0.011542454009604618 Norm. Diff.: 0.05870190048433734 tk: 5 x_norm: 5.100076277744397\n",
      "Iteration 32 - Grad. Norm.: 0.011352105279463776 Norm. Diff.: 0.057712270048023116 tk: 5 x_norm: 5.1438291258517665\n",
      "Iteration 33 - Grad. Norm.: 0.011168892020605283 Norm. Diff.: 0.056760526397318885 tk: 5 x_norm: 5.187046481870443\n",
      "Iteration 34 - Grad. Norm.: 0.010992409844044392 Norm. Diff.: 0.05584446010302644 tk: 5 x_norm: 5.229743810258475\n",
      "Iteration 35 - Grad. Norm.: 0.01082228736248468 Norm. Diff.: 0.05496204922022196 tk: 5 x_norm: 5.271935622535017\n",
      "Iteration 36 - Grad. Norm.: 0.010658182405517774 Norm. Diff.: 0.054111436812423426 tk: 5 x_norm: 5.313635582457262\n",
      "Iteration 37 - Grad. Norm.: 0.010499778809307676 Norm. Diff.: 0.053290912027588865 tk: 5 x_norm: 5.3548565965613575\n",
      "Iteration 38 - Grad. Norm.: 0.010346783674123578 Norm. Diff.: 0.052498894046538375 tk: 5 x_norm: 5.395610892289318\n",
      "Iteration 39 - Grad. Norm.: 0.010198925005613414 Norm. Diff.: 0.0517339183706179 tk: 5 x_norm: 5.435910085567235\n",
      "Iteration 40 - Grad. Norm.: 0.010055949673115894 Norm. Diff.: 0.050994625028067064 tk: 5 x_norm: 5.475765239403506\n",
      "Iteration 41 - Grad. Norm.: 0.00991762163179917 Norm. Diff.: 0.05027974836557943 tk: 5 x_norm: 5.515186914828691\n",
      "Iteration 42 - Grad. Norm.: 0.009783720365906778 Norm. Diff.: 0.049588108158995864 tk: 5 x_norm: 5.554185215292414\n",
      "Iteration 43 - Grad. Norm.: 0.009654039518584677 Norm. Diff.: 0.04891860182953392 tk: 5 x_norm: 5.592769825460382\n",
      "Iteration 44 - Grad. Norm.: 0.009528385680190871 Norm. Diff.: 0.04827019759292336 tk: 5 x_norm: 5.630950045210301\n",
      "Iteration 45 - Grad. Norm.: 0.00940657731205772 Norm. Diff.: 0.04764192840095437 tk: 5 x_norm: 5.668734819504399\n",
      "Iteration 46 - Grad. Norm.: 0.009288443786697239 Norm. Diff.: 0.047032886560288596 tk: 5 x_norm: 5.706132764714663\n",
      "Iteration 47 - Grad. Norm.: 0.009173824528649512 Norm. Diff.: 0.04644221893348621 tk: 5 x_norm: 5.743152191891231\n",
      "Iteration 48 - Grad. Norm.: 0.009062568242754069 Norm. Diff.: 0.04586912264324751 tk: 5 x_norm: 5.779801127392229\n",
      "Iteration 49 - Grad. Norm.: 0.008954532218712436 Norm. Diff.: 0.04531284121377029 tk: 5 x_norm: 5.816087331232378\n",
      "Iteration 50 - Grad. Norm.: 0.008849581702513225 Norm. Diff.: 0.04477266109356217 tk: 5 x_norm: 5.852018313456026\n",
      "Iteration 51 - Grad. Norm.: 0.008747589326689507 Norm. Diff.: 0.0442479085125661 tk: 5 x_norm: 5.887601348796511\n",
      "Iteration 52 - Grad. Norm.: 0.008648434592534953 Norm. Diff.: 0.04373794663344752 tk: 5 x_norm: 5.922843489846482\n",
      "Iteration 53 - Grad. Norm.: 0.008552003398367881 Norm. Diff.: 0.04324217296267474 tk: 5 x_norm: 5.9577515789322195\n",
      "Iteration 54 - Grad. Norm.: 0.00845818760873844 Norm. Diff.: 0.0427600169918394 tk: 5 x_norm: 5.992332258857884\n",
      "Iteration 55 - Grad. Norm.: 0.008366884660153454 Norm. Diff.: 0.04229093804369218 tk: 5 x_norm: 6.026591982662588\n",
      "Iteration 56 - Grad. Norm.: 0.00827799719946767 Norm. Diff.: 0.04183442330076726 tk: 5 x_norm: 6.060537022513511\n",
      "Iteration 57 - Grad. Norm.: 0.00819143275157915 Norm. Diff.: 0.0413899859973384 tk: 5 x_norm: 6.094173477841201\n",
      "Iteration 58 - Grad. Norm.: 0.008107103413483375 Norm. Diff.: 0.040957163757895695 tk: 5 x_norm: 6.127507282808913\n",
      "Iteration 59 - Grad. Norm.: 0.008024925572098265 Norm. Diff.: 0.04053551706741689 tk: 5 x_norm: 6.160544213195214\n",
      "Iteration 60 - Grad. Norm.: 0.007944819643579409 Norm. Diff.: 0.04012462786049136 tk: 5 x_norm: 6.193289892758523\n",
      "Iteration 61 - Grad. Norm.: 0.007866709832110139 Norm. Diff.: 0.03972409821789706 tk: 5 x_norm: 6.2257497991429025\n",
      "Iteration 62 - Grad. Norm.: 0.007790523906379961 Norm. Diff.: 0.03933354916055067 tk: 5 x_norm: 6.257929269376674\n",
      "Iteration 63 - Grad. Norm.: 0.007716192992164045 Norm. Diff.: 0.038952619531899824 tk: 5 x_norm: 6.289833505008441\n",
      "Iteration 64 - Grad. Norm.: 0.007643651379589124 Norm. Diff.: 0.03858096496082022 tk: 5 x_norm: 6.32146757691937\n",
      "Iteration 65 - Grad. Norm.: 0.007572836343822244 Norm. Diff.: 0.0382182568979456 tk: 5 x_norm: 6.352836429845363\n",
      "Iteration 66 - Grad. Norm.: 0.007503687978050367 Norm. Diff.: 0.03786418171911121 tk: 5 x_norm: 6.383944886638537\n",
      "Iteration 67 - Grad. Norm.: 0.007436149037734645 Norm. Diff.: 0.03751843989025181 tk: 5 x_norm: 6.414797652293544\n",
      "Iteration 68 - Grad. Norm.: 0.007370164795224553 Norm. Diff.: 0.037180745188673245 tk: 5 x_norm: 6.445399317761025\n",
      "Iteration 69 - Grad. Norm.: 0.007305682903906841 Norm. Diff.: 0.036850823976122764 tk: 5 x_norm: 6.4757543635677415\n",
      "Iteration 70 - Grad. Norm.: 0.007242653271142864 Norm. Diff.: 0.03652841451953422 tk: 5 x_norm: 6.505867163260412\n",
      "Iteration 71 - Grad. Norm.: 0.007181027939318518 Norm. Diff.: 0.03621326635571432 tk: 5 x_norm: 6.535741986688262\n",
      "Iteration 72 - Grad. Norm.: 0.007120760974392532 Norm. Diff.: 0.03590513969659258 tk: 5 x_norm: 6.565383003137404\n",
      "Iteration 73 - Grad. Norm.: 0.00706180836138476 Norm. Diff.: 0.0356038048719627 tk: 5 x_norm: 6.594794284328683\n",
      "Iteration 74 - Grad. Norm.: 0.0070041279062951845 Norm. Diff.: 0.03530904180692379 tk: 5 x_norm: 6.623979807289179\n",
      "Iteration 75 - Grad. Norm.: 0.006947679143988687 Norm. Diff.: 0.035020639531475925 tk: 5 x_norm: 6.652943457106436\n",
      "Iteration 76 - Grad. Norm.: 0.006892423251620309 Norm. Diff.: 0.03473839571994344 tk: 5 x_norm: 6.681689029573478\n",
      "Iteration 77 - Grad. Norm.: 0.006838322967211188 Norm. Diff.: 0.03446211625810151 tk: 5 x_norm: 6.710220233731739\n",
      "Iteration 78 - Grad. Norm.: 0.006785342513017727 Norm. Diff.: 0.03419161483605594 tk: 5 x_norm: 6.738540694318314\n",
      "Iteration 79 - Grad. Norm.: 0.006733447523365182 Norm. Diff.: 0.03392671256508867 tk: 5 x_norm: 6.766653954123283\n",
      "Iteration 80 - Grad. Norm.: 0.006682604976643397 Norm. Diff.: 0.033667237616825926 tk: 5 x_norm: 6.79456347626223\n",
      "Iteration 81 - Grad. Norm.: 0.006632783131185928 Norm. Diff.: 0.033413024883216985 tk: 5 x_norm: 6.8222726463686225\n",
      "Iteration 82 - Grad. Norm.: 0.006583951464775524 Norm. Diff.: 0.03316391565592961 tk: 5 x_norm: 6.849784774710303\n",
      "Iteration 83 - Grad. Norm.: 0.006536080617538423 Norm. Diff.: 0.032919757323877585 tk: 5 x_norm: 6.877103098233852\n",
      "Iteration 84 - Grad. Norm.: 0.006489142338007995 Norm. Diff.: 0.03268040308769206 tk: 5 x_norm: 6.904230782540435\n",
      "Iteration 85 - Grad. Norm.: 0.006443109432154281 Norm. Diff.: 0.032445711690039986 tk: 5 x_norm: 6.931170923796241\n",
      "Iteration 86 - Grad. Norm.: 0.006397955715191257 Norm. Diff.: 0.032215547160771414 tk: 5 x_norm: 6.957926550580559\n",
      "Iteration 87 - Grad. Norm.: 0.006353655965987035 Norm. Diff.: 0.031989778575956314 tk: 5 x_norm: 6.984500625674142\n",
      "Iteration 88 - Grad. Norm.: 0.006310185883914801 Norm. Diff.: 0.03176827982993518 tk: 5 x_norm: 7.010896047790501\n",
      "Iteration 89 - Grad. Norm.: 0.006267522047993853 Norm. Diff.: 0.03155092941957407 tk: 5 x_norm: 7.037115653252374\n",
      "Iteration 90 - Grad. Norm.: 0.0062256418781806155 Norm. Diff.: 0.03133761023996934 tk: 5 x_norm: 7.063162217615676\n",
      "Iteration 91 - Grad. Norm.: 0.006184523598679103 Norm. Diff.: 0.0311282093909031 tk: 5 x_norm: 7.0890384572429275\n",
      "Iteration 92 - Grad. Norm.: 0.006144146203149559 Norm. Diff.: 0.030922617993395508 tk: 5 x_norm: 7.114747030828146\n",
      "Iteration 93 - Grad. Norm.: 0.006104489421701856 Norm. Diff.: 0.030720731015747803 tk: 5 x_norm: 7.140290540875032\n",
      "Iteration 94 - Grad. Norm.: 0.006065533689568208 Norm. Diff.: 0.03052244710850927 tk: 5 x_norm: 7.1656715351301425\n",
      "Iteration 95 - Grad. Norm.: 0.0060272601173566075 Norm. Diff.: 0.03032766844784107 tk: 5 x_norm: 7.190892507972765\n",
      "Iteration 96 - Grad. Norm.: 0.0059896504627929064 Norm. Diff.: 0.030136300586783023 tk: 5 x_norm: 7.215955901762982\n",
      "Iteration 97 - Grad. Norm.: 0.005952687103865626 Norm. Diff.: 0.02994825231396458 tk: 5 x_norm: 7.2408641081494585\n",
      "Iteration 98 - Grad. Norm.: 0.005916353013292988 Norm. Diff.: 0.029763435519328127 tk: 5 x_norm: 7.2656194693383656\n",
      "Iteration 99 - Grad. Norm.: 0.005880631734237009 Norm. Diff.: 0.029581765066464892 tk: 5 x_norm: 7.290224279324753\n",
      "Iteration 100 - Grad. Norm.: 0.005845507357194208 Norm. Diff.: 0.029403158671184995 tk: 5 x_norm: 7.3146807850877344\n",
      "Iteration 101 - Grad. Norm.: 0.005810964497996975 Norm. Diff.: 0.029227536785970978 tk: 5 x_norm: 7.338991187750657\n",
      "Iteration 102 - Grad. Norm.: 0.005776988276863809 Norm. Diff.: 0.029054822489984856 tk: 5 x_norm: 7.363157643707488\n",
      "Iteration 103 - Grad. Norm.: 0.005743564298440498 Norm. Diff.: 0.028884941384319053 tk: 5 x_norm: 7.38718226571656\n",
      "Iteration 104 - Grad. Norm.: 0.005710678632777918 Norm. Diff.: 0.028717821492202488 tk: 5 x_norm: 7.4110671239627255\n",
      "Iteration 105 - Grad. Norm.: 0.005678317797195463 Norm. Diff.: 0.028553393163889607 tk: 5 x_norm: 7.434814247089042\n",
      "Iteration 106 - Grad. Norm.: 0.00564646873898221 Norm. Diff.: 0.02839158898597736 tk: 5 x_norm: 7.458425623198962\n",
      "Iteration 107 - Grad. Norm.: 0.005615118818890957 Norm. Diff.: 0.02823234369491105 tk: 5 x_norm: 7.481903200829988\n",
      "Iteration 108 - Grad. Norm.: 0.005584255795382843 Norm. Diff.: 0.02807559409445473 tk: 5 x_norm: 7.505248889899782\n",
      "Iteration 109 - Grad. Norm.: 0.005553867809582866 Norm. Diff.: 0.027921278976914203 tk: 5 x_norm: 7.528464562625599\n",
      "Iteration 110 - Grad. Norm.: 0.005523943370908989 Norm. Diff.: 0.027769339047914312 tk: 5 x_norm: 7.551552054417913\n",
      "Iteration 111 - Grad. Norm.: 0.0054944713433397645 Norm. Diff.: 0.027619716854544892 tk: 5 x_norm: 7.574513164749113\n",
      "Iteration 112 - Grad. Norm.: 0.005465440932287348 Norm. Diff.: 0.027472356716698815 tk: 5 x_norm: 7.597349657998026\n",
      "Iteration 113 - Grad. Norm.: 0.005436841672044922 Norm. Diff.: 0.027327204661436767 tk: 5 x_norm: 7.620063264271106\n",
      "Iteration 114 - Grad. Norm.: 0.0054086634137791205 Norm. Diff.: 0.02718420836022453 tk: 5 x_norm: 7.64265568020099\n",
      "Iteration 115 - Grad. Norm.: 0.005380896314039965 Norm. Diff.: 0.02704331706889565 tk: 5 x_norm: 7.6651285697231835\n",
      "Iteration 116 - Grad. Norm.: 0.005353530823762216 Norm. Diff.: 0.026904481570199798 tk: 5 x_norm: 7.687483564831559\n",
      "Iteration 117 - Grad. Norm.: 0.005326557677733729 Norm. Diff.: 0.026767654118811112 tk: 5 x_norm: 7.709722266313349\n",
      "Iteration 118 - Grad. Norm.: 0.00529996788450755 Norm. Diff.: 0.026632788388668657 tk: 5 x_norm: 7.7318462444642835\n",
      "Iteration 119 - Grad. Norm.: 0.005273752716736079 Norm. Diff.: 0.02649983942253774 tk: 5 x_norm: 7.753857039784492\n",
      "Iteration 120 - Grad. Norm.: 0.005247903701906571 Norm. Diff.: 0.026368763583680337 tk: 5 x_norm: 7.775756163655808\n",
      "Iteration 121 - Grad. Norm.: 0.005222412613458654 Norm. Diff.: 0.0262395185095329 tk: 5 x_norm: 7.797545099001002\n",
      "Iteration 122 - Grad. Norm.: 0.0051972714622654 Norm. Diff.: 0.026112063067293207 tk: 5 x_norm: 7.81922530092558\n",
      "Iteration 123 - Grad. Norm.: 0.005172472488460624 Norm. Diff.: 0.025986357311326997 tk: 5 x_norm: 7.840798197342625\n",
      "Iteration 124 - Grad. Norm.: 0.005148008153596033 Norm. Diff.: 0.02586236244230311 tk: 5 x_norm: 7.8622651895812625\n",
      "Iteration 125 - Grad. Norm.: 0.005123871133112667 Norm. Diff.: 0.025740040767980154 tk: 5 x_norm: 7.883627652979195\n",
      "Iteration 126 - Grad. Norm.: 0.005100054309111971 Norm. Diff.: 0.025619355665563368 tk: 5 x_norm: 7.904886937459868\n",
      "Iteration 127 - Grad. Norm.: 0.005076550763412619 Norm. Diff.: 0.02550027154555984 tk: 5 x_norm: 7.926044368094676\n",
      "Iteration 128 - Grad. Norm.: 0.005053353770879928 Norm. Diff.: 0.02538275381706305 tk: 5 x_norm: 7.947101245650691\n",
      "Iteration 129 - Grad. Norm.: 0.005030456793015412 Norm. Diff.: 0.025266768854399612 tk: 5 x_norm: 7.968058847124352\n",
      "Iteration 130 - Grad. Norm.: 0.005007853471794668 Norm. Diff.: 0.025152283965077023 tk: 5 x_norm: 7.988918426261543\n",
      "Iteration 131 - Grad. Norm.: 0.004985537623742439 Norm. Diff.: 0.025039267358973338 tk: 5 x_norm: 8.009681214064443\n",
      "Iteration 132 - Grad. Norm.: 0.00496350323423421 Norm. Diff.: 0.024927688118712182 tk: 5 x_norm: 8.030348419285577\n",
      "Iteration 133 - Grad. Norm.: 0.00494174445201434 Norm. Diff.: 0.024817516171171027 tk: 5 x_norm: 8.050921228909427\n",
      "Iteration 134 - Grad. Norm.: 0.004920255583921091 Norm. Diff.: 0.02470872226007168 tk: 5 x_norm: 8.071400808621982\n",
      "Iteration 135 - Grad. Norm.: 0.004899031089809628 Norm. Diff.: 0.02460127791960552 tk: 5 x_norm: 8.091788303268565\n",
      "Iteration 136 - Grad. Norm.: 0.004878065577664277 Norm. Diff.: 0.024495155449048164 tk: 5 x_norm: 8.112084837300293\n",
      "Iteration 137 - Grad. Norm.: 0.0048573537988919 Norm. Diff.: 0.02439032788832139 tk: 5 x_norm: 8.132291515209515\n",
      "Iteration 138 - Grad. Norm.: 0.0048368906437886855 Norm. Diff.: 0.02428676899445943 tk: 5 x_norm: 8.152409421954514\n",
      "Iteration 139 - Grad. Norm.: 0.004816671137172886 Norm. Diff.: 0.024184453218943403 tk: 5 x_norm: 8.1724396233738\n",
      "Iteration 140 - Grad. Norm.: 0.004796690434176531 Norm. Diff.: 0.024083355685864474 tk: 5 x_norm: 8.192383166590304\n",
      "Iteration 141 - Grad. Norm.: 0.004776943816189436 Norm. Diff.: 0.023983452170882682 tk: 5 x_norm: 8.212241080405732\n",
      "Iteration 142 - Grad. Norm.: 0.004757426686949174 Norm. Diff.: 0.02388471908094717 tk: 5 x_norm: 8.232014375685388\n",
      "Iteration 143 - Grad. Norm.: 0.004738134568770871 Norm. Diff.: 0.023787133434745852 tk: 5 x_norm: 8.251704045733728\n",
      "Iteration 144 - Grad. Norm.: 0.004719063098911212 Norm. Diff.: 0.02369067284385434 tk: 5 x_norm: 8.271311066660848\n",
      "Iteration 145 - Grad. Norm.: 0.004700208026061033 Norm. Diff.: 0.02359531549455605 tk: 5 x_norm: 8.290836397740293\n",
      "Iteration 146 - Grad. Norm.: 0.004681565206961339 Norm. Diff.: 0.023501040130305167 tk: 5 x_norm: 8.310280981758263\n",
      "Iteration 147 - Grad. Norm.: 0.0046631306031377695 Norm. Diff.: 0.023407826034806744 tk: 5 x_norm: 8.329645745354577\n",
      "Iteration 148 - Grad. Norm.: 0.0046449002777486995 Norm. Diff.: 0.023315653015688834 tk: 5 x_norm: 8.348931599355577\n",
      "Iteration 149 - Grad. Norm.: 0.004626870392542518 Norm. Diff.: 0.02322450138874355 tk: 5 x_norm: 8.368139439099176\n",
      "Iteration 150 - Grad. Norm.: 0.004609037204919693 Norm. Diff.: 0.023134351962712657 tk: 5 x_norm: 8.387270144752287\n",
      "Iteration 151 - Grad. Norm.: 0.004591397065095509 Norm. Diff.: 0.023045186024598423 tk: 5 x_norm: 8.406324581620847\n",
      "Iteration 152 - Grad. Norm.: 0.004573946413359559 Norm. Diff.: 0.022956985325477564 tk: 5 x_norm: 8.425303600452606\n",
      "Iteration 153 - Grad. Norm.: 0.004556681777428187 Norm. Diff.: 0.022869732066797793 tk: 5 x_norm: 8.444208037732885\n",
      "Iteration 154 - Grad. Norm.: 0.004539599769886302 Norm. Diff.: 0.02278340888714096 tk: 5 x_norm: 8.463038715973518\n",
      "Iteration 155 - Grad. Norm.: 0.00452269708571512 Norm. Diff.: 0.022697998849431487 tk: 5 x_norm: 8.481796443995103\n",
      "Iteration 156 - Grad. Norm.: 0.004505970499902511 Norm. Diff.: 0.022613485428575664 tk: 5 x_norm: 8.500482017202804\n",
      "Iteration 157 - Grad. Norm.: 0.004489416865132891 Norm. Diff.: 0.022529852499512535 tk: 5 x_norm: 8.519096217855822\n",
      "Iteration 158 - Grad. Norm.: 0.004473033109553527 Norm. Diff.: 0.022447084325664415 tk: 5 x_norm: 8.537639815330706\n",
      "Iteration 159 - Grad. Norm.: 0.0044568162346144986 Norm. Diff.: 0.02236516554776766 tk: 5 x_norm: 8.556113566378716\n",
      "Iteration 160 - Grad. Norm.: 0.004440763312979452 Norm. Diff.: 0.022284081173072536 tk: 5 x_norm: 8.574518215377303\n",
      "Iteration 161 - Grad. Norm.: 0.004424871486504592 Norm. Diff.: 0.022203816564897224 tk: 5 x_norm: 8.592854494575944\n",
      "Iteration 162 - Grad. Norm.: 0.0044091379642833385 Norm. Diff.: 0.02212435743252299 tk: 5 x_norm: 8.611123124336434\n",
      "Iteration 163 - Grad. Norm.: 0.004393560020754221 Norm. Diff.: 0.022045689821416695 tk: 5 x_norm: 8.62932481336775\n",
      "Iteration 164 - Grad. Norm.: 0.004378134993869741 Norm. Diff.: 0.021967800103771133 tk: 5 x_norm: 8.647460258955713\n",
      "Iteration 165 - Grad. Norm.: 0.0043628602833239135 Norm. Diff.: 0.021890674969348663 tk: 5 x_norm: 8.665530147187466\n",
      "Iteration 166 - Grad. Norm.: 0.004347733348836403 Norm. Diff.: 0.021814301416619535 tk: 5 x_norm: 8.683535153170999\n",
      "Iteration 167 - Grad. Norm.: 0.00433275170849119 Norm. Diff.: 0.02173866674418197 tk: 5 x_norm: 8.70147594124977\n",
      "Iteration 168 - Grad. Norm.: 0.004317912937127823 Norm. Diff.: 0.02166375854245593 tk: 5 x_norm: 8.719353165212606\n",
      "Iteration 169 - Grad. Norm.: 0.004303214664783347 Norm. Diff.: 0.021589564685639134 tk: 5 x_norm: 8.737167468498956\n",
      "Iteration 170 - Grad. Norm.: 0.004288654575183136 Norm. Diff.: 0.021516073323916734 tk: 5 x_norm: 8.754919484399625\n",
      "Iteration 171 - Grad. Norm.: 0.004274230404278877 Norm. Diff.: 0.021443272875915652 tk: 5 x_norm: 8.772609836253098\n",
      "Iteration 172 - Grad. Norm.: 0.004259939938832053 Norm. Diff.: 0.021371152021394377 tk: 5 x_norm: 8.79023913763761\n",
      "Iteration 173 - Grad. Norm.: 0.004245781015041309 Norm. Diff.: 0.02129969969416024 tk: 5 x_norm: 8.807807992558946\n",
      "Iteration 174 - Grad. Norm.: 0.004231751517212209 Norm. Diff.: 0.02122890507520653 tk: 5 x_norm: 8.82531699563423\n",
      "Iteration 175 - Grad. Norm.: 0.004217849376467856 Norm. Diff.: 0.02115875758606108 tk: 5 x_norm: 8.842766732271683\n",
      "Iteration 176 - Grad. Norm.: 0.004204072569498997 Norm. Diff.: 0.021089246882339263 tk: 5 x_norm: 8.860157778846485\n",
      "Iteration 177 - Grad. Norm.: 0.004190419117352251 Norm. Diff.: 0.021020362847495012 tk: 5 x_norm: 8.877490702872857\n",
      "Iteration 178 - Grad. Norm.: 0.0041768870842551304 Norm. Diff.: 0.020952095586761275 tk: 5 x_norm: 8.894766063172419\n",
      "Iteration 179 - Grad. Norm.: 0.004163474576476612 Norm. Diff.: 0.02088443542127569 tk: 5 x_norm: 8.911984410038947\n",
      "Iteration 180 - Grad. Norm.: 0.00415017974122207 Norm. Diff.: 0.020817372882383053 tk: 5 x_norm: 8.929146285399577\n",
      "Iteration 181 - Grad. Norm.: 0.004137000765561341 Norm. Diff.: 0.020750898706110334 tk: 5 x_norm: 8.946252222972568\n",
      "Iteration 182 - Grad. Norm.: 0.0041239358753888955 Norm. Diff.: 0.02068500382780678 tk: 5 x_norm: 8.963302748421711\n",
      "Iteration 183 - Grad. Norm.: 0.004110983334414956 Norm. Diff.: 0.02061967937694445 tk: 5 x_norm: 8.98029837950742\n",
      "Iteration 184 - Grad. Norm.: 0.0040981414431865764 Norm. Diff.: 0.02055491667207484 tk: 5 x_norm: 8.997239626234652\n",
      "Iteration 185 - Grad. Norm.: 0.004085408538137675 Norm. Diff.: 0.020490707215932866 tk: 5 x_norm: 9.014126990997669\n",
      "Iteration 186 - Grad. Norm.: 0.004072782990667028 Norm. Diff.: 0.02042704269068838 tk: 5 x_norm: 9.030960968721734\n",
      "Iteration 187 - Grad. Norm.: 0.004060263206243351 Norm. Diff.: 0.02036391495333513 tk: 5 x_norm: 9.047742047001842\n",
      "Iteration 188 - Grad. Norm.: 0.004047847623536561 Norm. Diff.: 0.02030131603121674 tk: 5 x_norm: 9.064470706238508\n",
      "Iteration 189 - Grad. Norm.: 0.004035534713574314 Norm. Diff.: 0.020239238117682735 tk: 5 x_norm: 9.081147419770717\n",
      "Iteration 190 - Grad. Norm.: 0.0040233229789230765 Norm. Diff.: 0.02017767356787155 tk: 5 x_norm: 9.097772654006082\n",
      "Iteration 191 - Grad. Norm.: 0.0040112109528928725 Norm. Diff.: 0.020116614894615352 tk: 5 x_norm: 9.114346868548282\n",
      "Iteration 192 - Grad. Norm.: 0.0039991971987649345 Norm. Diff.: 0.020056054764464395 tk: 5 x_norm: 9.130870516321844\n",
      "Iteration 193 - Grad. Norm.: 0.003987280309041588 Norm. Diff.: 0.019995985993824707 tk: 5 x_norm: 9.147344043694327\n",
      "Iteration 194 - Grad. Norm.: 0.003975458904717568 Norm. Diff.: 0.019936401545207896 tk: 5 x_norm: 9.163767890595956\n",
      "Iteration 195 - Grad. Norm.: 0.003963731634572135 Norm. Diff.: 0.019877294523587875 tk: 5 x_norm: 9.180142490636797\n",
      "Iteration 196 - Grad. Norm.: 0.003952097174481336 Norm. Diff.: 0.019818658172860736 tk: 5 x_norm: 9.196468271221502\n",
      "Iteration 197 - Grad. Norm.: 0.003940554226749706 Norm. Diff.: 0.01976048587240669 tk: 5 x_norm: 9.212745653661653\n",
      "Iteration 198 - Grad. Norm.: 0.003929101519460888 Norm. Diff.: 0.019702771133748492 tk: 5 x_norm: 9.22897505328586\n",
      "Iteration 199 - Grad. Norm.: 0.003917737805846478 Norm. Diff.: 0.019645507597304466 tk: 5 x_norm: 9.245156879547515\n",
      "Iteration 200 - Grad. Norm.: 0.003906461863672607 Norm. Diff.: 0.019588689029232432 tk: 5 x_norm: 9.261291536130411\n",
      "Iteration 201 - Grad. Norm.: 0.003895272494643651 Norm. Diff.: 0.019532309318363066 tk: 5 x_norm: 9.277379421052132\n",
      "Iteration 202 - Grad. Norm.: 0.003884168523822536 Norm. Diff.: 0.01947636247321824 tk: 5 x_norm: 9.293420926765386\n",
      "Iteration 203 - Grad. Norm.: 0.003873148799067174 Norm. Diff.: 0.01942084261911262 tk: 5 x_norm: 9.309416440257232\n",
      "Iteration 204 - Grad. Norm.: 0.003862212190482467 Norm. Diff.: 0.01936574399533585 tk: 5 x_norm: 9.325366343146303\n",
      "Iteration 205 - Grad. Norm.: 0.003851357589887427 Norm. Diff.: 0.01931106095241228 tk: 5 x_norm: 9.341271011778074\n",
      "Iteration 206 - Grad. Norm.: 0.003840583910296955 Norm. Diff.: 0.01925678794943711 tk: 5 x_norm: 9.357130817318152\n",
      "Iteration 207 - Grad. Norm.: 0.0038298900854178133 Norm. Diff.: 0.01920291955148479 tk: 5 x_norm: 9.372946125843725\n",
      "Iteration 208 - Grad. Norm.: 0.0038192750691583787 Norm. Diff.: 0.019149450427089116 tk: 5 x_norm: 9.388717298433141\n",
      "Iteration 209 - Grad. Norm.: 0.003808737835151722 Norm. Diff.: 0.019096375345791845 tk: 5 x_norm: 9.404444691253678\n",
      "Iteration 210 - Grad. Norm.: 0.003798277376291648 Norm. Diff.: 0.019043689175758608 tk: 5 x_norm: 9.420128655647579\n",
      "Iteration 211 - Grad. Norm.: 0.0037878927042812854 Norm. Diff.: 0.018991386881458218 tk: 5 x_norm: 9.43576953821631\n",
      "Iteration 212 - Grad. Norm.: 0.003777582849193835 Norm. Diff.: 0.018939463521406453 tk: 5 x_norm: 9.451367680903184\n",
      "Iteration 213 - Grad. Norm.: 0.003767346859045158 Norm. Diff.: 0.01888791424596918 tk: 5 x_norm: 9.466923421074299\n",
      "Iteration 214 - Grad. Norm.: 0.003757183799377783 Norm. Diff.: 0.018836734295225793 tk: 5 x_norm: 9.482437091597857\n",
      "Iteration 215 - Grad. Norm.: 0.0037470927528560558 Norm. Diff.: 0.018785918996888862 tk: 5 x_norm: 9.497909020921941\n",
      "Iteration 216 - Grad. Norm.: 0.0037370728188720584 Norm. Diff.: 0.018735463764280178 tk: 5 x_norm: 9.513339533150699\n",
      "Iteration 217 - Grad. Norm.: 0.0037271231131619877 Norm. Diff.: 0.018685364094360293 tk: 5 x_norm: 9.528728948119044\n",
      "Iteration 218 - Grad. Norm.: 0.0037172427674327076 Norm. Diff.: 0.01863561556580992 tk: 5 x_norm: 9.544077581465874\n",
      "Iteration 219 - Grad. Norm.: 0.003707430928998128 Norm. Diff.: 0.018586213837163527 tk: 5 x_norm: 9.559385744705834\n",
      "Iteration 220 - Grad. Norm.: 0.00369768676042518 Norm. Diff.: 0.01853715464499069 tk: 5 x_norm: 9.574653745299665\n",
      "Iteration 221 - Grad. Norm.: 0.003688009439189058 Norm. Diff.: 0.018488433802125944 tk: 5 x_norm: 9.589881886723186\n",
      "Iteration 222 - Grad. Norm.: 0.0036783981573374775 Norm. Diff.: 0.018440047195945282 tk: 5 x_norm: 9.605070468534876\n",
      "Iteration 223 - Grad. Norm.: 0.00366885212116371 Norm. Diff.: 0.018391990786687407 tk: 5 x_norm: 9.620219786442187\n",
      "Iteration 224 - Grad. Norm.: 0.003659370550888077 Norm. Diff.: 0.018344260605818542 tk: 5 x_norm: 9.635330132366512\n",
      "Iteration 225 - Grad. Norm.: 0.0036499526803477284 Norm. Diff.: 0.018296852754440346 tk: 5 x_norm: 9.650401794506912\n",
      "Iteration 226 - Grad. Norm.: 0.0036405977566944386 Norm. Diff.: 0.01824976340173871 tk: 5 x_norm: 9.66543505740259\n",
      "Iteration 227 - Grad. Norm.: 0.0036313050401001637 Norm. Diff.: 0.0182029887834722 tk: 5 x_norm: 9.680430201994136\n",
      "Iteration 228 - Grad. Norm.: 0.0036220738034701853 Norm. Diff.: 0.01815652520050089 tk: 5 x_norm: 9.695387505683604\n",
      "Iteration 229 - Grad. Norm.: 0.00361290333216359 Norm. Diff.: 0.01811036901735097 tk: 5 x_norm: 9.71030724239342\n",
      "Iteration 230 - Grad. Norm.: 0.003603792923720884 Norm. Diff.: 0.01806451666081794 tk: 5 x_norm: 9.725189682624134\n",
      "Iteration 231 - Grad. Norm.: 0.003594741887598559 Norm. Diff.: 0.018018964618604447 tk: 5 x_norm: 9.740035093511064\n",
      "Iteration 232 - Grad. Norm.: 0.003585749544910379 Norm. Diff.: 0.01797370943799279 tk: 5 x_norm: 9.75484373887986\n",
      "Iteration 233 - Grad. Norm.: 0.003576815228175211 Norm. Diff.: 0.017928747724551875 tk: 5 x_norm: 9.769615879300982\n",
      "Iteration 234 - Grad. Norm.: 0.0035679382810712527 Norm. Diff.: 0.017884076140876046 tk: 5 x_norm: 9.78435177214314\n",
      "Iteration 235 - Grad. Norm.: 0.0035591180581964043 Norm. Diff.: 0.017839691405356295 tk: 5 x_norm: 9.7990516716257\n",
      "Iteration 236 - Grad. Norm.: 0.0035503539248346832 Norm. Diff.: 0.01779559029098202 tk: 5 x_norm: 9.8137158288701\n",
      "Iteration 237 - Grad. Norm.: 0.0035416452567284683 Norm. Diff.: 0.01775176962417343 tk: 5 x_norm: 9.828344491950283\n",
      "Iteration 238 - Grad. Norm.: 0.003532991439856431 Norm. Diff.: 0.017708226283642364 tk: 5 x_norm: 9.842937905942149\n",
      "Iteration 239 - Grad. Norm.: 0.0035243918702169935 Norm. Diff.: 0.017664957199282152 tk: 5 x_norm: 9.857496312972092\n",
      "Iteration 240 - Grad. Norm.: 0.0035158459536171406 Norm. Diff.: 0.017621959351084897 tk: 5 x_norm: 9.8720199522646\n",
      "Iteration 241 - Grad. Norm.: 0.0035073531054664897 Norm. Diff.: 0.01757922976808577 tk: 5 x_norm: 9.886509060188947\n",
      "Iteration 242 - Grad. Norm.: 0.0034989127505763986 Norm. Diff.: 0.017536765527332486 tk: 5 x_norm: 9.900963870305036\n",
      "Iteration 243 - Grad. Norm.: 0.0034905243229640453 Norm. Diff.: 0.017494563752882043 tk: 5 x_norm: 9.915384613408317\n",
      "Iteration 244 - Grad. Norm.: 0.003482187265661298 Norm. Diff.: 0.017452621614820214 tk: 5 x_norm: 9.929771517573922\n",
      "Iteration 245 - Grad. Norm.: 0.003473901030528257 Norm. Diff.: 0.017410936328306512 tk: 5 x_norm: 9.944124808199922\n",
      "Iteration 246 - Grad. Norm.: 0.0034656650780713503 Norm. Diff.: 0.01736950515264122 tk: 5 x_norm: 9.958444708049793\n",
      "Iteration 247 - Grad. Norm.: 0.003457478877265842 Norm. Diff.: 0.017328325390356728 tk: 5 x_norm: 9.972731437294097\n",
      "Iteration 248 - Grad. Norm.: 0.003449341905382658 Norm. Diff.: 0.017287394386329112 tk: 5 x_norm: 9.986985213551353\n",
      "Iteration 249 - Grad. Norm.: 0.0034412536478193763 Norm. Diff.: 0.017246709526913193 tk: 5 x_norm: 10.00120625192817\n",
      "Iteration 250 - Grad. Norm.: 0.0034332135979353168 Norm. Diff.: 0.017206268239096812 tk: 5 x_norm: 10.015394765058634\n",
      "Iteration 251 - Grad. Norm.: 0.003425221256890568 Norm. Diff.: 0.017166067989676626 tk: 5 x_norm: 10.029550963142936\n",
      "Iteration 252 - Grad. Norm.: 0.0034172761334888913 Norm. Diff.: 0.01712610628445285 tk: 5 x_norm: 10.043675053985313\n",
      "Iteration 253 - Grad. Norm.: 0.0034093777440243815 Norm. Diff.: 0.017086380667444438 tk: 5 x_norm: 10.057767243031272\n",
      "Iteration 254 - Grad. Norm.: 0.003401525612131752 Norm. Diff.: 0.0170468887201219 tk: 5 x_norm: 10.071827733404131\n",
      "Iteration 255 - Grad. Norm.: 0.003393719268640217 Norm. Diff.: 0.01700762806065876 tk: 5 x_norm: 10.085856725940886\n",
      "Iteration 256 - Grad. Norm.: 0.00338595825143081 Norm. Diff.: 0.016968596343201105 tk: 5 x_norm: 10.099854419227407\n",
      "Iteration 257 - Grad. Norm.: 0.0033782421052970762 Norm. Diff.: 0.0169297912571541 tk: 5 x_norm: 10.113821009633005\n",
      "Iteration 258 - Grad. Norm.: 0.003370570381809056 Norm. Diff.: 0.016891210526485376 tk: 5 x_norm: 10.127756691344358\n",
      "Iteration 259 - Grad. Norm.: 0.003362942639180458 Norm. Diff.: 0.0168528519090453 tk: 5 x_norm: 10.141661656398801\n",
      "Iteration 260 - Grad. Norm.: 0.003355358442138933 Norm. Diff.: 0.016814713195902328 tk: 5 x_norm: 10.155536094717057\n",
      "Iteration 261 - Grad. Norm.: 0.0033478173617993994 Norm. Diff.: 0.016776792210694627 tk: 5 x_norm: 10.169380194135293\n",
      "Iteration 262 - Grad. Norm.: 0.0033403189755403075 Norm. Diff.: 0.016739086808997043 tk: 5 x_norm: 10.183194140436676\n",
      "Iteration 263 - Grad. Norm.: 0.0033328628668827577 Norm. Diff.: 0.016701594877701592 tk: 5 x_norm: 10.196978117382294\n",
      "Iteration 264 - Grad. Norm.: 0.0033254486253724586 Norm. Diff.: 0.01666431433441381 tk: 5 x_norm: 10.210732306741557\n",
      "Iteration 265 - Grad. Norm.: 0.0033180758464643697 Norm. Diff.: 0.016627243126862284 tk: 5 x_norm: 10.22445688832202\n",
      "Iteration 266 - Grad. Norm.: 0.00331074413141003 Norm. Diff.: 0.01659037923232184 tk: 5 x_norm: 10.238152039998702\n",
      "Iteration 267 - Grad. Norm.: 0.0033034530871474494 Norm. Diff.: 0.016553720657050235 tk: 5 x_norm: 10.251817937742835\n",
      "Iteration 268 - Grad. Norm.: 0.003296202326193536 Norm. Diff.: 0.016517265435737272 tk: 5 x_norm: 10.265454755650136\n",
      "Iteration 269 - Grad. Norm.: 0.003288991466538963 Norm. Diff.: 0.016481011630967744 tk: 5 x_norm: 10.279062665968546\n",
      "Iteration 270 - Grad. Norm.: 0.003281820131545451 Norm. Diff.: 0.016444957332694805 tk: 5 x_norm: 10.292641839125487\n",
      "Iteration 271 - Grad. Norm.: 0.0032746879498453518 Norm. Diff.: 0.016409100657727282 tk: 5 x_norm: 10.30619244375464\n",
      "Iteration 272 - Grad. Norm.: 0.00326759455524352 Norm. Diff.: 0.016373439749226778 tk: 5 x_norm: 10.319714646722206\n",
      "Iteration 273 - Grad. Norm.: 0.0032605395866213984 Norm. Diff.: 0.01633797277621761 tk: 5 x_norm: 10.333208613152767\n",
      "Iteration 274 - Grad. Norm.: 0.0032535226878432524 Norm. Diff.: 0.016302697933107003 tk: 5 x_norm: 10.346674506454626\n",
      "Iteration 275 - Grad. Norm.: 0.0032465435076645087 Norm. Diff.: 0.01626761343921631 tk: 5 x_norm: 10.360112488344734\n",
      "Iteration 276 - Grad. Norm.: 0.003239601699642142 Norm. Diff.: 0.016232717538322467 tk: 5 x_norm: 10.373522718873168\n",
      "Iteration 277 - Grad. Norm.: 0.003232696922047064 Norm. Diff.: 0.016198008498210674 tk: 5 x_norm: 10.386905356447178\n",
      "Iteration 278 - Grad. Norm.: 0.003225828837778448 Norm. Diff.: 0.01616348461023528 tk: 5 x_norm: 10.400260557854807\n",
      "Iteration 279 - Grad. Norm.: 0.003218997114279963 Norm. Diff.: 0.016129144188892185 tk: 5 x_norm: 10.413588478288114\n",
      "Iteration 280 - Grad. Norm.: 0.0032122014234578487 Norm. Diff.: 0.016094985571399795 tk: 5 x_norm: 10.42688927136596\n",
      "Iteration 281 - Grad. Norm.: 0.0032054414416007957 Norm. Diff.: 0.016061007117289205 tk: 5 x_norm: 10.440163089156439\n",
      "Iteration 282 - Grad. Norm.: 0.003198716849301587 Norm. Diff.: 0.01602720720800405 tk: 5 x_norm: 10.453410082198868\n",
      "Iteration 283 - Grad. Norm.: 0.003192027331380455 Norm. Diff.: 0.015993584246507892 tk: 5 x_norm: 10.466630399525444\n",
      "Iteration 284 - Grad. Norm.: 0.003185372576810098 Norm. Diff.: 0.015960136656902255 tk: 5 x_norm: 10.479824188682493\n",
      "Iteration 285 - Grad. Norm.: 0.0031787522786423496 Norm. Diff.: 0.01592686288405052 tk: 5 x_norm: 10.492991595751363\n",
      "Iteration 286 - Grad. Norm.: 0.003172166133936415 Norm. Diff.: 0.015893761393211754 tk: 5 x_norm: 10.506132765368958\n",
      "Iteration 287 - Grad. Norm.: 0.0031656138436886748 Norm. Diff.: 0.01586083066968209 tk: 5 x_norm: 10.519247840747914\n",
      "Iteration 288 - Grad. Norm.: 0.003159095112763989 Norm. Diff.: 0.015828069218443375 tk: 5 x_norm: 10.532336963696437\n",
      "Iteration 289 - Grad. Norm.: 0.0031526096498284877 Norm. Diff.: 0.015795475563819907 tk: 5 x_norm: 10.54540027463778\n",
      "Iteration 290 - Grad. Norm.: 0.003146157167283786 Norm. Diff.: 0.01576304824914251 tk: 5 x_norm: 10.55843791262942\n",
      "Iteration 291 - Grad. Norm.: 0.0031397373812026264 Norm. Diff.: 0.015730785836418976 tk: 5 x_norm: 10.571450015381881\n",
      "Iteration 292 - Grad. Norm.: 0.003133350011265866 Norm. Diff.: 0.015698686906013105 tk: 5 x_norm: 10.584436719277251\n",
      "Iteration 293 - Grad. Norm.: 0.003126994780700804 Norm. Diff.: 0.015666750056329354 tk: 5 x_norm: 10.597398159387366\n",
      "Iteration 294 - Grad. Norm.: 0.0031206714162208367 Norm. Diff.: 0.015634973903503994 tk: 5 x_norm: 10.610334469491725\n",
      "Iteration 295 - Grad. Norm.: 0.003114379647966349 Norm. Diff.: 0.015603357081104167 tk: 5 x_norm: 10.623245782095053\n",
      "Iteration 296 - Grad. Norm.: 0.003108119209446878 Norm. Diff.: 0.015571898239831655 tk: 5 x_norm: 10.636132228444605\n",
      "Iteration 297 - Grad. Norm.: 0.003101889837484468 Norm. Diff.: 0.01554059604723443 tk: 5 x_norm: 10.648993938547168\n",
      "Iteration 298 - Grad. Norm.: 0.003095691272158211 Norm. Diff.: 0.015509449187422418 tk: 5 x_norm: 10.661831041185767\n",
      "Iteration 299 - Grad. Norm.: 0.003089523256749953 Norm. Diff.: 0.015478456360791065 tk: 5 x_norm: 10.67464366393612\n",
      "Iteration 300 - Grad. Norm.: 0.003083385537691112 Norm. Diff.: 0.01544761628374974 tk: 5 x_norm: 10.68743193318277\n",
      "Iteration 301 - Grad. Norm.: 0.0030772778645105966 Norm. Diff.: 0.015416927688455493 tk: 5 x_norm: 10.700195974135012\n",
      "Iteration 302 - Grad. Norm.: 0.0030711999897838106 Norm. Diff.: 0.01538638932255296 tk: 5 x_norm: 10.712935910842496\n",
      "Iteration 303 - Grad. Norm.: 0.0030651516690826854 Norm. Diff.: 0.015355999948919041 tk: 5 x_norm: 10.725651866210608\n",
      "Iteration 304 - Grad. Norm.: 0.0030591326609267543 Norm. Diff.: 0.01532575834541341 tk: 5 x_norm: 10.738343962015591\n",
      "Iteration 305 - Grad. Norm.: 0.0030531427267352037 Norm. Diff.: 0.015295663304633726 tk: 5 x_norm: 10.751012318919395\n",
      "Iteration 306 - Grad. Norm.: 0.0030471816307799213 Norm. Diff.: 0.015265713633676068 tk: 5 x_norm: 10.763657056484327\n",
      "Iteration 307 - Grad. Norm.: 0.0030412491401394723 Norm. Diff.: 0.015235908153899703 tk: 5 x_norm: 10.776278293187403\n",
      "Iteration 308 - Grad. Norm.: 0.003035345024654035 Norm. Diff.: 0.015206245700697322 tk: 5 x_norm: 10.788876146434522\n",
      "Iteration 309 - Grad. Norm.: 0.003029469056881203 Norm. Diff.: 0.015176725123270155 tk: 5 x_norm: 10.801450732574365\n",
      "Iteration 310 - Grad. Norm.: 0.0030236210120527167 Norm. Diff.: 0.015147345284406045 tk: 5 x_norm: 10.814002166912099\n",
      "Iteration 311 - Grad. Norm.: 0.0030178006680320235 Norm. Diff.: 0.015118105060263582 tk: 5 x_norm: 10.826530563722827\n",
      "Iteration 312 - Grad. Norm.: 0.003012007805272707 Norm. Diff.: 0.015089003340160043 tk: 5 x_norm: 10.839036036264869\n",
      "Iteration 313 - Grad. Norm.: 0.0030062422067777335 Norm. Diff.: 0.015060039026363561 tk: 5 x_norm: 10.851518696792757\n",
      "Iteration 314 - Grad. Norm.: 0.0030005036580595034 Norm. Diff.: 0.01503121103388873 tk: 5 x_norm: 10.863978656570104\n",
      "Iteration 315 - Grad. Norm.: 0.0029947919471006884 Norm. Diff.: 0.015002518290297482 tk: 5 x_norm: 10.876416025882188\n",
      "Iteration 316 - Grad. Norm.: 0.0029891068643158438 Norm. Diff.: 0.014973959735503447 tk: 5 x_norm: 10.888830914048395\n",
      "Iteration 317 - Grad. Norm.: 0.002983448202513769 Norm. Diff.: 0.014945534321579315 tk: 5 x_norm: 10.901223429434424\n",
      "Iteration 318 - Grad. Norm.: 0.0029778157568606063 Norm. Diff.: 0.014917241012568866 tk: 5 x_norm: 10.91359367946432\n",
      "Iteration 319 - Grad. Norm.: 0.002972209324843648 Norm. Diff.: 0.014889078784302996 tk: 5 x_norm: 10.9259417706323\n",
      "Iteration 320 - Grad. Norm.: 0.002966628706235858 Norm. Diff.: 0.014861046624218254 tk: 5 x_norm: 10.938267808514407\n",
      "Iteration 321 - Grad. Norm.: 0.002961073703061062 Norm. Diff.: 0.014833143531179241 tk: 5 x_norm: 10.950571897779966\n",
      "Iteration 322 - Grad. Norm.: 0.0029555441195598243 Norm. Diff.: 0.014805368515305293 tk: 5 x_norm: 10.962854142202865\n",
      "Iteration 323 - Grad. Norm.: 0.0029500397621559666 Norm. Diff.: 0.014777720597799096 tk: 5 x_norm: 10.975114644672667\n",
      "Iteration 324 - Grad. Norm.: 0.0029445604394237363 Norm. Diff.: 0.014750198810779852 tk: 5 x_norm: 10.987353507205519\n",
      "Iteration 325 - Grad. Norm.: 0.002939105962055583 Norm. Diff.: 0.01472280219711864 tk: 5 x_norm: 10.999570830954935\n",
      "Iteration 326 - Grad. Norm.: 0.0029336761428305712 Norm. Diff.: 0.014695529810277873 tk: 5 x_norm: 11.011766716222372\n",
      "Iteration 327 - Grad. Norm.: 0.0029282707965833654 Norm. Diff.: 0.014668380714152822 tk: 5 x_norm: 11.023941262467654\n",
      "Iteration 328 - Grad. Norm.: 0.0029228897401738178 Norm. Diff.: 0.014641353982916893 tk: 5 x_norm: 11.036094568319239\n",
      "Iteration 329 - Grad. Norm.: 0.0029175327924571104 Norm. Diff.: 0.014614448700869061 tk: 5 x_norm: 11.048226731584329\n",
      "Iteration 330 - Grad. Norm.: 0.002912199774254474 Norm. Diff.: 0.014587663962285646 tk: 5 x_norm: 11.060337849258806\n",
      "Iteration 331 - Grad. Norm.: 0.002906890508324432 Norm. Diff.: 0.014560998871272365 tk: 5 x_norm: 11.072428017537046\n",
      "Iteration 332 - Grad. Norm.: 0.0029016048193346 Norm. Diff.: 0.01453445254162217 tk: 5 x_norm: 11.084497331821542\n",
      "Iteration 333 - Grad. Norm.: 0.0028963425338339836 Norm. Diff.: 0.014508024096673004 tk: 5 x_norm: 11.096545886732416\n",
      "Iteration 334 - Grad. Norm.: 0.002891103480225805 Norm. Diff.: 0.014481712669169882 tk: 5 x_norm: 11.10857377611677\n",
      "Iteration 335 - Grad. Norm.: 0.0028858874887408284 Norm. Diff.: 0.014455517401129134 tk: 5 x_norm: 11.120581093057892\n",
      "Iteration 336 - Grad. Norm.: 0.002880694391411154 Norm. Diff.: 0.01442943744370406 tk: 5 x_norm: 11.132567929884319\n",
      "Iteration 337 - Grad. Norm.: 0.0028755240220445077 Norm. Diff.: 0.014403471957055745 tk: 5 x_norm: 11.144534378178793\n",
      "Iteration 338 - Grad. Norm.: 0.0028703762161989984 Norm. Diff.: 0.014377620110222507 tk: 5 x_norm: 11.156480528787029\n",
      "Iteration 339 - Grad. Norm.: 0.00286525081115832 Norm. Diff.: 0.014351881080994935 tk: 5 x_norm: 11.168406471826398\n",
      "Iteration 340 - Grad. Norm.: 0.0028601476459074095 Norm. Diff.: 0.01432625405579157 tk: 5 x_norm: 11.180312296694463\n",
      "Iteration 341 - Grad. Norm.: 0.0028550665611085367 Norm. Diff.: 0.014300738229537029 tk: 5 x_norm: 11.192198092077374\n",
      "Iteration 342 - Grad. Norm.: 0.002850007399077831 Norm. Diff.: 0.014275332805542733 tk: 5 x_norm: 11.204063945958161\n",
      "Iteration 343 - Grad. Norm.: 0.002844970003762213 Norm. Diff.: 0.014250036995389136 tk: 5 x_norm: 11.215909945624881\n",
      "Iteration 344 - Grad. Norm.: 0.0028399542207167483 Norm. Diff.: 0.01422485001881114 tk: 5 x_norm: 11.227736177678665\n",
      "Iteration 345 - Grad. Norm.: 0.0028349598970823947 Norm. Diff.: 0.014199771103583739 tk: 5 x_norm: 11.23954272804163\n",
      "Iteration 346 - Grad. Norm.: 0.002829986881564146 Norm. Diff.: 0.014174799485411985 tk: 5 x_norm: 11.251329681964682\n",
      "Iteration 347 - Grad. Norm.: 0.0028250350244095543 Norm. Diff.: 0.014149934407820761 tk: 5 x_norm: 11.263097124035196\n",
      "Iteration 348 - Grad. Norm.: 0.0028201041773876353 Norm. Diff.: 0.014125175122047829 tk: 5 x_norm: 11.274845138184599\n",
      "Iteration 349 - Grad. Norm.: 0.0028151941937681396 Norm. Diff.: 0.014100520886938183 tk: 5 x_norm: 11.286573807695824\n",
      "Iteration 350 - Grad. Norm.: 0.002810304928301176 Norm. Diff.: 0.014075970968840614 tk: 5 x_norm: 11.298283215210661\n",
      "Iteration 351 - Grad. Norm.: 0.0028054362371971947 Norm. Diff.: 0.014051524641505941 tk: 5 x_norm: 11.309973442737013\n",
      "Iteration 352 - Grad. Norm.: 0.0028005879781073245 Norm. Diff.: 0.014027181185985926 tk: 5 x_norm: 11.321644571656025\n",
      "Iteration 353 - Grad. Norm.: 0.0027957600101040253 Norm. Diff.: 0.014002939890536718 tk: 5 x_norm: 11.333296682729129\n",
      "Iteration 354 - Grad. Norm.: 0.0027909521936620918 Norm. Diff.: 0.013978800050520138 tk: 5 x_norm: 11.344929856104972\n",
      "Iteration 355 - Grad. Norm.: 0.00278616439063997 Norm. Diff.: 0.013954760968310428 tk: 5 x_norm: 11.356544171326254\n",
      "Iteration 356 - Grad. Norm.: 0.002781396464261402 Norm. Diff.: 0.01393082195319988 tk: 5 x_norm: 11.368139707336475\n",
      "Iteration 357 - Grad. Norm.: 0.002776648279097364 Norm. Diff.: 0.013906982321307004 tk: 5 x_norm: 11.379716542486555\n",
      "Iteration 358 - Grad. Norm.: 0.0027719197010483265 Norm. Diff.: 0.013883241395486905 tk: 5 x_norm: 11.391274754541406\n",
      "Iteration 359 - Grad. Norm.: 0.002767210597326803 Norm. Diff.: 0.013859598505241605 tk: 5 x_norm: 11.402814420686349\n",
      "Iteration 360 - Grad. Norm.: 0.0027625208364401932 Norm. Diff.: 0.013836052986634064 tk: 5 x_norm: 11.414335617533519\n",
      "Iteration 361 - Grad. Norm.: 0.002757850288173912 Norm. Diff.: 0.013812604182200896 tk: 5 x_norm: 11.425838421128095\n",
      "Iteration 362 - Grad. Norm.: 0.0027531988235747987 Norm. Diff.: 0.013789251440869645 tk: 5 x_norm: 11.43732290695451\n",
      "Iteration 363 - Grad. Norm.: 0.002748566314934802 Norm. Diff.: 0.013765994117873959 tk: 5 x_norm: 11.448789149942527\n",
      "Iteration 364 - Grad. Norm.: 0.00274395263577493 Norm. Diff.: 0.013742831574673993 tk: 5 x_norm: 11.460237224473264\n",
      "Iteration 365 - Grad. Norm.: 0.002739357660829471 Norm. Diff.: 0.013719763178874722 tk: 5 x_norm: 11.471667204385106\n",
      "Iteration 366 - Grad. Norm.: 0.002734781266030468 Norm. Diff.: 0.013696788304147386 tk: 5 x_norm: 11.483079162979557\n",
      "Iteration 367 - Grad. Norm.: 0.002730223328492438 Norm. Diff.: 0.013673906330152407 tk: 5 x_norm: 11.494473173027002\n",
      "Iteration 368 - Grad. Norm.: 0.002725683726497365 Norm. Diff.: 0.013651116642462267 tk: 5 x_norm: 11.50584930677237\n",
      "Iteration 369 - Grad. Norm.: 0.0027211623394799017 Norm. Diff.: 0.013628418632486742 tk: 5 x_norm: 11.517207635940764\n",
      "Iteration 370 - Grad. Norm.: 0.0027166590480128413 Norm. Diff.: 0.013605811697399488 tk: 5 x_norm: 11.528548231742967\n",
      "Iteration 371 - Grad. Norm.: 0.0027121737337927965 Norm. Diff.: 0.013583295240064207 tk: 5 x_norm: 11.539871164880896\n",
      "Iteration 372 - Grad. Norm.: 0.0027077062796261346 Norm. Diff.: 0.013560868668963978 tk: 5 x_norm: 11.551176505552977\n",
      "Iteration 373 - Grad. Norm.: 0.002703256569415108 Norm. Diff.: 0.013538531398130738 tk: 5 x_norm: 11.562464323459444\n",
      "Iteration 374 - Grad. Norm.: 0.0026988244881442297 Norm. Diff.: 0.013516282847075541 tk: 5 x_norm: 11.573734687807564\n",
      "Iteration 375 - Grad. Norm.: 0.002694409921866849 Norm. Diff.: 0.013494122440721096 tk: 5 x_norm: 11.584987667316806\n",
      "Iteration 376 - Grad. Norm.: 0.0026900127576919473 Norm. Diff.: 0.013472049609334267 tk: 5 x_norm: 11.59622333022392\n",
      "Iteration 377 - Grad. Norm.: 0.0026856328837711343 Norm. Diff.: 0.013450063788459846 tk: 5 x_norm: 11.607441744287945\n",
      "Iteration 378 - Grad. Norm.: 0.0026812701892858595 Norm. Diff.: 0.013428164418855712 tk: 5 x_norm: 11.61864297679518\n",
      "Iteration 379 - Grad. Norm.: 0.0026769245644348086 Norm. Diff.: 0.013406350946429323 tk: 5 x_norm: 11.629827094564048\n",
      "Iteration 380 - Grad. Norm.: 0.0026725959004215067 Norm. Diff.: 0.013384622822174046 tk: 5 x_norm: 11.640994163949937\n",
      "Iteration 381 - Grad. Norm.: 0.002668284089442109 Norm. Diff.: 0.013362979502107552 tk: 5 x_norm: 11.652144250849926\n",
      "Iteration 382 - Grad. Norm.: 0.0026639890246733795 Norm. Diff.: 0.01334142044721058 tk: 5 x_norm: 11.6632774207075\n",
      "Iteration 383 - Grad. Norm.: 0.0026597106002608593 Norm. Diff.: 0.013319945123366922 tk: 5 x_norm: 11.674393738517159\n",
      "Iteration 384 - Grad. Norm.: 0.0026554487113072114 Norm. Diff.: 0.013298553001304253 tk: 5 x_norm: 11.685493268828996\n",
      "Iteration 385 - Grad. Norm.: 0.0026512032538607406 Norm. Diff.: 0.013277243556536035 tk: 5 x_norm: 11.696576075753201\n",
      "Iteration 386 - Grad. Norm.: 0.0026469741249041034 Norm. Diff.: 0.013256016269303741 tk: 5 x_norm: 11.707642222964509\n",
      "Iteration 387 - Grad. Norm.: 0.002642761222343163 Norm. Diff.: 0.013234870624520483 tk: 5 x_norm: 11.718691773706576\n",
      "Iteration 388 - Grad. Norm.: 0.002638564444996042 Norm. Diff.: 0.01321380611171585 tk: 5 x_norm: 11.729724790796325\n",
      "Iteration 389 - Grad. Norm.: 0.002634383692582316 Norm. Diff.: 0.013192822224980293 tk: 5 x_norm: 11.740741336628211\n",
      "Iteration 390 - Grad. Norm.: 0.002630218865712386 Norm. Diff.: 0.013171918462911554 tk: 5 x_norm: 11.751741473178447\n",
      "Iteration 391 - Grad. Norm.: 0.0026260698658769955 Norm. Diff.: 0.013151094328561923 tk: 5 x_norm: 11.76272526200915\n",
      "Iteration 392 - Grad. Norm.: 0.002621936595436917 Norm. Diff.: 0.013130349329384972 tk: 5 x_norm: 11.773692764272472\n",
      "Iteration 393 - Grad. Norm.: 0.002617818957612782 Norm. Diff.: 0.013109682977184582 tk: 5 x_norm: 11.784644040714635\n",
      "Iteration 394 - Grad. Norm.: 0.002613716856475067 Norm. Diff.: 0.013089094788063771 tk: 5 x_norm: 11.795579151679954\n",
      "Iteration 395 - Grad. Norm.: 0.002609630196934223 Norm. Diff.: 0.013068584282375386 tk: 5 x_norm: 11.806498157114778\n",
      "Iteration 396 - Grad. Norm.: 0.002605558884730955 Norm. Diff.: 0.013048150984671141 tk: 5 x_norm: 11.817401116571384\n",
      "Iteration 397 - Grad. Norm.: 0.0026015028264266367 Norm. Diff.: 0.013027794423654744 tk: 5 x_norm: 11.828288089211847\n",
      "Iteration 398 - Grad. Norm.: 0.0025974619293938745 Norm. Diff.: 0.013007514132133125 tk: 5 x_norm: 11.839159133811833\n",
      "Iteration 399 - Grad. Norm.: 0.0025934361018071983 Norm. Diff.: 0.012987309646969489 tk: 5 x_norm: 11.850014308764342\n",
      "Iteration 400 - Grad. Norm.: 0.002589425252633895 Norm. Diff.: 0.012967180509036103 tk: 5 x_norm: 11.860853672083437\n",
      "Iteration 401 - Grad. Norm.: 0.00258542929162497 Norm. Diff.: 0.012947126263169498 tk: 5 x_norm: 11.871677281407878\n",
      "Iteration 402 - Grad. Norm.: 0.002581448129306243 Norm. Diff.: 0.012927146458124891 tk: 5 x_norm: 11.882485194004758\n",
      "Iteration 403 - Grad. Norm.: 0.002577481676969569 Norm. Diff.: 0.012907240646531199 tk: 5 x_norm: 11.893277466773064\n",
      "Iteration 404 - Grad. Norm.: 0.0025735298466641773 Norm. Diff.: 0.012887408384847863 tk: 5 x_norm: 11.904054156247176\n",
      "Iteration 405 - Grad. Norm.: 0.0025695925511881514 Norm. Diff.: 0.012867649233320854 tk: 5 x_norm: 11.91481531860039\n",
      "Iteration 406 - Grad. Norm.: 0.0025656697040800157 Norm. Diff.: 0.01284796275594082 tk: 5 x_norm: 11.925561009648312\n",
      "Iteration 407 - Grad. Norm.: 0.002561761219610443 Norm. Diff.: 0.012828348520400048 tk: 5 x_norm: 11.936291284852281\n",
      "Iteration 408 - Grad. Norm.: 0.002557867012774085 Norm. Diff.: 0.012808806098052263 tk: 5 x_norm: 11.9470061993227\n",
      "Iteration 409 - Grad. Norm.: 0.002553986999281509 Norm. Diff.: 0.012789335063870446 tk: 5 x_norm: 11.957705807822352\n",
      "Iteration 410 - Grad. Norm.: 0.002550121095551259 Norm. Diff.: 0.012769934996407585 tk: 5 x_norm: 11.968390164769668\n",
      "Iteration 411 - Grad. Norm.: 0.0025462692187020164 Norm. Diff.: 0.012750605477756256 tk: 5 x_norm: 11.979059324241948\n",
      "Iteration 412 - Grad. Norm.: 0.0025424312865448785 Norm. Diff.: 0.012731346093509961 tk: 5 x_norm: 11.989713339978575\n",
      "Iteration 413 - Grad. Norm.: 0.0025386072175757335 Norm. Diff.: 0.012712156432724404 tk: 5 x_norm: 12.000352265384127\n",
      "Iteration 414 - Grad. Norm.: 0.0025347969309677553 Norm. Diff.: 0.012693036087878702 tk: 5 x_norm: 12.01097615353151\n",
      "Iteration 415 - Grad. Norm.: 0.002531000346563991 Norm. Diff.: 0.012673984654838773 tk: 5 x_norm: 12.02158505716503\n",
      "Iteration 416 - Grad. Norm.: 0.0025272173848700534 Norm. Diff.: 0.012655001732819965 tk: 5 x_norm: 12.032179028703426\n",
      "Iteration 417 - Grad. Norm.: 0.002523447967046912 Norm. Diff.: 0.01263608692435023 tk: 5 x_norm: 12.042758120242869\n",
      "Iteration 418 - Grad. Norm.: 0.0025196920149037866 Norm. Diff.: 0.012617239835234483 tk: 5 x_norm: 12.053322383559914\n",
      "Iteration 419 - Grad. Norm.: 0.002515949450891135 Norm. Diff.: 0.012598460074518928 tk: 5 x_norm: 12.063871870114452\n",
      "Iteration 420 - Grad. Norm.: 0.002512220198093739 Norm. Diff.: 0.012579747254455764 tk: 5 x_norm: 12.074406631052574\n",
      "Iteration 421 - Grad. Norm.: 0.002508504180223868 Norm. Diff.: 0.012561100990468688 tk: 5 x_norm: 12.084926717209447\n",
      "Iteration 422 - Grad. Norm.: 0.002504801321614565 Norm. Diff.: 0.012542520901119422 tk: 5 x_norm: 12.095432179112136\n",
      "Iteration 423 - Grad. Norm.: 0.002501111547212996 Norm. Diff.: 0.012524006608072848 tk: 5 x_norm: 12.105923066982369\n",
      "Iteration 424 - Grad. Norm.: 0.002497434782573899 Norm. Diff.: 0.01250555773606494 tk: 5 x_norm: 12.116399430739335\n",
      "Iteration 425 - Grad. Norm.: 0.0024937709538531212 Norm. Diff.: 0.0124871739128695 tk: 5 x_norm: 12.12686132000237\n",
      "Iteration 426 - Grad. Norm.: 0.002490119987801236 Norm. Diff.: 0.012468854769265647 tk: 5 x_norm: 12.137308784093664\n",
      "Iteration 427 - Grad. Norm.: 0.0024864818117572587 Norm. Diff.: 0.01245059993900623 tk: 5 x_norm: 12.14774187204093\n",
      "Iteration 428 - Grad. Norm.: 0.002482856353642427 Norm. Diff.: 0.012432409058786247 tk: 5 x_norm: 12.158160632580003\n",
      "Iteration 429 - Grad. Norm.: 0.0024792435419540766 Norm. Diff.: 0.012414281768212165 tk: 5 x_norm: 12.168565114157474\n",
      "Iteration 430 - Grad. Norm.: 0.002475643305759599 Norm. Diff.: 0.012396217709770396 tk: 5 x_norm: 12.178955364933236\n",
      "Iteration 431 - Grad. Norm.: 0.002472055574690458 Norm. Diff.: 0.012378216528798109 tk: 5 x_norm: 12.189331432783012\n",
      "Iteration 432 - Grad. Norm.: 0.002468480278936317 Norm. Diff.: 0.012360277873452294 tk: 5 x_norm: 12.199693365300892\n",
      "Iteration 433 - Grad. Norm.: 0.0024649173492392136 Norm. Diff.: 0.012342401394681625 tk: 5 x_norm: 12.21004120980178\n",
      "Iteration 434 - Grad. Norm.: 0.002461366716887827 Norm. Diff.: 0.012324586746196135 tk: 5 x_norm: 12.22037501332386\n",
      "Iteration 435 - Grad. Norm.: 0.0024578283137118135 Norm. Diff.: 0.01230683358443918 tk: 5 x_norm: 12.23069482263103\n",
      "Iteration 436 - Grad. Norm.: 0.002454302072076215 Norm. Diff.: 0.012289141568559087 tk: 5 x_norm: 12.241000684215265\n",
      "Iteration 437 - Grad. Norm.: 0.0024507879248759426 Norm. Diff.: 0.01227151036038108 tk: 5 x_norm: 12.251292644299005\n",
      "Iteration 438 - Grad. Norm.: 0.002447285805530331 Norm. Diff.: 0.012253939624379796 tk: 5 x_norm: 12.261570748837485\n",
      "Iteration 439 - Grad. Norm.: 0.0024437956479777525 Norm. Diff.: 0.012236429027651737 tk: 5 x_norm: 12.271835043521058\n",
      "Iteration 440 - Grad. Norm.: 0.0024403173866703225 Norm. Diff.: 0.012218978239888776 tk: 5 x_norm: 12.282085573777469\n",
      "Iteration 441 - Grad. Norm.: 0.002436850956568645 Norm. Diff.: 0.012201586933351627 tk: 5 x_norm: 12.292322384774119\n",
      "Iteration 442 - Grad. Norm.: 0.0024333962931366447 Norm. Diff.: 0.012184254782843299 tk: 5 x_norm: 12.3025455214203\n",
      "Iteration 443 - Grad. Norm.: 0.0024299533323364603 Norm. Diff.: 0.012166981465683261 tk: 5 x_norm: 12.312755028369404\n",
      "Iteration 444 - Grad. Norm.: 0.0024265220106233915 Norm. Diff.: 0.012149766661682306 tk: 5 x_norm: 12.322950950021108\n",
      "Iteration 445 - Grad. Norm.: 0.0024231022649409267 Norm. Diff.: 0.012132610053116917 tk: 5 x_norm: 12.33313333052353\n",
      "Iteration 446 - Grad. Norm.: 0.002419694032715823 Norm. Diff.: 0.012115511324704644 tk: 5 x_norm: 12.343302213775374\n",
      "Iteration 447 - Grad. Norm.: 0.002416297251853246 Norm. Diff.: 0.012098470163579062 tk: 5 x_norm: 12.353457643428015\n",
      "Iteration 448 - Grad. Norm.: 0.002412911860731978 Norm. Diff.: 0.012081486259266203 tk: 5 x_norm: 12.363599662887632\n",
      "Iteration 449 - Grad. Norm.: 0.002409537798199679 Norm. Diff.: 0.012064559303659822 tk: 5 x_norm: 12.37372831531723\n",
      "Iteration 450 - Grad. Norm.: 0.0024061750035682112 Norm. Diff.: 0.012047688990998439 tk: 5 x_norm: 12.383843643638702\n",
      "Iteration 451 - Grad. Norm.: 0.0024028234166090182 Norm. Diff.: 0.012030875017841029 tk: 5 x_norm: 12.39394569053484\n",
      "Iteration 452 - Grad. Norm.: 0.0023994829775485656 Norm. Diff.: 0.012014117083045135 tk: 5 x_norm: 12.404034498451344\n",
      "Iteration 453 - Grad. Norm.: 0.002396153627063832 Norm. Diff.: 0.01199741488774283 tk: 5 x_norm: 12.414110109598779\n",
      "Iteration 454 - Grad. Norm.: 0.002392835306277859 Norm. Diff.: 0.011980768135319095 tk: 5 x_norm: 12.42417256595455\n",
      "Iteration 455 - Grad. Norm.: 0.002389527956755357 Norm. Diff.: 0.011964176531389308 tk: 5 x_norm: 12.434221909264807\n",
      "Iteration 456 - Grad. Norm.: 0.002386231520498361 Norm. Diff.: 0.011947639783776718 tk: 5 x_norm: 12.444258181046372\n",
      "Iteration 457 - Grad. Norm.: 0.0023829459399419438 Norm. Diff.: 0.011931157602491832 tk: 5 x_norm: 12.454281422588636\n",
      "Iteration 458 - Grad. Norm.: 0.002379671157949976 Norm. Diff.: 0.011914729699709537 tk: 5 x_norm: 12.46429167495541\n",
      "Iteration 459 - Grad. Norm.: 0.002376407117810941 Norm. Diff.: 0.01189835578974982 tk: 5 x_norm: 12.474288978986781\n",
      "Iteration 460 - Grad. Norm.: 0.0023731537632337993 Norm. Diff.: 0.011882035589054783 tk: 5 x_norm: 12.484273375300935\n",
      "Iteration 461 - Grad. Norm.: 0.0023699110383439094 Norm. Diff.: 0.011865768816169017 tk: 5 x_norm: 12.49424490429599\n",
      "Iteration 462 - Grad. Norm.: 0.0023666788876789825 Norm. Diff.: 0.011849555191719558 tk: 5 x_norm: 12.50420360615174\n",
      "Iteration 463 - Grad. Norm.: 0.0023634572561851024 Norm. Diff.: 0.011833394438394915 tk: 5 x_norm: 12.51414952083148\n",
      "Iteration 464 - Grad. Norm.: 0.0023602460892127794 Norm. Diff.: 0.011817286280925593 tk: 5 x_norm: 12.524082688083707\n",
      "Iteration 465 - Grad. Norm.: 0.002357045332513067 Norm. Diff.: 0.011801230446063913 tk: 5 x_norm: 12.534003147443888\n",
      "Iteration 466 - Grad. Norm.: 0.0023538549322337037 Norm. Diff.: 0.011785226662565436 tk: 5 x_norm: 12.543910938236154\n",
      "Iteration 467 - Grad. Norm.: 0.0023506748349153223 Norm. Diff.: 0.011769274661168632 tk: 5 x_norm: 12.553806099575004\n",
      "Iteration 468 - Grad. Norm.: 0.0023475049874876904 Norm. Diff.: 0.011753374174576598 tk: 5 x_norm: 12.563688670366975\n",
      "Iteration 469 - Grad. Norm.: 0.002344345337265999 Norm. Diff.: 0.011737524937438359 tk: 5 x_norm: 12.573558689312314\n",
      "Iteration 470 - Grad. Norm.: 0.002341195831947194 Norm. Diff.: 0.011721726686330137 tk: 5 x_norm: 12.583416194906608\n",
      "Iteration 471 - Grad. Norm.: 0.0023380564196063577 Norm. Diff.: 0.01170597915973592 tk: 5 x_norm: 12.593261225442415\n",
      "Iteration 472 - Grad. Norm.: 0.0023349270486931204 Norm. Diff.: 0.011690282098031761 tk: 5 x_norm: 12.603093819010875\n",
      "Iteration 473 - Grad. Norm.: 0.002331807668028127 Norm. Diff.: 0.011674635243465653 tk: 5 x_norm: 12.61291401350329\n",
      "Iteration 474 - Grad. Norm.: 0.0023286982267995316 Norm. Diff.: 0.011659038340140782 tk: 5 x_norm: 12.622721846612702\n",
      "Iteration 475 - Grad. Norm.: 0.0023255986745595457 Norm. Diff.: 0.011643491133997723 tk: 5 x_norm: 12.632517355835468\n",
      "Iteration 476 - Grad. Norm.: 0.0023225089612210225 Norm. Diff.: 0.011627993372797806 tk: 5 x_norm: 12.642300578472776\n",
      "Iteration 477 - Grad. Norm.: 0.0023194290370540677 Norm. Diff.: 0.011612544806105123 tk: 5 x_norm: 12.652071551632174\n",
      "Iteration 478 - Grad. Norm.: 0.0023163588526827175 Norm. Diff.: 0.011597145185270332 tk: 5 x_norm: 12.661830312229105\n",
      "Iteration 479 - Grad. Norm.: 0.0023132983590816265 Norm. Diff.: 0.011581794263413566 tk: 5 x_norm: 12.67157689698837\n",
      "Iteration 480 - Grad. Norm.: 0.002310247507572807 Norm. Diff.: 0.011566491795408133 tk: 5 x_norm: 12.68131134244562\n",
      "Iteration 481 - Grad. Norm.: 0.0023072062498224106 Norm. Diff.: 0.011551237537863978 tk: 5 x_norm: 12.691033684948826\n",
      "Iteration 482 - Grad. Norm.: 0.002304174537837534 Norm. Diff.: 0.011536031249112082 tk: 5 x_norm: 12.700743960659711\n",
      "Iteration 483 - Grad. Norm.: 0.0023011523239630707 Norm. Diff.: 0.011520872689187618 tk: 5 x_norm: 12.710442205555198\n",
      "Iteration 484 - Grad. Norm.: 0.0022981395608785964 Norm. Diff.: 0.011505761619815433 tk: 5 x_norm: 12.720128455428824\n",
      "Iteration 485 - Grad. Norm.: 0.0022951362015952888 Norm. Diff.: 0.011490697804392963 tk: 5 x_norm: 12.729802745892142\n",
      "Iteration 486 - Grad. Norm.: 0.0022921421994528783 Norm. Diff.: 0.011475681007976461 tk: 5 x_norm: 12.739465112376108\n",
      "Iteration 487 - Grad. Norm.: 0.0022891575081166486 Norm. Diff.: 0.011460710997264426 tk: 5 x_norm: 12.74911559013246\n",
      "Iteration 488 - Grad. Norm.: 0.0022861820815744463 Norm. Diff.: 0.011445787540583263 tk: 5 x_norm: 12.758754214235095\n",
      "Iteration 489 - Grad. Norm.: 0.0022832158741337484 Norm. Diff.: 0.011430910407872193 tk: 5 x_norm: 12.768381019581385\n",
      "Iteration 490 - Grad. Norm.: 0.00228025884041875 Norm. Diff.: 0.011416079370668806 tk: 5 x_norm: 12.777996040893544\n",
      "Iteration 491 - Grad. Norm.: 0.002277310935367486 Norm. Diff.: 0.011401294202093801 tk: 5 x_norm: 12.787599312719921\n",
      "Iteration 492 - Grad. Norm.: 0.0022743721142289897 Norm. Diff.: 0.011386554676837466 tk: 5 x_norm: 12.797190869436331\n",
      "Iteration 493 - Grad. Norm.: 0.0022714423325604725 Norm. Diff.: 0.011371860571145058 tk: 5 x_norm: 12.806770745247338\n",
      "Iteration 494 - Grad. Norm.: 0.002268521546224551 Norm. Diff.: 0.011357211662802442 tk: 5 x_norm: 12.816338974187536\n",
      "Iteration 495 - Grad. Norm.: 0.0022656097113864944 Norm. Diff.: 0.011342607731122818 tk: 5 x_norm: 12.825895590122817\n",
      "Iteration 496 - Grad. Norm.: 0.002262706784511497 Norm. Diff.: 0.01132804855693243 tk: 5 x_norm: 12.835440626751643\n",
      "Iteration 497 - Grad. Norm.: 0.002259812722361998 Norm. Diff.: 0.011313533922557427 tk: 5 x_norm: 12.844974117606261\n",
      "Iteration 498 - Grad. Norm.: 0.0022569274819950152 Norm. Diff.: 0.011299063611809856 tk: 5 x_norm: 12.854496096053966\n",
      "Iteration 499 - Grad. Norm.: 0.0022540510207595173 Norm. Diff.: 0.011284637409975073 tk: 5 x_norm: 12.864006595298294\n",
      "Iteration 500 - Grad. Norm.: 0.0022511832962938197 Norm. Diff.: 0.011270255103797512 tk: 5 x_norm: 12.873505648380243\n",
      "Iteration 501 - Grad. Norm.: 0.0022483242665230128 Norm. Diff.: 0.01125591648146907 tk: 5 x_norm: 12.88299328817947\n",
      "Iteration 502 - Grad. Norm.: 0.002245473889656417 Norm. Diff.: 0.01124162133261511 tk: 5 x_norm: 12.892469547415468\n",
      "Iteration 503 - Grad. Norm.: 0.002242632124185063 Norm. Diff.: 0.011227369448282001 tk: 5 x_norm: 12.901934458648729\n",
      "Iteration 504 - Grad. Norm.: 0.0022397989288792017 Norm. Diff.: 0.011213160620925347 tk: 5 x_norm: 12.911388054281936\n",
      "Iteration 505 - Grad. Norm.: 0.0022369742627858483 Norm. Diff.: 0.011198994644395993 tk: 5 x_norm: 12.920830366561077\n",
      "Iteration 506 - Grad. Norm.: 0.002234158085226336 Norm. Diff.: 0.011184871313929218 tk: 5 x_norm: 12.9302614275766\n",
      "Iteration 507 - Grad. Norm.: 0.0022313503557939147 Norm. Diff.: 0.0111707904261316 tk: 5 x_norm: 12.939681269264542\n",
      "Iteration 508 - Grad. Norm.: 0.002228551034351362 Norm. Diff.: 0.011156751778969503 tk: 5 x_norm: 12.949089923407634\n",
      "Iteration 509 - Grad. Norm.: 0.002225760081028628 Norm. Diff.: 0.011142755171756901 tk: 5 x_norm: 12.958487421636422\n",
      "Iteration 510 - Grad. Norm.: 0.002222977456220503 Norm. Diff.: 0.011128800405143208 tk: 5 x_norm: 12.967873795430341\n",
      "Iteration 511 - Grad. Norm.: 0.002220203120584311 Norm. Diff.: 0.01111488728110252 tk: 5 x_norm: 12.977249076118822\n",
      "Iteration 512 - Grad. Norm.: 0.002217437035037624 Norm. Diff.: 0.01110101560292159 tk: 5 x_norm: 12.986613294882341\n",
      "Iteration 513 - Grad. Norm.: 0.002214679160756005 Norm. Diff.: 0.011087185175188046 tk: 5 x_norm: 12.99596648275351\n",
      "Iteration 514 - Grad. Norm.: 0.002211929459170776 Norm. Diff.: 0.011073395803780058 tk: 5 x_norm: 13.005308670618097\n",
      "Iteration 515 - Grad. Norm.: 0.002209187891966806 Norm. Diff.: 0.011059647295853856 tk: 5 x_norm: 13.014639889216108\n",
      "Iteration 516 - Grad. Norm.: 0.002206454421080324 Norm. Diff.: 0.011045939459834089 tk: 5 x_norm: 13.02396016914278\n",
      "Iteration 517 - Grad. Norm.: 0.002203729008696758 Norm. Diff.: 0.011032272105401662 tk: 5 x_norm: 13.03326954084964\n",
      "Iteration 518 - Grad. Norm.: 0.0022010116172485896 Norm. Diff.: 0.011018645043483813 tk: 5 x_norm: 13.042568034645486\n",
      "Iteration 519 - Grad. Norm.: 0.0021983022094132425 Norm. Diff.: 0.011005058086242907 tk: 5 x_norm: 13.051855680697416\n",
      "Iteration 520 - Grad. Norm.: 0.00219560074811098 Norm. Diff.: 0.01099151104706617 tk: 5 x_norm: 13.061132509031818\n",
      "Iteration 521 - Grad. Norm.: 0.002192907196502838 Norm. Diff.: 0.010978003740554791 tk: 5 x_norm: 13.070398549535337\n",
      "Iteration 522 - Grad. Norm.: 0.0021902215179885717 Norm. Diff.: 0.010964535982514139 tk: 5 x_norm: 13.079653831955873\n",
      "Iteration 523 - Grad. Norm.: 0.0021875436762046176 Norm. Diff.: 0.010951107589942869 tk: 5 x_norm: 13.088898385903539\n",
      "Iteration 524 - Grad. Norm.: 0.0021848736350220986 Norm. Diff.: 0.010937718381023018 tk: 5 x_norm: 13.098132240851612\n",
      "Iteration 525 - Grad. Norm.: 0.0021822113585448256 Norm. Diff.: 0.010924368175110648 tk: 5 x_norm: 13.107355426137506\n",
      "Iteration 526 - Grad. Norm.: 0.002179556811107335 Norm. Diff.: 0.010911056792724201 tk: 5 x_norm: 13.116567970963663\n",
      "Iteration 527 - Grad. Norm.: 0.0021769099572729353 Norm. Diff.: 0.01089778405553664 tk: 5 x_norm: 13.125769904398545\n",
      "Iteration 528 - Grad. Norm.: 0.0021742707618317932 Norm. Diff.: 0.010884549786364698 tk: 5 x_norm: 13.134961255377506\n",
      "Iteration 529 - Grad. Norm.: 0.002171639189799015 Norm. Diff.: 0.010871353809158994 tk: 5 x_norm: 13.144142052703733\n",
      "Iteration 530 - Grad. Norm.: 0.0021690152064127656 Norm. Diff.: 0.010858195948994995 tk: 5 x_norm: 13.153312325049146\n",
      "Iteration 531 - Grad. Norm.: 0.002166398777132401 Norm. Diff.: 0.010845076032063824 tk: 5 x_norm: 13.162472100955295\n",
      "Iteration 532 - Grad. Norm.: 0.00216378986763662 Norm. Diff.: 0.010831993885662028 tk: 5 x_norm: 13.171621408834236\n",
      "Iteration 533 - Grad. Norm.: 0.0021611884438216345 Norm. Diff.: 0.010818949338183174 tk: 5 x_norm: 13.180760276969439\n",
      "Iteration 534 - Grad. Norm.: 0.002158594471799357 Norm. Diff.: 0.010805942219108213 tk: 5 x_norm: 13.189888733516623\n",
      "Iteration 535 - Grad. Norm.: 0.0021560079178956164 Norm. Diff.: 0.010792972358996894 tk: 5 x_norm: 13.199006806504663\n",
      "Iteration 536 - Grad. Norm.: 0.002153428748648377 Norm. Diff.: 0.010780039589478022 tk: 5 x_norm: 13.20811452383641\n",
      "Iteration 537 - Grad. Norm.: 0.0021508569308059857 Norm. Diff.: 0.010767143743241763 tk: 5 x_norm: 13.217211913289562\n",
      "Iteration 538 - Grad. Norm.: 0.002148292431325438 Norm. Diff.: 0.010754284654029916 tk: 5 x_norm: 13.226299002517496\n",
      "Iteration 539 - Grad. Norm.: 0.0021457352173706525 Norm. Diff.: 0.010741462156627213 tk: 5 x_norm: 13.235375819050104\n",
      "Iteration 540 - Grad. Norm.: 0.0021431852563107735 Norm. Diff.: 0.01072867608685346 tk: 5 x_norm: 13.244442390294614\n",
      "Iteration 541 - Grad. Norm.: 0.002140642515718487 Norm. Diff.: 0.010715926281553833 tk: 5 x_norm: 13.253498743536412\n",
      "Iteration 542 - Grad. Norm.: 0.002138106963368345 Norm. Diff.: 0.01070321257859244 tk: 5 x_norm: 13.26254490593986\n",
      "Iteration 543 - Grad. Norm.: 0.0021355785672351243 Norm. Diff.: 0.01069053481684174 tk: 5 x_norm: 13.271580904549095\n",
      "Iteration 544 - Grad. Norm.: 0.0021330572954921857 Norm. Diff.: 0.010677892836175772 tk: 5 x_norm: 13.280606766288804\n",
      "Iteration 545 - Grad. Norm.: 0.0021305431165098625 Norm. Diff.: 0.01066528647746088 tk: 5 x_norm: 13.28962251796506\n",
      "Iteration 546 - Grad. Norm.: 0.002128035998853847 Norm. Diff.: 0.010652715582549266 tk: 5 x_norm: 13.298628186266054\n",
      "Iteration 547 - Grad. Norm.: 0.002125535911283619 Norm. Diff.: 0.010640179994269246 tk: 5 x_norm: 13.30762379776291\n",
      "Iteration 548 - Grad. Norm.: 0.0021230428227508665 Norm. Diff.: 0.010627679556418116 tk: 5 x_norm: 13.316609378910421\n",
      "Iteration 549 - Grad. Norm.: 0.0021205567023979376 Norm. Diff.: 0.01061521411375443 tk: 5 x_norm: 13.325584956047843\n",
      "Iteration 550 - Grad. Norm.: 0.0021180775195562963 Norm. Diff.: 0.010602783511989688 tk: 5 x_norm: 13.334550555399616\n",
      "Iteration 551 - Grad. Norm.: 0.002115605243745003 Norm. Diff.: 0.01059038759778148 tk: 5 x_norm: 13.343506203076144\n",
      "Iteration 552 - Grad. Norm.: 0.002113139844669208 Norm. Diff.: 0.010578026218724982 tk: 5 x_norm: 13.352451925074503\n",
      "Iteration 553 - Grad. Norm.: 0.002110681292218653 Norm. Diff.: 0.010565699223346072 tk: 5 x_norm: 13.361387747279217\n",
      "Iteration 554 - Grad. Norm.: 0.0021082295564662005 Norm. Diff.: 0.010553406461093312 tk: 5 x_norm: 13.370313695462938\n",
      "Iteration 555 - Grad. Norm.: 0.00210578460766636 Norm. Diff.: 0.010541147782331048 tk: 5 x_norm: 13.379229795287218\n",
      "Iteration 556 - Grad. Norm.: 0.0021033464162538477 Norm. Diff.: 0.010528923038331795 tk: 5 x_norm: 13.388136072303181\n",
      "Iteration 557 - Grad. Norm.: 0.0021009149528421487 Norm. Diff.: 0.010516732081269298 tk: 5 x_norm: 13.39703255195226\n",
      "Iteration 558 - Grad. Norm.: 0.0020984901882220956 Norm. Diff.: 0.010504574764210753 tk: 5 x_norm: 13.405919259566888\n",
      "Iteration 559 - Grad. Norm.: 0.002096072093360458 Norm. Diff.: 0.01049245094111047 tk: 5 x_norm: 13.414796220371205\n",
      "Iteration 560 - Grad. Norm.: 0.0020936606393985595 Norm. Diff.: 0.0104803604668023 tk: 5 x_norm: 13.423663459481737\n",
      "Iteration 561 - Grad. Norm.: 0.002091255797650888 Norm. Diff.: 0.010468303196992868 tk: 5 x_norm: 13.432521001908084\n",
      "Iteration 562 - Grad. Norm.: 0.002088857539603734 Norm. Diff.: 0.010456278988254481 tk: 5 x_norm: 13.441368872553607\n",
      "Iteration 563 - Grad. Norm.: 0.002086465836913839 Norm. Diff.: 0.010444287698018705 tk: 5 x_norm: 13.450207096216094\n",
      "Iteration 564 - Grad. Norm.: 0.002084080661407054 Norm. Diff.: 0.010432329184569314 tk: 5 x_norm: 13.459035697588432\n",
      "Iteration 565 - Grad. Norm.: 0.0020817019850770126 Norm. Diff.: 0.010420403307035232 tk: 5 x_norm: 13.467854701259261\n",
      "Iteration 566 - Grad. Norm.: 0.002079329780083819 Norm. Diff.: 0.010408509925385145 tk: 5 x_norm: 13.47666413171363\n",
      "Iteration 567 - Grad. Norm.: 0.00207696401875275 Norm. Diff.: 0.010396648900419043 tk: 5 x_norm: 13.485464013333663\n",
      "Iteration 568 - Grad. Norm.: 0.0020746046735729577 Norm. Diff.: 0.010384820093763725 tk: 5 x_norm: 13.494254370399185\n",
      "Iteration 569 - Grad. Norm.: 0.0020722517171962045 Norm. Diff.: 0.010373023367864736 tk: 5 x_norm: 13.503035227088368\n",
      "Iteration 570 - Grad. Norm.: 0.0020699051224355902 Norm. Diff.: 0.010361258585980984 tk: 5 x_norm: 13.511806607478375\n",
      "Iteration 571 - Grad. Norm.: 0.0020675648622643108 Norm. Diff.: 0.010349525612177963 tk: 5 x_norm: 13.520568535545964\n",
      "Iteration 572 - Grad. Norm.: 0.002065230909814404 Norm. Diff.: 0.010337824311321435 tk: 5 x_norm: 13.529321035168133\n",
      "Iteration 573 - Grad. Norm.: 0.0020629032383755403 Norm. Diff.: 0.010326154549072092 tk: 5 x_norm: 13.53806413012273\n",
      "Iteration 574 - Grad. Norm.: 0.002060581821393791 Norm. Diff.: 0.010314516191877614 tk: 5 x_norm: 13.546797844089069\n",
      "Iteration 575 - Grad. Norm.: 0.0020582666324704345 Norm. Diff.: 0.01030290910696899 tk: 5 x_norm: 13.555522200648529\n",
      "Iteration 576 - Grad. Norm.: 0.0020559576453607602 Norm. Diff.: 0.010291333162352182 tk: 5 x_norm: 13.564237223285161\n",
      "Iteration 577 - Grad. Norm.: 0.0020536548339728862 Norm. Diff.: 0.010279788226803812 tk: 5 x_norm: 13.572942935386285\n",
      "Iteration 578 - Grad. Norm.: 0.002051358172366591 Norm. Diff.: 0.010268274169864344 tk: 5 x_norm: 13.58163936024309\n",
      "Iteration 579 - Grad. Norm.: 0.002049067634752153 Norm. Diff.: 0.010256790861832931 tk: 5 x_norm: 13.590326521051196\n",
      "Iteration 580 - Grad. Norm.: 0.0020467831954892025 Norm. Diff.: 0.010245338173760648 tk: 5 x_norm: 13.599004440911278\n",
      "Iteration 581 - Grad. Norm.: 0.002044504829085591 Norm. Diff.: 0.01023391597744599 tk: 5 x_norm: 13.607673142829594\n",
      "Iteration 582 - Grad. Norm.: 0.0020422325101962504 Norm. Diff.: 0.010222524145427972 tk: 5 x_norm: 13.616332649718599\n",
      "Iteration 583 - Grad. Norm.: 0.0020399662136220955 Norm. Diff.: 0.01021116255098131 tk: 5 x_norm: 13.624982984397487\n",
      "Iteration 584 - Grad. Norm.: 0.0020377059143089054 Norm. Diff.: 0.010199831068110518 tk: 5 x_norm: 13.633624169592773\n",
      "Iteration 585 - Grad. Norm.: 0.0020354515873462348 Norm. Diff.: 0.010188529571544511 tk: 5 x_norm: 13.642256227938828\n",
      "Iteration 586 - Grad. Norm.: 0.002033203207966327 Norm. Diff.: 0.010177257936731035 tk: 5 x_norm: 13.650879181978459\n",
      "Iteration 587 - Grad. Norm.: 0.0020309607515430423 Norm. Diff.: 0.010166016039831756 tk: 5 x_norm: 13.659493054163432\n",
      "Iteration 588 - Grad. Norm.: 0.002028724193590787 Norm. Diff.: 0.010154803757715252 tk: 5 x_norm: 13.668097866855044\n",
      "Iteration 589 - Grad. Norm.: 0.002026493509763471 Norm. Diff.: 0.010143620967953914 tk: 5 x_norm: 13.67669364232464\n",
      "Iteration 590 - Grad. Norm.: 0.002024268675853451 Norm. Diff.: 0.010132467548817355 tk: 5 x_norm: 13.685280402754158\n",
      "Iteration 591 - Grad. Norm.: 0.0020220496677905053 Norm. Diff.: 0.01012134337926725 tk: 5 x_norm: 13.693858170236668\n",
      "Iteration 592 - Grad. Norm.: 0.002019836461640802 Norm. Diff.: 0.01011024833895254 tk: 5 x_norm: 13.702426966776882\n",
      "Iteration 593 - Grad. Norm.: 0.0020176290336058876 Norm. Diff.: 0.010099182308203945 tk: 5 x_norm: 13.710986814291688\n",
      "Iteration 594 - Grad. Norm.: 0.0020154273600216798 Norm. Diff.: 0.010088145168029503 tk: 5 x_norm: 13.719537734610673\n",
      "Iteration 595 - Grad. Norm.: 0.002013231417357463 Norm. Diff.: 0.010077136800108442 tk: 5 x_norm: 13.728079749476619\n",
      "Iteration 596 - Grad. Norm.: 0.002011041182214921 Norm. Diff.: 0.010066157086787321 tk: 5 x_norm: 13.736612880546033\n",
      "Iteration 597 - Grad. Norm.: 0.002008856631327134 Norm. Diff.: 0.010055205911074599 tk: 5 x_norm: 13.745137149389645\n",
      "Iteration 598 - Grad. Norm.: 0.0020066777415576257 Norm. Diff.: 0.010044283156635627 tk: 5 x_norm: 13.753652577492906\n",
      "Iteration 599 - Grad. Norm.: 0.002004504489899398 Norm. Diff.: 0.010033388707788015 tk: 5 x_norm: 13.762159186256486\n",
      "Iteration 600 - Grad. Norm.: 0.0020023368534739733 Norm. Diff.: 0.0100225224494969 tk: 5 x_norm: 13.770656996996777\n",
      "Iteration 601 - Grad. Norm.: 0.002000174809530463 Norm. Diff.: 0.01001168426736978 tk: 5 x_norm: 13.779146030946373\n",
      "Iteration 602 - Grad. Norm.: 0.0019980183354446263 Norm. Diff.: 0.010000874047652384 tk: 5 x_norm: 13.787626309254563\n",
      "Iteration 603 - Grad. Norm.: 0.00199586740871794 Norm. Diff.: 0.00999009167722307 tk: 5 x_norm: 13.796097852987808\n",
      "Iteration 604 - Grad. Norm.: 0.001993722006976691 Norm. Diff.: 0.00997933704358969 tk: 5 x_norm: 13.804560683130212\n",
      "Iteration 605 - Grad. Norm.: 0.001991582107971064 Norm. Diff.: 0.009968610034883595 tk: 5 x_norm: 13.813014820584025\n",
      "Iteration 606 - Grad. Norm.: 0.001989447689574232 Norm. Diff.: 0.009957910539855251 tk: 5 x_norm: 13.821460286170076\n",
      "Iteration 607 - Grad. Norm.: 0.0019873187297814784 Norm. Diff.: 0.009947238447871078 tk: 5 x_norm: 13.82989710062826\n",
      "Iteration 608 - Grad. Norm.: 0.001985195206709301 Norm. Diff.: 0.009936593648907519 tk: 5 x_norm: 13.838325284618007\n",
      "Iteration 609 - Grad. Norm.: 0.0019830770985945424 Norm. Diff.: 0.00992597603354643 tk: 5 x_norm: 13.84674485871872\n",
      "Iteration 610 - Grad. Norm.: 0.0019809643837935174 Norm. Diff.: 0.009915385492972842 tk: 5 x_norm: 13.855155843430262\n",
      "Iteration 611 - Grad. Norm.: 0.001978857040781151 Norm. Diff.: 0.009904821918967618 tk: 5 x_norm: 13.863558259173372\n",
      "Iteration 612 - Grad. Norm.: 0.0019767550481501347 Norm. Diff.: 0.00989428520390574 tk: 5 x_norm: 13.871952126290141\n",
      "Iteration 613 - Grad. Norm.: 0.0019746583846100697 Norm. Diff.: 0.009883775240750663 tk: 5 x_norm: 13.880337465044446\n",
      "Iteration 614 - Grad. Norm.: 0.001972567028986634 Norm. Diff.: 0.00987329192305033 tk: 5 x_norm: 13.888714295622394\n",
      "Iteration 615 - Grad. Norm.: 0.0019704809602207577 Norm. Diff.: 0.009862835144933213 tk: 5 x_norm: 13.89708263813276\n",
      "Iteration 616 - Grad. Norm.: 0.001968400157367791 Norm. Diff.: 0.00985240480110379 tk: 5 x_norm: 13.90544251260742\n",
      "Iteration 617 - Grad. Norm.: 0.0019663245995966945 Norm. Diff.: 0.00984200078683892 tk: 5 x_norm: 13.913793939001788\n",
      "Iteration 618 - Grad. Norm.: 0.0019642542661892294 Norm. Diff.: 0.009831622997983435 tk: 5 x_norm: 13.922136937195233\n",
      "Iteration 619 - Grad. Norm.: 0.001962189136539159 Norm. Diff.: 0.009821271330946147 tk: 5 x_norm: 13.930471526991518\n",
      "Iteration 620 - Grad. Norm.: 0.0019601291901514524 Norm. Diff.: 0.009810945682695726 tk: 5 x_norm: 13.938797728119212\n",
      "Iteration 621 - Grad. Norm.: 0.001958074406641498 Norm. Diff.: 0.009800645950757128 tk: 5 x_norm: 13.947115560232106\n",
      "Iteration 622 - Grad. Norm.: 0.0019560247657343264 Norm. Diff.: 0.00979037203320746 tk: 5 x_norm: 13.955425042909644\n",
      "Iteration 623 - Grad. Norm.: 0.0019539802472638332 Norm. Diff.: 0.009780123828671695 tk: 5 x_norm: 13.963726195657312\n",
      "Iteration 624 - Grad. Norm.: 0.0019519408311720187 Norm. Diff.: 0.009769901236319219 tk: 5 x_norm: 13.972019037907057\n",
      "Iteration 625 - Grad. Norm.: 0.001949906497508225 Norm. Diff.: 0.009759704155860192 tk: 5 x_norm: 13.980303589017707\n",
      "Iteration 626 - Grad. Norm.: 0.0019478772264283854 Norm. Diff.: 0.009749532487541172 tk: 5 x_norm: 13.988579868275341\n",
      "Iteration 627 - Grad. Norm.: 0.0019458529981942767 Norm. Diff.: 0.009739386132141925 tk: 5 x_norm: 13.99684789489373\n",
      "Iteration 628 - Grad. Norm.: 0.0019438337931727832 Norm. Diff.: 0.009729264990971207 tk: 5 x_norm: 14.005107688014686\n",
      "Iteration 629 - Grad. Norm.: 0.0019418195918351588 Norm. Diff.: 0.009719168965863922 tk: 5 x_norm: 14.0133592667085\n",
      "Iteration 630 - Grad. Norm.: 0.0019398103747563086 Norm. Diff.: 0.009709097959175877 tk: 5 x_norm: 14.021602649974298\n",
      "Iteration 631 - Grad. Norm.: 0.00193780612261406 Norm. Diff.: 0.009699051873781492 tk: 5 x_norm: 14.029837856740446\n",
      "Iteration 632 - Grad. Norm.: 0.0019358068161884575 Norm. Diff.: 0.009689030613070323 tk: 5 x_norm: 14.038064905864939\n",
      "Iteration 633 - Grad. Norm.: 0.0019338124363610476 Norm. Diff.: 0.009679034080942148 tk: 5 x_norm: 14.046283816135762\n",
      "Iteration 634 - Grad. Norm.: 0.0019318229641141845 Norm. Diff.: 0.009669062181805318 tk: 5 x_norm: 14.054494606271286\n",
      "Iteration 635 - Grad. Norm.: 0.00192983838053033 Norm. Diff.: 0.009659114820570797 tk: 5 x_norm: 14.062697294920646\n",
      "Iteration 636 - Grad. Norm.: 0.0019278586667913675 Norm. Diff.: 0.009649191902651661 tk: 5 x_norm: 14.070891900664092\n",
      "Iteration 637 - Grad. Norm.: 0.001925883804177917 Norm. Diff.: 0.009639293333956824 tk: 5 x_norm: 14.07907844201338\n",
      "Iteration 638 - Grad. Norm.: 0.0019239137740686622 Norm. Diff.: 0.009629419020889575 tk: 5 x_norm: 14.087256937412143\n",
      "Iteration 639 - Grad. Norm.: 0.0019219485579396694 Norm. Diff.: 0.009619568870343315 tk: 5 x_norm: 14.09542740523623\n",
      "Iteration 640 - Grad. Norm.: 0.0019199881373637348 Norm. Diff.: 0.009609742789698311 tk: 5 x_norm: 14.103589863794088\n",
      "Iteration 641 - Grad. Norm.: 0.0019180324940097132 Norm. Diff.: 0.00959994068681864 tk: 5 x_norm: 14.111744331327131\n",
      "Iteration 642 - Grad. Norm.: 0.0019160816096418733 Norm. Diff.: 0.009590162470048543 tk: 5 x_norm: 14.119890826010062\n",
      "Iteration 643 - Grad. Norm.: 0.0019141354661192454 Norm. Diff.: 0.00958040804820935 tk: 5 x_norm: 14.12802936595126\n",
      "Iteration 644 - Grad. Norm.: 0.0019121940453949737 Norm. Diff.: 0.00957067733059627 tk: 5 x_norm: 14.136159969193118\n",
      "Iteration 645 - Grad. Norm.: 0.0019102573295156882 Norm. Diff.: 0.009560970226974807 tk: 5 x_norm: 14.144282653712386\n",
      "Iteration 646 - Grad. Norm.: 0.0019083253006208663 Norm. Diff.: 0.009551286647578452 tk: 5 x_norm: 14.15239743742053\n",
      "Iteration 647 - Grad. Norm.: 0.0019063979409422087 Norm. Diff.: 0.009541626503104307 tk: 5 x_norm: 14.160504338164072\n",
      "Iteration 648 - Grad. Norm.: 0.0019044752328030196 Norm. Diff.: 0.009531989704711023 tk: 5 x_norm: 14.168603373724924\n",
      "Iteration 649 - Grad. Norm.: 0.0019025571586175855 Norm. Diff.: 0.009522376164014973 tk: 5 x_norm: 14.176694561820732\n",
      "Iteration 650 - Grad. Norm.: 0.0019006437008905707 Norm. Diff.: 0.009512785793088082 tk: 5 x_norm: 14.184777920105207\n",
      "Iteration 651 - Grad. Norm.: 0.001898734842216409 Norm. Diff.: 0.009503218504452954 tk: 5 x_norm: 14.192853466168476\n",
      "Iteration 652 - Grad. Norm.: 0.0018968305652787042 Norm. Diff.: 0.009493674211082059 tk: 5 x_norm: 14.200921217537386\n",
      "Iteration 653 - Grad. Norm.: 0.0018949308528496361 Norm. Diff.: 0.009484152826393517 tk: 5 x_norm: 14.208981191675859\n",
      "Iteration 654 - Grad. Norm.: 0.0018930356877893638 Norm. Diff.: 0.009474654264248194 tk: 5 x_norm: 14.217033405985205\n",
      "Iteration 655 - Grad. Norm.: 0.0018911450530454518 Norm. Diff.: 0.009465178438946793 tk: 5 x_norm: 14.225077877804438\n",
      "Iteration 656 - Grad. Norm.: 0.0018892589316522805 Norm. Diff.: 0.009455725265227517 tk: 5 x_norm: 14.233114624410623\n",
      "Iteration 657 - Grad. Norm.: 0.0018873773067304741 Norm. Diff.: 0.009446294658261556 tk: 5 x_norm: 14.24114366301917\n",
      "Iteration 658 - Grad. Norm.: 0.0018855001614863308 Norm. Diff.: 0.009436886533652294 tk: 5 x_norm: 14.249165010784168\n",
      "Iteration 659 - Grad. Norm.: 0.001883627479211255 Norm. Diff.: 0.009427500807431743 tk: 5 x_norm: 14.25717868479869\n",
      "Iteration 660 - Grad. Norm.: 0.0018817592432811994 Norm. Diff.: 0.009418137396056223 tk: 5 x_norm: 14.26518470209511\n",
      "Iteration 661 - Grad. Norm.: 0.0018798954371561066 Norm. Diff.: 0.009408796216406095 tk: 5 x_norm: 14.27318307964542\n",
      "Iteration 662 - Grad. Norm.: 0.0018780360443793542 Norm. Diff.: 0.009399477185780523 tk: 5 x_norm: 14.28117383436152\n",
      "Iteration 663 - Grad. Norm.: 0.0018761810485772186 Norm. Diff.: 0.009390180221896771 tk: 5 x_norm: 14.289156983095541\n",
      "Iteration 664 - Grad. Norm.: 0.0018743304334583196 Norm. Diff.: 0.009380905242886243 tk: 5 x_norm: 14.297132542640146\n",
      "Iteration 665 - Grad. Norm.: 0.0018724841828130893 Norm. Diff.: 0.00937165216729155 tk: 5 x_norm: 14.305100529728826\n",
      "Iteration 666 - Grad. Norm.: 0.0018706422805132383 Norm. Diff.: 0.009362420914065436 tk: 5 x_norm: 14.313060961036204\n",
      "Iteration 667 - Grad. Norm.: 0.0018688047105112255 Norm. Diff.: 0.00935321140256634 tk: 5 x_norm: 14.321013853178327\n",
      "Iteration 668 - Grad. Norm.: 0.0018669714568397334 Norm. Diff.: 0.009344023552556124 tk: 5 x_norm: 14.328959222712975\n",
      "Iteration 669 - Grad. Norm.: 0.0018651425036111486 Norm. Diff.: 0.009334857284198705 tk: 5 x_norm: 14.336897086139938\n",
      "Iteration 670 - Grad. Norm.: 0.0018633178350170461 Norm. Diff.: 0.009325712518055704 tk: 5 x_norm: 14.344827459901312\n",
      "Iteration 671 - Grad. Norm.: 0.001861497435327673 Norm. Diff.: 0.009316589175085398 tk: 5 x_norm: 14.352750360381803\n",
      "Iteration 672 - Grad. Norm.: 0.0018596812888914472 Norm. Diff.: 0.00930748717663825 tk: 5 x_norm: 14.360665803908985\n",
      "Iteration 673 - Grad. Norm.: 0.0018578693801344513 Norm. Diff.: 0.009298406444457112 tk: 5 x_norm: 14.368573806753615\n",
      "Iteration 674 - Grad. Norm.: 0.0018560616935599334 Norm. Diff.: 0.009289346900672235 tk: 5 x_norm: 14.376474385129901\n",
      "Iteration 675 - Grad. Norm.: 0.0018542582137478084 Norm. Diff.: 0.00928030846779989 tk: 5 x_norm: 14.384367555195784\n",
      "Iteration 676 - Grad. Norm.: 0.0018524589253541756 Norm. Diff.: 0.009271291068738955 tk: 5 x_norm: 14.392253333053219\n",
      "Iteration 677 - Grad. Norm.: 0.00185066381311082 Norm. Diff.: 0.009262294626770876 tk: 5 x_norm: 14.400131734748458\n",
      "Iteration 678 - Grad. Norm.: 0.0018488728618247395 Norm. Diff.: 0.009253319065554088 tk: 5 x_norm: 14.408002776272305\n",
      "Iteration 679 - Grad. Norm.: 0.0018470860563776586 Norm. Diff.: 0.009244364309123856 tk: 5 x_norm: 14.415866473560428\n",
      "Iteration 680 - Grad. Norm.: 0.0018453033817255574 Norm. Diff.: 0.009235430281888233 tk: 5 x_norm: 14.42372284249359\n",
      "Iteration 681 - Grad. Norm.: 0.0018435248228981975 Norm. Diff.: 0.009226516908627844 tk: 5 x_norm: 14.431571898897941\n",
      "Iteration 682 - Grad. Norm.: 0.0018417503649986527 Norm. Diff.: 0.009217624114490945 tk: 5 x_norm: 14.439413658545282\n",
      "Iteration 683 - Grad. Norm.: 0.001839979993202852 Norm. Diff.: 0.009208751824993443 tk: 5 x_norm: 14.447248137153334\n",
      "Iteration 684 - Grad. Norm.: 0.001838213692759111 Norm. Diff.: 0.009199899966014165 tk: 5 x_norm: 14.455075350385998\n",
      "Iteration 685 - Grad. Norm.: 0.0018364514489876808 Norm. Diff.: 0.00919106846379549 tk: 5 x_norm: 14.462895313853616\n",
      "Iteration 686 - Grad. Norm.: 0.0018346932472802927 Norm. Diff.: 0.009182257244938343 tk: 5 x_norm: 14.470708043113236\n",
      "Iteration 687 - Grad. Norm.: 0.0018329390730997105 Norm. Diff.: 0.009173466236401471 tk: 5 x_norm: 14.478513553668872\n",
      "Iteration 688 - Grad. Norm.: 0.0018311889119792843 Norm. Diff.: 0.00916469536549853 tk: 5 x_norm: 14.486311860971755\n",
      "Iteration 689 - Grad. Norm.: 0.001829442749522509 Norm. Diff.: 0.009155944559896321 tk: 5 x_norm: 14.494102980420601\n",
      "Iteration 690 - Grad. Norm.: 0.0018277005714025815 Norm. Diff.: 0.00914721374761262 tk: 5 x_norm: 14.501886927361847\n",
      "Iteration 691 - Grad. Norm.: 0.0018259623633619733 Norm. Diff.: 0.009138502857012919 tk: 5 x_norm: 14.509663717089918\n",
      "Iteration 692 - Grad. Norm.: 0.0018242281112119943 Norm. Diff.: 0.009129811816809809 tk: 5 x_norm: 14.517433364847475\n",
      "Iteration 693 - Grad. Norm.: 0.0018224978008323641 Norm. Diff.: 0.009121140556059905 tk: 5 x_norm: 14.525195885825655\n",
      "Iteration 694 - Grad. Norm.: 0.0018207714181707902 Norm. Diff.: 0.009112489004161776 tk: 5 x_norm: 14.532951295164327\n",
      "Iteration 695 - Grad. Norm.: 0.0018190489492425444 Norm. Diff.: 0.009103857090853923 tk: 5 x_norm: 14.54069960795234\n",
      "Iteration 696 - Grad. Norm.: 0.001817330380130043 Norm. Diff.: 0.009095244746212776 tk: 5 x_norm: 14.548440839227757\n",
      "Iteration 697 - Grad. Norm.: 0.001815615696982439 Norm. Diff.: 0.009086651900650082 tk: 5 x_norm: 14.556175003978097\n",
      "Iteration 698 - Grad. Norm.: 0.0018139048860152023 Norm. Diff.: 0.009078078484912232 tk: 5 x_norm: 14.563902117140598\n",
      "Iteration 699 - Grad. Norm.: 0.001812197933509717 Norm. Diff.: 0.00906952443007611 tk: 5 x_norm: 14.57162219360242\n",
      "Iteration 700 - Grad. Norm.: 0.0018104948258128738 Norm. Diff.: 0.009060989667548468 tk: 5 x_norm: 14.579335248200914\n",
      "Iteration 701 - Grad. Norm.: 0.0018087955493366703 Norm. Diff.: 0.009052474129064337 tk: 5 x_norm: 14.587041295723836\n",
      "Iteration 702 - Grad. Norm.: 0.0018071000905578087 Norm. Diff.: 0.009043977746683349 tk: 5 x_norm: 14.594740350909603\n",
      "Iteration 703 - Grad. Norm.: 0.0018054084360173063 Norm. Diff.: 0.009035500452789101 tk: 5 x_norm: 14.602432428447504\n",
      "Iteration 704 - Grad. Norm.: 0.0018037205723200952 Norm. Diff.: 0.009027042180086544 tk: 5 x_norm: 14.61011754297794\n",
      "Iteration 705 - Grad. Norm.: 0.0018020364861346372 Norm. Diff.: 0.009018602861600427 tk: 5 x_norm: 14.617795709092672\n",
      "Iteration 706 - Grad. Norm.: 0.0018003561641925416 Norm. Diff.: 0.009010182430673211 tk: 5 x_norm: 14.625466941335011\n",
      "Iteration 707 - Grad. Norm.: 0.0017986795932881713 Norm. Diff.: 0.009001780820962726 tk: 5 x_norm: 14.633131254200078\n",
      "Iteration 708 - Grad. Norm.: 0.0017970067602782727 Norm. Diff.: 0.008993397966440865 tk: 5 x_norm: 14.64078866213502\n",
      "Iteration 709 - Grad. Norm.: 0.001795337652081591 Norm. Diff.: 0.008985033801391349 tk: 5 x_norm: 14.648439179539222\n",
      "Iteration 710 - Grad. Norm.: 0.0017936722556785001 Norm. Diff.: 0.008976688260407931 tk: 5 x_norm: 14.65608282076455\n",
      "Iteration 711 - Grad. Norm.: 0.0017920105581106277 Norm. Diff.: 0.008968361278392432 tk: 5 x_norm: 14.663719600115552\n",
      "Iteration 712 - Grad. Norm.: 0.001790352546480489 Norm. Diff.: 0.008960052790553244 tk: 5 x_norm: 14.671349531849698\n",
      "Iteration 713 - Grad. Norm.: 0.0017886982079511199 Norm. Diff.: 0.008951762732402481 tk: 5 x_norm: 14.678972630177581\n",
      "Iteration 714 - Grad. Norm.: 0.0017870475297457123 Norm. Diff.: 0.008943491039755572 tk: 5 x_norm: 14.686588909263136\n",
      "Iteration 715 - Grad. Norm.: 0.0017854004991472556 Norm. Diff.: 0.008935237648728387 tk: 5 x_norm: 14.694198383223869\n",
      "Iteration 716 - Grad. Norm.: 0.0017837571034981783 Norm. Diff.: 0.008927002495736193 tk: 5 x_norm: 14.70180106613106\n",
      "Iteration 717 - Grad. Norm.: 0.0017821173301999942 Norm. Diff.: 0.00891878551749088 tk: 5 x_norm: 14.709396972009976\n",
      "Iteration 718 - Grad. Norm.: 0.0017804811667129464 Norm. Diff.: 0.008910586650999966 tk: 5 x_norm: 14.716986114840083\n",
      "Iteration 719 - Grad. Norm.: 0.001778848600555662 Norm. Diff.: 0.008902405833564693 tk: 5 x_norm: 14.724568508555258\n",
      "Iteration 720 - Grad. Norm.: 0.0017772196193048036 Norm. Diff.: 0.008894243002778439 tk: 5 x_norm: 14.732144167044003\n",
      "Iteration 721 - Grad. Norm.: 0.0017755942105947252 Norm. Diff.: 0.008886098096524037 tk: 5 x_norm: 14.739713104149637\n",
      "Iteration 722 - Grad. Norm.: 0.0017739723621171294 Norm. Diff.: 0.00887797105297357 tk: 5 x_norm: 14.74727533367052\n",
      "Iteration 723 - Grad. Norm.: 0.0017723540616207294 Norm. Diff.: 0.008869861810585699 tk: 5 x_norm: 14.75483086936025\n",
      "Iteration 724 - Grad. Norm.: 0.0017707392969109135 Norm. Diff.: 0.00886177030810371 tk: 5 x_norm: 14.762379724927854\n",
      "Iteration 725 - Grad. Norm.: 0.0017691280558494076 Norm. Diff.: 0.008853696484554554 tk: 5 x_norm: 14.76992191403802\n",
      "Iteration 726 - Grad. Norm.: 0.0017675203263539474 Norm. Diff.: 0.008845640279247067 tk: 5 x_norm: 14.777457450311266\n",
      "Iteration 727 - Grad. Norm.: 0.0017659160963979482 Norm. Diff.: 0.008837601631769816 tk: 5 x_norm: 14.784986347324168\n",
      "Iteration 728 - Grad. Norm.: 0.0017643153540101767 Norm. Diff.: 0.008829580481989847 tk: 5 x_norm: 14.79250861860953\n",
      "Iteration 729 - Grad. Norm.: 0.0017627180872744294 Norm. Diff.: 0.00882157677005089 tk: 5 x_norm: 14.800024277656611\n",
      "Iteration 730 - Grad. Norm.: 0.001761124284329208 Norm. Diff.: 0.008813590436372112 tk: 5 x_norm: 14.807533337911298\n",
      "Iteration 731 - Grad. Norm.: 0.0017595339333674044 Norm. Diff.: 0.008805621421646192 tk: 5 x_norm: 14.815035812776308\n",
      "Iteration 732 - Grad. Norm.: 0.0017579470226359794 Norm. Diff.: 0.008797669666836986 tk: 5 x_norm: 14.822531715611394\n",
      "Iteration 733 - Grad. Norm.: 0.0017563635404356493 Norm. Diff.: 0.00878973511317975 tk: 5 x_norm: 14.830021059733514\n",
      "Iteration 734 - Grad. Norm.: 0.001754783475120576 Norm. Diff.: 0.008781817702178276 tk: 5 x_norm: 14.83750385841704\n",
      "Iteration 735 - Grad. Norm.: 0.001753206815098053 Norm. Diff.: 0.008773917375602899 tk: 5 x_norm: 14.844980124893947\n",
      "Iteration 736 - Grad. Norm.: 0.001751633548828203 Norm. Diff.: 0.008766034075490243 tk: 5 x_norm: 14.852449872353988\n",
      "Iteration 737 - Grad. Norm.: 0.0017500636648236658 Norm. Diff.: 0.008758167744141029 tk: 5 x_norm: 14.859913113944911\n",
      "Iteration 738 - Grad. Norm.: 0.0017484971516493009 Norm. Diff.: 0.008750318324118411 tk: 5 x_norm: 14.867369862772605\n",
      "Iteration 739 - Grad. Norm.: 0.001746933997921886 Norm. Diff.: 0.008742485758246404 tk: 5 x_norm: 14.874820131901325\n",
      "Iteration 740 - Grad. Norm.: 0.001745374192309812 Norm. Diff.: 0.008734669989609456 tk: 5 x_norm: 14.882263934353842\n",
      "Iteration 741 - Grad. Norm.: 0.0017438177235327955 Norm. Diff.: 0.008726870961549092 tk: 5 x_norm: 14.88970128311166\n",
      "Iteration 742 - Grad. Norm.: 0.0017422645803615792 Norm. Diff.: 0.00871908861766402 tk: 5 x_norm: 14.897132191115176\n",
      "Iteration 743 - Grad. Norm.: 0.0017407147516176377 Norm. Diff.: 0.008711322901807856 tk: 5 x_norm: 14.904556671263858\n",
      "Iteration 744 - Grad. Norm.: 0.0017391682261728957 Norm. Diff.: 0.008703573758088182 tk: 5 x_norm: 14.911974736416447\n",
      "Iteration 745 - Grad. Norm.: 0.0017376249929494287 Norm. Diff.: 0.008695841130864485 tk: 5 x_norm: 14.919386399391115\n",
      "Iteration 746 - Grad. Norm.: 0.001736085040919187 Norm. Diff.: 0.008688124964747275 tk: 5 x_norm: 14.926791672965654\n",
      "Iteration 747 - Grad. Norm.: 0.0017345483591037036 Norm. Diff.: 0.008680425204595927 tk: 5 x_norm: 14.934190569877648\n",
      "Iteration 748 - Grad. Norm.: 0.0017330149365738221 Norm. Diff.: 0.00867274179551849 tk: 5 x_norm: 14.94158310282465\n",
      "Iteration 749 - Grad. Norm.: 0.0017314847624494071 Norm. Diff.: 0.008665074682869135 tk: 5 x_norm: 14.948969284464358\n",
      "Iteration 750 - Grad. Norm.: 0.001729957825899072 Norm. Diff.: 0.008657423812247066 tk: 5 x_norm: 14.956349127414791\n",
      "Iteration 751 - Grad. Norm.: 0.0017284341161399011 Norm. Diff.: 0.0086497891294954 tk: 5 x_norm: 14.963722644254457\n",
      "Iteration 752 - Grad. Norm.: 0.0017269136224371772 Norm. Diff.: 0.0086421705806995 tk: 5 x_norm: 14.97108984752252\n",
      "Iteration 753 - Grad. Norm.: 0.0017253963341041102 Norm. Diff.: 0.00863456811218588 tk: 5 x_norm: 14.978450749718986\n",
      "Iteration 754 - Grad. Norm.: 0.0017238822405015654 Norm. Diff.: 0.008626981670520726 tk: 5 x_norm: 14.985805363304864\n",
      "Iteration 755 - Grad. Norm.: 0.0017223713310377947 Norm. Diff.: 0.00861941120250779 tk: 5 x_norm: 14.99315370070233\n",
      "Iteration 756 - Grad. Norm.: 0.0017208635951681745 Norm. Diff.: 0.008611856655189093 tk: 5 x_norm: 15.000495774294896\n",
      "Iteration 757 - Grad. Norm.: 0.001719359022394938 Norm. Diff.: 0.008604317975840806 tk: 5 x_norm: 15.007831596427588\n",
      "Iteration 758 - Grad. Norm.: 0.0017178576022669142 Norm. Diff.: 0.008596795111974783 tk: 5 x_norm: 15.015161179407102\n",
      "Iteration 759 - Grad. Norm.: 0.0017163593243792665 Norm. Diff.: 0.008589288011334621 tk: 5 x_norm: 15.022484535501965\n",
      "Iteration 760 - Grad. Norm.: 0.0017148641783732372 Norm. Diff.: 0.008581796621896322 tk: 5 x_norm: 15.029801676942707\n",
      "Iteration 761 - Grad. Norm.: 0.0017133721539358843 Norm. Diff.: 0.008574320891866142 tk: 5 x_norm: 15.037112615922032\n",
      "Iteration 762 - Grad. Norm.: 0.0017118832407998364 Norm. Diff.: 0.008566860769679467 tk: 5 x_norm: 15.044417364594947\n",
      "Iteration 763 - Grad. Norm.: 0.0017103974287430285 Norm. Diff.: 0.008559416203999252 tk: 5 x_norm: 15.051715935078969\n",
      "Iteration 764 - Grad. Norm.: 0.0017089147075884572 Norm. Diff.: 0.00855198714371517 tk: 5 x_norm: 15.059008339454248\n",
      "Iteration 765 - Grad. Norm.: 0.0017074350672039314 Norm. Diff.: 0.008544573537942466 tk: 5 x_norm: 15.066294589763741\n",
      "Iteration 766 - Grad. Norm.: 0.0017059584975018206 Norm. Diff.: 0.00853717533601961 tk: 5 x_norm: 15.073574698013367\n",
      "Iteration 767 - Grad. Norm.: 0.0017044849884388137 Norm. Diff.: 0.00852979248750911 tk: 5 x_norm: 15.08084867617217\n",
      "Iteration 768 - Grad. Norm.: 0.0017030145300156651 Norm. Diff.: 0.008522424942194054 tk: 5 x_norm: 15.088116536172475\n",
      "Iteration 769 - Grad. Norm.: 0.0017015471122769673 Norm. Diff.: 0.008515072650078342 tk: 5 x_norm: 15.095378289910037\n",
      "Iteration 770 - Grad. Norm.: 0.0017000827253108941 Norm. Diff.: 0.008507735561384918 tk: 5 x_norm: 15.10263394924419\n",
      "Iteration 771 - Grad. Norm.: 0.00169862135924897 Norm. Diff.: 0.008500413626554366 tk: 5 x_norm: 15.109883525998026\n",
      "Iteration 772 - Grad. Norm.: 0.0016971630042658316 Norm. Diff.: 0.00849310679624491 tk: 5 x_norm: 15.117127031958514\n",
      "Iteration 773 - Grad. Norm.: 0.001695707650578989 Norm. Diff.: 0.008485815021329278 tk: 5 x_norm: 15.12436447887669\n",
      "Iteration 774 - Grad. Norm.: 0.0016942552884485925 Norm. Diff.: 0.008478538252895063 tk: 5 x_norm: 15.131595878467767\n",
      "Iteration 775 - Grad. Norm.: 0.0016928059081772024 Norm. Diff.: 0.008471276442242997 tk: 5 x_norm: 15.138821242411325\n",
      "Iteration 776 - Grad. Norm.: 0.0016913595001095498 Norm. Diff.: 0.008464029540886079 tk: 5 x_norm: 15.146040582351425\n",
      "Iteration 777 - Grad. Norm.: 0.0016899160546323174 Norm. Diff.: 0.008456797500547824 tk: 5 x_norm: 15.153253909896788\n",
      "Iteration 778 - Grad. Norm.: 0.0016884755621739025 Norm. Diff.: 0.008449580273161504 tk: 5 x_norm: 15.160461236620923\n",
      "Iteration 779 - Grad. Norm.: 0.0016870380132041982 Norm. Diff.: 0.0084423778108696 tk: 5 x_norm: 15.16766257406228\n",
      "Iteration 780 - Grad. Norm.: 0.0016856033982343608 Norm. Diff.: 0.008435190066021062 tk: 5 x_norm: 15.174857933724399\n",
      "Iteration 781 - Grad. Norm.: 0.0016841717078165885 Norm. Diff.: 0.008428016991171784 tk: 5 x_norm: 15.182047327076052\n",
      "Iteration 782 - Grad. Norm.: 0.0016827429325439066 Norm. Diff.: 0.00842085853908289 tk: 5 x_norm: 15.189230765551391\n",
      "Iteration 783 - Grad. Norm.: 0.0016813170630499336 Norm. Diff.: 0.008413714662719545 tk: 5 x_norm: 15.196408260550081\n",
      "Iteration 784 - Grad. Norm.: 0.001679894090008676 Norm. Diff.: 0.008406585315249505 tk: 5 x_norm: 15.203579823437462\n",
      "Iteration 785 - Grad. Norm.: 0.0016784740041343024 Norm. Diff.: 0.008399470450043342 tk: 5 x_norm: 15.21074546554468\n",
      "Iteration 786 - Grad. Norm.: 0.0016770567961809253 Norm. Diff.: 0.008392370020671423 tk: 5 x_norm: 15.217905198168816\n",
      "Iteration 787 - Grad. Norm.: 0.0016756424569423969 Norm. Diff.: 0.008385283980904566 tk: 5 x_norm: 15.225059032573053\n",
      "Iteration 788 - Grad. Norm.: 0.001674230977252084 Norm. Diff.: 0.008378212284711865 tk: 5 x_norm: 15.232206979986803\n",
      "Iteration 789 - Grad. Norm.: 0.0016728223479826674 Norm. Diff.: 0.008371154886260567 tk: 5 x_norm: 15.239349051605833\n",
      "Iteration 790 - Grad. Norm.: 0.0016714165600459237 Norm. Diff.: 0.00836411173991333 tk: 5 x_norm: 15.246485258592427\n",
      "Iteration 791 - Grad. Norm.: 0.001670013604392517 Norm. Diff.: 0.008357082800229516 tk: 5 x_norm: 15.253615612075517\n",
      "Iteration 792 - Grad. Norm.: 0.0016686134720117964 Norm. Diff.: 0.008350068021962455 tk: 5 x_norm: 15.260740123150796\n",
      "Iteration 793 - Grad. Norm.: 0.0016672161539315836 Norm. Diff.: 0.008343067360059034 tk: 5 x_norm: 15.267858802880893\n",
      "Iteration 794 - Grad. Norm.: 0.0016658216412179722 Norm. Diff.: 0.008336080769657942 tk: 5 x_norm: 15.27497166229548\n",
      "Iteration 795 - Grad. Norm.: 0.0016644299249751243 Norm. Diff.: 0.008329108206090027 tk: 5 x_norm: 15.28207871239142\n",
      "Iteration 796 - Grad. Norm.: 0.0016630409963450665 Norm. Diff.: 0.008322149624875704 tk: 5 x_norm: 15.289179964132888\n",
      "Iteration 797 - Grad. Norm.: 0.0016616548465074896 Norm. Diff.: 0.008315204981725341 tk: 5 x_norm: 15.296275428451525\n",
      "Iteration 798 - Grad. Norm.: 0.0016602714666795507 Norm. Diff.: 0.00830827423253748 tk: 5 x_norm: 15.303365116246548\n",
      "Iteration 799 - Grad. Norm.: 0.0016588908481156726 Norm. Diff.: 0.008301357333397914 tk: 5 x_norm: 15.310449038384895\n",
      "Iteration 800 - Grad. Norm.: 0.0016575129821073495 Norm. Diff.: 0.008294454240578368 tk: 5 x_norm: 15.317527205701357\n",
      "Iteration 801 - Grad. Norm.: 0.001656137859982947 Norm. Diff.: 0.008287564910536838 tk: 5 x_norm: 15.324599628998698\n",
      "Iteration 802 - Grad. Norm.: 0.0016547654731075185 Norm. Diff.: 0.008280689299914617 tk: 5 x_norm: 15.331666319047796\n",
      "Iteration 803 - Grad. Norm.: 0.0016533958128825956 Norm. Diff.: 0.008273827365537608 tk: 5 x_norm: 15.33872728658776\n",
      "Iteration 804 - Grad. Norm.: 0.001652028870746013 Norm. Diff.: 0.008266979064413054 tk: 5 x_norm: 15.34578254232608\n",
      "Iteration 805 - Grad. Norm.: 0.0016506646381717071 Norm. Diff.: 0.008260144353729857 tk: 5 x_norm: 15.35283209693872\n",
      "Iteration 806 - Grad. Norm.: 0.0016493031066695325 Norm. Diff.: 0.008253323190858393 tk: 5 x_norm: 15.359875961070282\n",
      "Iteration 807 - Grad. Norm.: 0.0016479442677850703 Norm. Diff.: 0.00824651553334754 tk: 5 x_norm: 15.366914145334102\n",
      "Iteration 808 - Grad. Norm.: 0.0016465881130994415 Norm. Diff.: 0.008239721338925227 tk: 5 x_norm: 15.3739466603124\n",
      "Iteration 809 - Grad. Norm.: 0.0016452346342291262 Norm. Diff.: 0.008232940565497268 tk: 5 x_norm: 15.380973516556383\n",
      "Iteration 810 - Grad. Norm.: 0.0016438838228257742 Norm. Diff.: 0.008226173171145743 tk: 5 x_norm: 15.387994724586392\n",
      "Iteration 811 - Grad. Norm.: 0.0016425356705760214 Norm. Diff.: 0.008219419114128816 tk: 5 x_norm: 15.395010294891996\n",
      "Iteration 812 - Grad. Norm.: 0.0016411901692013138 Norm. Diff.: 0.008212678352880145 tk: 5 x_norm: 15.402020237932152\n",
      "Iteration 813 - Grad. Norm.: 0.0016398473104577203 Norm. Diff.: 0.008205950846006584 tk: 5 x_norm: 15.409024564135295\n",
      "Iteration 814 - Grad. Norm.: 0.0016385070861357558 Norm. Diff.: 0.008199236552288647 tk: 5 x_norm: 15.416023283899474\n",
      "Iteration 815 - Grad. Norm.: 0.001637169488060201 Norm. Diff.: 0.008192535430678648 tk: 5 x_norm: 15.423016407592476\n",
      "Iteration 816 - Grad. Norm.: 0.0016358345080899291 Norm. Diff.: 0.008185847440300842 tk: 5 x_norm: 15.430003945551942\n",
      "Iteration 817 - Grad. Norm.: 0.0016345021381177223 Norm. Diff.: 0.008179172540449618 tk: 5 x_norm: 15.436985908085477\n",
      "Iteration 818 - Grad. Norm.: 0.0016331723700701065 Norm. Diff.: 0.008172510690588724 tk: 5 x_norm: 15.443962305470793\n",
      "Iteration 819 - Grad. Norm.: 0.0016318451959071647 Norm. Diff.: 0.008165861850350549 tk: 5 x_norm: 15.450933147955801\n",
      "Iteration 820 - Grad. Norm.: 0.0016305206076223779 Norm. Diff.: 0.00815922597953589 tk: 5 x_norm: 15.45789844575875\n",
      "Iteration 821 - Grad. Norm.: 0.0016291985972424444 Norm. Diff.: 0.008152603038111892 tk: 5 x_norm: 15.464858209068334\n",
      "Iteration 822 - Grad. Norm.: 0.0016278791568271073 Norm. Diff.: 0.008145992986212183 tk: 5 x_norm: 15.471812448043805\n",
      "Iteration 823 - Grad. Norm.: 0.001626562278468993 Norm. Diff.: 0.008139395784135538 tk: 5 x_norm: 15.478761172815101\n",
      "Iteration 824 - Grad. Norm.: 0.0016252479542934373 Norm. Diff.: 0.00813281139234501 tk: 5 x_norm: 15.485704393482953\n",
      "Iteration 825 - Grad. Norm.: 0.0016239361764583172 Norm. Diff.: 0.008126239771467198 tk: 5 x_norm: 15.492642120119003\n",
      "Iteration 826 - Grad. Norm.: 0.0016226269371538869 Norm. Diff.: 0.008119680882291546 tk: 5 x_norm: 15.499574362765912\n",
      "Iteration 827 - Grad. Norm.: 0.001621320228602611 Norm. Diff.: 0.008113134685769512 tk: 5 x_norm: 15.50650113143749\n",
      "Iteration 828 - Grad. Norm.: 0.0016200160430590008 Norm. Diff.: 0.00810660114301306 tk: 5 x_norm: 15.51342243611879\n",
      "Iteration 829 - Grad. Norm.: 0.001618714372809451 Norm. Diff.: 0.00810008021529498 tk: 5 x_norm: 15.520338286766227\n",
      "Iteration 830 - Grad. Norm.: 0.001617415210172074 Norm. Diff.: 0.008093571864047166 tk: 5 x_norm: 15.527248693307707\n",
      "Iteration 831 - Grad. Norm.: 0.0016161185474965467 Norm. Diff.: 0.008087076050860436 tk: 5 x_norm: 15.534153665642704\n",
      "Iteration 832 - Grad. Norm.: 0.001614824377163939 Norm. Diff.: 0.008080592737482808 tk: 5 x_norm: 15.541053213642403\n",
      "Iteration 833 - Grad. Norm.: 0.0016135326915865625 Norm. Diff.: 0.00807412188581953 tk: 5 x_norm: 15.547947347149794\n",
      "Iteration 834 - Grad. Norm.: 0.0016122434832078108 Norm. Diff.: 0.008067663457932835 tk: 5 x_norm: 15.55483607597979\n",
      "Iteration 835 - Grad. Norm.: 0.0016109567445019993 Norm. Diff.: 0.00806121741603907 tk: 5 x_norm: 15.561719409919325\n",
      "Iteration 836 - Grad. Norm.: 0.0016096724679742125 Norm. Diff.: 0.00805478372250999 tk: 5 x_norm: 15.568597358727473\n",
      "Iteration 837 - Grad. Norm.: 0.001608390646160145 Norm. Diff.: 0.008048362339871074 tk: 5 x_norm: 15.575469932135555\n",
      "Iteration 838 - Grad. Norm.: 0.0016071112716259473 Norm. Diff.: 0.008041953230800664 tk: 5 x_norm: 15.58233713984724\n",
      "Iteration 839 - Grad. Norm.: 0.0016058343369680771 Norm. Diff.: 0.008035556358129808 tk: 5 x_norm: 15.589198991538666\n",
      "Iteration 840 - Grad. Norm.: 0.0016045598348131394 Norm. Diff.: 0.008029171684840583 tk: 5 x_norm: 15.596055496858524\n",
      "Iteration 841 - Grad. Norm.: 0.001603287757817739 Norm. Diff.: 0.008022799174065641 tk: 5 x_norm: 15.602906665428184\n",
      "Iteration 842 - Grad. Norm.: 0.0016020180986683293 Norm. Diff.: 0.008016438789088722 tk: 5 x_norm: 15.609752506841795\n",
      "Iteration 843 - Grad. Norm.: 0.0016007508500810654 Norm. Diff.: 0.008010090493341554 tk: 5 x_norm: 15.616593030666387\n",
      "Iteration 844 - Grad. Norm.: 0.0015994860048016467 Norm. Diff.: 0.008003754250405424 tk: 5 x_norm: 15.623428246441975\n",
      "Iteration 845 - Grad. Norm.: 0.0015982235556051775 Norm. Diff.: 0.007997430024008177 tk: 5 x_norm: 15.630258163681669\n",
      "Iteration 846 - Grad. Norm.: 0.0015969634952960154 Norm. Diff.: 0.007991117778026021 tk: 5 x_norm: 15.63708279187177\n",
      "Iteration 847 - Grad. Norm.: 0.0015957058167076251 Norm. Diff.: 0.00798481747648001 tk: 5 x_norm: 15.643902140471877\n",
      "Iteration 848 - Grad. Norm.: 0.001594450512702437 Norm. Diff.: 0.0079785290835381 tk: 5 x_norm: 15.650716218914988\n",
      "Iteration 849 - Grad. Norm.: 0.0015931975761716943 Norm. Diff.: 0.007972252563512205 tk: 5 x_norm: 15.657525036607609\n",
      "Iteration 850 - Grad. Norm.: 0.0015919470000353216 Norm. Diff.: 0.00796598788085859 tk: 5 x_norm: 15.664328602929839\n",
      "Iteration 851 - Grad. Norm.: 0.001590698777241771 Norm. Diff.: 0.007959735000176492 tk: 5 x_norm: 15.671126927235488\n",
      "Iteration 852 - Grad. Norm.: 0.0015894529007678836 Norm. Diff.: 0.007953493886208767 tk: 5 x_norm: 15.677920018852166\n",
      "Iteration 853 - Grad. Norm.: 0.0015882093636187533 Norm. Diff.: 0.007947264503839459 tk: 5 x_norm: 15.684707887081393\n",
      "Iteration 854 - Grad. Norm.: 0.0015869681588275785 Norm. Diff.: 0.00794104681809361 tk: 5 x_norm: 15.691490541198682\n",
      "Iteration 855 - Grad. Norm.: 0.0015857292794555302 Norm. Diff.: 0.007934840794137959 tk: 5 x_norm: 15.698267990453662\n",
      "Iteration 856 - Grad. Norm.: 0.0015844927185916088 Norm. Diff.: 0.007928646397277686 tk: 5 x_norm: 15.705040244070155\n",
      "Iteration 857 - Grad. Norm.: 0.0015832584693525064 Norm. Diff.: 0.00792246359295808 tk: 5 x_norm: 15.711807311246279\n",
      "Iteration 858 - Grad. Norm.: 0.0015820265248824737 Norm. Diff.: 0.007916292346762516 tk: 5 x_norm: 15.718569201154562\n",
      "Iteration 859 - Grad. Norm.: 0.0015807968783531786 Norm. Diff.: 0.007910132624412458 tk: 5 x_norm: 15.725325922942002\n",
      "Iteration 860 - Grad. Norm.: 0.001579569522963576 Norm. Diff.: 0.007903984391765836 tk: 5 x_norm: 15.732077485730214\n",
      "Iteration 861 - Grad. Norm.: 0.001578344451939771 Norm. Diff.: 0.007897847614817897 tk: 5 x_norm: 15.738823898615486\n",
      "Iteration 862 - Grad. Norm.: 0.001577121658534883 Norm. Diff.: 0.007891722259698992 tk: 5 x_norm: 15.745565170668884\n",
      "Iteration 863 - Grad. Norm.: 0.0015759011360289182 Norm. Diff.: 0.00788560829267442 tk: 5 x_norm: 15.752301310936357\n",
      "Iteration 864 - Grad. Norm.: 0.0015746828777286317 Norm. Diff.: 0.007879505680144665 tk: 5 x_norm: 15.759032328438826\n",
      "Iteration 865 - Grad. Norm.: 0.001573466876967401 Norm. Diff.: 0.007873414388643103 tk: 5 x_norm: 15.765758232172278\n",
      "Iteration 866 - Grad. Norm.: 0.0015722531271050906 Norm. Diff.: 0.007867334384836985 tk: 5 x_norm: 15.772479031107853\n",
      "Iteration 867 - Grad. Norm.: 0.0015710416215279272 Norm. Diff.: 0.00786126563552538 tk: 5 x_norm: 15.779194734191952\n",
      "Iteration 868 - Grad. Norm.: 0.0015698323536483684 Norm. Diff.: 0.007855208107639698 tk: 5 x_norm: 15.785905350346319\n",
      "Iteration 869 - Grad. Norm.: 0.0015686253169049738 Norm. Diff.: 0.007849161768241965 tk: 5 x_norm: 15.792610888468142\n",
      "Iteration 870 - Grad. Norm.: 0.0015674205047622764 Norm. Diff.: 0.00784312658452478 tk: 5 x_norm: 15.799311357430128\n",
      "Iteration 871 - Grad. Norm.: 0.0015662179107106592 Norm. Diff.: 0.007837102523811253 tk: 5 x_norm: 15.80600676608062\n",
      "Iteration 872 - Grad. Norm.: 0.0015650175282662286 Norm. Diff.: 0.0078310895535532 tk: 5 x_norm: 15.812697123243659\n",
      "Iteration 873 - Grad. Norm.: 0.001563819350970684 Norm. Diff.: 0.007825087641331122 tk: 5 x_norm: 15.819382437719108\n",
      "Iteration 874 - Grad. Norm.: 0.001562623372391201 Norm. Diff.: 0.007819096754853361 tk: 5 x_norm: 15.826062718282706\n",
      "Iteration 875 - Grad. Norm.: 0.001561429586120302 Norm. Diff.: 0.007813116861955904 tk: 5 x_norm: 15.832737973686191\n",
      "Iteration 876 - Grad. Norm.: 0.0015602379857757342 Norm. Diff.: 0.007807147930601589 tk: 5 x_norm: 15.839408212657368\n",
      "Iteration 877 - Grad. Norm.: 0.0015590485650003496 Norm. Diff.: 0.007801189928878594 tk: 5 x_norm: 15.846073443900206\n",
      "Iteration 878 - Grad. Norm.: 0.0015578613174619777 Norm. Diff.: 0.007795242825001908 tk: 5 x_norm: 15.852733676094921\n",
      "Iteration 879 - Grad. Norm.: 0.0015566762368533127 Norm. Diff.: 0.00778930658730987 tk: 5 x_norm: 15.85938891789808\n",
      "Iteration 880 - Grad. Norm.: 0.0015554933168917848 Norm. Diff.: 0.007783381184266506 tk: 5 x_norm: 15.866039177942662\n",
      "Iteration 881 - Grad. Norm.: 0.0015543125513194467 Norm. Diff.: 0.007777466584458827 tk: 5 x_norm: 15.872684464838178\n",
      "Iteration 882 - Grad. Norm.: 0.0015531339339028484 Norm. Diff.: 0.0077715627565972 tk: 5 x_norm: 15.87932478717072\n",
      "Iteration 883 - Grad. Norm.: 0.0015519574584329297 Norm. Diff.: 0.007765669669514081 tk: 5 x_norm: 15.885960153503087\n",
      "Iteration 884 - Grad. Norm.: 0.0015507831187248893 Norm. Diff.: 0.007759787292164698 tk: 5 x_norm: 15.892590572374845\n",
      "Iteration 885 - Grad. Norm.: 0.0015496109086180767 Norm. Diff.: 0.007753915593624524 tk: 5 x_norm: 15.89921605230241\n",
      "Iteration 886 - Grad. Norm.: 0.001548440821975874 Norm. Diff.: 0.00774805454309035 tk: 5 x_norm: 15.90583660177917\n",
      "Iteration 887 - Grad. Norm.: 0.001547272852685579 Norm. Diff.: 0.007742204109879307 tk: 5 x_norm: 15.912452229275516\n",
      "Iteration 888 - Grad. Norm.: 0.00154610699465829 Norm. Diff.: 0.007736364263427991 tk: 5 x_norm: 15.919062943238965\n",
      "Iteration 889 - Grad. Norm.: 0.0015449432418287957 Norm. Diff.: 0.0077305349732914655 tk: 5 x_norm: 15.925668752094232\n",
      "Iteration 890 - Grad. Norm.: 0.0015437815881554568 Norm. Diff.: 0.007724716209143959 tk: 5 x_norm: 15.932269664243321\n",
      "Iteration 891 - Grad. Norm.: 0.0015426220276200941 Norm. Diff.: 0.007718907940777183 tk: 5 x_norm: 15.93886568806559\n",
      "Iteration 892 - Grad. Norm.: 0.0015414645542278771 Norm. Diff.: 0.0077131101381004005 tk: 5 x_norm: 15.945456831917857\n",
      "Iteration 893 - Grad. Norm.: 0.001540309162007212 Norm. Diff.: 0.007707322771139448 tk: 5 x_norm: 15.952043104134468\n",
      "Iteration 894 - Grad. Norm.: 0.0015391558450096304 Norm. Diff.: 0.00770154581003605 tk: 5 x_norm: 15.958624513027381\n",
      "Iteration 895 - Grad. Norm.: 0.0015380045973096797 Norm. Diff.: 0.007695779225048157 tk: 5 x_norm: 15.965201066886248\n",
      "Iteration 896 - Grad. Norm.: 0.001536855413004812 Norm. Diff.: 0.007690022986548334 tk: 5 x_norm: 15.97177277397851\n",
      "Iteration 897 - Grad. Norm.: 0.0015357082862152752 Norm. Diff.: 0.007684277065024166 tk: 5 x_norm: 15.978339642549455\n",
      "Iteration 898 - Grad. Norm.: 0.0015345632110840043 Norm. Diff.: 0.00767854143107642 tk: 5 x_norm: 15.984901680822313\n",
      "Iteration 899 - Grad. Norm.: 0.0015334201817765144 Norm. Diff.: 0.007672816055419976 tk: 5 x_norm: 15.991458896998331\n",
      "Iteration 900 - Grad. Norm.: 0.0015322791924807938 Norm. Diff.: 0.007667100908882504 tk: 5 x_norm: 15.998011299256868\n",
      "Iteration 901 - Grad. Norm.: 0.0015311402374071936 Norm. Diff.: 0.007661395962404058 tk: 5 x_norm: 16.004558895755444\n",
      "Iteration 902 - Grad. Norm.: 0.0015300033107883255 Norm. Diff.: 0.007655701187036041 tk: 5 x_norm: 16.01110169462985\n",
      "Iteration 903 - Grad. Norm.: 0.0015288684068789546 Norm. Diff.: 0.007650016553941537 tk: 5 x_norm: 16.017639703994217\n",
      "Iteration 904 - Grad. Norm.: 0.0015277355199558944 Norm. Diff.: 0.007644342034394711 tk: 5 x_norm: 16.024172931941074\n",
      "Iteration 905 - Grad. Norm.: 0.001526604644317901 Norm. Diff.: 0.007638677599779378 tk: 5 x_norm: 16.030701386541462\n",
      "Iteration 906 - Grad. Norm.: 0.0015254757742855735 Norm. Diff.: 0.007633023221589462 tk: 5 x_norm: 16.037225075844987\n",
      "Iteration 907 - Grad. Norm.: 0.0015243489042012445 Norm. Diff.: 0.007627378871427894 tk: 5 x_norm: 16.043744007879905\n",
      "Iteration 908 - Grad. Norm.: 0.0015232240284288846 Norm. Diff.: 0.007621744521006309 tk: 5 x_norm: 16.0502581906532\n",
      "Iteration 909 - Grad. Norm.: 0.0015221011413539941 Norm. Diff.: 0.00761612014214428 tk: 5 x_norm: 16.056767632150656\n",
      "Iteration 910 - Grad. Norm.: 0.001520980237383502 Norm. Diff.: 0.007610505706769962 tk: 5 x_norm: 16.06327234033694\n",
      "Iteration 911 - Grad. Norm.: 0.001519861310945671 Norm. Diff.: 0.007604901186917541 tk: 5 x_norm: 16.069772323155675\n",
      "Iteration 912 - Grad. Norm.: 0.0015187443564899919 Norm. Diff.: 0.007599306554728414 tk: 5 x_norm: 16.076267588529504\n",
      "Iteration 913 - Grad. Norm.: 0.0015176293684870815 Norm. Diff.: 0.007593721782449902 tk: 5 x_norm: 16.0827581443602\n",
      "Iteration 914 - Grad. Norm.: 0.0015165163414285917 Norm. Diff.: 0.007588146842435358 tk: 5 x_norm: 16.089243998528698\n",
      "Iteration 915 - Grad. Norm.: 0.0015154052698270997 Norm. Diff.: 0.007582581707142885 tk: 5 x_norm: 16.0957251588952\n",
      "Iteration 916 - Grad. Norm.: 0.0015142961482160198 Norm. Diff.: 0.007577026349135515 tk: 5 x_norm: 16.102201633299227\n",
      "Iteration 917 - Grad. Norm.: 0.0015131889711494997 Norm. Diff.: 0.007571480741080132 tk: 5 x_norm: 16.108673429559726\n",
      "Iteration 918 - Grad. Norm.: 0.0015120837332023257 Norm. Diff.: 0.007565944855747576 tk: 5 x_norm: 16.115140555475104\n",
      "Iteration 919 - Grad. Norm.: 0.001510980428969824 Norm. Diff.: 0.007560418666011602 tk: 5 x_norm: 16.121603018823325\n",
      "Iteration 920 - Grad. Norm.: 0.001509879053067767 Norm. Diff.: 0.00755490214484917 tk: 5 x_norm: 16.12806082736198\n",
      "Iteration 921 - Grad. Norm.: 0.001508779600132278 Norm. Diff.: 0.0075493952653389075 tk: 5 x_norm: 16.13451398882837\n",
      "Iteration 922 - Grad. Norm.: 0.0015076820648197325 Norm. Diff.: 0.007543898000661368 tk: 5 x_norm: 16.140962510939538\n",
      "Iteration 923 - Grad. Norm.: 0.0015065864418066673 Norm. Diff.: 0.007538410324098603 tk: 5 x_norm: 16.147406401392395\n",
      "Iteration 924 - Grad. Norm.: 0.001505492725789685 Norm. Diff.: 0.0075329322090332135 tk: 5 x_norm: 16.153845667863756\n",
      "Iteration 925 - Grad. Norm.: 0.0015044009114853591 Norm. Diff.: 0.007527463628948468 tk: 5 x_norm: 16.16028031801042\n",
      "Iteration 926 - Grad. Norm.: 0.0015033109936301457 Norm. Diff.: 0.007522004557426883 tk: 5 x_norm: 16.166710359469256\n",
      "Iteration 927 - Grad. Norm.: 0.001502222966980285 Norm. Diff.: 0.007516554968150687 tk: 5 x_norm: 16.173135799857242\n",
      "Iteration 928 - Grad. Norm.: 0.0015011368263117134 Norm. Diff.: 0.0075111148349013565 tk: 5 x_norm: 16.179556646771566\n",
      "Iteration 929 - Grad. Norm.: 0.0015000525664199697 Norm. Diff.: 0.007505684131558638 tk: 5 x_norm: 16.18597290778968\n",
      "Iteration 930 - Grad. Norm.: 0.001498970182120107 Norm. Diff.: 0.007500262832099874 tk: 5 x_norm: 16.192384590469374\n",
      "Iteration 931 - Grad. Norm.: 0.0014978896682465966 Norm. Diff.: 0.007494850910600594 tk: 5 x_norm: 16.198791702348856\n",
      "Iteration 932 - Grad. Norm.: 0.0014968110196532471 Norm. Diff.: 0.0074894483412329925 tk: 5 x_norm: 16.205194250946796\n",
      "Iteration 933 - Grad. Norm.: 0.0014957342312131032 Norm. Diff.: 0.0074840550982661165 tk: 5 x_norm: 16.211592243762418\n",
      "Iteration 934 - Grad. Norm.: 0.001494659297818368 Norm. Diff.: 0.007478671156065472 tk: 5 x_norm: 16.217985688275558\n",
      "Iteration 935 - Grad. Norm.: 0.0014935862143803042 Norm. Diff.: 0.007473296489091797 tk: 5 x_norm: 16.22437459194674\n",
      "Iteration 936 - Grad. Norm.: 0.0014925149758291572 Norm. Diff.: 0.007467931071901583 tk: 5 x_norm: 16.230758962217237\n",
      "Iteration 937 - Grad. Norm.: 0.0014914455771140556 Norm. Diff.: 0.007462574879145787 tk: 5 x_norm: 16.23713880650913\n",
      "Iteration 938 - Grad. Norm.: 0.0014903780132029334 Norm. Diff.: 0.007457227885570269 tk: 5 x_norm: 16.243514132225407\n",
      "Iteration 939 - Grad. Norm.: 0.0014893122790824364 Norm. Diff.: 0.00745189006601479 tk: 5 x_norm: 16.24988494674999\n",
      "Iteration 940 - Grad. Norm.: 0.001488248369757842 Norm. Diff.: 0.007446561395412161 tk: 5 x_norm: 16.256251257447836\n",
      "Iteration 941 - Grad. Norm.: 0.0014871862802529699 Norm. Diff.: 0.0074412418487892745 tk: 5 x_norm: 16.262613071664983\n",
      "Iteration 942 - Grad. Norm.: 0.0014861260056100952 Norm. Diff.: 0.0074359314012647755 tk: 5 x_norm: 16.26897039672862\n",
      "Iteration 943 - Grad. Norm.: 0.0014850675408898699 Norm. Diff.: 0.0074306300280504054 tk: 5 x_norm: 16.275323239947152\n",
      "Iteration 944 - Grad. Norm.: 0.0014840108811712306 Norm. Diff.: 0.00742533770444946 tk: 5 x_norm: 16.281671608610285\n",
      "Iteration 945 - Grad. Norm.: 0.0014829560215513205 Norm. Diff.: 0.007420054405855939 tk: 5 x_norm: 16.28801550998905\n",
      "Iteration 946 - Grad. Norm.: 0.0014819029571454035 Norm. Diff.: 0.007414780107756634 tk: 5 x_norm: 16.294354951335926\n",
      "Iteration 947 - Grad. Norm.: 0.0014808516830867808 Norm. Diff.: 0.0074095147857269105 tk: 5 x_norm: 16.300689939884837\n",
      "Iteration 948 - Grad. Norm.: 0.0014798021945267082 Norm. Diff.: 0.007404258415433861 tk: 5 x_norm: 16.30702048285128\n",
      "Iteration 949 - Grad. Norm.: 0.0014787544866343167 Norm. Diff.: 0.007399010972633519 tk: 5 x_norm: 16.31334658743234\n",
      "Iteration 950 - Grad. Norm.: 0.0014777085545965268 Norm. Diff.: 0.007393772433171508 tk: 5 x_norm: 16.319668260806793\n",
      "Iteration 951 - Grad. Norm.: 0.0014766643936179693 Norm. Diff.: 0.007388542772982563 tk: 5 x_norm: 16.32598551013514\n",
      "Iteration 952 - Grad. Norm.: 0.0014756219989209053 Norm. Diff.: 0.007383321968089994 tk: 5 x_norm: 16.332298342559692\n",
      "Iteration 953 - Grad. Norm.: 0.001474581365745142 Norm. Diff.: 0.007378109994604443 tk: 5 x_norm: 16.338606765204617\n",
      "Iteration 954 - Grad. Norm.: 0.0014735424893479584 Norm. Diff.: 0.0073729068287257515 tk: 5 x_norm: 16.344910785176\n",
      "Iteration 955 - Grad. Norm.: 0.0014725053650040199 Norm. Diff.: 0.007367712446739853 tk: 5 x_norm: 16.35121040956194\n",
      "Iteration 956 - Grad. Norm.: 0.0014714699880053028 Norm. Diff.: 0.007362526825019994 tk: 5 x_norm: 16.357505645432568\n",
      "Iteration 957 - Grad. Norm.: 0.0014704363536610164 Norm. Diff.: 0.007357349940026578 tk: 5 x_norm: 16.363796499840127\n",
      "Iteration 958 - Grad. Norm.: 0.001469404457297519 Norm. Diff.: 0.007352181768305069 tk: 5 x_norm: 16.37008297981905\n",
      "Iteration 959 - Grad. Norm.: 0.0014683742942582455 Norm. Diff.: 0.007347022286487626 tk: 5 x_norm: 16.376365092385996\n",
      "Iteration 960 - Grad. Norm.: 0.0014673458599036276 Norm. Diff.: 0.007341871471291251 tk: 5 x_norm: 16.382642844539916\n",
      "Iteration 961 - Grad. Norm.: 0.0014663191496110187 Norm. Diff.: 0.0073367292995181145 tk: 5 x_norm: 16.38891624326215\n",
      "Iteration 962 - Grad. Norm.: 0.0014652941587746133 Norm. Diff.: 0.007331595748055112 tk: 5 x_norm: 16.395185295516413\n",
      "Iteration 963 - Grad. Norm.: 0.0014642708828053743 Norm. Diff.: 0.007326470793873162 tk: 5 x_norm: 16.401450008248943\n",
      "Iteration 964 - Grad. Norm.: 0.0014632493171309554 Norm. Diff.: 0.007321354414026928 tk: 5 x_norm: 16.407710388388487\n",
      "Iteration 965 - Grad. Norm.: 0.0014622294571956266 Norm. Diff.: 0.007316246585654846 tk: 5 x_norm: 16.413966442846416\n",
      "Iteration 966 - Grad. Norm.: 0.0014612112984601958 Norm. Diff.: 0.007311147285978035 tk: 5 x_norm: 16.42021817851675\n",
      "Iteration 967 - Grad. Norm.: 0.0014601948364019414 Norm. Diff.: 0.007306056492301116 tk: 5 x_norm: 16.426465602276227\n",
      "Iteration 968 - Grad. Norm.: 0.001459180066514528 Norm. Diff.: 0.007300974182009647 tk: 5 x_norm: 16.432708720984373\n",
      "Iteration 969 - Grad. Norm.: 0.0014581669843079421 Norm. Diff.: 0.007295900332572687 tk: 5 x_norm: 16.43894754148354\n",
      "Iteration 970 - Grad. Norm.: 0.001457155585308411 Norm. Diff.: 0.007290834921539669 tk: 5 x_norm: 16.445182070598992\n",
      "Iteration 971 - Grad. Norm.: 0.0014561458650583336 Norm. Diff.: 0.007285777926542182 tk: 5 x_norm: 16.451412315138935\n",
      "Iteration 972 - Grad. Norm.: 0.0014551378191162072 Norm. Diff.: 0.007280729325291771 tk: 5 x_norm: 16.457638281894596\n",
      "Iteration 973 - Grad. Norm.: 0.0014541314430565552 Norm. Diff.: 0.007275689095580869 tk: 5 x_norm: 16.463859977640272\n",
      "Iteration 974 - Grad. Norm.: 0.0014531267324698533 Norm. Diff.: 0.007270657215282831 tk: 5 x_norm: 16.47007740913339\n",
      "Iteration 975 - Grad. Norm.: 0.001452123682962458 Norm. Diff.: 0.00726563366234928 tk: 5 x_norm: 16.476290583114558\n",
      "Iteration 976 - Grad. Norm.: 0.001451122290156539 Norm. Diff.: 0.007260618414812324 tk: 5 x_norm: 16.482499506307636\n",
      "Iteration 977 - Grad. Norm.: 0.0014501225496900043 Norm. Diff.: 0.007255611450782623 tk: 5 x_norm: 16.488704185419785\n",
      "Iteration 978 - Grad. Norm.: 0.0014491244572164292 Norm. Diff.: 0.007250612748449978 tk: 5 x_norm: 16.494904627141516\n",
      "Iteration 979 - Grad. Norm.: 0.0014481280084049908 Norm. Diff.: 0.007245622286082286 tk: 5 x_norm: 16.501100838146762\n",
      "Iteration 980 - Grad. Norm.: 0.0014471331989403932 Norm. Diff.: 0.0072406400420248675 tk: 5 x_norm: 16.50729282509292\n",
      "Iteration 981 - Grad. Norm.: 0.0014461400245227994 Norm. Diff.: 0.00723566599470199 tk: 5 x_norm: 16.513480594620926\n",
      "Iteration 982 - Grad. Norm.: 0.001445148480867766 Norm. Diff.: 0.007230700122614029 tk: 5 x_norm: 16.51966415335528\n",
      "Iteration 983 - Grad. Norm.: 0.0014441585637061675 Norm. Diff.: 0.00722574240433889 tk: 5 x_norm: 16.525843507904128\n",
      "Iteration 984 - Grad. Norm.: 0.0014431702687841342 Norm. Diff.: 0.007220792818530901 tk: 5 x_norm: 16.532018664859326\n",
      "Iteration 985 - Grad. Norm.: 0.0014421835918629797 Norm. Diff.: 0.007215851343920802 tk: 5 x_norm: 16.53818963079645\n",
      "Iteration 986 - Grad. Norm.: 0.0014411985287191354 Norm. Diff.: 0.0072109179593147785 tk: 5 x_norm: 16.54435641227489\n",
      "Iteration 987 - Grad. Norm.: 0.0014402150751440853 Norm. Diff.: 0.007205992643595583 tk: 5 x_norm: 16.550519015837914\n",
      "Iteration 988 - Grad. Norm.: 0.0014392332269442946 Norm. Diff.: 0.0072010753757205176 tk: 5 x_norm: 16.55667744801267\n",
      "Iteration 989 - Grad. Norm.: 0.001438252979941143 Norm. Diff.: 0.007196166134721522 tk: 5 x_norm: 16.562831715310292\n",
      "Iteration 990 - Grad. Norm.: 0.0014372743299708639 Norm. Diff.: 0.007191264899705628 tk: 5 x_norm: 16.56898182422594\n",
      "Iteration 991 - Grad. Norm.: 0.0014362972728844746 Norm. Diff.: 0.00718637164985435 tk: 5 x_norm: 16.575127781238816\n",
      "Iteration 992 - Grad. Norm.: 0.0014353218045477093 Norm. Diff.: 0.007181486364422351 tk: 5 x_norm: 16.581269592812294\n",
      "Iteration 993 - Grad. Norm.: 0.001434347920840954 Norm. Diff.: 0.007176609022738571 tk: 5 x_norm: 16.5874072653939\n",
      "Iteration 994 - Grad. Norm.: 0.0014333756176591877 Norm. Diff.: 0.0071717396042047885 tk: 5 x_norm: 16.593540805415394\n",
      "Iteration 995 - Grad. Norm.: 0.001432404890911909 Norm. Diff.: 0.007166878088295931 tk: 5 x_norm: 16.599670219292843\n",
      "Iteration 996 - Grad. Norm.: 0.001431435736523079 Norm. Diff.: 0.0071620244545595345 tk: 5 x_norm: 16.605795513426628\n",
      "Iteration 997 - Grad. Norm.: 0.0014304681504310524 Norm. Diff.: 0.007157178682615382 tk: 5 x_norm: 16.611916694201547\n",
      "Iteration 998 - Grad. Norm.: 0.0014295021285885155 Norm. Diff.: 0.007152340752155187 tk: 5 x_norm: 16.61803376798682\n",
      "Iteration 999 - Grad. Norm.: 0.0014285376669624231 Norm. Diff.: 0.007147510642942581 tk: 5 x_norm: 16.624146741136176\n",
      "Iteration 1000 - Grad. Norm.: 0.001427574761533938 Norm. Diff.: 0.0071426883348122 tk: 5 x_norm: 16.630255619987892\n",
      "Iteration 1001 - Grad. Norm.: 0.001426613408298363 Norm. Diff.: 0.00713787380766982 tk: 5 x_norm: 16.636360410864835\n",
      "Iteration 1002 - Grad. Norm.: 0.0014256536032650827 Norm. Diff.: 0.007133067041491886 tk: 5 x_norm: 16.64246112007453\n",
      "Iteration 1003 - Grad. Norm.: 0.0014246953424574998 Norm. Diff.: 0.007128268016325397 tk: 5 x_norm: 16.6485577539092\n",
      "Iteration 1004 - Grad. Norm.: 0.001423738621912974 Norm. Diff.: 0.007123476712287506 tk: 5 x_norm: 16.654650318645828\n",
      "Iteration 1005 - Grad. Norm.: 0.001422783437682761 Norm. Diff.: 0.007118693109564867 tk: 5 x_norm: 16.660738820546193\n",
      "Iteration 1006 - Grad. Norm.: 0.0014218297858319502 Norm. Diff.: 0.007113917188413782 tk: 5 x_norm: 16.66682326585693\n",
      "Iteration 1007 - Grad. Norm.: 0.0014208776624394029 Norm. Diff.: 0.007109148929159825 tk: 5 x_norm: 16.672903660809567\n",
      "Iteration 1008 - Grad. Norm.: 0.0014199270635976962 Norm. Diff.: 0.007104388312196988 tk: 5 x_norm: 16.678980011620617\n",
      "Iteration 1009 - Grad. Norm.: 0.0014189779854130607 Norm. Diff.: 0.007099635317988454 tk: 5 x_norm: 16.685052324491554\n",
      "Iteration 1010 - Grad. Norm.: 0.0014180304240053163 Norm. Diff.: 0.007094889927065341 tk: 5 x_norm: 16.691120605608948\n",
      "Iteration 1011 - Grad. Norm.: 0.00141708437550782 Norm. Diff.: 0.0070901521200266125 tk: 5 x_norm: 16.697184861144436\n",
      "Iteration 1012 - Grad. Norm.: 0.0014161398360674005 Norm. Diff.: 0.007085421877538961 tk: 5 x_norm: 16.703245097254825\n",
      "Iteration 1013 - Grad. Norm.: 0.0014151968018443033 Norm. Diff.: 0.007080699180336991 tk: 5 x_norm: 16.70930132008213\n",
      "Iteration 1014 - Grad. Norm.: 0.0014142552690121326 Norm. Diff.: 0.007075984009221425 tk: 5 x_norm: 16.715353535753604\n",
      "Iteration 1015 - Grad. Norm.: 0.0014133152337577864 Norm. Diff.: 0.00707127634506063 tk: 5 x_norm: 16.721401750381798\n",
      "Iteration 1016 - Grad. Norm.: 0.0014123766922814068 Norm. Diff.: 0.007066576168789012 tk: 5 x_norm: 16.72744597006461\n",
      "Iteration 1017 - Grad. Norm.: 0.0014114396407963173 Norm. Diff.: 0.007061883461407116 tk: 5 x_norm: 16.73348620088534\n",
      "Iteration 1018 - Grad. Norm.: 0.0014105040755289656 Norm. Diff.: 0.007057198203981674 tk: 5 x_norm: 16.739522448912734\n",
      "Iteration 1019 - Grad. Norm.: 0.0014095699927188692 Norm. Diff.: 0.007052520377644898 tk: 5 x_norm: 16.745554720201014\n",
      "Iteration 1020 - Grad. Norm.: 0.001408637388618554 Norm. Diff.: 0.007047849963594307 tk: 5 x_norm: 16.75158302078995\n",
      "Iteration 1021 - Grad. Norm.: 0.001407706259493504 Norm. Diff.: 0.0070431869430926984 tk: 5 x_norm: 16.757607356704906\n",
      "Iteration 1022 - Grad. Norm.: 0.0014067766016221 Norm. Diff.: 0.007038531297467414 tk: 5 x_norm: 16.763627733956863\n",
      "Iteration 1023 - Grad. Norm.: 0.001405848411295562 Norm. Diff.: 0.007033883008110558 tk: 5 x_norm: 16.769644158542494\n",
      "Iteration 1024 - Grad. Norm.: 0.001404921684817902 Norm. Diff.: 0.00702924205647778 tk: 5 x_norm: 16.7756566364442\n",
      "Iteration 1025 - Grad. Norm.: 0.0014039964185058563 Norm. Diff.: 0.007024608424089562 tk: 5 x_norm: 16.781665173630135\n",
      "Iteration 1026 - Grad. Norm.: 0.0014030726086888446 Norm. Diff.: 0.00701998209252929 tk: 5 x_norm: 16.7876697760543\n",
      "Iteration 1027 - Grad. Norm.: 0.0014021502517089005 Norm. Diff.: 0.007015363043444171 tk: 5 x_norm: 16.793670449656556\n",
      "Iteration 1028 - Grad. Norm.: 0.001401229343920628 Norm. Diff.: 0.007010751258544426 tk: 5 x_norm: 16.799667200362663\n",
      "Iteration 1029 - Grad. Norm.: 0.0014003098816911426 Norm. Diff.: 0.0070061467196031475 tk: 5 x_norm: 16.805660034084358\n",
      "Iteration 1030 - Grad. Norm.: 0.0013993918614000165 Norm. Diff.: 0.007001549408455692 tk: 5 x_norm: 16.811648956719374\n",
      "Iteration 1031 - Grad. Norm.: 0.001398475279439226 Norm. Diff.: 0.0069969593070000995 tk: 5 x_norm: 16.817633974151484\n",
      "Iteration 1032 - Grad. Norm.: 0.0013975601322130991 Norm. Diff.: 0.006992376397196104 tk: 5 x_norm: 16.823615092250574\n",
      "Iteration 1033 - Grad. Norm.: 0.0013966464161382609 Norm. Diff.: 0.006987800661065464 tk: 5 x_norm: 16.829592316872656\n",
      "Iteration 1034 - Grad. Norm.: 0.0013957341276435798 Norm. Diff.: 0.006983232080691046 tk: 5 x_norm: 16.83556565385994\n",
      "Iteration 1035 - Grad. Norm.: 0.0013948232631701156 Norm. Diff.: 0.006978670638217829 tk: 5 x_norm: 16.841535109040848\n",
      "Iteration 1036 - Grad. Norm.: 0.0013939138191710685 Norm. Diff.: 0.00697411631585068 tk: 5 x_norm: 16.8475006882301\n",
      "Iteration 1037 - Grad. Norm.: 0.0013930057921117268 Norm. Diff.: 0.006969569095855324 tk: 5 x_norm: 16.853462397228714\n",
      "Iteration 1038 - Grad. Norm.: 0.0013920991784694085 Norm. Diff.: 0.006965028960558709 tk: 5 x_norm: 16.859420241824076\n",
      "Iteration 1039 - Grad. Norm.: 0.0013911939747334211 Norm. Diff.: 0.006960495892347049 tk: 5 x_norm: 16.865374227789996\n",
      "Iteration 1040 - Grad. Norm.: 0.001390290177405001 Norm. Diff.: 0.006955969873667216 tk: 5 x_norm: 16.871324360886714\n",
      "Iteration 1041 - Grad. Norm.: 0.0013893877829972646 Norm. Diff.: 0.006951450887024882 tk: 5 x_norm: 16.877270646860975\n",
      "Iteration 1042 - Grad. Norm.: 0.0013884867880351599 Norm. Diff.: 0.0069469389149863356 tk: 5 x_norm: 16.883213091446063\n",
      "Iteration 1043 - Grad. Norm.: 0.0013875871890554126 Norm. Diff.: 0.006942433940175703 tk: 5 x_norm: 16.889151700361836\n",
      "Iteration 1044 - Grad. Norm.: 0.0013866889826064776 Norm. Diff.: 0.006937935945276995 tk: 5 x_norm: 16.895086479314788\n",
      "Iteration 1045 - Grad. Norm.: 0.0013857921652484905 Norm. Diff.: 0.006933444913032288 tk: 5 x_norm: 16.90101743399807\n",
      "Iteration 1046 - Grad. Norm.: 0.0013848967335532128 Norm. Diff.: 0.006928960826242299 tk: 5 x_norm: 16.906944570091554\n",
      "Iteration 1047 - Grad. Norm.: 0.0013840026841039862 Norm. Diff.: 0.006924483667766184 tk: 5 x_norm: 16.912867893261865\n",
      "Iteration 1048 - Grad. Norm.: 0.0013831100134956815 Norm. Diff.: 0.006920013420519952 tk: 5 x_norm: 16.9187874091624\n",
      "Iteration 1049 - Grad. Norm.: 0.0013822187183346521 Norm. Diff.: 0.00691555006747843 tk: 5 x_norm: 16.92470312343343\n",
      "Iteration 1050 - Grad. Norm.: 0.0013813287952386818 Norm. Diff.: 0.006911093591673191 tk: 5 x_norm: 16.930615041702097\n",
      "Iteration 1051 - Grad. Norm.: 0.0013804402408369345 Norm. Diff.: 0.006906643976193481 tk: 5 x_norm: 16.93652316958244\n",
      "Iteration 1052 - Grad. Norm.: 0.0013795530517699147 Norm. Diff.: 0.006902201204184652 tk: 5 x_norm: 16.942427512675494\n",
      "Iteration 1053 - Grad. Norm.: 0.0013786672246894093 Norm. Diff.: 0.006897765258849512 tk: 5 x_norm: 16.94832807656928\n",
      "Iteration 1054 - Grad. Norm.: 0.0013777827562584442 Norm. Diff.: 0.0068933361234470875 tk: 5 x_norm: 16.954224866838867\n",
      "Iteration 1055 - Grad. Norm.: 0.0013768996431512367 Norm. Diff.: 0.006888913781292229 tk: 5 x_norm: 16.960117889046433\n",
      "Iteration 1056 - Grad. Norm.: 0.0013760178820531464 Norm. Diff.: 0.006884498215756259 tk: 5 x_norm: 16.96600714874126\n",
      "Iteration 1057 - Grad. Norm.: 0.0013751374696606311 Norm. Diff.: 0.006880089410265839 tk: 5 x_norm: 16.97189265145981\n",
      "Iteration 1058 - Grad. Norm.: 0.0013742584026811956 Norm. Diff.: 0.006875687348302994 tk: 5 x_norm: 16.977774402725764\n",
      "Iteration 1059 - Grad. Norm.: 0.0013733806778333491 Norm. Diff.: 0.006871292013405919 tk: 5 x_norm: 16.983652408050045\n",
      "Iteration 1060 - Grad. Norm.: 0.001372504291846555 Norm. Diff.: 0.006866903389166797 tk: 5 x_norm: 16.98952667293087\n",
      "Iteration 1061 - Grad. Norm.: 0.0013716292414611866 Norm. Diff.: 0.006862521459232763 tk: 5 x_norm: 16.9953972028538\n",
      "Iteration 1062 - Grad. Norm.: 0.0013707555234284809 Norm. Diff.: 0.006858146207305877 tk: 5 x_norm: 17.001264003291748\n",
      "Iteration 1063 - Grad. Norm.: 0.0013698831345104953 Norm. Diff.: 0.006853777617142448 tk: 5 x_norm: 17.00712707970506\n",
      "Iteration 1064 - Grad. Norm.: 0.0013690120714800525 Norm. Diff.: 0.00684941567255242 tk: 5 x_norm: 17.012986437541525\n",
      "Iteration 1065 - Grad. Norm.: 0.00136814233112071 Norm. Diff.: 0.006845060357400292 tk: 5 x_norm: 17.018842082236425\n",
      "Iteration 1066 - Grad. Norm.: 0.001367273910226701 Norm. Diff.: 0.0068407116556035855 tk: 5 x_norm: 17.02469401921258\n",
      "Iteration 1067 - Grad. Norm.: 0.0013664068056028992 Norm. Diff.: 0.006836369551133472 tk: 5 x_norm: 17.030542253880363\n",
      "Iteration 1068 - Grad. Norm.: 0.0013655410140647668 Norm. Diff.: 0.006832034028014498 tk: 5 x_norm: 17.036386791637785\n",
      "Iteration 1069 - Grad. Norm.: 0.0013646765324383174 Norm. Diff.: 0.006827705070323709 tk: 5 x_norm: 17.042227637870486\n",
      "Iteration 1070 - Grad. Norm.: 0.0013638133575600638 Norm. Diff.: 0.006823382662191606 tk: 5 x_norm: 17.048064797951806\n",
      "Iteration 1071 - Grad. Norm.: 0.0013629514862769805 Norm. Diff.: 0.006819066787800496 tk: 5 x_norm: 17.053898277242805\n",
      "Iteration 1072 - Grad. Norm.: 0.001362090915446459 Norm. Diff.: 0.00681475743138504 tk: 5 x_norm: 17.059728081092302\n",
      "Iteration 1073 - Grad. Norm.: 0.0013612316419362568 Norm. Diff.: 0.006810454577232257 tk: 5 x_norm: 17.065554214836943\n",
      "Iteration 1074 - Grad. Norm.: 0.0013603736626244653 Norm. Diff.: 0.006806158209681447 tk: 5 x_norm: 17.071376683801198\n",
      "Iteration 1075 - Grad. Norm.: 0.0013595169743994607 Norm. Diff.: 0.006801868313122223 tk: 5 x_norm: 17.07719549329742\n",
      "Iteration 1076 - Grad. Norm.: 0.0013586615741598568 Norm. Diff.: 0.006797584871997156 tk: 5 x_norm: 17.08301064862588\n",
      "Iteration 1077 - Grad. Norm.: 0.0013578074588144725 Norm. Diff.: 0.006793307870799098 tk: 5 x_norm: 17.088822155074812\n",
      "Iteration 1078 - Grad. Norm.: 0.0013569546252822802 Norm. Diff.: 0.006789037294072351 tk: 5 x_norm: 17.094630017920437\n",
      "Iteration 1079 - Grad. Norm.: 0.0013561030704923682 Norm. Diff.: 0.006784773126411466 tk: 5 x_norm: 17.100434242427017\n",
      "Iteration 1080 - Grad. Norm.: 0.0013552527913838971 Norm. Diff.: 0.00678051535246171 tk: 5 x_norm: 17.106234833846866\n",
      "Iteration 1081 - Grad. Norm.: 0.0013544037849060576 Norm. Diff.: 0.006776263956919483 tk: 5 x_norm: 17.112031797420425\n",
      "Iteration 1082 - Grad. Norm.: 0.00135355604801803 Norm. Diff.: 0.006772018924530236 tk: 5 x_norm: 17.11782513837626\n",
      "Iteration 1083 - Grad. Norm.: 0.001352709577688943 Norm. Diff.: 0.006767780240090077 tk: 5 x_norm: 17.123614861931134\n",
      "Iteration 1084 - Grad. Norm.: 0.0013518643708978284 Norm. Diff.: 0.006763547888444729 tk: 5 x_norm: 17.129400973290004\n",
      "Iteration 1085 - Grad. Norm.: 0.001351020424633586 Norm. Diff.: 0.0067593218544892706 tk: 5 x_norm: 17.135183477646105\n",
      "Iteration 1086 - Grad. Norm.: 0.0013501777358949374 Norm. Diff.: 0.006755102123167946 tk: 5 x_norm: 17.14096238018095\n",
      "Iteration 1087 - Grad. Norm.: 0.0013493363016903897 Norm. Diff.: 0.006750888679474668 tk: 5 x_norm: 17.14673768606438\n",
      "Iteration 1088 - Grad. Norm.: 0.001348496119038192 Norm. Diff.: 0.006746681508451896 tk: 5 x_norm: 17.15250940045459\n",
      "Iteration 1089 - Grad. Norm.: 0.0013476571849662966 Norm. Diff.: 0.006742480595190934 tk: 5 x_norm: 17.15827752849819\n",
      "Iteration 1090 - Grad. Norm.: 0.0013468194965123167 Norm. Diff.: 0.006738285924831352 tk: 5 x_norm: 17.16404207533021\n",
      "Iteration 1091 - Grad. Norm.: 0.00134598305072349 Norm. Diff.: 0.006734097482561597 tk: 5 x_norm: 17.169803046074165\n",
      "Iteration 1092 - Grad. Norm.: 0.0013451478446566362 Norm. Diff.: 0.006729915253617465 tk: 5 x_norm: 17.175560445842063\n",
      "Iteration 1093 - Grad. Norm.: 0.0013443138753781198 Norm. Diff.: 0.006725739223283316 tk: 5 x_norm: 17.181314279734455\n",
      "Iteration 1094 - Grad. Norm.: 0.001343481139963809 Norm. Diff.: 0.006721569376890596 tk: 5 x_norm: 17.18706455284048\n",
      "Iteration 1095 - Grad. Norm.: 0.001342649635499035 Norm. Diff.: 0.0067174056998189355 tk: 5 x_norm: 17.192811270237872\n",
      "Iteration 1096 - Grad. Norm.: 0.0013418193590785568 Norm. Diff.: 0.0067132481774951755 tk: 5 x_norm: 17.19855443699302\n",
      "Iteration 1097 - Grad. Norm.: 0.0013409903078065227 Norm. Diff.: 0.006709096795392831 tk: 5 x_norm: 17.20429405816101\n",
      "Iteration 1098 - Grad. Norm.: 0.0013401624787964255 Norm. Diff.: 0.006704951539032525 tk: 5 x_norm: 17.21003013878562\n",
      "Iteration 1099 - Grad. Norm.: 0.0013393358691710742 Norm. Diff.: 0.006700812393982201 tk: 5 x_norm: 17.215762683899385\n",
      "Iteration 1100 - Grad. Norm.: 0.0013385104760625438 Norm. Diff.: 0.006696679345855378 tk: 5 x_norm: 17.221491698523643\n",
      "Iteration 1101 - Grad. Norm.: 0.0013376862966121492 Norm. Diff.: 0.006692552380312732 tk: 5 x_norm: 17.227217187668536\n",
      "Iteration 1102 - Grad. Norm.: 0.0013368633279703982 Norm. Diff.: 0.006688431483060804 tk: 5 x_norm: 17.232939156333064\n",
      "Iteration 1103 - Grad. Norm.: 0.0013360415672969597 Norm. Diff.: 0.006684316639851929 tk: 5 x_norm: 17.238657609505122\n",
      "Iteration 1104 - Grad. Norm.: 0.0013352210117606226 Norm. Diff.: 0.006680207836484657 tk: 5 x_norm: 17.244372552161515\n",
      "Iteration 1105 - Grad. Norm.: 0.0013344016585392618 Norm. Diff.: 0.006676105058803185 tk: 5 x_norm: 17.250083989268024\n",
      "Iteration 1106 - Grad. Norm.: 0.0013335835048197983 Norm. Diff.: 0.006672008292696298 tk: 5 x_norm: 17.2557919257794\n",
      "Iteration 1107 - Grad. Norm.: 0.0013327665477981645 Norm. Diff.: 0.006667917524098821 tk: 5 x_norm: 17.26149636663943\n",
      "Iteration 1108 - Grad. Norm.: 0.0013319507846792644 Norm. Diff.: 0.006663832738991003 tk: 5 x_norm: 17.267197316780962\n",
      "Iteration 1109 - Grad. Norm.: 0.0013311362126769406 Norm. Diff.: 0.0066597539233962475 tk: 5 x_norm: 17.27289478112592\n",
      "Iteration 1110 - Grad. Norm.: 0.0013303228290139381 Norm. Diff.: 0.006655681063384665 tk: 5 x_norm: 17.27858876458536\n",
      "Iteration 1111 - Grad. Norm.: 0.001329510630921864 Norm. Diff.: 0.006651614145069711 tk: 5 x_norm: 17.284279272059504\n",
      "Iteration 1112 - Grad. Norm.: 0.0013286996156411553 Norm. Diff.: 0.006647553154609349 tk: 5 x_norm: 17.28996630843775\n",
      "Iteration 1113 - Grad. Norm.: 0.00132788978042104 Norm. Diff.: 0.006643498078205831 tk: 5 x_norm: 17.295649878598727\n",
      "Iteration 1114 - Grad. Norm.: 0.0013270811225195068 Norm. Diff.: 0.00663944890210526 tk: 5 x_norm: 17.30132998741032\n",
      "Iteration 1115 - Grad. Norm.: 0.001326273639203265 Norm. Diff.: 0.006635405612597506 tk: 5 x_norm: 17.3070066397297\n",
      "Iteration 1116 - Grad. Norm.: 0.0013254673277477082 Norm. Diff.: 0.00663136819601635 tk: 5 x_norm: 17.312679840403348\n",
      "Iteration 1117 - Grad. Norm.: 0.001324662185436883 Norm. Diff.: 0.0066273366387384815 tk: 5 x_norm: 17.31834959426712\n",
      "Iteration 1118 - Grad. Norm.: 0.0013238582095634526 Norm. Diff.: 0.00662331092718442 tk: 5 x_norm: 17.32401590614624\n",
      "Iteration 1119 - Grad. Norm.: 0.0013230553974286619 Norm. Diff.: 0.006619291047817337 tk: 5 x_norm: 17.329678780855353\n",
      "Iteration 1120 - Grad. Norm.: 0.001322253746342302 Norm. Diff.: 0.0066152769871433694 tk: 5 x_norm: 17.335338223198555\n",
      "Iteration 1121 - Grad. Norm.: 0.001321453253622677 Norm. Diff.: 0.006611268731711554 tk: 5 x_norm: 17.34099423796943\n",
      "Iteration 1122 - Grad. Norm.: 0.0013206539165965705 Norm. Diff.: 0.006607266268113412 tk: 5 x_norm: 17.34664682995106\n",
      "Iteration 1123 - Grad. Norm.: 0.001319855732599208 Norm. Diff.: 0.006603269582982756 tk: 5 x_norm: 17.352296003916077\n",
      "Iteration 1124 - Grad. Norm.: 0.0013190586989742267 Norm. Diff.: 0.006599278662996128 tk: 5 x_norm: 17.357941764626695\n",
      "Iteration 1125 - Grad. Norm.: 0.0013182628130736411 Norm. Diff.: 0.00659529349487117 tk: 5 x_norm: 17.363584116834726\n",
      "Iteration 1126 - Grad. Norm.: 0.001317468072257806 Norm. Diff.: 0.006591314065368346 tk: 5 x_norm: 17.36922306528163\n",
      "Iteration 1127 - Grad. Norm.: 0.0013166744738953879 Norm. Diff.: 0.006587340361288942 tk: 5 x_norm: 17.374858614698528\n",
      "Iteration 1128 - Grad. Norm.: 0.0013158820153633293 Norm. Diff.: 0.006583372369476807 tk: 5 x_norm: 17.380490769806237\n",
      "Iteration 1129 - Grad. Norm.: 0.0013150906940468138 Norm. Diff.: 0.006579410076816673 tk: 5 x_norm: 17.386119535315324\n",
      "Iteration 1130 - Grad. Norm.: 0.0013143005073392373 Norm. Diff.: 0.006575453470234228 tk: 5 x_norm: 17.391744915926097\n",
      "Iteration 1131 - Grad. Norm.: 0.0013135114526421725 Norm. Diff.: 0.006571502536696151 tk: 5 x_norm: 17.39736691632867\n",
      "Iteration 1132 - Grad. Norm.: 0.0013127235273653359 Norm. Diff.: 0.006567557263210706 tk: 5 x_norm: 17.402985541202973\n",
      "Iteration 1133 - Grad. Norm.: 0.0013119367289265566 Norm. Diff.: 0.006563617636826627 tk: 5 x_norm: 17.408600795218792\n",
      "Iteration 1134 - Grad. Norm.: 0.0013111510547517418 Norm. Diff.: 0.006559683644632803 tk: 5 x_norm: 17.414212683035803\n",
      "Iteration 1135 - Grad. Norm.: 0.0013103665022748488 Norm. Diff.: 0.00655575527375872 tk: 5 x_norm: 17.419821209303574\n",
      "Iteration 1136 - Grad. Norm.: 0.00130958306893785 Norm. Diff.: 0.006551832511374184 tk: 5 x_norm: 17.42542637866165\n",
      "Iteration 1137 - Grad. Norm.: 0.0013088007521906999 Norm. Diff.: 0.0065479153446893175 tk: 5 x_norm: 17.43102819573952\n",
      "Iteration 1138 - Grad. Norm.: 0.0013080195494913067 Norm. Diff.: 0.006544003760953477 tk: 5 x_norm: 17.43662666515669\n",
      "Iteration 1139 - Grad. Norm.: 0.0013072394583054992 Norm. Diff.: 0.006540097747456434 tk: 5 x_norm: 17.442221791522698\n",
      "Iteration 1140 - Grad. Norm.: 0.001306460476106992 Norm. Diff.: 0.006536197291527469 tk: 5 x_norm: 17.447813579437142\n",
      "Iteration 1141 - Grad. Norm.: 0.0013056826003773614 Norm. Diff.: 0.00653230238053478 tk: 5 x_norm: 17.453402033489724\n",
      "Iteration 1142 - Grad. Norm.: 0.0013049058286060085 Norm. Diff.: 0.006528413001886775 tk: 5 x_norm: 17.45898715826025\n",
      "Iteration 1143 - Grad. Norm.: 0.0013041301582901294 Norm. Diff.: 0.00652452914302993 tk: 5 x_norm: 17.464568958318686\n",
      "Iteration 1144 - Grad. Norm.: 0.0013033555869346874 Norm. Diff.: 0.006520650791450559 tk: 5 x_norm: 17.47014743822518\n",
      "Iteration 1145 - Grad. Norm.: 0.0013025821120523774 Norm. Diff.: 0.006516777934673462 tk: 5 x_norm: 17.475722602530084\n",
      "Iteration 1146 - Grad. Norm.: 0.0013018097311635998 Norm. Diff.: 0.006512910560261834 tk: 5 x_norm: 17.481294455773988\n",
      "Iteration 1147 - Grad. Norm.: 0.0013010384417964274 Norm. Diff.: 0.006509048655818078 tk: 5 x_norm: 17.48686300248776\n",
      "Iteration 1148 - Grad. Norm.: 0.0013002682414865762 Norm. Diff.: 0.006505192208982193 tk: 5 x_norm: 17.49242824719254\n",
      "Iteration 1149 - Grad. Norm.: 0.0012994991277773748 Norm. Diff.: 0.0065013412074328555 tk: 5 x_norm: 17.49799019439982\n",
      "Iteration 1150 - Grad. Norm.: 0.001298731098219737 Norm. Diff.: 0.006497495638886788 tk: 5 x_norm: 17.503548848611413\n",
      "Iteration 1151 - Grad. Norm.: 0.0012979641503721277 Norm. Diff.: 0.006493655491098736 tk: 5 x_norm: 17.509104214319546\n",
      "Iteration 1152 - Grad. Norm.: 0.0012971982818005359 Norm. Diff.: 0.006489820751860422 tk: 5 x_norm: 17.514656296006837\n",
      "Iteration 1153 - Grad. Norm.: 0.0012964334900784445 Norm. Diff.: 0.006485991409002782 tk: 5 x_norm: 17.52020509814634\n",
      "Iteration 1154 - Grad. Norm.: 0.0012956697727868028 Norm. Diff.: 0.006482167450392114 tk: 5 x_norm: 17.52575062520158\n",
      "Iteration 1155 - Grad. Norm.: 0.0012949071275139934 Norm. Diff.: 0.006478348863933958 tk: 5 x_norm: 17.531292881626573\n",
      "Iteration 1156 - Grad. Norm.: 0.001294145551855807 Norm. Diff.: 0.006474535637569991 tk: 5 x_norm: 17.536831871865857\n",
      "Iteration 1157 - Grad. Norm.: 0.001293385043415411 Norm. Diff.: 0.006470727759279196 tk: 5 x_norm: 17.542367600354517\n",
      "Iteration 1158 - Grad. Norm.: 0.0012926255998033215 Norm. Diff.: 0.00646692521707716 tk: 5 x_norm: 17.547900071518214\n",
      "Iteration 1159 - Grad. Norm.: 0.0012918672186373755 Norm. Diff.: 0.006463127999016671 tk: 5 x_norm: 17.55342928977322\n",
      "Iteration 1160 - Grad. Norm.: 0.0012911098975427007 Norm. Diff.: 0.006459336093186792 tk: 5 x_norm: 17.558955259526424\n",
      "Iteration 1161 - Grad. Norm.: 0.001290353634151688 Norm. Diff.: 0.006455549487713538 tk: 5 x_norm: 17.564477985175387\n",
      "Iteration 1162 - Grad. Norm.: 0.001289598426103963 Norm. Diff.: 0.006451768170758448 tk: 5 x_norm: 17.56999747110835\n",
      "Iteration 1163 - Grad. Norm.: 0.0012888442710463591 Norm. Diff.: 0.006447992130519686 tk: 5 x_norm: 17.57551372170427\n",
      "Iteration 1164 - Grad. Norm.: 0.0012880911666328873 Norm. Diff.: 0.0064442213552318205 tk: 5 x_norm: 17.581026741332842\n",
      "Iteration 1165 - Grad. Norm.: 0.0012873391105247096 Norm. Diff.: 0.006440455833164486 tk: 5 x_norm: 17.586536534354522\n",
      "Iteration 1166 - Grad. Norm.: 0.0012865881003901103 Norm. Diff.: 0.006436695552623518 tk: 5 x_norm: 17.59204310512058\n",
      "Iteration 1167 - Grad. Norm.: 0.0012858381339044718 Norm. Diff.: 0.006432940501950623 tk: 5 x_norm: 17.597546457973078\n",
      "Iteration 1168 - Grad. Norm.: 0.0012850892087502422 Norm. Diff.: 0.006429190669522342 tk: 5 x_norm: 17.603046597244944\n",
      "Iteration 1169 - Grad. Norm.: 0.001284341322616911 Norm. Diff.: 0.006425446043751177 tk: 5 x_norm: 17.60854352725997\n",
      "Iteration 1170 - Grad. Norm.: 0.001283594473200983 Norm. Diff.: 0.006421706613084732 tk: 5 x_norm: 17.61403725233286\n",
      "Iteration 1171 - Grad. Norm.: 0.0012828486582059458 Norm. Diff.: 0.006417972366004885 tk: 5 x_norm: 17.61952777676923\n",
      "Iteration 1172 - Grad. Norm.: 0.001282103875342249 Norm. Diff.: 0.0064142432910296 tk: 5 x_norm: 17.625015104865653\n",
      "Iteration 1173 - Grad. Norm.: 0.001281360122327274 Norm. Diff.: 0.006410519376711266 tk: 5 x_norm: 17.630499240909693\n",
      "Iteration 1174 - Grad. Norm.: 0.0012806173968853102 Norm. Diff.: 0.006406800611636354 tk: 5 x_norm: 17.635980189179897\n",
      "Iteration 1175 - Grad. Norm.: 0.0012798756967475225 Norm. Diff.: 0.0064030869844265495 tk: 5 x_norm: 17.64145795394586\n",
      "Iteration 1176 - Grad. Norm.: 0.0012791350196519325 Norm. Diff.: 0.006399378483737573 tk: 5 x_norm: 17.64693253946822\n",
      "Iteration 1177 - Grad. Norm.: 0.0012783953633433863 Norm. Diff.: 0.006395675098259724 tk: 5 x_norm: 17.652403949998707\n",
      "Iteration 1178 - Grad. Norm.: 0.0012776567255735319 Norm. Diff.: 0.006391976816716855 tk: 5 x_norm: 17.657872189780157\n",
      "Iteration 1179 - Grad. Norm.: 0.0012769191041007908 Norm. Diff.: 0.006388283627867739 tk: 5 x_norm: 17.66333726304653\n",
      "Iteration 1180 - Grad. Norm.: 0.0012761824966903313 Norm. Diff.: 0.006384595520503932 tk: 5 x_norm: 17.66879917402296\n",
      "Iteration 1181 - Grad. Norm.: 0.0012754469011140494 Norm. Diff.: 0.0063809124834517126 tk: 5 x_norm: 17.674257926925748\n",
      "Iteration 1182 - Grad. Norm.: 0.0012747123151505314 Norm. Diff.: 0.006377234505570371 tk: 5 x_norm: 17.67971352596242\n",
      "Iteration 1183 - Grad. Norm.: 0.0012739787365850398 Norm. Diff.: 0.006373561575752631 tk: 5 x_norm: 17.685165975331724\n",
      "Iteration 1184 - Grad. Norm.: 0.0012732461632094815 Norm. Diff.: 0.006369893682925113 tk: 5 x_norm: 17.69061527922367\n",
      "Iteration 1185 - Grad. Norm.: 0.0012725145928223832 Norm. Diff.: 0.006366230816047421 tk: 5 x_norm: 17.696061441819573\n",
      "Iteration 1186 - Grad. Norm.: 0.0012717840232288665 Norm. Diff.: 0.006362572964111942 tk: 5 x_norm: 17.701504467292008\n",
      "Iteration 1187 - Grad. Norm.: 0.0012710544522406267 Norm. Diff.: 0.006358920116144511 tk: 5 x_norm: 17.706944359804936\n",
      "Iteration 1188 - Grad. Norm.: 0.0012703258776759002 Norm. Diff.: 0.006355272261203129 tk: 5 x_norm: 17.712381123513648\n",
      "Iteration 1189 - Grad. Norm.: 0.0012695982973594448 Norm. Diff.: 0.006351629388379525 tk: 5 x_norm: 17.717814762564824\n",
      "Iteration 1190 - Grad. Norm.: 0.0012688717091225148 Norm. Diff.: 0.006347991486797211 tk: 5 x_norm: 17.723245281096567\n",
      "Iteration 1191 - Grad. Norm.: 0.0012681461108028347 Norm. Diff.: 0.006344358545612675 tk: 5 x_norm: 17.728672683238376\n",
      "Iteration 1192 - Grad. Norm.: 0.0012674215002445766 Norm. Diff.: 0.006340730554014185 tk: 5 x_norm: 17.734096973111242\n",
      "Iteration 1193 - Grad. Norm.: 0.001266697875298333 Norm. Diff.: 0.0063371075012226535 tk: 5 x_norm: 17.739518154827625\n",
      "Iteration 1194 - Grad. Norm.: 0.0012659752338210954 Norm. Diff.: 0.006333489376491668 tk: 5 x_norm: 17.744936232491487\n",
      "Iteration 1195 - Grad. Norm.: 0.0012652535736762268 Norm. Diff.: 0.006329876169105365 tk: 5 x_norm: 17.750351210198314\n",
      "Iteration 1196 - Grad. Norm.: 0.0012645328927334426 Norm. Diff.: 0.00632626786838108 tk: 5 x_norm: 17.755763092035163\n",
      "Iteration 1197 - Grad. Norm.: 0.0012638131888687814 Norm. Diff.: 0.006322664463667146 tk: 5 x_norm: 17.76117188208065\n",
      "Iteration 1198 - Grad. Norm.: 0.0012630944599645833 Norm. Diff.: 0.006319065944343915 tk: 5 x_norm: 17.766577584404995\n",
      "Iteration 1199 - Grad. Norm.: 0.0012623767039094695 Norm. Diff.: 0.0063154722998227785 tk: 5 x_norm: 17.771980203070047\n",
      "Iteration 1200 - Grad. Norm.: 0.001261659918598311 Norm. Diff.: 0.006311883519547161 tk: 5 x_norm: 17.77737974212931\n",
      "Iteration 1201 - Grad. Norm.: 0.0012609441019322133 Norm. Diff.: 0.006308299592991553 tk: 5 x_norm: 17.78277620562794\n",
      "Iteration 1202 - Grad. Norm.: 0.0012602292518184871 Norm. Diff.: 0.006304720509661141 tk: 5 x_norm: 17.788169597602803\n",
      "Iteration 1203 - Grad. Norm.: 0.0012595153661706276 Norm. Diff.: 0.0063011462590922985 tk: 5 x_norm: 17.793559922082476\n",
      "Iteration 1204 - Grad. Norm.: 0.0012588024429082926 Norm. Diff.: 0.006297576830853155 tk: 5 x_norm: 17.79894718308728\n",
      "Iteration 1205 - Grad. Norm.: 0.001258090479957274 Norm. Diff.: 0.006294012214541323 tk: 5 x_norm: 17.80433138462931\n",
      "Iteration 1206 - Grad. Norm.: 0.0012573794752494818 Norm. Diff.: 0.006290452399786496 tk: 5 x_norm: 17.809712530712435\n",
      "Iteration 1207 - Grad. Norm.: 0.0012566694267229176 Norm. Diff.: 0.006286897376247491 tk: 5 x_norm: 17.81509062533234\n",
      "Iteration 1208 - Grad. Norm.: 0.0012559603323216506 Norm. Diff.: 0.006283347133614509 tk: 5 x_norm: 17.820465672476544\n",
      "Iteration 1209 - Grad. Norm.: 0.0012552521899957987 Norm. Diff.: 0.006279801661608341 tk: 5 x_norm: 17.825837676124422\n",
      "Iteration 1210 - Grad. Norm.: 0.0012545449977015017 Norm. Diff.: 0.006276260949978854 tk: 5 x_norm: 17.83120664024723\n",
      "Iteration 1211 - Grad. Norm.: 0.0012538387534009022 Norm. Diff.: 0.0062727249885074984 tk: 5 x_norm: 17.83657256880813\n",
      "Iteration 1212 - Grad. Norm.: 0.0012531334550621213 Norm. Diff.: 0.006269193767004498 tk: 5 x_norm: 17.841935465762198\n",
      "Iteration 1213 - Grad. Norm.: 0.0012524291006592377 Norm. Diff.: 0.006265667275310726 tk: 5 x_norm: 17.84729533505647\n",
      "Iteration 1214 - Grad. Norm.: 0.0012517256881722648 Norm. Diff.: 0.006262145503296203 tk: 5 x_norm: 17.85265218062994\n",
      "Iteration 1215 - Grad. Norm.: 0.0012510232155871289 Norm. Diff.: 0.006258628440861162 tk: 5 x_norm: 17.858006006413607\n",
      "Iteration 1216 - Grad. Norm.: 0.001250321680895646 Norm. Diff.: 0.006255116077935686 tk: 5 x_norm: 17.863356816330466\n",
      "Iteration 1217 - Grad. Norm.: 0.0012496210820955038 Norm. Diff.: 0.006251608404478329 tk: 5 x_norm: 17.868704614295574\n",
      "Iteration 1218 - Grad. Norm.: 0.0012489214171902334 Norm. Diff.: 0.006248105410477525 tk: 5 x_norm: 17.87404940421602\n",
      "Iteration 1219 - Grad. Norm.: 0.0012482226841891947 Norm. Diff.: 0.00624460708595098 tk: 5 x_norm: 17.879391189990994\n",
      "Iteration 1220 - Grad. Norm.: 0.0012475248811075518 Norm. Diff.: 0.006241113420945884 tk: 5 x_norm: 17.88472997551178\n",
      "Iteration 1221 - Grad. Norm.: 0.001246828005966249 Norm. Diff.: 0.006237624405537811 tk: 5 x_norm: 17.89006576466179\n",
      "Iteration 1222 - Grad. Norm.: 0.0012461320567919941 Norm. Diff.: 0.006234140029831225 tk: 5 x_norm: 17.895398561316576\n",
      "Iteration 1223 - Grad. Norm.: 0.0012454370316172336 Norm. Diff.: 0.006230660283959956 tk: 5 x_norm: 17.90072836934387\n",
      "Iteration 1224 - Grad. Norm.: 0.0012447429284801346 Norm. Diff.: 0.00622718515808623 tk: 5 x_norm: 17.906055192603578\n",
      "Iteration 1225 - Grad. Norm.: 0.0012440497454245605 Norm. Diff.: 0.006223714642400634 tk: 5 x_norm: 17.911379034947828\n",
      "Iteration 1226 - Grad. Norm.: 0.0012433574805000521 Norm. Diff.: 0.006220248727122897 tk: 5 x_norm: 17.916699900220987\n",
      "Iteration 1227 - Grad. Norm.: 0.0012426661317618067 Norm. Diff.: 0.006216787402500328 tk: 5 x_norm: 17.922017792259663\n",
      "Iteration 1228 - Grad. Norm.: 0.0012419756972706566 Norm. Diff.: 0.0062133306588090355 tk: 5 x_norm: 17.927332714892746\n",
      "Iteration 1229 - Grad. Norm.: 0.00124128617509305 Norm. Diff.: 0.006209878486353282 tk: 5 x_norm: 17.93264467194142\n",
      "Iteration 1230 - Grad. Norm.: 0.0012405975633010269 Norm. Diff.: 0.006206430875465209 tk: 5 x_norm: 17.937953667219194\n",
      "Iteration 1231 - Grad. Norm.: 0.0012399098599722028 Norm. Diff.: 0.006202987816505202 tk: 5 x_norm: 17.943259704531908\n",
      "Iteration 1232 - Grad. Norm.: 0.0012392230631897458 Norm. Diff.: 0.006199549299860977 tk: 5 x_norm: 17.94856278767777\n",
      "Iteration 1233 - Grad. Norm.: 0.0012385371710423574 Norm. Diff.: 0.006196115315948643 tk: 5 x_norm: 17.95386292044736\n",
      "Iteration 1234 - Grad. Norm.: 0.0012378521816242497 Norm. Diff.: 0.006192685855211764 tk: 5 x_norm: 17.959160106623674\n",
      "Iteration 1235 - Grad. Norm.: 0.0012371680930351315 Norm. Diff.: 0.006189260908121177 tk: 5 x_norm: 17.964454349982116\n",
      "Iteration 1236 - Grad. Norm.: 0.001236484903380181 Norm. Diff.: 0.006185840465175649 tk: 5 x_norm: 17.96974565429054\n",
      "Iteration 1237 - Grad. Norm.: 0.0012358026107700294 Norm. Diff.: 0.006182424516900979 tk: 5 x_norm: 17.975034023309277\n",
      "Iteration 1238 - Grad. Norm.: 0.0012351212133207415 Norm. Diff.: 0.006179013053850127 tk: 5 x_norm: 17.98031946079111\n",
      "Iteration 1239 - Grad. Norm.: 0.001234440709153796 Norm. Diff.: 0.00617560606660361 tk: 5 x_norm: 17.985601970481365\n",
      "Iteration 1240 - Grad. Norm.: 0.0012337610963960627 Norm. Diff.: 0.006172203545769028 tk: 5 x_norm: 17.990881556117877\n",
      "Iteration 1241 - Grad. Norm.: 0.0012330823731797884 Norm. Diff.: 0.0061688054819802095 tk: 5 x_norm: 17.996158221431013\n",
      "Iteration 1242 - Grad. Norm.: 0.0012324045376425714 Norm. Diff.: 0.006165411865898908 tk: 5 x_norm: 18.00143197014374\n",
      "Iteration 1243 - Grad. Norm.: 0.0012317275879273463 Norm. Diff.: 0.006162022688212681 tk: 5 x_norm: 18.00670280597158\n",
      "Iteration 1244 - Grad. Norm.: 0.0012310515221823641 Norm. Diff.: 0.006158637939636675 tk: 5 x_norm: 18.011970732622686\n",
      "Iteration 1245 - Grad. Norm.: 0.0012303763385611705 Norm. Diff.: 0.006155257610911628 tk: 5 x_norm: 18.01723575379782\n",
      "Iteration 1246 - Grad. Norm.: 0.0012297020352225905 Norm. Diff.: 0.0061518816928059225 tk: 5 x_norm: 18.022497873190403\n",
      "Iteration 1247 - Grad. Norm.: 0.0012290286103307049 Norm. Diff.: 0.006148510176112926 tk: 5 x_norm: 18.027757094486518\n",
      "Iteration 1248 - Grad. Norm.: 0.0012283560620548369 Norm. Diff.: 0.006145143051653521 tk: 5 x_norm: 18.033013421364934\n",
      "Iteration 1249 - Grad. Norm.: 0.001227684388569528 Norm. Diff.: 0.006141780310274189 tk: 5 x_norm: 18.038266857497135\n",
      "Iteration 1250 - Grad. Norm.: 0.0012270135880545227 Norm. Diff.: 0.006138421942847705 tk: 5 x_norm: 18.04351740654732\n",
      "Iteration 1251 - Grad. Norm.: 0.0012263436586947467 Norm. Diff.: 0.006135067940272696 tk: 5 x_norm: 18.04876507217244\n",
      "Iteration 1252 - Grad. Norm.: 0.0012256745986802906 Norm. Diff.: 0.006131718293473766 tk: 5 x_norm: 18.054009858022212\n",
      "Iteration 1253 - Grad. Norm.: 0.001225006406206393 Norm. Diff.: 0.006128372993401414 tk: 5 x_norm: 18.059251767739138\n",
      "Iteration 1254 - Grad. Norm.: 0.001224339079473417 Norm. Diff.: 0.006125032031031755 tk: 5 x_norm: 18.064490804958528\n",
      "Iteration 1255 - Grad. Norm.: 0.0012236726166868358 Norm. Diff.: 0.006121695397367012 tk: 5 x_norm: 18.06972697330851\n",
      "Iteration 1256 - Grad. Norm.: 0.0012230070160572138 Norm. Diff.: 0.006118363083434229 tk: 5 x_norm: 18.074960276410057\n",
      "Iteration 1257 - Grad. Norm.: 0.0012223422758001858 Norm. Diff.: 0.00611503508028613 tk: 5 x_norm: 18.080190717877013\n",
      "Iteration 1258 - Grad. Norm.: 0.0012216783941364424 Norm. Diff.: 0.006111711379000951 tk: 5 x_norm: 18.08541830131609\n",
      "Iteration 1259 - Grad. Norm.: 0.0012210153692917124 Norm. Diff.: 0.006108391970682218 tk: 5 x_norm: 18.09064303032691\n",
      "Iteration 1260 - Grad. Norm.: 0.0012203531994967388 Norm. Diff.: 0.0061050768464585405 tk: 5 x_norm: 18.09586490850201\n",
      "Iteration 1261 - Grad. Norm.: 0.0012196918829872677 Norm. Diff.: 0.006101765997483717 tk: 5 x_norm: 18.10108393942688\n",
      "Iteration 1262 - Grad. Norm.: 0.001219031418004027 Norm. Diff.: 0.006098459414936445 tk: 5 x_norm: 18.106300126679947\n",
      "Iteration 1263 - Grad. Norm.: 0.001218371802792709 Norm. Diff.: 0.006095157090020077 tk: 5 x_norm: 18.111513473832634\n",
      "Iteration 1264 - Grad. Norm.: 0.0012177130356039547 Norm. Diff.: 0.006091859013963683 tk: 5 x_norm: 18.116723984449344\n",
      "Iteration 1265 - Grad. Norm.: 0.001217055114693332 Norm. Diff.: 0.00608856517801963 tk: 5 x_norm: 18.12193166208751\n",
      "Iteration 1266 - Grad. Norm.: 0.0012163980383213253 Norm. Diff.: 0.006085275573466605 tk: 5 x_norm: 18.12713651029759\n",
      "Iteration 1267 - Grad. Norm.: 0.001215741804753308 Norm. Diff.: 0.0060819901916066175 tk: 5 x_norm: 18.132338532623088\n",
      "Iteration 1268 - Grad. Norm.: 0.0012150864122595355 Norm. Diff.: 0.006078709023766531 tk: 5 x_norm: 18.137537732600588\n",
      "Iteration 1269 - Grad. Norm.: 0.0012144318591151206 Norm. Diff.: 0.006075432061297611 tk: 5 x_norm: 18.142734113759754\n",
      "Iteration 1270 - Grad. Norm.: 0.0012137781436000205 Norm. Diff.: 0.006072159295575642 tk: 5 x_norm: 18.14792767962337\n",
      "Iteration 1271 - Grad. Norm.: 0.001213125263999017 Norm. Diff.: 0.006068890718000043 tk: 5 x_norm: 18.153118433707334\n",
      "Iteration 1272 - Grad. Norm.: 0.001212473218601702 Norm. Diff.: 0.006065626319995227 tk: 5 x_norm: 18.158306379520692\n",
      "Iteration 1273 - Grad. Norm.: 0.0012118220057024567 Norm. Diff.: 0.006062366093008378 tk: 5 x_norm: 18.16349152056565\n",
      "Iteration 1274 - Grad. Norm.: 0.0012111716236004396 Norm. Diff.: 0.006059110028512134 tk: 5 x_norm: 18.168673860337602\n",
      "Iteration 1275 - Grad. Norm.: 0.0012105220705995652 Norm. Diff.: 0.006055858118002021 tk: 5 x_norm: 18.173853402325125\n",
      "Iteration 1276 - Grad. Norm.: 0.001209873345008492 Norm. Diff.: 0.00605261035299778 tk: 5 x_norm: 18.17903015001002\n",
      "Iteration 1277 - Grad. Norm.: 0.0012092254451406001 Norm. Diff.: 0.006049366725042459 tk: 5 x_norm: 18.184204106867334\n",
      "Iteration 1278 - Grad. Norm.: 0.001208578369313978 Norm. Diff.: 0.00604612722570295 tk: 5 x_norm: 18.189375276365347\n",
      "Iteration 1279 - Grad. Norm.: 0.0012079321158514084 Norm. Diff.: 0.00604289184656979 tk: 5 x_norm: 18.19454366196562\n",
      "Iteration 1280 - Grad. Norm.: 0.001207286683080347 Norm. Diff.: 0.006039660579256992 tk: 5 x_norm: 18.199709267123005\n",
      "Iteration 1281 - Grad. Norm.: 0.0012066420693329055 Norm. Diff.: 0.006036433415401616 tk: 5 x_norm: 18.204872095285644\n",
      "Iteration 1282 - Grad. Norm.: 0.001205998272945844 Norm. Diff.: 0.006033210346664411 tk: 5 x_norm: 18.21003214989502\n",
      "Iteration 1283 - Grad. Norm.: 0.0012053552922605423 Norm. Diff.: 0.006029991364729086 tk: 5 x_norm: 18.21518943438594\n",
      "Iteration 1284 - Grad. Norm.: 0.0012047131256229947 Norm. Diff.: 0.0060267764613027896 tk: 5 x_norm: 18.220343952186596\n",
      "Iteration 1285 - Grad. Norm.: 0.0012040717713837875 Norm. Diff.: 0.006023565628114943 tk: 5 x_norm: 18.225495706718515\n",
      "Iteration 1286 - Grad. Norm.: 0.0012034312278980835 Norm. Diff.: 0.006020358856918831 tk: 5 x_norm: 18.230644701396656\n",
      "Iteration 1287 - Grad. Norm.: 0.0012027914935256094 Norm. Diff.: 0.006017156139490377 tk: 5 x_norm: 18.235790939629368\n",
      "Iteration 1288 - Grad. Norm.: 0.0012021525666306362 Norm. Diff.: 0.006013957467628022 tk: 5 x_norm: 18.24093442481843\n",
      "Iteration 1289 - Grad. Norm.: 0.0012015144455819664 Norm. Diff.: 0.006010762833153159 tk: 5 x_norm: 18.24607516035907\n",
      "Iteration 1290 - Grad. Norm.: 0.0012008771287529154 Norm. Diff.: 0.006007572227909887 tk: 5 x_norm: 18.25121314963998\n",
      "Iteration 1291 - Grad. Norm.: 0.0012002406145212982 Norm. Diff.: 0.006004385643764521 tk: 5 x_norm: 18.25634839604333\n",
      "Iteration 1292 - Grad. Norm.: 0.0011996049012694115 Norm. Diff.: 0.006001203072606699 tk: 5 x_norm: 18.261480902944783\n",
      "Iteration 1293 - Grad. Norm.: 0.0011989699873840218 Norm. Diff.: 0.005998024506346751 tk: 5 x_norm: 18.26661067371351\n",
      "Iteration 1294 - Grad. Norm.: 0.0011983358712563447 Norm. Diff.: 0.005994849936920108 tk: 5 x_norm: 18.27173771171223\n",
      "Iteration 1295 - Grad. Norm.: 0.0011977025512820345 Norm. Diff.: 0.005991679356281754 tk: 5 x_norm: 18.276862020297195\n",
      "Iteration 1296 - Grad. Norm.: 0.0011970700258611634 Norm. Diff.: 0.005988512756410219 tk: 5 x_norm: 18.28198360281823\n",
      "Iteration 1297 - Grad. Norm.: 0.0011964382933982152 Norm. Diff.: 0.0059853501293058295 tk: 5 x_norm: 18.287102462618726\n",
      "Iteration 1298 - Grad. Norm.: 0.0011958073523020587 Norm. Diff.: 0.005982191466990985 tk: 5 x_norm: 18.292218603035696\n",
      "Iteration 1299 - Grad. Norm.: 0.0011951772009859412 Norm. Diff.: 0.0059790367615102855 tk: 5 x_norm: 18.29733202739974\n",
      "Iteration 1300 - Grad. Norm.: 0.001194547837867469 Norm. Diff.: 0.005975886004929804 tk: 5 x_norm: 18.302442739035115\n",
      "Iteration 1301 - Grad. Norm.: 0.0011939192613685933 Norm. Diff.: 0.0059727391893373465 tk: 5 x_norm: 18.307550741259707\n",
      "Iteration 1302 - Grad. Norm.: 0.0011932914699155984 Norm. Diff.: 0.005969596306842955 tk: 5 x_norm: 18.312656037385075\n",
      "Iteration 1303 - Grad. Norm.: 0.0011926644619390822 Norm. Diff.: 0.005966457349577918 tk: 5 x_norm: 18.317758630716455\n",
      "Iteration 1304 - Grad. Norm.: 0.0011920382358739422 Norm. Diff.: 0.005963322309695432 tk: 5 x_norm: 18.32285852455277\n",
      "Iteration 1305 - Grad. Norm.: 0.0011914127901593628 Norm. Diff.: 0.005960191179369724 tk: 5 x_norm: 18.327955722186687\n",
      "Iteration 1306 - Grad. Norm.: 0.0011907881232388012 Norm. Diff.: 0.0059570639507966336 tk: 5 x_norm: 18.333050226904565\n",
      "Iteration 1307 - Grad. Norm.: 0.0011901642335599685 Norm. Diff.: 0.005953940616193968 tk: 5 x_norm: 18.338142041986533\n",
      "Iteration 1308 - Grad. Norm.: 0.001189541119574818 Norm. Diff.: 0.0059508211677997275 tk: 5 x_norm: 18.343231170706485\n",
      "Iteration 1309 - Grad. Norm.: 0.0011889187797395325 Norm. Diff.: 0.005947705597873875 tk: 5 x_norm: 18.348317616332068\n",
      "Iteration 1310 - Grad. Norm.: 0.0011882972125145043 Norm. Diff.: 0.005944593898697558 tk: 5 x_norm: 18.353401382124744\n",
      "Iteration 1311 - Grad. Norm.: 0.0011876764163643277 Norm. Diff.: 0.00594148606257247 tk: 5 x_norm: 18.35848247133978\n",
      "Iteration 1312 - Grad. Norm.: 0.0011870563897577802 Norm. Diff.: 0.005938382081821782 tk: 5 x_norm: 18.363560887226264\n",
      "Iteration 1313 - Grad. Norm.: 0.0011864371311678054 Norm. Diff.: 0.005935281948789014 tk: 5 x_norm: 18.368636633027137\n",
      "Iteration 1314 - Grad. Norm.: 0.0011858186390715092 Norm. Diff.: 0.0059321856558390024 tk: 5 x_norm: 18.37370971197919\n",
      "Iteration 1315 - Grad. Norm.: 0.001185200911950134 Norm. Diff.: 0.00592909319535749 tk: 5 x_norm: 18.37878012731308\n",
      "Iteration 1316 - Grad. Norm.: 0.001184583948289051 Norm. Diff.: 0.005926004559750658 tk: 5 x_norm: 18.383847882253374\n",
      "Iteration 1317 - Grad. Norm.: 0.0011839677465777447 Norm. Diff.: 0.0059229197414452425 tk: 5 x_norm: 18.38891298001853\n",
      "Iteration 1318 - Grad. Norm.: 0.0011833523053097982 Norm. Diff.: 0.0059198387328886935 tk: 5 x_norm: 18.393975423820923\n",
      "Iteration 1319 - Grad. Norm.: 0.001182737622982882 Norm. Diff.: 0.005916761526548939 tk: 5 x_norm: 18.399035216866874\n",
      "Iteration 1320 - Grad. Norm.: 0.0011821236980987377 Norm. Diff.: 0.0059136881149145564 tk: 5 x_norm: 18.40409236235665\n",
      "Iteration 1321 - Grad. Norm.: 0.0011815105291631614 Norm. Diff.: 0.005910618490493726 tk: 5 x_norm: 18.40914686348449\n",
      "Iteration 1322 - Grad. Norm.: 0.001180898114685998 Norm. Diff.: 0.005907552645815763 tk: 5 x_norm: 18.414198723438613\n",
      "Iteration 1323 - Grad. Norm.: 0.0011802864531811187 Norm. Diff.: 0.005904490573429858 tk: 5 x_norm: 18.41924794540124\n",
      "Iteration 1324 - Grad. Norm.: 0.001179675543166414 Norm. Diff.: 0.0059014322659054885 tk: 5 x_norm: 18.42429453254859\n",
      "Iteration 1325 - Grad. Norm.: 0.0011790653831637746 Norm. Diff.: 0.005898377715832057 tk: 5 x_norm: 18.429338488050934\n",
      "Iteration 1326 - Grad. Norm.: 0.001178455971699085 Norm. Diff.: 0.005895326915818911 tk: 5 x_norm: 18.43437981507257\n",
      "Iteration 1327 - Grad. Norm.: 0.001177847307302203 Norm. Diff.: 0.005892279858495422 tk: 5 x_norm: 18.439418516771862\n",
      "Iteration 1328 - Grad. Norm.: 0.0011772393885069478 Norm. Diff.: 0.0058892365365111 tk: 5 x_norm: 18.444454596301252\n",
      "Iteration 1329 - Grad. Norm.: 0.0011766322138510902 Norm. Diff.: 0.00588619694253477 tk: 5 x_norm: 18.449488056807258\n",
      "Iteration 1330 - Grad. Norm.: 0.0011760257818763365 Norm. Diff.: 0.005883161069255366 tk: 5 x_norm: 18.45451890143051\n",
      "Iteration 1331 - Grad. Norm.: 0.0011754200911283145 Norm. Diff.: 0.005880128909381651 tk: 5 x_norm: 18.459547133305776\n",
      "Iteration 1332 - Grad. Norm.: 0.0011748151401565633 Norm. Diff.: 0.005877100455641627 tk: 5 x_norm: 18.46457275556191\n",
      "Iteration 1333 - Grad. Norm.: 0.0011742109275145183 Norm. Diff.: 0.005874075700782871 tk: 5 x_norm: 18.469595771321973\n",
      "Iteration 1334 - Grad. Norm.: 0.001173607451759497 Norm. Diff.: 0.005871054637572521 tk: 5 x_norm: 18.474616183703148\n",
      "Iteration 1335 - Grad. Norm.: 0.0011730047114526863 Norm. Diff.: 0.005868037258797446 tk: 5 x_norm: 18.479633995816823\n",
      "Iteration 1336 - Grad. Norm.: 0.0011724027051591335 Norm. Diff.: 0.005865023557263455 tk: 5 x_norm: 18.48464921076856\n",
      "Iteration 1337 - Grad. Norm.: 0.0011718014314477275 Norm. Diff.: 0.005862013525795772 tk: 5 x_norm: 18.48966183165813\n",
      "Iteration 1338 - Grad. Norm.: 0.0011712008888911905 Norm. Diff.: 0.005859007157238658 tk: 5 x_norm: 18.49467186157956\n",
      "Iteration 1339 - Grad. Norm.: 0.001170601076066064 Norm. Diff.: 0.005856004444456073 tk: 5 x_norm: 18.499679303621058\n",
      "Iteration 1340 - Grad. Norm.: 0.0011700019915526923 Norm. Diff.: 0.005853005380330213 tk: 5 x_norm: 18.50468416086514\n",
      "Iteration 1341 - Grad. Norm.: 0.001169403633935215 Norm. Diff.: 0.005850009957763434 tk: 5 x_norm: 18.509686436388552\n",
      "Iteration 1342 - Grad. Norm.: 0.0011688060018015527 Norm. Diff.: 0.005847018169676084 tk: 5 x_norm: 18.51468613326233\n",
      "Iteration 1343 - Grad. Norm.: 0.0011682090937433925 Norm. Diff.: 0.005844030009007711 tk: 5 x_norm: 18.519683254551822\n",
      "Iteration 1344 - Grad. Norm.: 0.0011676129083561786 Norm. Diff.: 0.005841045468716858 tk: 5 x_norm: 18.52467780331666\n",
      "Iteration 1345 - Grad. Norm.: 0.0011670174442390973 Norm. Diff.: 0.005838064541780954 tk: 5 x_norm: 18.529669782610814\n",
      "Iteration 1346 - Grad. Norm.: 0.001166422699995066 Norm. Diff.: 0.005835087221195452 tk: 5 x_norm: 18.534659195482593\n",
      "Iteration 1347 - Grad. Norm.: 0.001165828674230716 Norm. Diff.: 0.005832113499975303 tk: 5 x_norm: 18.539646044974663\n",
      "Iteration 1348 - Grad. Norm.: 0.001165235365556391 Norm. Diff.: 0.005829143371153603 tk: 5 x_norm: 18.544630334124033\n",
      "Iteration 1349 - Grad. Norm.: 0.0011646427725861247 Norm. Diff.: 0.005826176827782245 tk: 5 x_norm: 18.549612065962126\n",
      "Iteration 1350 - Grad. Norm.: 0.0011640508939376299 Norm. Diff.: 0.005823213862930505 tk: 5 x_norm: 18.554591243514732\n",
      "Iteration 1351 - Grad. Norm.: 0.001163459728232292 Norm. Diff.: 0.005820254469688144 tk: 5 x_norm: 18.559567869802073\n",
      "Iteration 1352 - Grad. Norm.: 0.0011628692740951513 Norm. Diff.: 0.005817298641161434 tk: 5 x_norm: 18.564541947838784\n",
      "Iteration 1353 - Grad. Norm.: 0.0011622795301548922 Norm. Diff.: 0.005814346370475746 tk: 5 x_norm: 18.56951348063392\n",
      "Iteration 1354 - Grad. Norm.: 0.0011616904950438344 Norm. Diff.: 0.005811397650774614 tk: 5 x_norm: 18.574482471191025\n",
      "Iteration 1355 - Grad. Norm.: 0.001161102167397914 Norm. Diff.: 0.005808452475219173 tk: 5 x_norm: 18.579448922508067\n",
      "Iteration 1356 - Grad. Norm.: 0.0011605145458566794 Norm. Diff.: 0.005805510836989552 tk: 5 x_norm: 18.584412837577517\n",
      "Iteration 1357 - Grad. Norm.: 0.0011599276290632744 Norm. Diff.: 0.005802572729283484 tk: 5 x_norm: 18.589374219386343\n",
      "Iteration 1358 - Grad. Norm.: 0.0011593414156644266 Norm. Diff.: 0.005799638145316423 tk: 5 x_norm: 18.594333070916\n",
      "Iteration 1359 - Grad. Norm.: 0.0011587559043104395 Norm. Diff.: 0.005796707078322242 tk: 5 x_norm: 18.59928939514247\n",
      "Iteration 1360 - Grad. Norm.: 0.0011581710936551751 Norm. Diff.: 0.005793779521552282 tk: 5 x_norm: 18.604243195036275\n",
      "Iteration 1361 - Grad. Norm.: 0.001157586982356045 Norm. Diff.: 0.005790855468275985 tk: 5 x_norm: 18.60919447356248\n",
      "Iteration 1362 - Grad. Norm.: 0.0011570035690740008 Norm. Diff.: 0.0057879349117801945 tk: 5 x_norm: 18.614143233680704\n",
      "Iteration 1363 - Grad. Norm.: 0.0011564208524735193 Norm. Diff.: 0.00578501784536994 tk: 5 x_norm: 18.61908947834515\n",
      "Iteration 1364 - Grad. Norm.: 0.001155838831222591 Norm. Diff.: 0.005782104262367665 tk: 5 x_norm: 18.624033210504603\n",
      "Iteration 1365 - Grad. Norm.: 0.0011552575039927109 Norm. Diff.: 0.005779194156112891 tk: 5 x_norm: 18.62897443310245\n",
      "Iteration 1366 - Grad. Norm.: 0.0011546768694588655 Norm. Diff.: 0.005776287519963428 tk: 5 x_norm: 18.633913149076694\n",
      "Iteration 1367 - Grad. Norm.: 0.0011540969262995198 Norm. Diff.: 0.005773384347294221 tk: 5 x_norm: 18.63884936135997\n",
      "Iteration 1368 - Grad. Norm.: 0.00115351767319661 Norm. Diff.: 0.005770484631497518 tk: 5 x_norm: 18.64378307287954\n",
      "Iteration 1369 - Grad. Norm.: 0.0011529391088355304 Norm. Diff.: 0.005767588365982857 tk: 5 x_norm: 18.648714286557333\n",
      "Iteration 1370 - Grad. Norm.: 0.0011523612319051164 Norm. Diff.: 0.005764695544177603 tk: 5 x_norm: 18.653643005309934\n",
      "Iteration 1371 - Grad. Norm.: 0.0011517840410976443 Norm. Diff.: 0.005761806159525402 tk: 5 x_norm: 18.65856923204863\n",
      "Iteration 1372 - Grad. Norm.: 0.0011512075351088104 Norm. Diff.: 0.005758920205488125 tk: 5 x_norm: 18.663492969679375\n",
      "Iteration 1373 - Grad. Norm.: 0.0011506317126377243 Norm. Diff.: 0.005756037675544141 tk: 5 x_norm: 18.66841422110285\n",
      "Iteration 1374 - Grad. Norm.: 0.001150056572386899 Norm. Diff.: 0.005753158563188499 tk: 5 x_norm: 18.67333298921444\n",
      "Iteration 1375 - Grad. Norm.: 0.0011494821130622337 Norm. Diff.: 0.005750282861934353 tk: 5 x_norm: 18.678249276904282\n",
      "Iteration 1376 - Grad. Norm.: 0.0011489083333730114 Norm. Diff.: 0.0057474105653109965 tk: 5 x_norm: 18.683163087057242\n",
      "Iteration 1377 - Grad. Norm.: 0.0011483352320318795 Norm. Diff.: 0.0057445416668650395 tk: 5 x_norm: 18.688074422552955\n",
      "Iteration 1378 - Grad. Norm.: 0.0011477628077548457 Norm. Diff.: 0.005741676160159367 tk: 5 x_norm: 18.692983286265815\n",
      "Iteration 1379 - Grad. Norm.: 0.0011471910592612629 Norm. Diff.: 0.00573881403877406 tk: 5 x_norm: 18.697889681065018\n",
      "Iteration 1380 - Grad. Norm.: 0.0011466199852738178 Norm. Diff.: 0.005735955296306492 tk: 5 x_norm: 18.702793609814538\n",
      "Iteration 1381 - Grad. Norm.: 0.001146049584518525 Norm. Diff.: 0.005733099926369177 tk: 5 x_norm: 18.707695075373184\n",
      "Iteration 1382 - Grad. Norm.: 0.0011454798557247116 Norm. Diff.: 0.005730247922592784 tk: 5 x_norm: 18.71259408059457\n",
      "Iteration 1383 - Grad. Norm.: 0.0011449107976250073 Norm. Diff.: 0.005727399278623709 tk: 5 x_norm: 18.717490628327138\n",
      "Iteration 1384 - Grad. Norm.: 0.0011443424089553342 Norm. Diff.: 0.0057245539881250465 tk: 5 x_norm: 18.7223847214142\n",
      "Iteration 1385 - Grad. Norm.: 0.0011437746884548977 Norm. Diff.: 0.005721712044776551 tk: 5 x_norm: 18.727276362693914\n",
      "Iteration 1386 - Grad. Norm.: 0.0011432076348661733 Norm. Diff.: 0.005718873442274497 tk: 5 x_norm: 18.732165554999312\n",
      "Iteration 1387 - Grad. Norm.: 0.001142641246934898 Norm. Diff.: 0.0057160381743309304 tk: 5 x_norm: 18.737052301158325\n",
      "Iteration 1388 - Grad. Norm.: 0.0011420755234100575 Norm. Diff.: 0.005713206234674392 tk: 5 x_norm: 18.741936603993757\n",
      "Iteration 1389 - Grad. Norm.: 0.001141510463043879 Norm. Diff.: 0.005710377617050179 tk: 5 x_norm: 18.74681846632335\n",
      "Iteration 1390 - Grad. Norm.: 0.0011409460645918162 Norm. Diff.: 0.0057075523152192945 tk: 5 x_norm: 18.751697890959758\n",
      "Iteration 1391 - Grad. Norm.: 0.001140382326812545 Norm. Diff.: 0.005704730322959183 tk: 5 x_norm: 18.75657488071056\n",
      "Iteration 1392 - Grad. Norm.: 0.001139819248467946 Norm. Diff.: 0.005701911634062656 tk: 5 x_norm: 18.7614494383783\n",
      "Iteration 1393 - Grad. Norm.: 0.0011392568283231021 Norm. Diff.: 0.005699096242340013 tk: 5 x_norm: 18.76632156676047\n",
      "Iteration 1394 - Grad. Norm.: 0.0011386950651462806 Norm. Diff.: 0.0056962841416155685 tk: 5 x_norm: 18.77119126864955\n",
      "Iteration 1395 - Grad. Norm.: 0.0011381339577089275 Norm. Diff.: 0.005693475325731492 tk: 5 x_norm: 18.77605854683298\n",
      "Iteration 1396 - Grad. Norm.: 0.0011375735047856556 Norm. Diff.: 0.00569066978854456 tk: 5 x_norm: 18.780923404093212\n",
      "Iteration 1397 - Grad. Norm.: 0.001137013705154236 Norm. Diff.: 0.005687867523928252 tk: 5 x_norm: 18.78578584320772\n",
      "Iteration 1398 - Grad. Norm.: 0.0011364545575955878 Norm. Diff.: 0.005685068525771194 tk: 5 x_norm: 18.790645866948967\n",
      "Iteration 1399 - Grad. Norm.: 0.0011358960608937622 Norm. Diff.: 0.005682272787978069 tk: 5 x_norm: 18.795503478084477\n",
      "Iteration 1400 - Grad. Norm.: 0.001135338213835943 Norm. Diff.: 0.005679480304468829 tk: 5 x_norm: 18.800358679376806\n",
      "Iteration 1401 - Grad. Norm.: 0.0011347810152124282 Norm. Diff.: 0.005676691069179764 tk: 5 x_norm: 18.805211473583576\n",
      "Iteration 1402 - Grad. Norm.: 0.0011342244638166221 Norm. Diff.: 0.0056739050760622346 tk: 5 x_norm: 18.81006186345746\n",
      "Iteration 1403 - Grad. Norm.: 0.0011336685584450276 Norm. Diff.: 0.005671122319082968 tk: 5 x_norm: 18.814909851746233\n",
      "Iteration 1404 - Grad. Norm.: 0.0011331132978972345 Norm. Diff.: 0.0056683427922251195 tk: 5 x_norm: 18.81975544119275\n",
      "Iteration 1405 - Grad. Norm.: 0.0011325586809759081 Norm. Diff.: 0.0056655664894861455 tk: 5 x_norm: 18.82459863453498\n",
      "Iteration 1406 - Grad. Norm.: 0.0011320047064867847 Norm. Diff.: 0.005662793404879329 tk: 5 x_norm: 18.829439434505993\n",
      "Iteration 1407 - Grad. Norm.: 0.001131451373238653 Norm. Diff.: 0.005660023532434173 tk: 5 x_norm: 18.834277843834016\n",
      "Iteration 1408 - Grad. Norm.: 0.0011308986800433534 Norm. Diff.: 0.005657256866193302 tk: 5 x_norm: 18.839113865242382\n",
      "Iteration 1409 - Grad. Norm.: 0.0011303466257157656 Norm. Diff.: 0.005654493400216676 tk: 5 x_norm: 18.8439475014496\n",
      "Iteration 1410 - Grad. Norm.: 0.0011297952090737926 Norm. Diff.: 0.005651733128578672 tk: 5 x_norm: 18.848778755169324\n",
      "Iteration 1411 - Grad. Norm.: 0.001129244428938362 Norm. Diff.: 0.005648976045369024 tk: 5 x_norm: 18.8536076291104\n",
      "Iteration 1412 - Grad. Norm.: 0.0011286942841334058 Norm. Diff.: 0.005646222144691874 tk: 5 x_norm: 18.858434125976856\n",
      "Iteration 1413 - Grad. Norm.: 0.0011281447734858602 Norm. Diff.: 0.005643471420666888 tk: 5 x_norm: 18.86325824846791\n",
      "Iteration 1414 - Grad. Norm.: 0.0011275958958256482 Norm. Diff.: 0.005640723867429281 tk: 5 x_norm: 18.868079999278\n",
      "Iteration 1415 - Grad. Norm.: 0.0011270476499856742 Norm. Diff.: 0.0056379794791281525 tk: 5 x_norm: 18.87289938109678\n",
      "Iteration 1416 - Grad. Norm.: 0.0011265000348018163 Norm. Diff.: 0.005635238249928332 tk: 5 x_norm: 18.877716396609138\n",
      "Iteration 1417 - Grad. Norm.: 0.0011259530491129109 Norm. Diff.: 0.005632500174009219 tk: 5 x_norm: 18.882531048495203\n",
      "Iteration 1418 - Grad. Norm.: 0.0011254066917607485 Norm. Diff.: 0.005629765245564549 tk: 5 x_norm: 18.887343339430366\n",
      "Iteration 1419 - Grad. Norm.: 0.0011248609615900627 Norm. Diff.: 0.005627033458803863 tk: 5 x_norm: 18.892153272085274\n",
      "Iteration 1420 - Grad. Norm.: 0.001124315857448521 Norm. Diff.: 0.005624304807950248 tk: 5 x_norm: 18.89696084912587\n",
      "Iteration 1421 - Grad. Norm.: 0.001123771378186716 Norm. Diff.: 0.005621579287242665 tk: 5 x_norm: 18.901766073213363\n",
      "Iteration 1422 - Grad. Norm.: 0.0011232275226581536 Norm. Diff.: 0.005618856890933645 tk: 5 x_norm: 18.906568947004285\n",
      "Iteration 1423 - Grad. Norm.: 0.001122684289719248 Norm. Diff.: 0.005616137613290751 tk: 5 x_norm: 18.911369473150465\n",
      "Iteration 1424 - Grad. Norm.: 0.0011221416782293088 Norm. Diff.: 0.005613421448596205 tk: 5 x_norm: 18.91616765429906\n",
      "Iteration 1425 - Grad. Norm.: 0.001121599687050534 Norm. Diff.: 0.005610708391146623 tk: 5 x_norm: 18.92096349309256\n",
      "Iteration 1426 - Grad. Norm.: 0.0011210583150479993 Norm. Diff.: 0.005607998435252793 tk: 5 x_norm: 18.92575699216881\n",
      "Iteration 1427 - Grad. Norm.: 0.0011205175610896523 Norm. Diff.: 0.005605291575239966 tk: 5 x_norm: 18.93054815416099\n",
      "Iteration 1428 - Grad. Norm.: 0.0011199774240462995 Norm. Diff.: 0.005602587805448273 tk: 5 x_norm: 18.935336981697674\n",
      "Iteration 1429 - Grad. Norm.: 0.0011194379027915982 Norm. Diff.: 0.005599887120231612 tk: 5 x_norm: 18.940123477402793\n",
      "Iteration 1430 - Grad. Norm.: 0.0011188989962020502 Norm. Diff.: 0.005597189513958197 tk: 5 x_norm: 18.94490764389567\n",
      "Iteration 1431 - Grad. Norm.: 0.0011183607031569902 Norm. Diff.: 0.005594494981010405 tk: 5 x_norm: 18.949689483791044\n",
      "Iteration 1432 - Grad. Norm.: 0.0011178230225385767 Norm. Diff.: 0.00559180351578503 tk: 5 x_norm: 18.95446899969905\n",
      "Iteration 1433 - Grad. Norm.: 0.0011172859532317858 Norm. Diff.: 0.005589115112692898 tk: 5 x_norm: 18.959246194225248\n",
      "Iteration 1434 - Grad. Norm.: 0.0011167494941243998 Norm. Diff.: 0.005586429766159049 tk: 5 x_norm: 18.964021069970634\n",
      "Iteration 1435 - Grad. Norm.: 0.0011162136441069989 Norm. Diff.: 0.005583747470621954 tk: 5 x_norm: 18.96879362953165\n",
      "Iteration 1436 - Grad. Norm.: 0.0011156784020729543 Norm. Diff.: 0.005581068220534977 tk: 5 x_norm: 18.97356387550019\n",
      "Iteration 1437 - Grad. Norm.: 0.0011151437669184151 Norm. Diff.: 0.0055783920103649335 tk: 5 x_norm: 18.9783318104636\n",
      "Iteration 1438 - Grad. Norm.: 0.001114609737542306 Norm. Diff.: 0.005575718834591928 tk: 5 x_norm: 18.983097437004734\n",
      "Iteration 1439 - Grad. Norm.: 0.0011140763128463132 Norm. Diff.: 0.005573048687711331 tk: 5 x_norm: 18.987860757701895\n",
      "Iteration 1440 - Grad. Norm.: 0.0011135434917348786 Norm. Diff.: 0.005570381564231671 tk: 5 x_norm: 18.992621775128917\n",
      "Iteration 1441 - Grad. Norm.: 0.0011130112731151873 Norm. Diff.: 0.005567717458674424 tk: 5 x_norm: 18.99738049185511\n",
      "Iteration 1442 - Grad. Norm.: 0.0011124796558971664 Norm. Diff.: 0.005565056365575929 tk: 5 x_norm: 19.002136910445337\n",
      "Iteration 1443 - Grad. Norm.: 0.0011119486389934703 Norm. Diff.: 0.005562398279485876 tk: 5 x_norm: 19.00689103345996\n",
      "Iteration 1444 - Grad. Norm.: 0.0011114182213194724 Norm. Diff.: 0.00555974319496729 tk: 5 x_norm: 19.0116428634549\n",
      "Iteration 1445 - Grad. Norm.: 0.0011108884017932597 Norm. Diff.: 0.005557091106597149 tk: 5 x_norm: 19.01639240298162\n",
      "Iteration 1446 - Grad. Norm.: 0.001110359179335623 Norm. Diff.: 0.005554442008966499 tk: 5 x_norm: 19.02113965458714\n",
      "Iteration 1447 - Grad. Norm.: 0.0011098305528700475 Norm. Diff.: 0.005551795896678144 tk: 5 x_norm: 19.025884620814065\n",
      "Iteration 1448 - Grad. Norm.: 0.001109302521322707 Norm. Diff.: 0.005549152764350405 tk: 5 x_norm: 19.030627304200557\n",
      "Iteration 1449 - Grad. Norm.: 0.0011087750836224503 Norm. Diff.: 0.005546512606613406 tk: 5 x_norm: 19.035367707280404\n",
      "Iteration 1450 - Grad. Norm.: 0.0011082482387007996 Norm. Diff.: 0.005543875418112102 tk: 5 x_norm: 19.040105832582967\n",
      "Iteration 1451 - Grad. Norm.: 0.0011077219854919392 Norm. Diff.: 0.005541241193503838 tk: 5 x_norm: 19.04484168263323\n",
      "Iteration 1452 - Grad. Norm.: 0.0011071963229327038 Norm. Diff.: 0.005538609927459704 tk: 5 x_norm: 19.049575259951794\n",
      "Iteration 1453 - Grad. Norm.: 0.0011066712499625756 Norm. Diff.: 0.005535981614663682 tk: 5 x_norm: 19.054306567054915\n",
      "Iteration 1454 - Grad. Norm.: 0.0011061467655236739 Norm. Diff.: 0.005533356249812788 tk: 5 x_norm: 19.05903560645447\n",
      "Iteration 1455 - Grad. Norm.: 0.0011056228685607484 Norm. Diff.: 0.005530733827618505 tk: 5 x_norm: 19.063762380657984\n",
      "Iteration 1456 - Grad. Norm.: 0.0011050995580211662 Norm. Diff.: 0.005528114342803804 tk: 5 x_norm: 19.068486892168668\n",
      "Iteration 1457 - Grad. Norm.: 0.00110457683285491 Norm. Diff.: 0.00552549779010586 tk: 5 x_norm: 19.07320914348539\n",
      "Iteration 1458 - Grad. Norm.: 0.0011040546920145656 Norm. Diff.: 0.005522884164274552 tk: 5 x_norm: 19.077929137102704\n",
      "Iteration 1459 - Grad. Norm.: 0.0011035331344553174 Norm. Diff.: 0.005520273460072702 tk: 5 x_norm: 19.082646875510875\n",
      "Iteration 1460 - Grad. Norm.: 0.0011030121591349368 Norm. Diff.: 0.005517665672276609 tk: 5 x_norm: 19.087362361195847\n",
      "Iteration 1461 - Grad. Norm.: 0.0011024917650137751 Norm. Diff.: 0.0055150607956747505 tk: 5 x_norm: 19.09207559663929\n",
      "Iteration 1462 - Grad. Norm.: 0.001101971951054758 Norm. Diff.: 0.005512458825068716 tk: 5 x_norm: 19.096786584318604\n",
      "Iteration 1463 - Grad. Norm.: 0.0011014527162233757 Norm. Diff.: 0.005509859755273649 tk: 5 x_norm: 19.101495326706903\n",
      "Iteration 1464 - Grad. Norm.: 0.0011009340594876748 Norm. Diff.: 0.005507263581116847 tk: 5 x_norm: 19.106201826273068\n",
      "Iteration 1465 - Grad. Norm.: 0.0011004159798182497 Norm. Diff.: 0.0055046702974384555 tk: 5 x_norm: 19.11090608548172\n",
      "Iteration 1466 - Grad. Norm.: 0.0010998984761882381 Norm. Diff.: 0.005502079899091285 tk: 5 x_norm: 19.115608106793246\n",
      "Iteration 1467 - Grad. Norm.: 0.0010993815475733094 Norm. Diff.: 0.005499492380941112 tk: 5 x_norm: 19.120307892663803\n",
      "Iteration 1468 - Grad. Norm.: 0.0010988651929516589 Norm. Diff.: 0.0054969077378666685 tk: 5 x_norm: 19.125005445545344\n",
      "Iteration 1469 - Grad. Norm.: 0.0010983494113039997 Norm. Diff.: 0.005494325964758511 tk: 5 x_norm: 19.1297007678856\n",
      "Iteration 1470 - Grad. Norm.: 0.0010978342016135549 Norm. Diff.: 0.005491747056520073 tk: 5 x_norm: 19.134393862128114\n",
      "Iteration 1471 - Grad. Norm.: 0.0010973195628660509 Norm. Diff.: 0.0054891710080678 tk: 5 x_norm: 19.139084730712234\n",
      "Iteration 1472 - Grad. Norm.: 0.0010968054940497054 Norm. Diff.: 0.00548659781433015 tk: 5 x_norm: 19.14377337607314\n",
      "Iteration 1473 - Grad. Norm.: 0.0010962919941552268 Norm. Diff.: 0.00548402747024837 tk: 5 x_norm: 19.14845980064183\n",
      "Iteration 1474 - Grad. Norm.: 0.0010957790621758013 Norm. Diff.: 0.005481459970776033 tk: 5 x_norm: 19.15314400684516\n",
      "Iteration 1475 - Grad. Norm.: 0.0010952666971070866 Norm. Diff.: 0.00547889531087895 tk: 5 x_norm: 19.15782599710582\n",
      "Iteration 1476 - Grad. Norm.: 0.0010947548979472043 Norm. Diff.: 0.005476333485535504 tk: 5 x_norm: 19.16250577384238\n",
      "Iteration 1477 - Grad. Norm.: 0.0010942436636967342 Norm. Diff.: 0.0054737744897361326 tk: 5 x_norm: 19.167183339469254\n",
      "Iteration 1478 - Grad. Norm.: 0.0010937329933587035 Norm. Diff.: 0.005471218318483675 tk: 5 x_norm: 19.17185869639676\n",
      "Iteration 1479 - Grad. Norm.: 0.0010932228859385814 Norm. Diff.: 0.005468664966793729 tk: 5 x_norm: 19.176531847031093\n",
      "Iteration 1480 - Grad. Norm.: 0.0010927133404442717 Norm. Diff.: 0.005466114429692833 tk: 5 x_norm: 19.18120279377436\n",
      "Iteration 1481 - Grad. Norm.: 0.0010922043558861056 Norm. Diff.: 0.005463566702221336 tk: 5 x_norm: 19.18587153902455\n",
      "Iteration 1482 - Grad. Norm.: 0.0010916959312768314 Norm. Diff.: 0.005461021779430354 tk: 5 x_norm: 19.19053808517559\n",
      "Iteration 1483 - Grad. Norm.: 0.0010911880656316114 Norm. Diff.: 0.005458479656384098 tk: 5 x_norm: 19.195202434617336\n",
      "Iteration 1484 - Grad. Norm.: 0.001090680757968012 Norm. Diff.: 0.00545594032815803 tk: 5 x_norm: 19.199864589735565\n",
      "Iteration 1485 - Grad. Norm.: 0.001090174007305996 Norm. Diff.: 0.00545340378984004 tk: 5 x_norm: 19.204524552912012\n",
      "Iteration 1486 - Grad. Norm.: 0.0010896678126679177 Norm. Diff.: 0.005450870036529779 tk: 5 x_norm: 19.209182326524356\n",
      "Iteration 1487 - Grad. Norm.: 0.001089162173078512 Norm. Diff.: 0.005448339063339857 tk: 5 x_norm: 19.213837912946257\n",
      "Iteration 1488 - Grad. Norm.: 0.0010886570875648918 Norm. Diff.: 0.0054458108653924675 tk: 5 x_norm: 19.21849131454733\n",
      "Iteration 1489 - Grad. Norm.: 0.0010881525551565353 Norm. Diff.: 0.005443285437824276 tk: 5 x_norm: 19.22314253369318\n",
      "Iteration 1490 - Grad. Norm.: 0.001087648574885284 Norm. Diff.: 0.005440762775782859 tk: 5 x_norm: 19.227791572745414\n",
      "Iteration 1491 - Grad. Norm.: 0.0010871451457853329 Norm. Diff.: 0.005438242874426281 tk: 5 x_norm: 19.232438434061617\n",
      "Iteration 1492 - Grad. Norm.: 0.0010866422668932229 Norm. Diff.: 0.005435725728926608 tk: 5 x_norm: 19.23708311999541\n",
      "Iteration 1493 - Grad. Norm.: 0.0010861399372478337 Norm. Diff.: 0.005433211334466148 tk: 5 x_norm: 19.24172563289641\n",
      "Iteration 1494 - Grad. Norm.: 0.0010856381558903819 Norm. Diff.: 0.00543069968623941 tk: 5 x_norm: 19.246365975110283\n",
      "Iteration 1495 - Grad. Norm.: 0.001085136921864402 Norm. Diff.: 0.005428190779451891 tk: 5 x_norm: 19.25100414897872\n",
      "Iteration 1496 - Grad. Norm.: 0.001084636234215754 Norm. Diff.: 0.005425684609322208 tk: 5 x_norm: 19.255640156839455\n",
      "Iteration 1497 - Grad. Norm.: 0.0010841360919926057 Norm. Diff.: 0.005423181171078902 tk: 5 x_norm: 19.260274001026286\n",
      "Iteration 1498 - Grad. Norm.: 0.0010836364942454293 Norm. Diff.: 0.0054206804599630405 tk: 5 x_norm: 19.264905683869074\n",
      "Iteration 1499 - Grad. Norm.: 0.001083137440026996 Norm. Diff.: 0.005418182471227073 tk: 5 x_norm: 19.269535207693757\n",
      "Iteration 1500 - Grad. Norm.: 0.001082638928392365 Norm. Diff.: 0.005415687200134799 tk: 5 x_norm: 19.274162574822345\n",
      "Iteration 1501 - Grad. Norm.: 0.0010821409583988823 Norm. Diff.: 0.005413194641961723 tk: 5 x_norm: 19.27878778757295\n",
      "Iteration 1502 - Grad. Norm.: 0.0010816435291061662 Norm. Diff.: 0.005410704791994155 tk: 5 x_norm: 19.28341084825977\n",
      "Iteration 1503 - Grad. Norm.: 0.0010811466395761091 Norm. Diff.: 0.005408217645530911 tk: 5 x_norm: 19.288031759193128\n",
      "Iteration 1504 - Grad. Norm.: 0.0010806502888728643 Norm. Diff.: 0.0054057331978805585 tk: 5 x_norm: 19.292650522679462\n",
      "Iteration 1505 - Grad. Norm.: 0.0010801544760628394 Norm. Diff.: 0.0054032514443644415 tk: 5 x_norm: 19.297267141021322\n",
      "Iteration 1506 - Grad. Norm.: 0.001079659200214696 Norm. Diff.: 0.005400772380314201 tk: 5 x_norm: 19.301881616517413\n",
      "Iteration 1507 - Grad. Norm.: 0.0010791644603993329 Norm. Diff.: 0.005398296001073492 tk: 5 x_norm: 19.306493951462578\n",
      "Iteration 1508 - Grad. Norm.: 0.0010786702556898873 Norm. Diff.: 0.0053958223019968995 tk: 5 x_norm: 19.3111041481478\n",
      "Iteration 1509 - Grad. Norm.: 0.0010781765851617256 Norm. Diff.: 0.0053933512784494035 tk: 5 x_norm: 19.31571220886024\n",
      "Iteration 1510 - Grad. Norm.: 0.0010776834478924368 Norm. Diff.: 0.005390882925808551 tk: 5 x_norm: 19.32031813588322\n",
      "Iteration 1511 - Grad. Norm.: 0.0010771908429618232 Norm. Diff.: 0.005388417239462117 tk: 5 x_norm: 19.324921931496252\n",
      "Iteration 1512 - Grad. Norm.: 0.0010766987694518992 Norm. Diff.: 0.00538595421480933 tk: 5 x_norm: 19.329523597975026\n",
      "Iteration 1513 - Grad. Norm.: 0.001076207226446879 Norm. Diff.: 0.005383493847259491 tk: 5 x_norm: 19.334123137591423\n",
      "Iteration 1514 - Grad. Norm.: 0.0010757162130331736 Norm. Diff.: 0.005381036132234389 tk: 5 x_norm: 19.338720552613548\n",
      "Iteration 1515 - Grad. Norm.: 0.0010752257282993828 Norm. Diff.: 0.005378581065165937 tk: 5 x_norm: 19.343315845305696\n",
      "Iteration 1516 - Grad. Norm.: 0.00107473577133629 Norm. Diff.: 0.00537612864149705 tk: 5 x_norm: 19.347909017928405\n",
      "Iteration 1517 - Grad. Norm.: 0.0010742463412368537 Norm. Diff.: 0.005373678856681451 tk: 5 x_norm: 19.35250007273843\n",
      "Iteration 1518 - Grad. Norm.: 0.0010737574370962015 Norm. Diff.: 0.005371231706184274 tk: 5 x_norm: 19.357089011988773\n",
      "Iteration 1519 - Grad. Norm.: 0.0010732690580116241 Norm. Diff.: 0.005368787185480959 tk: 5 x_norm: 19.361675837928672\n",
      "Iteration 1520 - Grad. Norm.: 0.0010727812030825708 Norm. Diff.: 0.005366345290057984 tk: 5 x_norm: 19.36626055280364\n",
      "Iteration 1521 - Grad. Norm.: 0.0010722938714106383 Norm. Diff.: 0.005363906015412557 tk: 5 x_norm: 19.370843158855433\n",
      "Iteration 1522 - Grad. Norm.: 0.0010718070620995676 Norm. Diff.: 0.005361469357053197 tk: 5 x_norm: 19.375423658322095\n",
      "Iteration 1523 - Grad. Norm.: 0.0010713207742552387 Norm. Diff.: 0.005359035310497651 tk: 5 x_norm: 19.38000205343795\n",
      "Iteration 1524 - Grad. Norm.: 0.0010708350069856597 Norm. Diff.: 0.005356603871275819 tk: 5 x_norm: 19.384578346433592\n",
      "Iteration 1525 - Grad. Norm.: 0.0010703497594009652 Norm. Diff.: 0.005354175034928337 tk: 5 x_norm: 19.389152539535946\n",
      "Iteration 1526 - Grad. Norm.: 0.0010698650306134078 Norm. Diff.: 0.005351748797004844 tk: 5 x_norm: 19.393724634968212\n",
      "Iteration 1527 - Grad. Norm.: 0.0010693808197373515 Norm. Diff.: 0.005349325153067128 tk: 5 x_norm: 19.39829463494993\n",
      "Iteration 1528 - Grad. Norm.: 0.0010688971258892652 Norm. Diff.: 0.00534690409868664 tk: 5 x_norm: 19.40286254169694\n",
      "Iteration 1529 - Grad. Norm.: 0.001068413948187719 Norm. Diff.: 0.005344485629446461 tk: 5 x_norm: 19.407428357421427\n",
      "Iteration 1530 - Grad. Norm.: 0.0010679312857533733 Norm. Diff.: 0.0053420697409387215 tk: 5 x_norm: 19.411992084331914\n",
      "Iteration 1531 - Grad. Norm.: 0.001067449137708978 Norm. Diff.: 0.005339656428766897 tk: 5 x_norm: 19.416553724633264\n",
      "Iteration 1532 - Grad. Norm.: 0.001066967503179362 Norm. Diff.: 0.00533724568854498 tk: 5 x_norm: 19.4211132805267\n",
      "Iteration 1533 - Grad. Norm.: 0.0010664863812914298 Norm. Diff.: 0.0053348375158967275 tk: 5 x_norm: 19.425670754209808\n",
      "Iteration 1534 - Grad. Norm.: 0.001066005771174152 Norm. Diff.: 0.005332431906457254 tk: 5 x_norm: 19.430226147876553\n",
      "Iteration 1535 - Grad. Norm.: 0.0010655256719585625 Norm. Diff.: 0.0053300288558707646 tk: 5 x_norm: 19.43477946371727\n",
      "Iteration 1536 - Grad. Norm.: 0.0010650460827777532 Norm. Diff.: 0.005327628359792696 tk: 5 x_norm: 19.439330703918678\n",
      "Iteration 1537 - Grad. Norm.: 0.001064567002766862 Norm. Diff.: 0.0053252304138886935 tk: 5 x_norm: 19.443879870663903\n",
      "Iteration 1538 - Grad. Norm.: 0.001064088431063073 Norm. Diff.: 0.00532283501383445 tk: 5 x_norm: 19.448426966132477\n",
      "Iteration 1539 - Grad. Norm.: 0.001063610366805608 Norm. Diff.: 0.005320442155315402 tk: 5 x_norm: 19.45297199250033\n",
      "Iteration 1540 - Grad. Norm.: 0.0010631328091357199 Norm. Diff.: 0.005318051834028119 tk: 5 x_norm: 19.457514951939824\n",
      "Iteration 1541 - Grad. Norm.: 0.0010626557571966882 Norm. Diff.: 0.005315664045678502 tk: 5 x_norm: 19.462055846619744\n",
      "Iteration 1542 - Grad. Norm.: 0.0010621792101338096 Norm. Diff.: 0.0053132787859835285 tk: 5 x_norm: 19.46659467870531\n",
      "Iteration 1543 - Grad. Norm.: 0.0010617031670943965 Norm. Diff.: 0.00531089605066925 tk: 5 x_norm: 19.471131450358182\n",
      "Iteration 1544 - Grad. Norm.: 0.0010612276272277698 Norm. Diff.: 0.005308515835472143 tk: 5 x_norm: 19.47566616373649\n",
      "Iteration 1545 - Grad. Norm.: 0.0010607525896852506 Norm. Diff.: 0.005306138136138873 tk: 5 x_norm: 19.4801988209948\n",
      "Iteration 1546 - Grad. Norm.: 0.0010602780536201563 Norm. Diff.: 0.005303762948426095 tk: 5 x_norm: 19.48472942428416\n",
      "Iteration 1547 - Grad. Norm.: 0.0010598040181877932 Norm. Diff.: 0.005301390268100903 tk: 5 x_norm: 19.489257975752086\n",
      "Iteration 1548 - Grad. Norm.: 0.0010593304825454548 Norm. Diff.: 0.005299020090938966 tk: 5 x_norm: 19.493784477542587\n",
      "Iteration 1549 - Grad. Norm.: 0.0010588574458524097 Norm. Diff.: 0.00529665241272714 tk: 5 x_norm: 19.49830893179615\n",
      "Iteration 1550 - Grad. Norm.: 0.0010583849072699004 Norm. Diff.: 0.005294287229261973 tk: 5 x_norm: 19.502831340649763\n",
      "Iteration 1551 - Grad. Norm.: 0.0010579128659611357 Norm. Diff.: 0.005291924536349751 tk: 5 x_norm: 19.507351706236935\n",
      "Iteration 1552 - Grad. Norm.: 0.0010574413210912854 Norm. Diff.: 0.00528956432980548 tk: 5 x_norm: 19.511870030687668\n",
      "Iteration 1553 - Grad. Norm.: 0.001056970271827474 Norm. Diff.: 0.005287206605456492 tk: 5 x_norm: 19.516386316128504\n",
      "Iteration 1554 - Grad. Norm.: 0.001056499717338775 Norm. Diff.: 0.005284851359137338 tk: 5 x_norm: 19.5209005646825\n",
      "Iteration 1555 - Grad. Norm.: 0.0010560296567962066 Norm. Diff.: 0.0052824985866939175 tk: 5 x_norm: 19.525412778469256\n",
      "Iteration 1556 - Grad. Norm.: 0.001055560089372724 Norm. Diff.: 0.005280148283981016 tk: 5 x_norm: 19.529922959604928\n",
      "Iteration 1557 - Grad. Norm.: 0.0010550910142432144 Norm. Diff.: 0.00527780044686352 tk: 5 x_norm: 19.5344311102022\n",
      "Iteration 1558 - Grad. Norm.: 0.0010546224305844907 Norm. Diff.: 0.005275455071215857 tk: 5 x_norm: 19.538937232370333\n",
      "Iteration 1559 - Grad. Norm.: 0.0010541543375752892 Norm. Diff.: 0.005273112152922362 tk: 5 x_norm: 19.543441328215156\n",
      "Iteration 1560 - Grad. Norm.: 0.0010536867343962594 Norm. Diff.: 0.005270771687876608 tk: 5 x_norm: 19.54794339983907\n",
      "Iteration 1561 - Grad. Norm.: 0.0010532196202299603 Norm. Diff.: 0.00526843367198144 tk: 5 x_norm: 19.55244344934106\n",
      "Iteration 1562 - Grad. Norm.: 0.0010527529942608545 Norm. Diff.: 0.00526609810114984 tk: 5 x_norm: 19.556941478816682\n",
      "Iteration 1563 - Grad. Norm.: 0.0010522868556753053 Norm. Diff.: 0.005263764971304103 tk: 5 x_norm: 19.561437490358127\n",
      "Iteration 1564 - Grad. Norm.: 0.0010518212036615654 Norm. Diff.: 0.005261434278376509 tk: 5 x_norm: 19.565931486054165\n",
      "Iteration 1565 - Grad. Norm.: 0.0010513560374097767 Norm. Diff.: 0.005259106018307751 tk: 5 x_norm: 19.570423467990175\n",
      "Iteration 1566 - Grad. Norm.: 0.0010508913561119641 Norm. Diff.: 0.005256780187048919 tk: 5 x_norm: 19.574913438248174\n",
      "Iteration 1567 - Grad. Norm.: 0.0010504271589620244 Norm. Diff.: 0.005254456780559801 tk: 5 x_norm: 19.5794013989068\n",
      "Iteration 1568 - Grad. Norm.: 0.0010499634451557312 Norm. Diff.: 0.005252135794810165 tk: 5 x_norm: 19.58388735204132\n",
      "Iteration 1569 - Grad. Norm.: 0.0010495002138907175 Norm. Diff.: 0.0052498172257786635 tk: 5 x_norm: 19.588371299723644\n",
      "Iteration 1570 - Grad. Norm.: 0.001049037464366479 Norm. Diff.: 0.0052475010694534785 tk: 5 x_norm: 19.592853244022344\n",
      "Iteration 1571 - Grad. Norm.: 0.001048575195784367 Norm. Diff.: 0.005245187321832528 tk: 5 x_norm: 19.597333187002626\n",
      "Iteration 1572 - Grad. Norm.: 0.0010481134073475787 Norm. Diff.: 0.005242875978921694 tk: 5 x_norm: 19.601811130726386\n",
      "Iteration 1573 - Grad. Norm.: 0.0010476520982611562 Norm. Diff.: 0.0052405670367378105 tk: 5 x_norm: 19.60628707725217\n",
      "Iteration 1574 - Grad. Norm.: 0.0010471912677319812 Norm. Diff.: 0.005238260491305886 tk: 5 x_norm: 19.610761028635217\n",
      "Iteration 1575 - Grad. Norm.: 0.0010467309149687668 Norm. Diff.: 0.0052359563386599455 tk: 5 x_norm: 19.615232986927445\n",
      "Iteration 1576 - Grad. Norm.: 0.0010462710391820516 Norm. Diff.: 0.005233654574843746 tk: 5 x_norm: 19.61970295417747\n",
      "Iteration 1577 - Grad. Norm.: 0.0010458116395842011 Norm. Diff.: 0.005231355195910236 tk: 5 x_norm: 19.624170932430598\n",
      "Iteration 1578 - Grad. Norm.: 0.0010453527153893936 Norm. Diff.: 0.00522905819792102 tk: 5 x_norm: 19.62863692372886\n",
      "Iteration 1579 - Grad. Norm.: 0.001044894265813621 Norm. Diff.: 0.0052267635769468615 tk: 5 x_norm: 19.633100930110984\n",
      "Iteration 1580 - Grad. Norm.: 0.0010444362900746808 Norm. Diff.: 0.005224471329068052 tk: 5 x_norm: 19.63756295361243\n",
      "Iteration 1581 - Grad. Norm.: 0.0010439787873921713 Norm. Diff.: 0.005222181450373312 tk: 5 x_norm: 19.642022996265396\n",
      "Iteration 1582 - Grad. Norm.: 0.001043521756987488 Norm. Diff.: 0.005219893936960839 tk: 5 x_norm: 19.646481060098782\n",
      "Iteration 1583 - Grad. Norm.: 0.001043065198083815 Norm. Diff.: 0.005217608784937346 tk: 5 x_norm: 19.650937147138272\n",
      "Iteration 1584 - Grad. Norm.: 0.0010426091099061232 Norm. Diff.: 0.005215325990419072 tk: 5 x_norm: 19.655391259406287\n",
      "Iteration 1585 - Grad. Norm.: 0.0010421534916811635 Norm. Diff.: 0.0052130455495305325 tk: 5 x_norm: 19.659843398921982\n",
      "Iteration 1586 - Grad. Norm.: 0.0010416983426374603 Norm. Diff.: 0.005210767458405864 tk: 5 x_norm: 19.664293567701318\n",
      "Iteration 1587 - Grad. Norm.: 0.0010412436620053113 Norm. Diff.: 0.005208491713187172 tk: 5 x_norm: 19.66874176775699\n",
      "Iteration 1588 - Grad. Norm.: 0.0010407894490167759 Norm. Diff.: 0.005206218310026585 tk: 5 x_norm: 19.673188001098495\n",
      "Iteration 1589 - Grad. Norm.: 0.0010403357029056743 Norm. Diff.: 0.005203947245083909 tk: 5 x_norm: 19.677632269732104\n",
      "Iteration 1590 - Grad. Norm.: 0.001039882422907581 Norm. Diff.: 0.005201678514528343 tk: 5 x_norm: 19.682074575660884\n",
      "Iteration 1591 - Grad. Norm.: 0.0010394296082598211 Norm. Diff.: 0.0051994121145380896 tk: 5 x_norm: 19.686514920884708\n",
      "Iteration 1592 - Grad. Norm.: 0.0010389772582014617 Norm. Diff.: 0.00519714804129918 tk: 5 x_norm: 19.690953307400243\n",
      "Iteration 1593 - Grad. Norm.: 0.0010385253719733124 Norm. Diff.: 0.005194886291007376 tk: 5 x_norm: 19.695389737200973\n",
      "Iteration 1594 - Grad. Norm.: 0.0010380739488179145 Norm. Diff.: 0.005192626859866556 tk: 5 x_norm: 19.699824212277207\n",
      "Iteration 1595 - Grad. Norm.: 0.0010376229879795404 Norm. Diff.: 0.005190369744089725 tk: 5 x_norm: 19.70425673461608\n",
      "Iteration 1596 - Grad. Norm.: 0.001037172488704186 Norm. Diff.: 0.005188114939897774 tk: 5 x_norm: 19.708687306201558\n",
      "Iteration 1597 - Grad. Norm.: 0.0010367224502395662 Norm. Diff.: 0.005185862443520909 tk: 5 x_norm: 19.713115929014446\n",
      "Iteration 1598 - Grad. Norm.: 0.0010362728718351119 Norm. Diff.: 0.0051836122511976605 tk: 5 x_norm: 19.717542605032406\n",
      "Iteration 1599 - Grad. Norm.: 0.001035823752741962 Norm. Diff.: 0.005181364359175389 tk: 5 x_norm: 19.72196733622994\n",
      "Iteration 1600 - Grad. Norm.: 0.0010353750922129608 Norm. Diff.: 0.005179118763709863 tk: 5 x_norm: 19.726390124578426\n",
      "Iteration 1601 - Grad. Norm.: 0.0010349268895026513 Norm. Diff.: 0.005176875461064928 tk: 5 x_norm: 19.7308109720461\n",
      "Iteration 1602 - Grad. Norm.: 0.0010344791438672719 Norm. Diff.: 0.005174634447513309 tk: 5 x_norm: 19.735229880598073\n",
      "Iteration 1603 - Grad. Norm.: 0.0010340318545647516 Norm. Diff.: 0.0051723957193363715 tk: 5 x_norm: 19.739646852196344\n",
      "Iteration 1604 - Grad. Norm.: 0.0010335850208547026 Norm. Diff.: 0.0051701592728236045 tk: 5 x_norm: 19.744061888799788\n",
      "Iteration 1605 - Grad. Norm.: 0.0010331386419984187 Norm. Diff.: 0.00516792510427352 tk: 5 x_norm: 19.74847499236419\n",
      "Iteration 1606 - Grad. Norm.: 0.0010326927172588688 Norm. Diff.: 0.00516569320999209 tk: 5 x_norm: 19.752886164842227\n",
      "Iteration 1607 - Grad. Norm.: 0.0010322472459006915 Norm. Diff.: 0.005163463586294461 tk: 5 x_norm: 19.75729540818348\n",
      "Iteration 1608 - Grad. Norm.: 0.0010318022271901932 Norm. Diff.: 0.0051612362295032 tk: 5 x_norm: 19.761702724334462\n",
      "Iteration 1609 - Grad. Norm.: 0.0010313576603953392 Norm. Diff.: 0.005159011135950954 tk: 5 x_norm: 19.766108115238588\n",
      "Iteration 1610 - Grad. Norm.: 0.0010309135447857504 Norm. Diff.: 0.005156788301976629 tk: 5 x_norm: 19.770511582836207\n",
      "Iteration 1611 - Grad. Norm.: 0.0010304698796327007 Norm. Diff.: 0.005154567723928806 tk: 5 x_norm: 19.774913129064608\n",
      "Iteration 1612 - Grad. Norm.: 0.001030026664209111 Norm. Diff.: 0.005152349398163254 tk: 5 x_norm: 19.779312755858008\n",
      "Iteration 1613 - Grad. Norm.: 0.0010295838977895442 Norm. Diff.: 0.005150133321045567 tk: 5 x_norm: 19.783710465147596\n",
      "Iteration 1614 - Grad. Norm.: 0.0010291415796501984 Norm. Diff.: 0.005147919488947778 tk: 5 x_norm: 19.788106258861493\n",
      "Iteration 1615 - Grad. Norm.: 0.0010286997090689057 Norm. Diff.: 0.005145707898250897 tk: 5 x_norm: 19.792500138924787\n",
      "Iteration 1616 - Grad. Norm.: 0.0010282582853251272 Norm. Diff.: 0.005143498545344745 tk: 5 x_norm: 19.796892107259534\n",
      "Iteration 1617 - Grad. Norm.: 0.0010278173076999444 Norm. Diff.: 0.0051412914266257175 tk: 5 x_norm: 19.801282165784755\n",
      "Iteration 1618 - Grad. Norm.: 0.001027376775476061 Norm. Diff.: 0.005139086538499562 tk: 5 x_norm: 19.805670316416474\n",
      "Iteration 1619 - Grad. Norm.: 0.001026936687937792 Norm. Diff.: 0.0051368838773803785 tk: 5 x_norm: 19.810056561067682\n",
      "Iteration 1620 - Grad. Norm.: 0.001026497044371062 Norm. Diff.: 0.005134683439688789 tk: 5 x_norm: 19.814440901648364\n",
      "Iteration 1621 - Grad. Norm.: 0.0010260578440634013 Norm. Diff.: 0.005132485221855233 tk: 5 x_norm: 19.818823340065506\n",
      "Iteration 1622 - Grad. Norm.: 0.0010256190863039414 Norm. Diff.: 0.00513028922031712 tk: 5 x_norm: 19.823203878223108\n",
      "Iteration 1623 - Grad. Norm.: 0.001025180770383407 Norm. Diff.: 0.005128095431519592 tk: 5 x_norm: 19.827582518022176\n",
      "Iteration 1624 - Grad. Norm.: 0.0010247428955941149 Norm. Diff.: 0.0051259038519171456 tk: 5 x_norm: 19.831959261360726\n",
      "Iteration 1625 - Grad. Norm.: 0.0010243054612299688 Norm. Diff.: 0.005123714477970475 tk: 5 x_norm: 19.836334110133816\n",
      "Iteration 1626 - Grad. Norm.: 0.0010238684665864535 Norm. Diff.: 0.005121527306149972 tk: 5 x_norm: 19.840707066233524\n",
      "Iteration 1627 - Grad. Norm.: 0.001023431910960634 Norm. Diff.: 0.00511934233293219 tk: 5 x_norm: 19.84507813154897\n",
      "Iteration 1628 - Grad. Norm.: 0.001022995793651146 Norm. Diff.: 0.005117159554803282 tk: 5 x_norm: 19.849447307966308\n",
      "Iteration 1629 - Grad. Norm.: 0.0010225601139581925 Norm. Diff.: 0.005114978968255786 tk: 5 x_norm: 19.853814597368753\n",
      "Iteration 1630 - Grad. Norm.: 0.0010221248711835451 Norm. Diff.: 0.00511280056979096 tk: 5 x_norm: 19.858180001636583\n",
      "Iteration 1631 - Grad. Norm.: 0.001021690064630529 Norm. Diff.: 0.005110624355917516 tk: 5 x_norm: 19.862543522647112\n",
      "Iteration 1632 - Grad. Norm.: 0.0010212556936040308 Norm. Diff.: 0.00510845032315249 tk: 5 x_norm: 19.866905162274747\n",
      "Iteration 1633 - Grad. Norm.: 0.0010208217574104827 Norm. Diff.: 0.005106278468020074 tk: 5 x_norm: 19.871264922390967\n",
      "Iteration 1634 - Grad. Norm.: 0.0010203882553578678 Norm. Diff.: 0.0051041087870525486 tk: 5 x_norm: 19.875622804864317\n",
      "Iteration 1635 - Grad. Norm.: 0.0010199551867557078 Norm. Diff.: 0.005101941276789296 tk: 5 x_norm: 19.879978811560445\n",
      "Iteration 1636 - Grad. Norm.: 0.0010195225509150646 Norm. Diff.: 0.00509977593377859 tk: 5 x_norm: 19.88433294434209\n",
      "Iteration 1637 - Grad. Norm.: 0.0010190903471485307 Norm. Diff.: 0.005097612754575347 tk: 5 x_norm: 19.88868520506908\n",
      "Iteration 1638 - Grad. Norm.: 0.0010186585747702299 Norm. Diff.: 0.005095451735742508 tk: 5 x_norm: 19.893035595598363\n",
      "Iteration 1639 - Grad. Norm.: 0.00101822723309581 Norm. Diff.: 0.005093292873851117 tk: 5 x_norm: 19.89738411778399\n",
      "Iteration 1640 - Grad. Norm.: 0.001017796321442438 Norm. Diff.: 0.0050911361654790155 tk: 5 x_norm: 19.901730773477126\n",
      "Iteration 1641 - Grad. Norm.: 0.0010173658391287993 Norm. Diff.: 0.0050889816072123475 tk: 5 x_norm: 19.906075564526077\n",
      "Iteration 1642 - Grad. Norm.: 0.0010169357854750885 Norm. Diff.: 0.0050868291956439595 tk: 5 x_norm: 19.910418492776266\n",
      "Iteration 1643 - Grad. Norm.: 0.0010165061598030076 Norm. Diff.: 0.005084678927375419 tk: 5 x_norm: 19.914759560070245\n",
      "Iteration 1644 - Grad. Norm.: 0.0010160769614357646 Norm. Diff.: 0.005082530799015108 tk: 5 x_norm: 19.91909876824773\n",
      "Iteration 1645 - Grad. Norm.: 0.0010156481896980642 Norm. Diff.: 0.005080384807178778 tk: 5 x_norm: 19.92343611914556\n",
      "Iteration 1646 - Grad. Norm.: 0.0010152198439161062 Norm. Diff.: 0.005078240948490303 tk: 5 x_norm: 19.927771614597756\n",
      "Iteration 1647 - Grad. Norm.: 0.0010147919234175802 Norm. Diff.: 0.0050760992195806355 tk: 5 x_norm: 19.932105256435474\n",
      "Iteration 1648 - Grad. Norm.: 0.0010143644275316653 Norm. Diff.: 0.005073959617087936 tk: 5 x_norm: 19.93643704648705\n",
      "Iteration 1649 - Grad. Norm.: 0.001013937355589018 Norm. Diff.: 0.005071822137658548 tk: 5 x_norm: 19.940766986577987\n",
      "Iteration 1650 - Grad. Norm.: 0.0010135107069217763 Norm. Diff.: 0.005069686777945057 tk: 5 x_norm: 19.945095078530965\n",
      "Iteration 1651 - Grad. Norm.: 0.00101308448086355 Norm. Diff.: 0.005067553534608704 tk: 5 x_norm: 19.949421324165858\n",
      "Iteration 1652 - Grad. Norm.: 0.0010126586767494202 Norm. Diff.: 0.005065422404317696 tk: 5 x_norm: 19.95374572529972\n",
      "Iteration 1653 - Grad. Norm.: 0.0010122332939159304 Norm. Diff.: 0.005063293383746992 tk: 5 x_norm: 19.95806828374679\n",
      "Iteration 1654 - Grad. Norm.: 0.00101180833170109 Norm. Diff.: 0.005061166469579675 tk: 5 x_norm: 19.962389001318545\n",
      "Iteration 1655 - Grad. Norm.: 0.0010113837894443626 Norm. Diff.: 0.005059041658505433 tk: 5 x_norm: 19.966707879823627\n",
      "Iteration 1656 - Grad. Norm.: 0.001010959666486665 Norm. Diff.: 0.005056918947221871 tk: 5 x_norm: 19.97102492106792\n",
      "Iteration 1657 - Grad. Norm.: 0.001010535962170364 Norm. Diff.: 0.005054798332433298 tk: 5 x_norm: 19.97534012685452\n",
      "Iteration 1658 - Grad. Norm.: 0.0010101126758392705 Norm. Diff.: 0.005052679810851671 tk: 5 x_norm: 19.97965349898374\n",
      "Iteration 1659 - Grad. Norm.: 0.0010096898068386382 Norm. Diff.: 0.005050563379196513 tk: 5 x_norm: 19.98396503925313\n",
      "Iteration 1660 - Grad. Norm.: 0.0010092673545151545 Norm. Diff.: 0.005048449034193339 tk: 5 x_norm: 19.988274749457478\n",
      "Iteration 1661 - Grad. Norm.: 0.0010088453182169439 Norm. Diff.: 0.005046336772575657 tk: 5 x_norm: 19.992582631388814\n",
      "Iteration 1662 - Grad. Norm.: 0.001008423697293556 Norm. Diff.: 0.005044226591084678 tk: 5 x_norm: 19.9968886868364\n",
      "Iteration 1663 - Grad. Norm.: 0.0010080024910959677 Norm. Diff.: 0.005042118486467815 tk: 5 x_norm: 20.001192917586796\n",
      "Iteration 1664 - Grad. Norm.: 0.001007581698976574 Norm. Diff.: 0.0050400124554798925 tk: 5 x_norm: 20.00549532542377\n",
      "Iteration 1665 - Grad. Norm.: 0.0010071613202891892 Norm. Diff.: 0.005037908494883035 tk: 5 x_norm: 20.009795912128382\n",
      "Iteration 1666 - Grad. Norm.: 0.001006741354389042 Norm. Diff.: 0.005035806601445928 tk: 5 x_norm: 20.01409467947896\n",
      "Iteration 1667 - Grad. Norm.: 0.0010063218006327657 Norm. Diff.: 0.005033706771945344 tk: 5 x_norm: 20.01839162925111\n",
      "Iteration 1668 - Grad. Norm.: 0.0010059026583784016 Norm. Diff.: 0.005031609003163779 tk: 5 x_norm: 20.02268676321771\n",
      "Iteration 1669 - Grad. Norm.: 0.0010054839269853914 Norm. Diff.: 0.005029513291891991 tk: 5 x_norm: 20.02698008314894\n",
      "Iteration 1670 - Grad. Norm.: 0.0010050656058145759 Norm. Diff.: 0.005027419634926836 tk: 5 x_norm: 20.03127159081226\n",
      "Iteration 1671 - Grad. Norm.: 0.0010046476942281832 Norm. Diff.: 0.005025328029072867 tk: 5 x_norm: 20.035561287972442\n",
      "Iteration 1672 - Grad. Norm.: 0.0010042301915898387 Norm. Diff.: 0.005023238471140907 tk: 5 x_norm: 20.03984917639156\n",
      "Iteration 1673 - Grad. Norm.: 0.0010038130972645479 Norm. Diff.: 0.005021150957949113 tk: 5 x_norm: 20.044135257828984\n",
      "Iteration 1674 - Grad. Norm.: 0.0010033964106187004 Norm. Diff.: 0.0050190654863226675 tk: 5 x_norm: 20.048419534041425\n",
      "Iteration 1675 - Grad. Norm.: 0.0010029801310200627 Norm. Diff.: 0.005016982053093369 tk: 5 x_norm: 20.052702006782894\n",
      "Iteration 1676 - Grad. Norm.: 0.001002564257837776 Norm. Diff.: 0.005014900655100371 tk: 5 x_norm: 20.056982677804736\n",
      "Iteration 1677 - Grad. Norm.: 0.0010021487904423498 Norm. Diff.: 0.005012821289188911 tk: 5 x_norm: 20.061261548855637\n",
      "Iteration 1678 - Grad. Norm.: 0.0010017337282056634 Norm. Diff.: 0.00501074395221176 tk: 5 x_norm: 20.065538621681608\n",
      "Iteration 1679 - Grad. Norm.: 0.001001319070500955 Norm. Diff.: 0.0050086686410282105 tk: 5 x_norm: 20.06981389802601\n",
      "Iteration 1680 - Grad. Norm.: 0.0010009048167028236 Norm. Diff.: 0.005006595352504794 tk: 5 x_norm: 20.07408737962956\n",
      "Iteration 1681 - Grad. Norm.: 0.001000490966187222 Norm. Diff.: 0.005004524083514192 tk: 5 x_norm: 20.078359068230316\n",
      "Iteration 1682 - Grad. Norm.: 0.001000077518331457 Norm. Diff.: 0.005002454830936022 tk: 5 x_norm: 20.082628965563703\n",
      "Iteration 1683 - Grad. Norm.: 0.0009996644725141798 Norm. Diff.: 0.005000387591657497 tk: 5 x_norm: 20.086897073362515\n",
      "Iteration 1684 - Grad. Norm.: 0.0009992518281153851 Norm. Diff.: 0.004998322362570899 tk: 5 x_norm: 20.091163393356908\n",
      "Iteration 1685 - Grad. Norm.: 0.0009988395845164108 Norm. Diff.: 0.004996259140576594 tk: 5 x_norm: 20.09542792727443\n",
      "Iteration 1686 - Grad. Norm.: 0.0009984277410999291 Norm. Diff.: 0.004994197922582101 tk: 5 x_norm: 20.099690676839987\n",
      "Iteration 1687 - Grad. Norm.: 0.0009980162972499436 Norm. Diff.: 0.0049921387054997395 tk: 5 x_norm: 20.103951643775893\n",
      "Iteration 1688 - Grad. Norm.: 0.0009976052523517894 Norm. Diff.: 0.004990081486249611 tk: 5 x_norm: 20.10821082980185\n",
      "Iteration 1689 - Grad. Norm.: 0.0009971946057921255 Norm. Diff.: 0.004988026261758959 tk: 5 x_norm: 20.112468236634957\n",
      "Iteration 1690 - Grad. Norm.: 0.0009967843569589324 Norm. Diff.: 0.004985973028960559 tk: 5 x_norm: 20.11672386598971\n",
      "Iteration 1691 - Grad. Norm.: 0.0009963745052415077 Norm. Diff.: 0.004983921784794543 tk: 5 x_norm: 20.120977719578015\n",
      "Iteration 1692 - Grad. Norm.: 0.0009959650500304647 Norm. Diff.: 0.004981872526207414 tk: 5 x_norm: 20.125229799109206\n",
      "Iteration 1693 - Grad. Norm.: 0.000995555990717728 Norm. Diff.: 0.004979825250152126 tk: 5 x_norm: 20.129480106290018\n",
      "Iteration 1694 - Grad. Norm.: 0.0009951473266965256 Norm. Diff.: 0.0049777799535884616 tk: 5 x_norm: 20.13372864282462\n",
      "Iteration 1695 - Grad. Norm.: 0.0009947390573613929 Norm. Diff.: 0.004975736633482521 tk: 5 x_norm: 20.13797541041462\n",
      "Iteration 1696 - Grad. Norm.: 0.0009943311821081638 Norm. Diff.: 0.00497369528680676 tk: 5 x_norm: 20.14222041075903\n",
      "Iteration 1697 - Grad. Norm.: 0.0009939237003339684 Norm. Diff.: 0.004971655910540586 tk: 5 x_norm: 20.14646364555434\n",
      "Iteration 1698 - Grad. Norm.: 0.0009935166114372273 Norm. Diff.: 0.004969618501669919 tk: 5 x_norm: 20.15070511649447\n",
      "Iteration 1699 - Grad. Norm.: 0.0009931099148176533 Norm. Diff.: 0.004967583057186171 tk: 5 x_norm: 20.154944825270782\n",
      "Iteration 1700 - Grad. Norm.: 0.0009927036098762445 Norm. Diff.: 0.00496554957408831 tk: 5 x_norm: 20.1591827735721\n",
      "Iteration 1701 - Grad. Norm.: 0.0009922976960152782 Norm. Diff.: 0.004963518049381175 tk: 5 x_norm: 20.163418963084716\n",
      "Iteration 1702 - Grad. Norm.: 0.000991892172638313 Norm. Diff.: 0.004961488480076476 tk: 5 x_norm: 20.167653395492387\n",
      "Iteration 1703 - Grad. Norm.: 0.0009914870391501808 Norm. Diff.: 0.004959460863191673 tk: 5 x_norm: 20.171886072476337\n",
      "Iteration 1704 - Grad. Norm.: 0.0009910822949569856 Norm. Diff.: 0.004957435195750909 tk: 5 x_norm: 20.17611699571526\n",
      "Iteration 1705 - Grad. Norm.: 0.0009906779394661 Norm. Diff.: 0.00495541147478493 tk: 5 x_norm: 20.180346166885357\n",
      "Iteration 1706 - Grad. Norm.: 0.0009902739720861608 Norm. Diff.: 0.004953389697330571 tk: 5 x_norm: 20.184573587660285\n",
      "Iteration 1707 - Grad. Norm.: 0.0009898703922270628 Norm. Diff.: 0.0049513698604308765 tk: 5 x_norm: 20.188799259711214\n",
      "Iteration 1708 - Grad. Norm.: 0.0009894671992999636 Norm. Diff.: 0.00494935196113548 tk: 5 x_norm: 20.193023184706803\n",
      "Iteration 1709 - Grad. Norm.: 0.0009890643927172708 Norm. Diff.: 0.004947335996499681 tk: 5 x_norm: 20.197245364313222\n",
      "Iteration 1710 - Grad. Norm.: 0.0009886619718926452 Norm. Diff.: 0.004945321963586368 tk: 5 x_norm: 20.201465800194136\n",
      "Iteration 1711 - Grad. Norm.: 0.0009882599362409919 Norm. Diff.: 0.00494330985946316 tk: 5 x_norm: 20.205684494010733\n",
      "Iteration 1712 - Grad. Norm.: 0.0009878582851784625 Norm. Diff.: 0.0049412996812049975 tk: 5 x_norm: 20.209901447421714\n",
      "Iteration 1713 - Grad. Norm.: 0.000987457018122448 Norm. Diff.: 0.004939291425892395 tk: 5 x_norm: 20.214116662083303\n",
      "Iteration 1714 - Grad. Norm.: 0.0009870561344915772 Norm. Diff.: 0.004937285090612343 tk: 5 x_norm: 20.218330139649257\n",
      "Iteration 1715 - Grad. Norm.: 0.0009866556337057102 Norm. Diff.: 0.0049352806724577555 tk: 5 x_norm: 20.22254188177085\n",
      "Iteration 1716 - Grad. Norm.: 0.000986255515185941 Norm. Diff.: 0.004933278168528612 tk: 5 x_norm: 20.22675189009692\n",
      "Iteration 1717 - Grad. Norm.: 0.000985855778354586 Norm. Diff.: 0.004931277575929871 tk: 5 x_norm: 20.230960166273828\n",
      "Iteration 1718 - Grad. Norm.: 0.0009854564226351881 Norm. Diff.: 0.004929278891772831 tk: 5 x_norm: 20.23516671194548\n",
      "Iteration 1719 - Grad. Norm.: 0.0009850574474525111 Norm. Diff.: 0.004927282113175984 tk: 5 x_norm: 20.239371528753363\n",
      "Iteration 1720 - Grad. Norm.: 0.0009846588522325337 Norm. Diff.: 0.004925287237262481 tk: 5 x_norm: 20.24357461833648\n",
      "Iteration 1721 - Grad. Norm.: 0.000984260636402448 Norm. Diff.: 0.00492329426116276 tk: 5 x_norm: 20.24777598233143\n",
      "Iteration 1722 - Grad. Norm.: 0.0009838627993906588 Norm. Diff.: 0.00492130318201214 tk: 5 x_norm: 20.251975622372367\n",
      "Iteration 1723 - Grad. Norm.: 0.0009834653406267748 Norm. Diff.: 0.004919313996953237 tk: 5 x_norm: 20.256173540091012\n",
      "Iteration 1724 - Grad. Norm.: 0.00098306825954161 Norm. Diff.: 0.004917326703133796 tk: 5 x_norm: 20.26036973711668\n",
      "Iteration 1725 - Grad. Norm.: 0.000982671555567179 Norm. Diff.: 0.0049153412977080745 tk: 5 x_norm: 20.264564215076252\n",
      "Iteration 1726 - Grad. Norm.: 0.0009822752281366922 Norm. Diff.: 0.004913357777835851 tk: 5 x_norm: 20.2687569755942\n",
      "Iteration 1727 - Grad. Norm.: 0.0009818792766845554 Norm. Diff.: 0.004911376140683538 tk: 5 x_norm: 20.2729480202926\n",
      "Iteration 1728 - Grad. Norm.: 0.0009814837006463636 Norm. Diff.: 0.0049093963834229695 tk: 5 x_norm: 20.277137350791115\n",
      "Iteration 1729 - Grad. Norm.: 0.0009810884994589002 Norm. Diff.: 0.00490741850323162 tk: 5 x_norm: 20.281324968707\n",
      "Iteration 1730 - Grad. Norm.: 0.0009806936725601323 Norm. Diff.: 0.00490544249729445 tk: 5 x_norm: 20.28551087565514\n",
      "Iteration 1731 - Grad. Norm.: 0.0009802992193892082 Norm. Diff.: 0.004903468362800619 tk: 5 x_norm: 20.28969507324802\n",
      "Iteration 1732 - Grad. Norm.: 0.0009799051393864528 Norm. Diff.: 0.004901496096946199 tk: 5 x_norm: 20.293877563095723\n",
      "Iteration 1733 - Grad. Norm.: 0.0009795114319933677 Norm. Diff.: 0.004899525696932015 tk: 5 x_norm: 20.29805834680599\n",
      "Iteration 1734 - Grad. Norm.: 0.0009791180966526234 Norm. Diff.: 0.004897557159966995 tk: 5 x_norm: 20.302237425984163\n",
      "Iteration 1735 - Grad. Norm.: 0.0009787251328080607 Norm. Diff.: 0.004895590483263152 tk: 5 x_norm: 20.306414802233217\n",
      "Iteration 1736 - Grad. Norm.: 0.0009783325399046838 Norm. Diff.: 0.004893625664040373 tk: 5 x_norm: 20.310590477153763\n",
      "Iteration 1737 - Grad. Norm.: 0.0009779403173886597 Norm. Diff.: 0.004891662699523548 tk: 5 x_norm: 20.314764452344065\n",
      "Iteration 1738 - Grad. Norm.: 0.0009775484647073136 Norm. Diff.: 0.004889701586943414 tk: 5 x_norm: 20.318936729400008\n",
      "Iteration 1739 - Grad. Norm.: 0.000977156981309126 Norm. Diff.: 0.004887742323536576 tk: 5 x_norm: 20.323107309915148\n",
      "Iteration 1740 - Grad. Norm.: 0.0009767658666437324 Norm. Diff.: 0.0048857849065454765 tk: 5 x_norm: 20.32727619548069\n",
      "Iteration 1741 - Grad. Norm.: 0.0009763751201619124 Norm. Diff.: 0.004883829333218544 tk: 5 x_norm: 20.331443387685493\n",
      "Iteration 1742 - Grad. Norm.: 0.0009759847413155963 Norm. Diff.: 0.004881875600809387 tk: 5 x_norm: 20.335608888116084\n",
      "Iteration 1743 - Grad. Norm.: 0.0009755947295578577 Norm. Diff.: 0.004879923706578066 tk: 5 x_norm: 20.339772698356654\n",
      "Iteration 1744 - Grad. Norm.: 0.0009752050843429066 Norm. Diff.: 0.004877973647789277 tk: 5 x_norm: 20.343934819989077\n",
      "Iteration 1745 - Grad. Norm.: 0.0009748158051260925 Norm. Diff.: 0.004876025421714604 tk: 5 x_norm: 20.34809525459289\n",
      "Iteration 1746 - Grad. Norm.: 0.0009744268913638999 Norm. Diff.: 0.004874079025630202 tk: 5 x_norm: 20.352254003745326\n",
      "Iteration 1747 - Grad. Norm.: 0.0009740383425139407 Norm. Diff.: 0.0048721344568195945 tk: 5 x_norm: 20.3564110690213\n",
      "Iteration 1748 - Grad. Norm.: 0.0009736501580349584 Norm. Diff.: 0.004870191712569645 tk: 5 x_norm: 20.360566451993414\n",
      "Iteration 1749 - Grad. Norm.: 0.0009732623373868176 Norm. Diff.: 0.0048682507901746256 tk: 5 x_norm: 20.364720154231982\n",
      "Iteration 1750 - Grad. Norm.: 0.0009728748800305079 Norm. Diff.: 0.004866311686934175 tk: 5 x_norm: 20.36887217730499\n",
      "Iteration 1751 - Grad. Norm.: 0.0009724877854281359 Norm. Diff.: 0.004864374400152452 tk: 5 x_norm: 20.373022522778157\n",
      "Iteration 1752 - Grad. Norm.: 0.0009721010530429243 Norm. Diff.: 0.0048624389271407316 tk: 5 x_norm: 20.377171192214906\n",
      "Iteration 1753 - Grad. Norm.: 0.0009717146823392089 Norm. Diff.: 0.004860505265214488 tk: 5 x_norm: 20.381318187176362\n",
      "Iteration 1754 - Grad. Norm.: 0.0009713286727824332 Norm. Diff.: 0.004858573411696045 tk: 5 x_norm: 20.38546350922139\n",
      "Iteration 1755 - Grad. Norm.: 0.000970943023839151 Norm. Diff.: 0.004856643363912359 tk: 5 x_norm: 20.389607159906546\n",
      "Iteration 1756 - Grad. Norm.: 0.0009705577349770167 Norm. Diff.: 0.004854715119195675 tk: 5 x_norm: 20.39374914078616\n",
      "Iteration 1757 - Grad. Norm.: 0.0009701728056647867 Norm. Diff.: 0.0048527886748849286 tk: 5 x_norm: 20.39788945341225\n",
      "Iteration 1758 - Grad. Norm.: 0.0009697882353723159 Norm. Diff.: 0.004850864028324 tk: 5 x_norm: 20.4020280993346\n",
      "Iteration 1759 - Grad. Norm.: 0.0009694040235705539 Norm. Diff.: 0.004848941176861656 tk: 5 x_norm: 20.406165080100727\n",
      "Iteration 1760 - Grad. Norm.: 0.0009690201697315412 Norm. Diff.: 0.004847020117852779 tk: 5 x_norm: 20.410300397255895\n",
      "Iteration 1761 - Grad. Norm.: 0.0009686366733284088 Norm. Diff.: 0.004845100848657763 tk: 5 x_norm: 20.41443405234312\n",
      "Iteration 1762 - Grad. Norm.: 0.0009682535338353725 Norm. Diff.: 0.004843183366641896 tk: 5 x_norm: 20.41856604690316\n",
      "Iteration 1763 - Grad. Norm.: 0.000967870750727734 Norm. Diff.: 0.004841267669176903 tk: 5 x_norm: 20.422696382474555\n",
      "Iteration 1764 - Grad. Norm.: 0.0009674883234818707 Norm. Diff.: 0.00483935375363882 tk: 5 x_norm: 20.42682506059359\n",
      "Iteration 1765 - Grad. Norm.: 0.0009671062515752411 Norm. Diff.: 0.0048374416174093784 tk: 5 x_norm: 20.43095208279433\n",
      "Iteration 1766 - Grad. Norm.: 0.0009667245344863794 Norm. Diff.: 0.004835531257876222 tk: 5 x_norm: 20.435077450608613\n",
      "Iteration 1767 - Grad. Norm.: 0.0009663431716948874 Norm. Diff.: 0.004833622672431903 tk: 5 x_norm: 20.439201165566047\n",
      "Iteration 1768 - Grad. Norm.: 0.0009659621626814386 Norm. Diff.: 0.004831715858474267 tk: 5 x_norm: 20.443323229194032\n",
      "Iteration 1769 - Grad. Norm.: 0.0009655815069277719 Norm. Diff.: 0.004829810813407158 tk: 5 x_norm: 20.447443643017735\n",
      "Iteration 1770 - Grad. Norm.: 0.0009652012039166897 Norm. Diff.: 0.004827907534638931 tk: 5 x_norm: 20.451562408560136\n",
      "Iteration 1771 - Grad. Norm.: 0.0009648212531320543 Norm. Diff.: 0.004826006019583505 tk: 5 x_norm: 20.455679527341996\n",
      "Iteration 1772 - Grad. Norm.: 0.0009644416540587849 Norm. Diff.: 0.004824106265660251 tk: 5 x_norm: 20.459795000881886\n",
      "Iteration 1773 - Grad. Norm.: 0.000964062406182857 Norm. Diff.: 0.004822208270293665 tk: 5 x_norm: 20.463908830696166\n",
      "Iteration 1774 - Grad. Norm.: 0.000963683508991297 Norm. Diff.: 0.004820312030914512 tk: 5 x_norm: 20.468021018299016\n",
      "Iteration 1775 - Grad. Norm.: 0.000963304961972181 Norm. Diff.: 0.0048184175449563355 tk: 5 x_norm: 20.472131565202424\n",
      "Iteration 1776 - Grad. Norm.: 0.0009629267646146297 Norm. Diff.: 0.004816524809860892 tk: 5 x_norm: 20.476240472916192\n",
      "Iteration 1777 - Grad. Norm.: 0.0009625489164088102 Norm. Diff.: 0.0048146338230731 tk: 5 x_norm: 20.480347742947952\n",
      "Iteration 1778 - Grad. Norm.: 0.0009621714168459278 Norm. Diff.: 0.004812744582044169 tk: 5 x_norm: 20.484453376803152\n",
      "Iteration 1779 - Grad. Norm.: 0.0009617942654182275 Norm. Diff.: 0.004810857084229688 tk: 5 x_norm: 20.488557375985067\n",
      "Iteration 1780 - Grad. Norm.: 0.0009614174616189878 Norm. Diff.: 0.0048089713270912954 tk: 5 x_norm: 20.492659741994814\n",
      "Iteration 1781 - Grad. Norm.: 0.0009610410049425231 Norm. Diff.: 0.004807087308094883 tk: 5 x_norm: 20.496760476331357\n",
      "Iteration 1782 - Grad. Norm.: 0.000960664894884173 Norm. Diff.: 0.004805205024712586 tk: 5 x_norm: 20.50085958049147\n",
      "Iteration 1783 - Grad. Norm.: 0.0009602891309403076 Norm. Diff.: 0.004803324474420863 tk: 5 x_norm: 20.504957055969808\n",
      "Iteration 1784 - Grad. Norm.: 0.0009599137126083207 Norm. Diff.: 0.004801445654701463 tk: 5 x_norm: 20.50905290425886\n",
      "Iteration 1785 - Grad. Norm.: 0.0009595386393866267 Norm. Diff.: 0.004799568563041724 tk: 5 x_norm: 20.513147126848963\n",
      "Iteration 1786 - Grad. Norm.: 0.000959163910774658 Norm. Diff.: 0.004797693196933195 tk: 5 x_norm: 20.517239725228333\n",
      "Iteration 1787 - Grad. Norm.: 0.0009587895262728676 Norm. Diff.: 0.004795819553873256 tk: 5 x_norm: 20.521330700883034\n",
      "Iteration 1788 - Grad. Norm.: 0.0009584154853827166 Norm. Diff.: 0.004793947631364431 tk: 5 x_norm: 20.525420055297005\n",
      "Iteration 1789 - Grad. Norm.: 0.0009580417876066817 Norm. Diff.: 0.0047920774269135024 tk: 5 x_norm: 20.529507789952056\n",
      "Iteration 1790 - Grad. Norm.: 0.0009576684324482437 Norm. Diff.: 0.004790208938033367 tk: 5 x_norm: 20.533593906327862\n",
      "Iteration 1791 - Grad. Norm.: 0.0009572954194118931 Norm. Diff.: 0.004788342162241453 tk: 5 x_norm: 20.537678405901993\n",
      "Iteration 1792 - Grad. Norm.: 0.0009569227480031182 Norm. Diff.: 0.004786477097059462 tk: 5 x_norm: 20.541761290149893\n",
      "Iteration 1793 - Grad. Norm.: 0.0009565504177284132 Norm. Diff.: 0.004784613740015333 tk: 5 x_norm: 20.545842560544905\n",
      "Iteration 1794 - Grad. Norm.: 0.0009561784280952651 Norm. Diff.: 0.004782752088641903 tk: 5 x_norm: 20.549922218558244\n",
      "Iteration 1795 - Grad. Norm.: 0.000955806778612159 Norm. Diff.: 0.0047808921404763486 tk: 5 x_norm: 20.55400026565905\n",
      "Iteration 1796 - Grad. Norm.: 0.0009554354687885722 Norm. Diff.: 0.0047790338930609735 tk: 5 x_norm: 20.55807670331434\n",
      "Iteration 1797 - Grad. Norm.: 0.0009550644981349688 Norm. Diff.: 0.004777177343942897 tk: 5 x_norm: 20.562151532989052\n",
      "Iteration 1798 - Grad. Norm.: 0.0009546938661628034 Norm. Diff.: 0.004775322490674727 tk: 5 x_norm: 20.566224756146017\n",
      "Iteration 1799 - Grad. Norm.: 0.0009543235723845143 Norm. Diff.: 0.004773469330814138 tk: 5 x_norm: 20.570296374245988\n",
      "Iteration 1800 - Grad. Norm.: 0.0009539536163135201 Norm. Diff.: 0.0047716178619225495 tk: 5 x_norm: 20.574366388747634\n",
      "Iteration 1801 - Grad. Norm.: 0.0009535839974642218 Norm. Diff.: 0.0047697680815676265 tk: 5 x_norm: 20.57843480110755\n",
      "Iteration 1802 - Grad. Norm.: 0.0009532147153519946 Norm. Diff.: 0.004767919987320973 tk: 5 x_norm: 20.582501612780245\n",
      "Iteration 1803 - Grad. Norm.: 0.0009528457694931886 Norm. Diff.: 0.004766073576759867 tk: 5 x_norm: 20.586566825218164\n",
      "Iteration 1804 - Grad. Norm.: 0.000952477159405127 Norm. Diff.: 0.004764228847465914 tk: 5 x_norm: 20.590630439871692\n",
      "Iteration 1805 - Grad. Norm.: 0.0009521088846060996 Norm. Diff.: 0.004762385797025536 tk: 5 x_norm: 20.59469245818913\n",
      "Iteration 1806 - Grad. Norm.: 0.0009517409446153653 Norm. Diff.: 0.0047605444230303115 tk: 5 x_norm: 20.59875288161674\n",
      "Iteration 1807 - Grad. Norm.: 0.0009513733389531466 Norm. Diff.: 0.004758704723076954 tk: 5 x_norm: 20.602811711598722\n",
      "Iteration 1808 - Grad. Norm.: 0.0009510060671406277 Norm. Diff.: 0.004756866694765806 tk: 5 x_norm: 20.60686894957723\n",
      "Iteration 1809 - Grad. Norm.: 0.0009506391286999499 Norm. Diff.: 0.004755030335703017 tk: 5 x_norm: 20.61092459699236\n",
      "Iteration 1810 - Grad. Norm.: 0.0009502725231542127 Norm. Diff.: 0.0047531956434997405 tk: 5 x_norm: 20.614978655282172\n",
      "Iteration 1811 - Grad. Norm.: 0.0009499062500274698 Norm. Diff.: 0.004751362615771109 tk: 5 x_norm: 20.61903112588269\n",
      "Iteration 1812 - Grad. Norm.: 0.0009495403088447269 Norm. Diff.: 0.004749531250137185 tk: 5 x_norm: 20.623082010227897\n",
      "Iteration 1813 - Grad. Norm.: 0.000949174699131937 Norm. Diff.: 0.00474770154422378 tk: 5 x_norm: 20.62713130974975\n",
      "Iteration 1814 - Grad. Norm.: 0.0009488094204160016 Norm. Diff.: 0.004745873495659661 tk: 5 x_norm: 20.631179025878172\n",
      "Iteration 1815 - Grad. Norm.: 0.0009484444722247648 Norm. Diff.: 0.00474404710208001 tk: 5 x_norm: 20.63522516004107\n",
      "Iteration 1816 - Grad. Norm.: 0.0009480798540870148 Norm. Diff.: 0.004742222361123754 tk: 5 x_norm: 20.63926971366433\n",
      "Iteration 1817 - Grad. Norm.: 0.0009477155655324756 Norm. Diff.: 0.004740399270434998 tk: 5 x_norm: 20.643312688171818\n",
      "Iteration 1818 - Grad. Norm.: 0.0009473516060918096 Norm. Diff.: 0.0047385778276623795 tk: 5 x_norm: 20.647354084985395\n",
      "Iteration 1819 - Grad. Norm.: 0.0009469879752966153 Norm. Diff.: 0.004736758030458958 tk: 5 x_norm: 20.65139390552491\n",
      "Iteration 1820 - Grad. Norm.: 0.0009466246726794218 Norm. Diff.: 0.0047349398764830785 tk: 5 x_norm: 20.655432151208203\n",
      "Iteration 1821 - Grad. Norm.: 0.0009462616977736856 Norm. Diff.: 0.004733123363397188 tk: 5 x_norm: 20.659468823451125\n",
      "Iteration 1822 - Grad. Norm.: 0.0009458990501137938 Norm. Diff.: 0.004731308488868359 tk: 5 x_norm: 20.663503923667523\n",
      "Iteration 1823 - Grad. Norm.: 0.0009455367292350565 Norm. Diff.: 0.004729495250568827 tk: 5 x_norm: 20.667537453269265\n",
      "Iteration 1824 - Grad. Norm.: 0.0009451747346737055 Norm. Diff.: 0.004727683646175166 tk: 5 x_norm: 20.671569413666212\n",
      "Iteration 1825 - Grad. Norm.: 0.0009448130659668942 Norm. Diff.: 0.004725873673368403 tk: 5 x_norm: 20.675599806266245\n",
      "Iteration 1826 - Grad. Norm.: 0.0009444517226526911 Norm. Diff.: 0.00472406532983459 tk: 5 x_norm: 20.67962863247528\n",
      "Iteration 1827 - Grad. Norm.: 0.0009440907042700823 Norm. Diff.: 0.004722258613263196 tk: 5 x_norm: 20.683655893697228\n",
      "Iteration 1828 - Grad. Norm.: 0.0009437300103589656 Norm. Diff.: 0.004720453521350635 tk: 5 x_norm: 20.687681591334055\n",
      "Iteration 1829 - Grad. Norm.: 0.0009433696404601499 Norm. Diff.: 0.004718650051794819 tk: 5 x_norm: 20.69170572678574\n",
      "Iteration 1830 - Grad. Norm.: 0.0009430095941153504 Norm. Diff.: 0.004716848202300724 tk: 5 x_norm: 20.695728301450306\n",
      "Iteration 1831 - Grad. Norm.: 0.0009426498708671908 Norm. Diff.: 0.004715047970576756 tk: 5 x_norm: 20.699749316723807\n",
      "Iteration 1832 - Grad. Norm.: 0.0009422904702591946 Norm. Diff.: 0.004713249354335781 tk: 5 x_norm: 20.70376877400034\n",
      "Iteration 1833 - Grad. Norm.: 0.0009419313918357892 Norm. Diff.: 0.004711452351295989 tk: 5 x_norm: 20.707786674672054\n",
      "Iteration 1834 - Grad. Norm.: 0.0009415726351423001 Norm. Diff.: 0.00470965695917886 tk: 5 x_norm: 20.71180302012914\n",
      "Iteration 1835 - Grad. Norm.: 0.0009412141997249473 Norm. Diff.: 0.004707863175711521 tk: 5 x_norm: 20.715817811759845\n",
      "Iteration 1836 - Grad. Norm.: 0.0009408560851308491 Norm. Diff.: 0.004706070998624942 tk: 5 x_norm: 20.71983105095047\n",
      "Iteration 1837 - Grad. Norm.: 0.0009404982909080107 Norm. Diff.: 0.004704280425654189 tk: 5 x_norm: 20.723842739085388\n",
      "Iteration 1838 - Grad. Norm.: 0.0009401408166053295 Norm. Diff.: 0.0047024914545401855 tk: 5 x_norm: 20.727852877547022\n",
      "Iteration 1839 - Grad. Norm.: 0.0009397836617725903 Norm. Diff.: 0.004700704083026755 tk: 5 x_norm: 20.73186146771587\n",
      "Iteration 1840 - Grad. Norm.: 0.0009394268259604611 Norm. Diff.: 0.0046989183088629975 tk: 5 x_norm: 20.735868510970498\n",
      "Iteration 1841 - Grad. Norm.: 0.0009390703087204947 Norm. Diff.: 0.0046971341298023515 tk: 5 x_norm: 20.73987400868755\n",
      "Iteration 1842 - Grad. Norm.: 0.0009387141096051224 Norm. Diff.: 0.004695351543602594 tk: 5 x_norm: 20.743877962241754\n",
      "Iteration 1843 - Grad. Norm.: 0.0009383582281676556 Norm. Diff.: 0.004693570548025441 tk: 5 x_norm: 20.747880373005913\n",
      "Iteration 1844 - Grad. Norm.: 0.0009380026639622782 Norm. Diff.: 0.004691791140838271 tk: 5 x_norm: 20.751881242350915\n",
      "Iteration 1845 - Grad. Norm.: 0.0009376474165440502 Norm. Diff.: 0.004690013319811296 tk: 5 x_norm: 20.75588057164575\n",
      "Iteration 1846 - Grad. Norm.: 0.0009372924854689042 Norm. Diff.: 0.0046882370827200474 tk: 5 x_norm: 20.759878362257478\n",
      "Iteration 1847 - Grad. Norm.: 0.0009369378702936383 Norm. Diff.: 0.004686462427344528 tk: 5 x_norm: 20.76387461555129\n",
      "Iteration 1848 - Grad. Norm.: 0.0009365835705759203 Norm. Diff.: 0.004684689351468384 tk: 5 x_norm: 20.767869332890456\n",
      "Iteration 1849 - Grad. Norm.: 0.0009362295858742822 Norm. Diff.: 0.004682917852879562 tk: 5 x_norm: 20.771862515636343\n",
      "Iteration 1850 - Grad. Norm.: 0.0009358759157481162 Norm. Diff.: 0.004681147929371368 tk: 5 x_norm: 20.775854165148445\n",
      "Iteration 1851 - Grad. Norm.: 0.0009355225597576797 Norm. Diff.: 0.004679379578740776 tk: 5 x_norm: 20.77984428278436\n",
      "Iteration 1852 - Grad. Norm.: 0.0009351695174640833 Norm. Diff.: 0.004677612798788387 tk: 5 x_norm: 20.7838328698998\n",
      "Iteration 1853 - Grad. Norm.: 0.000934816788429295 Norm. Diff.: 0.004675847587320464 tk: 5 x_norm: 20.7878199278486\n",
      "Iteration 1854 - Grad. Norm.: 0.0009344643722161376 Norm. Diff.: 0.0046740839421464606 tk: 5 x_norm: 20.791805457982704\n",
      "Iteration 1855 - Grad. Norm.: 0.000934112268388284 Norm. Diff.: 0.004672321861080817 tk: 5 x_norm: 20.795789461652205\n",
      "Iteration 1856 - Grad. Norm.: 0.0009337604765102566 Norm. Diff.: 0.004670561341941379 tk: 5 x_norm: 20.799771940205304\n",
      "Iteration 1857 - Grad. Norm.: 0.0009334089961474264 Norm. Diff.: 0.004668802382551309 tk: 5 x_norm: 20.80375289498835\n",
      "Iteration 1858 - Grad. Norm.: 0.0009330578268660081 Norm. Diff.: 0.004667044980737312 tk: 5 x_norm: 20.80773232734582\n",
      "Iteration 1859 - Grad. Norm.: 0.0009327069682330588 Norm. Diff.: 0.004665289134330024 tk: 5 x_norm: 20.811710238620332\n",
      "Iteration 1860 - Grad. Norm.: 0.0009323564198164773 Norm. Diff.: 0.004663534841165112 tk: 5 x_norm: 20.81568663015265\n",
      "Iteration 1861 - Grad. Norm.: 0.0009320061811850016 Norm. Diff.: 0.004661782099082334 tk: 5 x_norm: 20.819661503281687\n",
      "Iteration 1862 - Grad. Norm.: 0.0009316562519082024 Norm. Diff.: 0.004660030905924891 tk: 5 x_norm: 20.823634859344505\n",
      "Iteration 1863 - Grad. Norm.: 0.0009313066315564904 Norm. Diff.: 0.004658281259541035 tk: 5 x_norm: 20.827606699676313\n",
      "Iteration 1864 - Grad. Norm.: 0.0009309573197011049 Norm. Diff.: 0.004656533157782507 tk: 5 x_norm: 20.831577025610486\n",
      "Iteration 1865 - Grad. Norm.: 0.0009306083159141154 Norm. Diff.: 0.004654786598505419 tk: 5 x_norm: 20.83554583847856\n",
      "Iteration 1866 - Grad. Norm.: 0.0009302596197684194 Norm. Diff.: 0.00465304157957047 tk: 5 x_norm: 20.83951313961023\n",
      "Iteration 1867 - Grad. Norm.: 0.0009299112308377417 Norm. Diff.: 0.00465129809884226 tk: 5 x_norm: 20.843478930333365\n",
      "Iteration 1868 - Grad. Norm.: 0.0009295631486966296 Norm. Diff.: 0.0046495561541886115 tk: 5 x_norm: 20.847443211973996\n",
      "Iteration 1869 - Grad. Norm.: 0.0009292153729204528 Norm. Diff.: 0.004647815743483183 tk: 5 x_norm: 20.851405985856353\n",
      "Iteration 1870 - Grad. Norm.: 0.0009288679030853992 Norm. Diff.: 0.004646076864602288 tk: 5 x_norm: 20.855367253302806\n",
      "Iteration 1871 - Grad. Norm.: 0.0009285207387684753 Norm. Diff.: 0.004644339515426976 tk: 5 x_norm: 20.859327015633944\n",
      "Iteration 1872 - Grad. Norm.: 0.0009281738795475043 Norm. Diff.: 0.004642603693842327 tk: 5 x_norm: 20.86328527416852\n",
      "Iteration 1873 - Grad. Norm.: 0.0009278273250011204 Norm. Diff.: 0.00464086939773757 tk: 5 x_norm: 20.867242030223473\n",
      "Iteration 1874 - Grad. Norm.: 0.0009274810747087697 Norm. Diff.: 0.004639136625005524 tk: 5 x_norm: 20.87119728511395\n",
      "Iteration 1875 - Grad. Norm.: 0.0009271351282507101 Norm. Diff.: 0.004637405373543938 tk: 5 x_norm: 20.875151040153284\n",
      "Iteration 1876 - Grad. Norm.: 0.0009267894852080027 Norm. Diff.: 0.004635675641253502 tk: 5 x_norm: 20.879103296653007\n",
      "Iteration 1877 - Grad. Norm.: 0.0009264441451625161 Norm. Diff.: 0.0046339474260401825 tk: 5 x_norm: 20.88305405592285\n",
      "Iteration 1878 - Grad. Norm.: 0.0009260991076969228 Norm. Diff.: 0.00463222072581283 tk: 5 x_norm: 20.887003319270757\n",
      "Iteration 1879 - Grad. Norm.: 0.0009257543723946943 Norm. Diff.: 0.004630495538484563 tk: 5 x_norm: 20.890951088002875\n",
      "Iteration 1880 - Grad. Norm.: 0.000925409938840104 Norm. Diff.: 0.004628771861973354 tk: 5 x_norm: 20.894897363423574\n",
      "Iteration 1881 - Grad. Norm.: 0.0009250658066182189 Norm. Diff.: 0.004627049694200325 tk: 5 x_norm: 20.898842146835417\n",
      "Iteration 1882 - Grad. Norm.: 0.000924721975314904 Norm. Diff.: 0.004625329033091126 tk: 5 x_norm: 20.90278543953921\n",
      "Iteration 1883 - Grad. Norm.: 0.0009243784445168163 Norm. Diff.: 0.004623609876574324 tk: 5 x_norm: 20.906727242833966\n",
      "Iteration 1884 - Grad. Norm.: 0.000924035213811404 Norm. Diff.: 0.004621892222583913 tk: 5 x_norm: 20.910667558016932\n",
      "Iteration 1885 - Grad. Norm.: 0.0009236922827869042 Norm. Diff.: 0.004620176069057009 tk: 5 x_norm: 20.91460638638358\n",
      "Iteration 1886 - Grad. Norm.: 0.0009233496510323424 Norm. Diff.: 0.004618461413934431 tk: 5 x_norm: 20.918543729227615\n",
      "Iteration 1887 - Grad. Norm.: 0.0009230073181375265 Norm. Diff.: 0.004616748255161643 tk: 5 x_norm: 20.92247958784098\n",
      "Iteration 1888 - Grad. Norm.: 0.0009226652836930518 Norm. Diff.: 0.004615036590687479 tk: 5 x_norm: 20.92641396351384\n",
      "Iteration 1889 - Grad. Norm.: 0.0009223235472902903 Norm. Diff.: 0.004613326418465087 tk: 5 x_norm: 20.93034685753463\n",
      "Iteration 1890 - Grad. Norm.: 0.0009219821085213959 Norm. Diff.: 0.00461161773645134 tk: 5 x_norm: 20.934278271190017\n",
      "Iteration 1891 - Grad. Norm.: 0.0009216409669793013 Norm. Diff.: 0.004609910542607075 tk: 5 x_norm: 20.93820820576491\n",
      "Iteration 1892 - Grad. Norm.: 0.0009213001222577088 Norm. Diff.: 0.004608204834896618 tk: 5 x_norm: 20.942136662542474\n",
      "Iteration 1893 - Grad. Norm.: 0.0009209595739511018 Norm. Diff.: 0.004606500611288596 tk: 5 x_norm: 20.94606364280414\n",
      "Iteration 1894 - Grad. Norm.: 0.0009206193216547286 Norm. Diff.: 0.004604797869755483 tk: 5 x_norm: 20.949989147829577\n",
      "Iteration 1895 - Grad. Norm.: 0.0009202793649646123 Norm. Diff.: 0.004603096608273706 tk: 5 x_norm: 20.953913178896734\n",
      "Iteration 1896 - Grad. Norm.: 0.0009199397034775386 Norm. Diff.: 0.004601396824823099 tk: 5 x_norm: 20.95783573728182\n",
      "Iteration 1897 - Grad. Norm.: 0.0009196003367910638 Norm. Diff.: 0.004599698517387805 tk: 5 x_norm: 20.961756824259297\n",
      "Iteration 1898 - Grad. Norm.: 0.000919261264503505 Norm. Diff.: 0.004598001683955093 tk: 5 x_norm: 20.965676441101927\n",
      "Iteration 1899 - Grad. Norm.: 0.0009189224862139413 Norm. Diff.: 0.004596306322517301 tk: 5 x_norm: 20.96959458908072\n",
      "Iteration 1900 - Grad. Norm.: 0.0009185840015222128 Norm. Diff.: 0.004594612431069488 tk: 5 x_norm: 20.97351126946498\n",
      "Iteration 1901 - Grad. Norm.: 0.0009182458100289183 Norm. Diff.: 0.004592920007610827 tk: 5 x_norm: 20.977426483522276\n",
      "Iteration 1902 - Grad. Norm.: 0.0009179079113354111 Norm. Diff.: 0.004591229050144668 tk: 5 x_norm: 20.98134023251848\n",
      "Iteration 1903 - Grad. Norm.: 0.0009175703050438008 Norm. Diff.: 0.004589539556676782 tk: 5 x_norm: 20.985252517717743\n",
      "Iteration 1904 - Grad. Norm.: 0.0009172329907569473 Norm. Diff.: 0.004587851525219183 tk: 5 x_norm: 20.9891633403825\n",
      "Iteration 1905 - Grad. Norm.: 0.000916895968078462 Norm. Diff.: 0.004586164953785059 tk: 5 x_norm: 20.99307270177349\n",
      "Iteration 1906 - Grad. Norm.: 0.0009165592366127075 Norm. Diff.: 0.004584479840392279 tk: 5 x_norm: 20.996980603149733\n",
      "Iteration 1907 - Grad. Norm.: 0.0009162227959647885 Norm. Diff.: 0.0045827961830636945 tk: 5 x_norm: 21.000887045768575\n",
      "Iteration 1908 - Grad. Norm.: 0.0009158866457405587 Norm. Diff.: 0.004581113979824173 tk: 5 x_norm: 21.004792030885636\n",
      "Iteration 1909 - Grad. Norm.: 0.0009155507855466134 Norm. Diff.: 0.004579433228702787 tk: 5 x_norm: 21.008695559754862\n",
      "Iteration 1910 - Grad. Norm.: 0.0009152152149902903 Norm. Diff.: 0.0045777539277329195 tk: 5 x_norm: 21.012597633628502\n",
      "Iteration 1911 - Grad. Norm.: 0.000914879933679663 Norm. Diff.: 0.00457607607495151 tk: 5 x_norm: 21.016498253757117\n",
      "Iteration 1912 - Grad. Norm.: 0.00091454494122355 Norm. Diff.: 0.004574399668398045 tk: 5 x_norm: 21.020397421389582\n",
      "Iteration 1913 - Grad. Norm.: 0.0009142102372314982 Norm. Diff.: 0.004572724706117683 tk: 5 x_norm: 21.02429513777309\n",
      "Iteration 1914 - Grad. Norm.: 0.0009138758213137922 Norm. Diff.: 0.004571051186157336 tk: 5 x_norm: 21.028191404153166\n",
      "Iteration 1915 - Grad. Norm.: 0.0009135416930814481 Norm. Diff.: 0.004569379106568894 tk: 5 x_norm: 21.032086221773643\n",
      "Iteration 1916 - Grad. Norm.: 0.0009132078521462119 Norm. Diff.: 0.004567708465407303 tk: 5 x_norm: 21.03597959187669\n",
      "Iteration 1917 - Grad. Norm.: 0.0009128742981205597 Norm. Diff.: 0.00456603926073117 tk: 5 x_norm: 21.03987151570282\n",
      "Iteration 1918 - Grad. Norm.: 0.0009125410306176938 Norm. Diff.: 0.004564371490602887 tk: 5 x_norm: 21.043761994490843\n",
      "Iteration 1919 - Grad. Norm.: 0.0009122080492515399 Norm. Diff.: 0.0045627051530887095 tk: 5 x_norm: 21.047651029477958\n",
      "Iteration 1920 - Grad. Norm.: 0.0009118753536367497 Norm. Diff.: 0.004561040246257706 tk: 5 x_norm: 21.051538621899663\n",
      "Iteration 1921 - Grad. Norm.: 0.0009115429433886943 Norm. Diff.: 0.004559376768183961 tk: 5 x_norm: 21.055424772989802\n",
      "Iteration 1922 - Grad. Norm.: 0.0009112108181234638 Norm. Diff.: 0.004557714716943707 tk: 5 x_norm: 21.059309483980595\n",
      "Iteration 1923 - Grad. Norm.: 0.000910878977457869 Norm. Diff.: 0.004556054090617273 tk: 5 x_norm: 21.063192756102577\n",
      "Iteration 1924 - Grad. Norm.: 0.0009105474210094348 Norm. Diff.: 0.004554394887289499 tk: 5 x_norm: 21.067074590584664\n",
      "Iteration 1925 - Grad. Norm.: 0.0009102161483964012 Norm. Diff.: 0.004552737105047293 tk: 5 x_norm: 21.0709549886541\n",
      "Iteration 1926 - Grad. Norm.: 0.0009098851592377205 Norm. Diff.: 0.004551080741982019 tk: 5 x_norm: 21.074833951536508\n",
      "Iteration 1927 - Grad. Norm.: 0.0009095544531530546 Norm. Diff.: 0.004549425796188605 tk: 5 x_norm: 21.07871148045586\n",
      "Iteration 1928 - Grad. Norm.: 0.0009092240297627771 Norm. Diff.: 0.004547772265765226 tk: 5 x_norm: 21.0825875766345\n",
      "Iteration 1929 - Grad. Norm.: 0.0009088938886879678 Norm. Diff.: 0.004546120148813782 tk: 5 x_norm: 21.086462241293138\n",
      "Iteration 1930 - Grad. Norm.: 0.000908564029550412 Norm. Diff.: 0.0045444694434399295 tk: 5 x_norm: 21.090335475650843\n",
      "Iteration 1931 - Grad. Norm.: 0.0009082344519725979 Norm. Diff.: 0.004542820147751922 tk: 5 x_norm: 21.09420728092508\n",
      "Iteration 1932 - Grad. Norm.: 0.000907905155577718 Norm. Diff.: 0.004541172259862905 tk: 5 x_norm: 21.09807765833167\n",
      "Iteration 1933 - Grad. Norm.: 0.000907576139989664 Norm. Diff.: 0.004539525777888745 tk: 5 x_norm: 21.101946609084816\n",
      "Iteration 1934 - Grad. Norm.: 0.0009072474048330257 Norm. Diff.: 0.004537880699948378 tk: 5 x_norm: 21.10581413439711\n",
      "Iteration 1935 - Grad. Norm.: 0.0009069189497330928 Norm. Diff.: 0.004536237024165125 tk: 5 x_norm: 21.109680235479534\n",
      "Iteration 1936 - Grad. Norm.: 0.000906590774315846 Norm. Diff.: 0.004534594748665412 tk: 5 x_norm: 21.11354491354144\n",
      "Iteration 1937 - Grad. Norm.: 0.0009062628782079633 Norm. Diff.: 0.004532953871579294 tk: 5 x_norm: 21.11740816979058\n",
      "Iteration 1938 - Grad. Norm.: 0.0009059352610368138 Norm. Diff.: 0.004531314391039784 tk: 5 x_norm: 21.121270005433107\n",
      "Iteration 1939 - Grad. Norm.: 0.0009056079224304554 Norm. Diff.: 0.004529676305183786 tk: 5 x_norm: 21.12513042167356\n",
      "Iteration 1940 - Grad. Norm.: 0.0009052808620176355 Norm. Diff.: 0.0045280396121522 tk: 5 x_norm: 21.12898941971488\n",
      "Iteration 1941 - Grad. Norm.: 0.0009049540794277895 Norm. Diff.: 0.004526404310088272 tk: 5 x_norm: 21.132847000758424\n",
      "Iteration 1942 - Grad. Norm.: 0.0009046275742910353 Norm. Diff.: 0.004524770397138686 tk: 5 x_norm: 21.136703166003933\n",
      "Iteration 1943 - Grad. Norm.: 0.0009043013462381786 Norm. Diff.: 0.0045231378714550114 tk: 5 x_norm: 21.140557916649566\n",
      "Iteration 1944 - Grad. Norm.: 0.000903975394900702 Norm. Diff.: 0.004521506731191024 tk: 5 x_norm: 21.1444112538919\n",
      "Iteration 1945 - Grad. Norm.: 0.0009036497199107732 Norm. Diff.: 0.004519876974503569 tk: 5 x_norm: 21.148263178925916\n",
      "Iteration 1946 - Grad. Norm.: 0.0009033243209012333 Norm. Diff.: 0.0045182485995540825 tk: 5 x_norm: 21.15211369294501\n",
      "Iteration 1947 - Grad. Norm.: 0.000902999197505605 Norm. Diff.: 0.004516621604506152 tk: 5 x_norm: 21.155962797141015\n",
      "Iteration 1948 - Grad. Norm.: 0.0009026743493580835 Norm. Diff.: 0.004514995987528037 tk: 5 x_norm: 21.159810492704167\n",
      "Iteration 1949 - Grad. Norm.: 0.0009023497760935406 Norm. Diff.: 0.004513371746790268 tk: 5 x_norm: 21.163656780823146\n",
      "Iteration 1950 - Grad. Norm.: 0.000902025477347516 Norm. Diff.: 0.004511748880467749 tk: 5 x_norm: 21.167501662685034\n",
      "Iteration 1951 - Grad. Norm.: 0.0009017014527562216 Norm. Diff.: 0.004510127386737661 tk: 5 x_norm: 21.171345139475374\n",
      "Iteration 1952 - Grad. Norm.: 0.0009013777019565408 Norm. Diff.: 0.004508507263781252 tk: 5 x_norm: 21.17518721237813\n",
      "Iteration 1953 - Grad. Norm.: 0.0009010542245860189 Norm. Diff.: 0.004506888509782854 tk: 5 x_norm: 21.179027882575696\n",
      "Iteration 1954 - Grad. Norm.: 0.0009007310202828709 Norm. Diff.: 0.004505271122930176 tk: 5 x_norm: 21.182867151248914\n",
      "Iteration 1955 - Grad. Norm.: 0.0009004080886859748 Norm. Diff.: 0.004503655101414283 tk: 5 x_norm: 21.186705019577072\n",
      "Iteration 1956 - Grad. Norm.: 0.0009000854294348703 Norm. Diff.: 0.004502040443430057 tk: 5 x_norm: 21.19054148873789\n",
      "Iteration 1957 - Grad. Norm.: 0.0008997630421697567 Norm. Diff.: 0.004500427147174388 tk: 5 x_norm: 21.194376559907553\n",
      "Iteration 1958 - Grad. Norm.: 0.0008994409265314959 Norm. Diff.: 0.0044988152108486655 tk: 5 x_norm: 21.19821023426069\n",
      "Iteration 1959 - Grad. Norm.: 0.0008991190821616023 Norm. Diff.: 0.0044972046326575985 tk: 5 x_norm: 21.20204251297037\n",
      "Iteration 1960 - Grad. Norm.: 0.000898797508702252 Norm. Diff.: 0.004495595410807941 tk: 5 x_norm: 21.205873397208144\n",
      "Iteration 1961 - Grad. Norm.: 0.0008984762057962711 Norm. Diff.: 0.004493987543511337 tk: 5 x_norm: 21.209702888144005\n",
      "Iteration 1962 - Grad. Norm.: 0.0008981551730871408 Norm. Diff.: 0.0044923810289812394 tk: 5 x_norm: 21.213530986946406\n",
      "Iteration 1963 - Grad. Norm.: 0.0008978344102189913 Norm. Diff.: 0.00449077586543556 tk: 5 x_norm: 21.21735769478228\n",
      "Iteration 1964 - Grad. Norm.: 0.0008975139168366045 Norm. Diff.: 0.004489172051095028 tk: 5 x_norm: 21.221183012817015\n",
      "Iteration 1965 - Grad. Norm.: 0.0008971936925854112 Norm. Diff.: 0.004487569584183188 tk: 5 x_norm: 21.225006942214478\n",
      "Iteration 1966 - Grad. Norm.: 0.0008968737371114859 Norm. Diff.: 0.00448596846292689 tk: 5 x_norm: 21.228829484136995\n",
      "Iteration 1967 - Grad. Norm.: 0.000896554050061549 Norm. Diff.: 0.0044843686855572384 tk: 5 x_norm: 21.23265063974539\n",
      "Iteration 1968 - Grad. Norm.: 0.0008962346310829648 Norm. Diff.: 0.004482770250307806 tk: 5 x_norm: 21.23647041019894\n",
      "Iteration 1969 - Grad. Norm.: 0.0008959154798237416 Norm. Diff.: 0.004481173155414965 tk: 5 x_norm: 21.240288796655427\n",
      "Iteration 1970 - Grad. Norm.: 0.000895596595932524 Norm. Diff.: 0.004479577399118637 tk: 5 x_norm: 21.2441058002711\n",
      "Iteration 1971 - Grad. Norm.: 0.0008952779790585964 Norm. Diff.: 0.004477982979662704 tk: 5 x_norm: 21.2479214222007\n",
      "Iteration 1972 - Grad. Norm.: 0.0008949596288518846 Norm. Diff.: 0.0044763898952931815 tk: 5 x_norm: 21.251735663597465\n",
      "Iteration 1973 - Grad. Norm.: 0.0008946415449629448 Norm. Diff.: 0.0044747981442593765 tk: 5 x_norm: 21.255548525613115\n",
      "Iteration 1974 - Grad. Norm.: 0.0008943237270429696 Norm. Diff.: 0.004473207724814747 tk: 5 x_norm: 21.259360009397867\n",
      "Iteration 1975 - Grad. Norm.: 0.0008940061747437849 Norm. Diff.: 0.004471618635214869 tk: 5 x_norm: 21.263170116100437\n",
      "Iteration 1976 - Grad. Norm.: 0.0008936888877178469 Norm. Diff.: 0.004470030873718929 tk: 5 x_norm: 21.266978846868046\n",
      "Iteration 1977 - Grad. Norm.: 0.0008933718656182425 Norm. Diff.: 0.004468444438589184 tk: 5 x_norm: 21.27078620284641\n",
      "Iteration 1978 - Grad. Norm.: 0.0008930551080986857 Norm. Diff.: 0.0044668593280912505 tk: 5 x_norm: 21.274592185179745\n",
      "Iteration 1979 - Grad. Norm.: 0.0008927386148135174 Norm. Diff.: 0.004465275540493245 tk: 5 x_norm: 21.278396795010806\n",
      "Iteration 1980 - Grad. Norm.: 0.0008924223854177044 Norm. Diff.: 0.00446369307406753 tk: 5 x_norm: 21.282200033480812\n",
      "Iteration 1981 - Grad. Norm.: 0.0008921064195668374 Norm. Diff.: 0.004462111927088522 tk: 5 x_norm: 21.286001901729545\n",
      "Iteration 1982 - Grad. Norm.: 0.000891790716917127 Norm. Diff.: 0.004460532097834342 tk: 5 x_norm: 21.289802400895255\n",
      "Iteration 1983 - Grad. Norm.: 0.0008914752771254076 Norm. Diff.: 0.004458953584585681 tk: 5 x_norm: 21.29360153211475\n",
      "Iteration 1984 - Grad. Norm.: 0.00089116009984913 Norm. Diff.: 0.004457376385626927 tk: 5 x_norm: 21.297399296523338\n",
      "Iteration 1985 - Grad. Norm.: 0.0008908451847463669 Norm. Diff.: 0.0044558004992456225 tk: 5 x_norm: 21.30119569525486\n",
      "Iteration 1986 - Grad. Norm.: 0.0008905305314758031 Norm. Diff.: 0.004454225923731714 tk: 5 x_norm: 21.30499072944168\n",
      "Iteration 1987 - Grad. Norm.: 0.0008902161396967391 Norm. Diff.: 0.004452652657379093 tk: 5 x_norm: 21.308784400214698\n",
      "Iteration 1988 - Grad. Norm.: 0.000889902009069092 Norm. Diff.: 0.0044510806984838025 tk: 5 x_norm: 21.31257670870333\n",
      "Iteration 1989 - Grad. Norm.: 0.0008895881392533858 Norm. Diff.: 0.004449510045345288 tk: 5 x_norm: 21.316367656035542\n",
      "Iteration 1990 - Grad. Norm.: 0.0008892745299107596 Norm. Diff.: 0.004447940696266938 tk: 5 x_norm: 21.320157243337828\n",
      "Iteration 1991 - Grad. Norm.: 0.0008889611807029587 Norm. Diff.: 0.004446372649553992 tk: 5 x_norm: 21.323945471735236\n",
      "Iteration 1992 - Grad. Norm.: 0.0008886480912923379 Norm. Diff.: 0.004444805903514823 tk: 5 x_norm: 21.327732342351332\n",
      "Iteration 1993 - Grad. Norm.: 0.0008883352613418563 Norm. Diff.: 0.004443240456461421 tk: 5 x_norm: 21.331517856308256\n",
      "Iteration 1994 - Grad. Norm.: 0.0008880226905150781 Norm. Diff.: 0.004441676306709431 tk: 5 x_norm: 21.335302014726672\n",
      "Iteration 1995 - Grad. Norm.: 0.0008877103784761738 Norm. Diff.: 0.0044401134525753755 tk: 5 x_norm: 21.339084818725798\n",
      "Iteration 1996 - Grad. Norm.: 0.0008873983248899107 Norm. Diff.: 0.004438551892380896 tk: 5 x_norm: 21.342866269423425\n",
      "Iteration 1997 - Grad. Norm.: 0.0008870865294216606 Norm. Diff.: 0.004436991624449602 tk: 5 x_norm: 21.346646367935865\n",
      "Iteration 1998 - Grad. Norm.: 0.0008867749917373928 Norm. Diff.: 0.004435432647108384 tk: 5 x_norm: 21.350425115378016\n",
      "Iteration 1999 - Grad. Norm.: 0.0008864637115036738 Norm. Diff.: 0.004433874958686748 tk: 5 x_norm: 21.354202512863324\n",
      "Iteration 2000 - Grad. Norm.: 0.0008861526883876665 Norm. Diff.: 0.004432318557518446 tk: 5 x_norm: 21.35797856150381\n",
      "Iteration 2001 - Grad. Norm.: 0.0008858419220571317 Norm. Diff.: 0.004430763441938129 tk: 5 x_norm: 21.361753262410037\n",
      "Iteration 2002 - Grad. Norm.: 0.0008855314121804172 Norm. Diff.: 0.0044292096102857 tk: 5 x_norm: 21.365526616691156\n",
      "Iteration 2003 - Grad. Norm.: 0.0008852211584264702 Norm. Diff.: 0.004427657060901981 tk: 5 x_norm: 21.36929862545488\n",
      "Iteration 2004 - Grad. Norm.: 0.0008849111604648228 Norm. Diff.: 0.004426105792132268 tk: 5 x_norm: 21.373069289807503\n",
      "Iteration 2005 - Grad. Norm.: 0.0008846014179655987 Norm. Diff.: 0.004424555802323952 tk: 5 x_norm: 21.37683861085388\n",
      "Iteration 2006 - Grad. Norm.: 0.0008842919305995091 Norm. Diff.: 0.004423007089828138 tk: 5 x_norm: 21.380606589697464\n",
      "Iteration 2007 - Grad. Norm.: 0.0008839826980378526 Norm. Diff.: 0.0044214596529976915 tk: 5 x_norm: 21.384373227440268\n",
      "Iteration 2008 - Grad. Norm.: 0.000883673719952511 Norm. Diff.: 0.004419913490189284 tk: 5 x_norm: 21.388138525182896\n",
      "Iteration 2009 - Grad. Norm.: 0.0008833649960159514 Norm. Diff.: 0.0044183685997626326 tk: 5 x_norm: 21.39190248402455\n",
      "Iteration 2010 - Grad. Norm.: 0.0008830565259012225 Norm. Diff.: 0.004416824980079704 tk: 5 x_norm: 21.39566510506299\n",
      "Iteration 2011 - Grad. Norm.: 0.0008827483092819551 Norm. Diff.: 0.004415282629506166 tk: 5 x_norm: 21.3994263893946\n",
      "Iteration 2012 - Grad. Norm.: 0.0008824403458323574 Norm. Diff.: 0.004413741546409856 tk: 5 x_norm: 21.403186338114338\n",
      "Iteration 2013 - Grad. Norm.: 0.0008821326352272188 Norm. Diff.: 0.0044122017291616114 tk: 5 x_norm: 21.406944952315758\n",
      "Iteration 2014 - Grad. Norm.: 0.0008818251771419026 Norm. Diff.: 0.0044106631761362935 tk: 5 x_norm: 21.41070223309102\n",
      "Iteration 2015 - Grad. Norm.: 0.000881517971252351 Norm. Diff.: 0.004409125885709471 tk: 5 x_norm: 21.414458181530875\n",
      "Iteration 2016 - Grad. Norm.: 0.000881211017235076 Norm. Diff.: 0.004407589856261786 tk: 5 x_norm: 21.418212798724685\n",
      "Iteration 2017 - Grad. Norm.: 0.0008809043147671676 Norm. Diff.: 0.004406055086175213 tk: 5 x_norm: 21.421966085760406\n",
      "Iteration 2018 - Grad. Norm.: 0.0008805978635262835 Norm. Diff.: 0.004404521573835873 tk: 5 x_norm: 21.42571804372462\n",
      "Iteration 2019 - Grad. Norm.: 0.0008802916631906535 Norm. Diff.: 0.004402989317631549 tk: 5 x_norm: 21.429468673702498\n",
      "Iteration 2020 - Grad. Norm.: 0.0008799857134390758 Norm. Diff.: 0.0044014583159535615 tk: 5 x_norm: 21.43321797677784\n",
      "Iteration 2021 - Grad. Norm.: 0.0008796800139509147 Norm. Diff.: 0.004399928567195354 tk: 5 x_norm: 21.436965954033052\n",
      "Iteration 2022 - Grad. Norm.: 0.0008793745644061047 Norm. Diff.: 0.004398400069754682 tk: 5 x_norm: 21.440712606549155\n",
      "Iteration 2023 - Grad. Norm.: 0.0008790693644851403 Norm. Diff.: 0.004396872822030468 tk: 5 x_norm: 21.444457935405804\n",
      "Iteration 2024 - Grad. Norm.: 0.0008787644138690834 Norm. Diff.: 0.004395346822426009 tk: 5 x_norm: 21.448201941681262\n",
      "Iteration 2025 - Grad. Norm.: 0.0008784597122395567 Norm. Diff.: 0.004393822069345243 tk: 5 x_norm: 21.451944626452423\n",
      "Iteration 2026 - Grad. Norm.: 0.0008781552592787427 Norm. Diff.: 0.004392298561198047 tk: 5 x_norm: 21.4556859907948\n",
      "Iteration 2027 - Grad. Norm.: 0.0008778510546693868 Norm. Diff.: 0.004390776296393865 tk: 5 x_norm: 21.45942603578255\n",
      "Iteration 2028 - Grad. Norm.: 0.0008775470980947896 Norm. Diff.: 0.004389255273346733 tk: 5 x_norm: 21.46316476248845\n",
      "Iteration 2029 - Grad. Norm.: 0.000877243389238811 Norm. Diff.: 0.004387735490473954 tk: 5 x_norm: 21.466902171983907\n",
      "Iteration 2030 - Grad. Norm.: 0.0008769399277858651 Norm. Diff.: 0.0043862169461940026 tk: 5 x_norm: 21.470638265338987\n",
      "Iteration 2031 - Grad. Norm.: 0.0008766367134209216 Norm. Diff.: 0.0043846996389292365 tk: 5 x_norm: 21.474373043622368\n",
      "Iteration 2032 - Grad. Norm.: 0.0008763337458295028 Norm. Diff.: 0.004383183567104602 tk: 5 x_norm: 21.47810650790139\n",
      "Iteration 2033 - Grad. Norm.: 0.0008760310246976837 Norm. Diff.: 0.004381668729147365 tk: 5 x_norm: 21.481838659242015\n",
      "Iteration 2034 - Grad. Norm.: 0.0008757285497120888 Norm. Diff.: 0.00438015512348836 tk: 5 x_norm: 21.48556949870888\n",
      "Iteration 2035 - Grad. Norm.: 0.0008754263205598941 Norm. Diff.: 0.004378642748560665 tk: 5 x_norm: 21.48929902736524\n",
      "Iteration 2036 - Grad. Norm.: 0.0008751243369288208 Norm. Diff.: 0.004377131602799735 tk: 5 x_norm: 21.493027246273027\n",
      "Iteration 2037 - Grad. Norm.: 0.0008748225985071388 Norm. Diff.: 0.0043756216846441405 tk: 5 x_norm: 21.496754156492802\n",
      "Iteration 2038 - Grad. Norm.: 0.0008745211049836648 Norm. Diff.: 0.004374112992535651 tk: 5 x_norm: 21.500479759083795\n",
      "Iteration 2039 - Grad. Norm.: 0.0008742198560477569 Norm. Diff.: 0.004372605524918246 tk: 5 x_norm: 21.504204055103898\n",
      "Iteration 2040 - Grad. Norm.: 0.000873918851389318 Norm. Diff.: 0.004371099280238578 tk: 5 x_norm: 21.507927045609655\n",
      "Iteration 2041 - Grad. Norm.: 0.0008736180906987948 Norm. Diff.: 0.0043695942569464035 tk: 5 x_norm: 21.511648731656273\n",
      "Iteration 2042 - Grad. Norm.: 0.000873317573667169 Norm. Diff.: 0.00436809045349398 tk: 5 x_norm: 21.51536911429762\n",
      "Iteration 2043 - Grad. Norm.: 0.0008730172999859669 Norm. Diff.: 0.004366587868335677 tk: 5 x_norm: 21.519088194586246\n",
      "Iteration 2044 - Grad. Norm.: 0.0008727172693472526 Norm. Diff.: 0.004365086499929998 tk: 5 x_norm: 21.522805973573348\n",
      "Iteration 2045 - Grad. Norm.: 0.0008724174814436237 Norm. Diff.: 0.004363586346736244 tk: 5 x_norm: 21.526522452308814\n",
      "Iteration 2046 - Grad. Norm.: 0.0008721179359682154 Norm. Diff.: 0.004362087407217964 tk: 5 x_norm: 21.5302376318412\n",
      "Iteration 2047 - Grad. Norm.: 0.0008718186326146999 Norm. Diff.: 0.004360589679840904 tk: 5 x_norm: 21.533951513217726\n",
      "Iteration 2048 - Grad. Norm.: 0.0008715195710772767 Norm. Diff.: 0.0043590931630735005 tk: 5 x_norm: 21.537664097484313\n",
      "Iteration 2049 - Grad. Norm.: 0.0008712207510506818 Norm. Diff.: 0.004357597855386462 tk: 5 x_norm: 21.541375385685537\n",
      "Iteration 2050 - Grad. Norm.: 0.000870922172230182 Norm. Diff.: 0.00435610375525336 tk: 5 x_norm: 21.545085378864684\n",
      "Iteration 2051 - Grad. Norm.: 0.0008706238343115711 Norm. Diff.: 0.004354610861151039 tk: 5 x_norm: 21.548794078063708\n",
      "Iteration 2052 - Grad. Norm.: 0.0008703257369911732 Norm. Diff.: 0.004353119171557803 tk: 5 x_norm: 21.552501484323244\n",
      "Iteration 2053 - Grad. Norm.: 0.0008700278799658384 Norm. Diff.: 0.0043516286849559745 tk: 5 x_norm: 21.556207598682636\n",
      "Iteration 2054 - Grad. Norm.: 0.0008697302629329447 Norm. Diff.: 0.004350139399829234 tk: 5 x_norm: 21.559912422179913\n",
      "Iteration 2055 - Grad. Norm.: 0.0008694328855903911 Norm. Diff.: 0.004348651314664618 tk: 5 x_norm: 21.56361595585179\n",
      "Iteration 2056 - Grad. Norm.: 0.0008691357476366032 Norm. Diff.: 0.004347164427951844 tk: 5 x_norm: 21.567318200733684\n",
      "Iteration 2057 - Grad. Norm.: 0.0008688388487705285 Norm. Diff.: 0.004345678738183028 tk: 5 x_norm: 21.57101915785972\n",
      "Iteration 2058 - Grad. Norm.: 0.0008685421886916352 Norm. Diff.: 0.0043441942438528225 tk: 5 x_norm: 21.5747188282627\n",
      "Iteration 2059 - Grad. Norm.: 0.0008682457670999113 Norm. Diff.: 0.004342710943458053 tk: 5 x_norm: 21.578417212974163\n",
      "Iteration 2060 - Grad. Norm.: 0.0008679495836958631 Norm. Diff.: 0.004341228835499748 tk: 5 x_norm: 21.58211431302432\n",
      "Iteration 2061 - Grad. Norm.: 0.000867653638180516 Norm. Diff.: 0.0043397479184792385 tk: 5 x_norm: 21.585810129442116\n",
      "Iteration 2062 - Grad. Norm.: 0.0008673579302554104 Norm. Diff.: 0.004338268190902538 tk: 5 x_norm: 21.58950466325518\n",
      "Iteration 2063 - Grad. Norm.: 0.0008670624596226031 Norm. Diff.: 0.004336789651277016 tk: 5 x_norm: 21.59319791548988\n",
      "Iteration 2064 - Grad. Norm.: 0.0008667672259846632 Norm. Diff.: 0.0043353122981128955 tk: 5 x_norm: 21.596889887171283\n",
      "Iteration 2065 - Grad. Norm.: 0.000866472229044674 Norm. Diff.: 0.004333836129923403 tk: 5 x_norm: 21.60058057932317\n",
      "Iteration 2066 - Grad. Norm.: 0.0008661774685062317 Norm. Diff.: 0.004332361145223498 tk: 5 x_norm: 21.604269992968057\n",
      "Iteration 2067 - Grad. Norm.: 0.000865882944073439 Norm. Diff.: 0.004330887342531148 tk: 5 x_norm: 21.607958129127155\n",
      "Iteration 2068 - Grad. Norm.: 0.0008655886554509131 Norm. Diff.: 0.004329414720367105 tk: 5 x_norm: 21.611644988820423\n",
      "Iteration 2069 - Grad. Norm.: 0.0008652946023437764 Norm. Diff.: 0.004327943277254554 tk: 5 x_norm: 21.615330573066533\n",
      "Iteration 2070 - Grad. Norm.: 0.000865000784457659 Norm. Diff.: 0.004326473011718745 tk: 5 x_norm: 21.619014882882887\n",
      "Iteration 2071 - Grad. Norm.: 0.0008647072014986961 Norm. Diff.: 0.004325003922288459 tk: 5 x_norm: 21.62269791928561\n",
      "Iteration 2072 - Grad. Norm.: 0.0008644138531735299 Norm. Diff.: 0.004323536007493333 tk: 5 x_norm: 21.626379683289574\n",
      "Iteration 2073 - Grad. Norm.: 0.0008641207391893045 Norm. Diff.: 0.004322069265867591 tk: 5 x_norm: 21.63006017590837\n",
      "Iteration 2074 - Grad. Norm.: 0.0008638278592536665 Norm. Diff.: 0.004320603695946446 tk: 5 x_norm: 21.633739398154333\n",
      "Iteration 2075 - Grad. Norm.: 0.0008635352130747646 Norm. Diff.: 0.004319139296268182 tk: 5 x_norm: 21.63741735103853\n",
      "Iteration 2076 - Grad. Norm.: 0.0008632428003612484 Norm. Diff.: 0.004317676065373583 tk: 5 x_norm: 21.641094035570767\n",
      "Iteration 2077 - Grad. Norm.: 0.0008629506208222651 Norm. Diff.: 0.004316214001806167 tk: 5 x_norm: 21.644769452759615\n",
      "Iteration 2078 - Grad. Norm.: 0.0008626586741674606 Norm. Diff.: 0.004314753104111476 tk: 5 x_norm: 21.64844360361236\n",
      "Iteration 2079 - Grad. Norm.: 0.0008623669601069777 Norm. Diff.: 0.0043132933708375605 tk: 5 x_norm: 21.652116489135054\n",
      "Iteration 2080 - Grad. Norm.: 0.0008620754783514543 Norm. Diff.: 0.004311834800534996 tk: 5 x_norm: 21.655788110332484\n",
      "Iteration 2081 - Grad. Norm.: 0.0008617842286120257 Norm. Diff.: 0.004310377391757382 tk: 5 x_norm: 21.659458468208197\n",
      "Iteration 2082 - Grad. Norm.: 0.0008614932106003172 Norm. Diff.: 0.004308921143060246 tk: 5 x_norm: 21.663127563764498\n",
      "Iteration 2083 - Grad. Norm.: 0.0008612024240284485 Norm. Diff.: 0.004307466053001416 tk: 5 x_norm: 21.666795398002428\n",
      "Iteration 2084 - Grad. Norm.: 0.0008609118686090287 Norm. Diff.: 0.004306012120142096 tk: 5 x_norm: 21.670461971921803\n",
      "Iteration 2085 - Grad. Norm.: 0.0008606215440551608 Norm. Diff.: 0.00430455934304512 tk: 5 x_norm: 21.674127286521205\n",
      "Iteration 2086 - Grad. Norm.: 0.000860331450080433 Norm. Diff.: 0.004303107720275967 tk: 5 x_norm: 21.677791342797953\n",
      "Iteration 2087 - Grad. Norm.: 0.0008600415863989242 Norm. Diff.: 0.004301657250401818 tk: 5 x_norm: 21.681454141748144\n",
      "Iteration 2088 - Grad. Norm.: 0.000859751952725199 Norm. Diff.: 0.0043002079319944715 tk: 5 x_norm: 21.68511568436664\n",
      "Iteration 2089 - Grad. Norm.: 0.0008594625487743082 Norm. Diff.: 0.004298759763625857 tk: 5 x_norm: 21.688775971647072\n",
      "Iteration 2090 - Grad. Norm.: 0.0008591733742617866 Norm. Diff.: 0.004297312743871406 tk: 5 x_norm: 21.692435004581842\n",
      "Iteration 2091 - Grad. Norm.: 0.0008588844289036544 Norm. Diff.: 0.0042958668713087575 tk: 5 x_norm: 21.69609278416212\n",
      "Iteration 2092 - Grad. Norm.: 0.0008585957124164122 Norm. Diff.: 0.004294422144518295 tk: 5 x_norm: 21.699749311377847\n",
      "Iteration 2093 - Grad. Norm.: 0.0008583072245170444 Norm. Diff.: 0.00429297856208201 tk: 5 x_norm: 21.703404587217744\n",
      "Iteration 2094 - Grad. Norm.: 0.0008580189649230137 Norm. Diff.: 0.00429153612258537 tk: 5 x_norm: 21.707058612669314\n",
      "Iteration 2095 - Grad. Norm.: 0.0008577309333522632 Norm. Diff.: 0.004290094824615036 tk: 5 x_norm: 21.710711388718842\n",
      "Iteration 2096 - Grad. Norm.: 0.0008574431295232151 Norm. Diff.: 0.004288654666761426 tk: 5 x_norm: 21.714362916351387\n",
      "Iteration 2097 - Grad. Norm.: 0.0008571555531547673 Norm. Diff.: 0.004287215647616152 tk: 5 x_norm: 21.718013196550793\n",
      "Iteration 2098 - Grad. Norm.: 0.0008568682039662945 Norm. Diff.: 0.004285777765773729 tk: 5 x_norm: 21.721662230299692\n",
      "Iteration 2099 - Grad. Norm.: 0.000856581081677646 Norm. Diff.: 0.004284341019831303 tk: 5 x_norm: 21.725310018579513\n",
      "Iteration 2100 - Grad. Norm.: 0.0008562941860091479 Norm. Diff.: 0.004282905408388474 tk: 5 x_norm: 21.728956562370467\n",
      "Iteration 2101 - Grad. Norm.: 0.0008560075166815947 Norm. Diff.: 0.004281470930045974 tk: 5 x_norm: 21.732601862651546\n",
      "Iteration 2102 - Grad. Norm.: 0.0008557210734162559 Norm. Diff.: 0.0042800375834081495 tk: 5 x_norm: 21.736245920400567\n",
      "Iteration 2103 - Grad. Norm.: 0.0008554348559348719 Norm. Diff.: 0.004278605367081603 tk: 5 x_norm: 21.739888736594114\n",
      "Iteration 2104 - Grad. Norm.: 0.0008551488639596508 Norm. Diff.: 0.004277174279674276 tk: 5 x_norm: 21.743530312207593\n",
      "Iteration 2105 - Grad. Norm.: 0.000854863097213273 Norm. Diff.: 0.004275744319798348 tk: 5 x_norm: 21.74717064821519\n",
      "Iteration 2106 - Grad. Norm.: 0.0008545775554188833 Norm. Diff.: 0.0042743154860663424 tk: 5 x_norm: 21.750809745589905\n",
      "Iteration 2107 - Grad. Norm.: 0.0008542922383000937 Norm. Diff.: 0.004272887777094384 tk: 5 x_norm: 21.754447605303543\n",
      "Iteration 2108 - Grad. Norm.: 0.0008540071455809857 Norm. Diff.: 0.004271461191500232 tk: 5 x_norm: 21.758084228326716\n",
      "Iteration 2109 - Grad. Norm.: 0.0008537222769860991 Norm. Diff.: 0.004270035727905094 tk: 5 x_norm: 21.761719615628834\n",
      "Iteration 2110 - Grad. Norm.: 0.0008534376322404427 Norm. Diff.: 0.004268611384930478 tk: 5 x_norm: 21.765353768178137\n",
      "Iteration 2111 - Grad. Norm.: 0.0008531532110694857 Norm. Diff.: 0.00426718816120224 tk: 5 x_norm: 21.768986686941656\n",
      "Iteration 2112 - Grad. Norm.: 0.0008528690131991597 Norm. Diff.: 0.004265766055347638 tk: 5 x_norm: 21.772618372885255\n",
      "Iteration 2113 - Grad. Norm.: 0.0008525850383558551 Norm. Diff.: 0.004264345065995893 tk: 5 x_norm: 21.776248826973607\n",
      "Iteration 2114 - Grad. Norm.: 0.0008523012862664245 Norm. Diff.: 0.004262925191779295 tk: 5 x_norm: 21.779878050170193\n",
      "Iteration 2115 - Grad. Norm.: 0.0008520177566581757 Norm. Diff.: 0.004261506431332039 tk: 5 x_norm: 21.78350604343734\n",
      "Iteration 2116 - Grad. Norm.: 0.0008517344492588775 Norm. Diff.: 0.004260088783291185 tk: 5 x_norm: 21.787132807736175\n",
      "Iteration 2117 - Grad. Norm.: 0.000851451363796753 Norm. Diff.: 0.004258672246294301 tk: 5 x_norm: 21.79075834402666\n",
      "Iteration 2118 - Grad. Norm.: 0.0008511685000004817 Norm. Diff.: 0.004257256818983799 tk: 5 x_norm: 21.794382653267576\n",
      "Iteration 2119 - Grad. Norm.: 0.0008508858575991975 Norm. Diff.: 0.0042558425000024745 tk: 5 x_norm: 21.798005736416545\n",
      "Iteration 2120 - Grad. Norm.: 0.0008506034363224875 Norm. Diff.: 0.004254429287996046 tk: 5 x_norm: 21.801627594430002\n",
      "Iteration 2121 - Grad. Norm.: 0.0008503212359003918 Norm. Diff.: 0.00425301718161233 tk: 5 x_norm: 21.805248228263235\n",
      "Iteration 2122 - Grad. Norm.: 0.0008500392560634008 Norm. Diff.: 0.004251606179501979 tk: 5 x_norm: 21.808867638870346\n",
      "Iteration 2123 - Grad. Norm.: 0.0008497574965424579 Norm. Diff.: 0.004250196280317065 tk: 5 x_norm: 21.812485827204288\n",
      "Iteration 2124 - Grad. Norm.: 0.000849475957068953 Norm. Diff.: 0.0042487874827121675 tk: 5 x_norm: 21.816102794216846\n",
      "Iteration 2125 - Grad. Norm.: 0.0008491946373747272 Norm. Diff.: 0.0042473797853447015 tk: 5 x_norm: 21.81971854085865\n",
      "Iteration 2126 - Grad. Norm.: 0.000848913537192068 Norm. Diff.: 0.0042459731868736625 tk: 5 x_norm: 21.823333068079158\n",
      "Iteration 2127 - Grad. Norm.: 0.0008486326562537084 Norm. Diff.: 0.004244567685960422 tk: 5 x_norm: 21.826946376826694\n",
      "Iteration 2128 - Grad. Norm.: 0.0008483519942928284 Norm. Diff.: 0.0042431632812684455 tk: 5 x_norm: 21.8305584680484\n",
      "Iteration 2129 - Grad. Norm.: 0.0008480715510430516 Norm. Diff.: 0.004241759971464255 tk: 5 x_norm: 21.834169342690306\n",
      "Iteration 2130 - Grad. Norm.: 0.0008477913262384496 Norm. Diff.: 0.004240357755215216 tk: 5 x_norm: 21.837779001697246\n",
      "Iteration 2131 - Grad. Norm.: 0.0008475113196135288 Norm. Diff.: 0.0042389566311921405 tk: 5 x_norm: 21.841387446012934\n",
      "Iteration 2132 - Grad. Norm.: 0.0008472315309032447 Norm. Diff.: 0.004237556598067543 tk: 5 x_norm: 21.844994676579933\n",
      "Iteration 2133 - Grad. Norm.: 0.0008469519598429875 Norm. Diff.: 0.004236157654516232 tk: 5 x_norm: 21.848600694339655\n",
      "Iteration 2134 - Grad. Norm.: 0.0008466726061685938 Norm. Diff.: 0.004234759799214865 tk: 5 x_norm: 21.85220550023238\n",
      "Iteration 2135 - Grad. Norm.: 0.000846393469616333 Norm. Diff.: 0.0042333630308427714 tk: 5 x_norm: 21.855809095197234\n",
      "Iteration 2136 - Grad. Norm.: 0.0008461145499229145 Norm. Diff.: 0.0042319673480815485 tk: 5 x_norm: 21.859411480172216\n",
      "Iteration 2137 - Grad. Norm.: 0.0008458358468254862 Norm. Diff.: 0.004230572749614642 tk: 5 x_norm: 21.863012656094178\n",
      "Iteration 2138 - Grad. Norm.: 0.0008455573600616312 Norm. Diff.: 0.004229179234127602 tk: 5 x_norm: 21.86661262389885\n",
      "Iteration 2139 - Grad. Norm.: 0.0008452790893693651 Norm. Diff.: 0.004227786800308337 tk: 5 x_norm: 21.870211384520807\n",
      "Iteration 2140 - Grad. Norm.: 0.0008450010344871413 Norm. Diff.: 0.004226395446846634 tk: 5 x_norm: 21.873808938893518\n",
      "Iteration 2141 - Grad. Norm.: 0.0008447231951538441 Norm. Diff.: 0.004225005172435801 tk: 5 x_norm: 21.877405287949305\n",
      "Iteration 2142 - Grad. Norm.: 0.0008444455711087903 Norm. Diff.: 0.00422361597576935 tk: 5 x_norm: 21.88100043261937\n",
      "Iteration 2143 - Grad. Norm.: 0.0008441681620917293 Norm. Diff.: 0.004222227855543795 tk: 5 x_norm: 21.884594373833785\n",
      "Iteration 2144 - Grad. Norm.: 0.0008438909678428396 Norm. Diff.: 0.004220840810458872 tk: 5 x_norm: 21.888187112521504\n",
      "Iteration 2145 - Grad. Norm.: 0.0008436139881027275 Norm. Diff.: 0.0042194548392140915 tk: 5 x_norm: 21.891778649610355\n",
      "Iteration 2146 - Grad. Norm.: 0.0008433372226124318 Norm. Diff.: 0.0042180699405137585 tk: 5 x_norm: 21.895368986027044\n",
      "Iteration 2147 - Grad. Norm.: 0.0008430606711134154 Norm. Diff.: 0.004216686113062154 tk: 5 x_norm: 21.89895812269716\n",
      "Iteration 2148 - Grad. Norm.: 0.0008427843333475679 Norm. Diff.: 0.004215303355567097 tk: 5 x_norm: 21.902546060545173\n",
      "Iteration 2149 - Grad. Norm.: 0.0008425082090572076 Norm. Diff.: 0.004213921666738005 tk: 5 x_norm: 21.90613280049445\n",
      "Iteration 2150 - Grad. Norm.: 0.000842232297985075 Norm. Diff.: 0.004212541045286114 tk: 5 x_norm: 21.909718343467233\n",
      "Iteration 2151 - Grad. Norm.: 0.0008419565998743346 Norm. Diff.: 0.004211161489925649 tk: 5 x_norm: 21.913302690384654\n",
      "Iteration 2152 - Grad. Norm.: 0.0008416811144685744 Norm. Diff.: 0.004209782999371806 tk: 5 x_norm: 21.916885842166742\n",
      "Iteration 2153 - Grad. Norm.: 0.0008414058415118054 Norm. Diff.: 0.004208405572342878 tk: 5 x_norm: 21.92046779973241\n",
      "Iteration 2154 - Grad. Norm.: 0.0008411307807484564 Norm. Diff.: 0.004207029207559041 tk: 5 x_norm: 21.924048563999477\n",
      "Iteration 2155 - Grad. Norm.: 0.0008408559319233812 Norm. Diff.: 0.004205653903742281 tk: 5 x_norm: 21.927628135884646\n",
      "Iteration 2156 - Grad. Norm.: 0.0008405812947818476 Norm. Diff.: 0.0042042796596167996 tk: 5 x_norm: 21.93120651630353\n",
      "Iteration 2157 - Grad. Norm.: 0.0008403068690695474 Norm. Diff.: 0.004202906473909075 tk: 5 x_norm: 21.934783706170624\n",
      "Iteration 2158 - Grad. Norm.: 0.0008400326545325849 Norm. Diff.: 0.004201534345347588 tk: 5 x_norm: 21.938359706399346\n",
      "Iteration 2159 - Grad. Norm.: 0.0008397586509174841 Norm. Diff.: 0.0042001632726626865 tk: 5 x_norm: 21.941934517902006\n",
      "Iteration 2160 - Grad. Norm.: 0.000839484857971183 Norm. Diff.: 0.004198793254587527 tk: 5 x_norm: 21.945508141589823\n",
      "Iteration 2161 - Grad. Norm.: 0.0008392112754410354 Norm. Diff.: 0.004197424289856112 tk: 5 x_norm: 21.949080578372914\n",
      "Iteration 2162 - Grad. Norm.: 0.0008389379030748088 Norm. Diff.: 0.0041960563772051535 tk: 5 x_norm: 21.952651829160317\n",
      "Iteration 2163 - Grad. Norm.: 0.0008386647406206837 Norm. Diff.: 0.004194689515374295 tk: 5 x_norm: 21.956221894859976\n",
      "Iteration 2164 - Grad. Norm.: 0.0008383917878272527 Norm. Diff.: 0.004193323703103288 tk: 5 x_norm: 21.959790776378753\n",
      "Iteration 2165 - Grad. Norm.: 0.0008381190444435184 Norm. Diff.: 0.004191958939136482 tk: 5 x_norm: 21.963358474622403\n",
      "Iteration 2166 - Grad. Norm.: 0.0008378465102188967 Norm. Diff.: 0.004190595222217492 tk: 5 x_norm: 21.96692499049562\n",
      "Iteration 2167 - Grad. Norm.: 0.0008375741849032107 Norm. Diff.: 0.00418923255109445 tk: 5 x_norm: 21.970490324902006\n",
      "Iteration 2168 - Grad. Norm.: 0.0008373020682466929 Norm. Diff.: 0.004187870924516086 tk: 5 x_norm: 21.97405447874409\n",
      "Iteration 2169 - Grad. Norm.: 0.0008370301599999841 Norm. Diff.: 0.0041865103412333845 tk: 5 x_norm: 21.977617452923308\n",
      "Iteration 2170 - Grad. Norm.: 0.0008367584599141286 Norm. Diff.: 0.004185150799999717 tk: 5 x_norm: 21.981179248340037\n",
      "Iteration 2171 - Grad. Norm.: 0.0008364869677405821 Norm. Diff.: 0.0041837922995707506 tk: 5 x_norm: 21.98473986589356\n",
      "Iteration 2172 - Grad. Norm.: 0.0008362156832312012 Norm. Diff.: 0.00418243483870287 tk: 5 x_norm: 21.9882993064821\n",
      "Iteration 2173 - Grad. Norm.: 0.0008359446061382488 Norm. Diff.: 0.0041810784161561065 tk: 5 x_norm: 21.991857571002807\n",
      "Iteration 2174 - Grad. Norm.: 0.0008356737362143916 Norm. Diff.: 0.0041797230306912575 tk: 5 x_norm: 21.995414660351752\n",
      "Iteration 2175 - Grad. Norm.: 0.0008354030732126959 Norm. Diff.: 0.004178368681071925 tk: 5 x_norm: 21.99897057542395\n",
      "Iteration 2176 - Grad. Norm.: 0.0008351326168866326 Norm. Diff.: 0.004177015366063633 tk: 5 x_norm: 22.002525317113342\n",
      "Iteration 2177 - Grad. Norm.: 0.0008348623669900728 Norm. Diff.: 0.004175663084433341 tk: 5 x_norm: 22.0060788863128\n",
      "Iteration 2178 - Grad. Norm.: 0.0008345923232772876 Norm. Diff.: 0.004174311834950342 tk: 5 x_norm: 22.009631283914143\n",
      "Iteration 2179 - Grad. Norm.: 0.0008343224855029466 Norm. Diff.: 0.004172961616386486 tk: 5 x_norm: 22.01318251080812\n",
      "Iteration 2180 - Grad. Norm.: 0.000834052853422118 Norm. Diff.: 0.004171612427514948 tk: 5 x_norm: 22.016732567884436\n",
      "Iteration 2181 - Grad. Norm.: 0.0008337834267902677 Norm. Diff.: 0.004170264267110488 tk: 5 x_norm: 22.02028145603171\n",
      "Iteration 2182 - Grad. Norm.: 0.000833514205363259 Norm. Diff.: 0.004168917133951418 tk: 5 x_norm: 22.023829176137532\n",
      "Iteration 2183 - Grad. Norm.: 0.0008332451888973472 Norm. Diff.: 0.004167571026816342 tk: 5 x_norm: 22.027375729088423\n",
      "Iteration 2184 - Grad. Norm.: 0.0008329763771491877 Norm. Diff.: 0.004166225944486795 tk: 5 x_norm: 22.030921115769864\n",
      "Iteration 2185 - Grad. Norm.: 0.0008327077698758277 Norm. Diff.: 0.004164881885745918 tk: 5 x_norm: 22.034465337066266\n",
      "Iteration 2186 - Grad. Norm.: 0.0008324393668347063 Norm. Diff.: 0.004163538849379142 tk: 5 x_norm: 22.038008393861\n",
      "Iteration 2187 - Grad. Norm.: 0.0008321711677836561 Norm. Diff.: 0.004162196834173623 tk: 5 x_norm: 22.041550287036397\n",
      "Iteration 2188 - Grad. Norm.: 0.0008319031724809018 Norm. Diff.: 0.004160855838918169 tk: 5 x_norm: 22.04509101747373\n",
      "Iteration 2189 - Grad. Norm.: 0.0008316353806850597 Norm. Diff.: 0.004159515862404321 tk: 5 x_norm: 22.04863058605324\n",
      "Iteration 2190 - Grad. Norm.: 0.0008313677921551335 Norm. Diff.: 0.00415817690342495 tk: 5 x_norm: 22.052168993654103\n",
      "Iteration 2191 - Grad. Norm.: 0.0008311004066505172 Norm. Diff.: 0.0041568389607756625 tk: 5 x_norm: 22.05570624115449\n",
      "Iteration 2192 - Grad. Norm.: 0.0008308332239309942 Norm. Diff.: 0.004155502033252546 tk: 5 x_norm: 22.059242329431495\n",
      "Iteration 2193 - Grad. Norm.: 0.0008305662437567335 Norm. Diff.: 0.004154166119654805 tk: 5 x_norm: 22.0627772593612\n",
      "Iteration 2194 - Grad. Norm.: 0.0008302994658882913 Norm. Diff.: 0.004152831218783655 tk: 5 x_norm: 22.066311031818643\n",
      "Iteration 2195 - Grad. Norm.: 0.0008300328900866113 Norm. Diff.: 0.004151497329441519 tk: 5 x_norm: 22.069843647677825\n",
      "Iteration 2196 - Grad. Norm.: 0.0008297665161130192 Norm. Diff.: 0.004150164450433268 tk: 5 x_norm: 22.073375107811717\n",
      "Iteration 2197 - Grad. Norm.: 0.0008295003437292283 Norm. Diff.: 0.004148832580565084 tk: 5 x_norm: 22.076905413092263\n",
      "Iteration 2198 - Grad. Norm.: 0.0008292343726973322 Norm. Diff.: 0.004147501718646419 tk: 5 x_norm: 22.08043456439037\n",
      "Iteration 2199 - Grad. Norm.: 0.0008289686027798084 Norm. Diff.: 0.004146171863486882 tk: 5 x_norm: 22.08396256257592\n",
      "Iteration 2200 - Grad. Norm.: 0.0008287030337395176 Norm. Diff.: 0.0041448430138990725 tk: 5 x_norm: 22.08748940851777\n",
      "Iteration 2201 - Grad. Norm.: 0.0008284376653396997 Norm. Diff.: 0.004143515168697485 tk: 5 x_norm: 22.09101510308376\n",
      "Iteration 2202 - Grad. Norm.: 0.000828172497343974 Norm. Diff.: 0.004142188326698528 tk: 5 x_norm: 22.09453964714069\n",
      "Iteration 2203 - Grad. Norm.: 0.000827907529516343 Norm. Diff.: 0.004140862486719786 tk: 5 x_norm: 22.09806304155436\n",
      "Iteration 2204 - Grad. Norm.: 0.0008276427616211821 Norm. Diff.: 0.004139537647581823 tk: 5 x_norm: 22.101585287189536\n",
      "Iteration 2205 - Grad. Norm.: 0.0008273781934232492 Norm. Diff.: 0.004138213808106176 tk: 5 x_norm: 22.105106384909966\n",
      "Iteration 2206 - Grad. Norm.: 0.0008271138246876793 Norm. Diff.: 0.004136890967116421 tk: 5 x_norm: 22.108626335578396\n",
      "Iteration 2207 - Grad. Norm.: 0.0008268496551799784 Norm. Diff.: 0.004135569123438362 tk: 5 x_norm: 22.11214514005654\n",
      "Iteration 2208 - Grad. Norm.: 0.0008265856846660348 Norm. Diff.: 0.004134248275899872 tk: 5 x_norm: 22.115662799205108\n",
      "Iteration 2209 - Grad. Norm.: 0.0008263219129121063 Norm. Diff.: 0.0041329284233300794 tk: 5 x_norm: 22.1191793138838\n",
      "Iteration 2210 - Grad. Norm.: 0.0008260583396848281 Norm. Diff.: 0.004131609564560561 tk: 5 x_norm: 22.122694684951306\n",
      "Iteration 2211 - Grad. Norm.: 0.0008257949647512038 Norm. Diff.: 0.004130291698423888 tk: 5 x_norm: 22.126208913265305\n",
      "Iteration 2212 - Grad. Norm.: 0.0008255317878786159 Norm. Diff.: 0.004128974823755869 tk: 5 x_norm: 22.129721999682467\n",
      "Iteration 2213 - Grad. Norm.: 0.0008252688088348129 Norm. Diff.: 0.004127658939393184 tk: 5 x_norm: 22.133233945058468\n",
      "Iteration 2214 - Grad. Norm.: 0.000825006027387917 Norm. Diff.: 0.004126344044174076 tk: 5 x_norm: 22.136744750247967\n",
      "Iteration 2215 - Grad. Norm.: 0.0008247434433064181 Norm. Diff.: 0.0041250301369396575 tk: 5 x_norm: 22.14025441610463\n",
      "Iteration 2216 - Grad. Norm.: 0.0008244810563591779 Norm. Diff.: 0.00412371721653217 tk: 5 x_norm: 22.14376294348113\n",
      "Iteration 2217 - Grad. Norm.: 0.0008242188663154251 Norm. Diff.: 0.004122405281796075 tk: 5 x_norm: 22.14727033322912\n",
      "Iteration 2218 - Grad. Norm.: 0.0008239568729447553 Norm. Diff.: 0.004121094331577405 tk: 5 x_norm: 22.150776586199285\n",
      "Iteration 2219 - Grad. Norm.: 0.0008236950760171336 Norm. Diff.: 0.004119784364724016 tk: 5 x_norm: 22.154281703241285\n",
      "Iteration 2220 - Grad. Norm.: 0.0008234334753028886 Norm. Diff.: 0.004118475380085652 tk: 5 x_norm: 22.157785685203812\n",
      "Iteration 2221 - Grad. Norm.: 0.0008231720705727159 Norm. Diff.: 0.004117167376514515 tk: 5 x_norm: 22.161288532934545\n",
      "Iteration 2222 - Grad. Norm.: 0.0008229108615976744 Norm. Diff.: 0.004115860352863622 tk: 5 x_norm: 22.16479024728019\n",
      "Iteration 2223 - Grad. Norm.: 0.0008226498481491883 Norm. Diff.: 0.004114554307988481 tk: 5 x_norm: 22.16829082908645\n",
      "Iteration 2224 - Grad. Norm.: 0.0008223890299990448 Norm. Diff.: 0.004113249240746054 tk: 5 x_norm: 22.171790279198056\n",
      "Iteration 2225 - Grad. Norm.: 0.000822128406919392 Norm. Diff.: 0.004111945149995243 tk: 5 x_norm: 22.175288598458742\n",
      "Iteration 2226 - Grad. Norm.: 0.0008218679786827412 Norm. Diff.: 0.004110642034596894 tk: 5 x_norm: 22.178785787711256\n",
      "Iteration 2227 - Grad. Norm.: 0.0008216077450619634 Norm. Diff.: 0.004109339893413722 tk: 5 x_norm: 22.182281847797363\n",
      "Iteration 2228 - Grad. Norm.: 0.0008213477058302911 Norm. Diff.: 0.004108038725309621 tk: 5 x_norm: 22.185776779557866\n",
      "Iteration 2229 - Grad. Norm.: 0.0008210878607613151 Norm. Diff.: 0.004106738529151395 tk: 5 x_norm: 22.189270583832563\n",
      "Iteration 2230 - Grad. Norm.: 0.000820828209628985 Norm. Diff.: 0.004105439303806641 tk: 5 x_norm: 22.192763261460293\n",
      "Iteration 2231 - Grad. Norm.: 0.0008205687522076083 Norm. Diff.: 0.004104141048144996 tk: 5 x_norm: 22.196254813278905\n",
      "Iteration 2232 - Grad. Norm.: 0.0008203094882718499 Norm. Diff.: 0.004102843761038099 tk: 5 x_norm: 22.199745240125285\n",
      "Iteration 2233 - Grad. Norm.: 0.0008200504175967308 Norm. Diff.: 0.004101547441359337 tk: 5 x_norm: 22.20323454283534\n",
      "Iteration 2234 - Grad. Norm.: 0.0008197915399576289 Norm. Diff.: 0.004100252087983517 tk: 5 x_norm: 22.206722722243995\n",
      "Iteration 2235 - Grad. Norm.: 0.0008195328551302754 Norm. Diff.: 0.004098957699788146 tk: 5 x_norm: 22.21020977918523\n",
      "Iteration 2236 - Grad. Norm.: 0.0008192743628907568 Norm. Diff.: 0.004097664275651349 tk: 5 x_norm: 22.21369571449203\n",
      "Iteration 2237 - Grad. Norm.: 0.000819016063015512 Norm. Diff.: 0.004096371814453799 tk: 5 x_norm: 22.217180528996437\n",
      "Iteration 2238 - Grad. Norm.: 0.0008187579552813341 Norm. Diff.: 0.004095080315077633 tk: 5 x_norm: 22.220664223529496\n",
      "Iteration 2239 - Grad. Norm.: 0.0008185000394653672 Norm. Diff.: 0.004093789776406733 tk: 5 x_norm: 22.22414679892132\n",
      "Iteration 2240 - Grad. Norm.: 0.0008182423153451065 Norm. Diff.: 0.004092500197326679 tk: 5 x_norm: 22.22762825600105\n",
      "Iteration 2241 - Grad. Norm.: 0.0008179847826984 Norm. Diff.: 0.004091211576725746 tk: 5 x_norm: 22.231108595596854\n",
      "Iteration 2242 - Grad. Norm.: 0.0008177274413034417 Norm. Diff.: 0.004089923913492226 tk: 5 x_norm: 22.234587818535953\n",
      "Iteration 2243 - Grad. Norm.: 0.0008174702909387784 Norm. Diff.: 0.004088637206516979 tk: 5 x_norm: 22.2380659256446\n",
      "Iteration 2244 - Grad. Norm.: 0.0008172133313833051 Norm. Diff.: 0.004087351454693769 tk: 5 x_norm: 22.241542917748102\n",
      "Iteration 2245 - Grad. Norm.: 0.0008169565624162615 Norm. Diff.: 0.00408606665691652 tk: 5 x_norm: 22.24501879567081\n",
      "Iteration 2246 - Grad. Norm.: 0.0008166999838172368 Norm. Diff.: 0.00408478281208129 tk: 5 x_norm: 22.248493560236106\n",
      "Iteration 2247 - Grad. Norm.: 0.0008164435953661653 Norm. Diff.: 0.004083499919086452 tk: 5 x_norm: 22.251967212266443\n",
      "Iteration 2248 - Grad. Norm.: 0.0008161873968433296 Norm. Diff.: 0.004082217976830939 tk: 5 x_norm: 22.25543975258331\n",
      "Iteration 2249 - Grad. Norm.: 0.0008159313880293527 Norm. Diff.: 0.004080936984216695 tk: 5 x_norm: 22.258911182007253\n",
      "Iteration 2250 - Grad. Norm.: 0.0008156755687052058 Norm. Diff.: 0.004079656940146978 tk: 5 x_norm: 22.262381501357854\n",
      "Iteration 2251 - Grad. Norm.: 0.0008154199386522021 Norm. Diff.: 0.004078377843525789 tk: 5 x_norm: 22.265850711453773\n",
      "Iteration 2252 - Grad. Norm.: 0.0008151644976519969 Norm. Diff.: 0.0040770996932609615 tk: 5 x_norm: 22.269318813112715\n",
      "Iteration 2253 - Grad. Norm.: 0.0008149092454865881 Norm. Diff.: 0.004075822488259705 tk: 5 x_norm: 22.272785807151433\n",
      "Iteration 2254 - Grad. Norm.: 0.0008146541819383152 Norm. Diff.: 0.00407454622743293 tk: 5 x_norm: 22.276251694385756\n",
      "Iteration 2255 - Grad. Norm.: 0.0008143993067898585 Norm. Diff.: 0.004073270909691549 tk: 5 x_norm: 22.279716475630558\n",
      "Iteration 2256 - Grad. Norm.: 0.0008141446198242385 Norm. Diff.: 0.004071996533949468 tk: 5 x_norm: 22.283180151699785\n",
      "Iteration 2257 - Grad. Norm.: 0.0008138901208248142 Norm. Diff.: 0.004070723099121072 tk: 5 x_norm: 22.286642723406434\n",
      "Iteration 2258 - Grad. Norm.: 0.0008136358095752837 Norm. Diff.: 0.0040694506041239874 tk: 5 x_norm: 22.29010419156258\n",
      "Iteration 2259 - Grad. Norm.: 0.0008133816858596837 Norm. Diff.: 0.004068179047876218 tk: 5 x_norm: 22.29356455697936\n",
      "Iteration 2260 - Grad. Norm.: 0.0008131277494623861 Norm. Diff.: 0.004066908429298557 tk: 5 x_norm: 22.297023820466965\n",
      "Iteration 2261 - Grad. Norm.: 0.0008128740001681019 Norm. Diff.: 0.004065638747311846 tk: 5 x_norm: 22.300481982834675\n",
      "Iteration 2262 - Grad. Norm.: 0.0008126204377618768 Norm. Diff.: 0.0040643700008404175 tk: 5 x_norm: 22.30393904489083\n",
      "Iteration 2263 - Grad. Norm.: 0.0008123670620290897 Norm. Diff.: 0.004063102188809222 tk: 5 x_norm: 22.30739500744283\n",
      "Iteration 2264 - Grad. Norm.: 0.0008121138727554584 Norm. Diff.: 0.004061835310145393 tk: 5 x_norm: 22.310849871297183\n",
      "Iteration 2265 - Grad. Norm.: 0.0008118608697270316 Norm. Diff.: 0.004060569363777062 tk: 5 x_norm: 22.31430363725942\n",
      "Iteration 2266 - Grad. Norm.: 0.0008116080527301913 Norm. Diff.: 0.004059304348635027 tk: 5 x_norm: 22.317756306134207\n",
      "Iteration 2267 - Grad. Norm.: 0.000811355421551653 Norm. Diff.: 0.00405804026365093 tk: 5 x_norm: 22.321207878725236\n",
      "Iteration 2268 - Grad. Norm.: 0.0008111029759784615 Norm. Diff.: 0.0040567771077582885 tk: 5 x_norm: 22.324658355835304\n",
      "Iteration 2269 - Grad. Norm.: 0.0008108507157979978 Norm. Diff.: 0.004055514879892153 tk: 5 x_norm: 22.328107738266283\n",
      "Iteration 2270 - Grad. Norm.: 0.0008105986407979682 Norm. Diff.: 0.004054253578989818 tk: 5 x_norm: 22.331556026819133\n",
      "Iteration 2271 - Grad. Norm.: 0.0008103467507664116 Norm. Diff.: 0.004052993203989572 tk: 5 x_norm: 22.33500322229389\n",
      "Iteration 2272 - Grad. Norm.: 0.0008100950454916948 Norm. Diff.: 0.004051733753832173 tk: 5 x_norm: 22.33844932548967\n",
      "Iteration 2273 - Grad. Norm.: 0.0008098435247625142 Norm. Diff.: 0.004050475227458594 tk: 5 x_norm: 22.341894337204682\n",
      "Iteration 2274 - Grad. Norm.: 0.0008095921883678936 Norm. Diff.: 0.0040492176238126855 tk: 5 x_norm: 22.345338258236236\n",
      "Iteration 2275 - Grad. Norm.: 0.0008093410360971826 Norm. Diff.: 0.004047960941839361 tk: 5 x_norm: 22.34878108938069\n",
      "Iteration 2276 - Grad. Norm.: 0.000809090067740059 Norm. Diff.: 0.004046705180485876 tk: 5 x_norm: 22.35222283143354\n",
      "Iteration 2277 - Grad. Norm.: 0.0008088392830865273 Norm. Diff.: 0.0040454503387005215 tk: 5 x_norm: 22.355663485189346\n",
      "Iteration 2278 - Grad. Norm.: 0.0008085886819269145 Norm. Diff.: 0.004044196415432709 tk: 5 x_norm: 22.359103051441767\n",
      "Iteration 2279 - Grad. Norm.: 0.0008083382640518739 Norm. Diff.: 0.004042943409634347 tk: 5 x_norm: 22.362541530983556\n",
      "Iteration 2280 - Grad. Norm.: 0.0008080880292523813 Norm. Diff.: 0.0040416913202592115 tk: 5 x_norm: 22.36597892460656\n",
      "Iteration 2281 - Grad. Norm.: 0.0008078379773197377 Norm. Diff.: 0.004040440146261945 tk: 5 x_norm: 22.369415233101734\n",
      "Iteration 2282 - Grad. Norm.: 0.0008075881080455657 Norm. Diff.: 0.004039189886598598 tk: 5 x_norm: 22.372850457259112\n",
      "Iteration 2283 - Grad. Norm.: 0.0008073384212218092 Norm. Diff.: 0.004037940540227876 tk: 5 x_norm: 22.37628459786785\n",
      "Iteration 2284 - Grad. Norm.: 0.0008070889166407351 Norm. Diff.: 0.004036692106109209 tk: 5 x_norm: 22.3797176557162\n",
      "Iteration 2285 - Grad. Norm.: 0.0008068395940949291 Norm. Diff.: 0.0040354445832034595 tk: 5 x_norm: 22.383149631591508\n",
      "Iteration 2286 - Grad. Norm.: 0.0008065904533772976 Norm. Diff.: 0.004034197970474664 tk: 5 x_norm: 22.386580526280213\n",
      "Iteration 2287 - Grad. Norm.: 0.0008063414942810665 Norm. Diff.: 0.004032952266886405 tk: 5 x_norm: 22.390010340567898\n",
      "Iteration 2288 - Grad. Norm.: 0.0008060927165997797 Norm. Diff.: 0.004031707471405301 tk: 5 x_norm: 22.39343907523922\n",
      "Iteration 2289 - Grad. Norm.: 0.0008058441201273016 Norm. Diff.: 0.004030463582998927 tk: 5 x_norm: 22.39686673107795\n",
      "Iteration 2290 - Grad. Norm.: 0.0008055957046578105 Norm. Diff.: 0.004029220600636476 tk: 5 x_norm: 22.400293308866985\n",
      "Iteration 2291 - Grad. Norm.: 0.0008053474699858037 Norm. Diff.: 0.004027978523288992 tk: 5 x_norm: 22.403718809388312\n",
      "Iteration 2292 - Grad. Norm.: 0.0008050994159060955 Norm. Diff.: 0.004026737349929103 tk: 5 x_norm: 22.40714323342305\n",
      "Iteration 2293 - Grad. Norm.: 0.0008048515422138138 Norm. Diff.: 0.004025497079530591 tk: 5 x_norm: 22.410566581751418\n",
      "Iteration 2294 - Grad. Norm.: 0.0008046038487044014 Norm. Diff.: 0.004024257711069123 tk: 5 x_norm: 22.413988855152752\n",
      "Iteration 2295 - Grad. Norm.: 0.0008043563351736172 Norm. Diff.: 0.004023019243521989 tk: 5 x_norm: 22.417410054405508\n",
      "Iteration 2296 - Grad. Norm.: 0.0008041090014175322 Norm. Diff.: 0.004021781675868023 tk: 5 x_norm: 22.42083018028726\n",
      "Iteration 2297 - Grad. Norm.: 0.000803861847232531 Norm. Diff.: 0.004020545007087677 tk: 5 x_norm: 22.424249233574702\n",
      "Iteration 2298 - Grad. Norm.: 0.0008036148724153112 Norm. Diff.: 0.004019309236162741 tk: 5 x_norm: 22.427667215043655\n",
      "Iteration 2299 - Grad. Norm.: 0.0008033680767628815 Norm. Diff.: 0.004018074362076646 tk: 5 x_norm: 22.43108412546904\n",
      "Iteration 2300 - Grad. Norm.: 0.0008031214600725614 Norm. Diff.: 0.0040168403838144705 tk: 5 x_norm: 22.434499965624926\n",
      "Iteration 2301 - Grad. Norm.: 0.0008028750221419818 Norm. Diff.: 0.004015607300362812 tk: 5 x_norm: 22.437914736284494\n",
      "Iteration 2302 - Grad. Norm.: 0.000802628762769084 Norm. Diff.: 0.004014375110709865 tk: 5 x_norm: 22.44132843822005\n",
      "Iteration 2303 - Grad. Norm.: 0.000802382681752116 Norm. Diff.: 0.004013143813845395 tk: 5 x_norm: 22.444741072203033\n",
      "Iteration 2304 - Grad. Norm.: 0.0008021367788896386 Norm. Diff.: 0.004011913408760667 tk: 5 x_norm: 22.44815263900402\n",
      "Iteration 2305 - Grad. Norm.: 0.000801891053980516 Norm. Diff.: 0.004010683894448199 tk: 5 x_norm: 22.451563139392697\n",
      "Iteration 2306 - Grad. Norm.: 0.0008016455068239255 Norm. Diff.: 0.004009455269902497 tk: 5 x_norm: 22.454972574137898\n",
      "Iteration 2307 - Grad. Norm.: 0.0008014001372193456 Norm. Diff.: 0.004008227534119795 tk: 5 x_norm: 22.458380944007573\n",
      "Iteration 2308 - Grad. Norm.: 0.0008011549449665648 Norm. Diff.: 0.0040070006860969 tk: 5 x_norm: 22.461788249768826\n",
      "Iteration 2309 - Grad. Norm.: 0.0008009099298656753 Norm. Diff.: 0.0040057747248328345 tk: 5 x_norm: 22.465194492187887\n",
      "Iteration 2310 - Grad. Norm.: 0.0008006650917170764 Norm. Diff.: 0.004004549649328396 tk: 5 x_norm: 22.46859967203012\n",
      "Iteration 2311 - Grad. Norm.: 0.0008004204303214707 Norm. Diff.: 0.004003325458585372 tk: 5 x_norm: 22.472003790060036\n",
      "Iteration 2312 - Grad. Norm.: 0.0008001759454798641 Norm. Diff.: 0.004002102151607449 tk: 5 x_norm: 22.475406847041278\n",
      "Iteration 2313 - Grad. Norm.: 0.0007999316369935651 Norm. Diff.: 0.0040008797273992525 tk: 5 x_norm: 22.478808843736626\n",
      "Iteration 2314 - Grad. Norm.: 0.0007996875046641896 Norm. Diff.: 0.00399965818496816 tk: 5 x_norm: 22.482209780908015\n",
      "Iteration 2315 - Grad. Norm.: 0.0007994435482936483 Norm. Diff.: 0.00399843752332105 tk: 5 x_norm: 22.48560965931651\n",
      "Iteration 2316 - Grad. Norm.: 0.0007991997676841585 Norm. Diff.: 0.0039972177414680735 tk: 5 x_norm: 22.48900847972233\n",
      "Iteration 2317 - Grad. Norm.: 0.0007989561626382393 Norm. Diff.: 0.003995998838420787 tk: 5 x_norm: 22.492406242884837\n",
      "Iteration 2318 - Grad. Norm.: 0.0007987127329587045 Norm. Diff.: 0.003994780813191205 tk: 5 x_norm: 22.495802949562535\n",
      "Iteration 2319 - Grad. Norm.: 0.0007984694784486727 Norm. Diff.: 0.003993563664793471 tk: 5 x_norm: 22.499198600513093\n",
      "Iteration 2320 - Grad. Norm.: 0.000798226398911559 Norm. Diff.: 0.003992347392243125 tk: 5 x_norm: 22.502593196493308\n",
      "Iteration 2321 - Grad. Norm.: 0.0007979834941510793 Norm. Diff.: 0.003991131994557794 tk: 5 x_norm: 22.505986738259146\n",
      "Iteration 2322 - Grad. Norm.: 0.0007977407639712444 Norm. Diff.: 0.003989917470755401 tk: 5 x_norm: 22.509379226565713\n",
      "Iteration 2323 - Grad. Norm.: 0.000797498208176365 Norm. Diff.: 0.003988703819856177 tk: 5 x_norm: 22.512770662167277\n",
      "Iteration 2324 - Grad. Norm.: 0.0007972558265710481 Norm. Diff.: 0.003987491040882046 tk: 5 x_norm: 22.516161045817256\n",
      "Iteration 2325 - Grad. Norm.: 0.0007970136189601956 Norm. Diff.: 0.0039862791328554555 tk: 5 x_norm: 22.519550378268235\n",
      "Iteration 2326 - Grad. Norm.: 0.0007967715851490053 Norm. Diff.: 0.003985068094800753 tk: 5 x_norm: 22.522938660271937\n",
      "Iteration 2327 - Grad. Norm.: 0.0007965297249429719 Norm. Diff.: 0.0039838579257447425 tk: 5 x_norm: 22.52632589257926\n",
      "Iteration 2328 - Grad. Norm.: 0.0007962880381478827 Norm. Diff.: 0.003982648624714819 tk: 5 x_norm: 22.529712075940257\n",
      "Iteration 2329 - Grad. Norm.: 0.0007960465245698189 Norm. Diff.: 0.0039814401907393515 tk: 5 x_norm: 22.533097211104142\n",
      "Iteration 2330 - Grad. Norm.: 0.0007958051840151563 Norm. Diff.: 0.003980232622849148 tk: 5 x_norm: 22.536481298819297\n",
      "Iteration 2331 - Grad. Norm.: 0.0007955640162905632 Norm. Diff.: 0.003979025920075848 tk: 5 x_norm: 22.53986433983326\n",
      "Iteration 2332 - Grad. Norm.: 0.0007953230212029979 Norm. Diff.: 0.003977820081452812 tk: 5 x_norm: 22.54324633489274\n",
      "Iteration 2333 - Grad. Norm.: 0.0007950821985597128 Norm. Diff.: 0.003976615106015064 tk: 5 x_norm: 22.546627284743604\n",
      "Iteration 2334 - Grad. Norm.: 0.0007948415481682494 Norm. Diff.: 0.003975410992798549 tk: 5 x_norm: 22.550007190130902\n",
      "Iteration 2335 - Grad. Norm.: 0.000794601069836443 Norm. Diff.: 0.003974207740841566 tk: 5 x_norm: 22.553386051798842\n",
      "Iteration 2336 - Grad. Norm.: 0.0007943607633724137 Norm. Diff.: 0.003973005349182328 tk: 5 x_norm: 22.55676387049081\n",
      "Iteration 2337 - Grad. Norm.: 0.0007941206285845753 Norm. Diff.: 0.003971803816862232 tk: 5 x_norm: 22.560140646949343\n",
      "Iteration 2338 - Grad. Norm.: 0.000793880665281628 Norm. Diff.: 0.003970603142922722 tk: 5 x_norm: 22.56351638191618\n",
      "Iteration 2339 - Grad. Norm.: 0.000793640873272562 Norm. Diff.: 0.003969403326408118 tk: 5 x_norm: 22.566891076132215\n",
      "Iteration 2340 - Grad. Norm.: 0.0007934012523666522 Norm. Diff.: 0.003968204366362779 tk: 5 x_norm: 22.57026473033753\n",
      "Iteration 2341 - Grad. Norm.: 0.0007931618023734641 Norm. Diff.: 0.00396700626183358 tk: 5 x_norm: 22.573637345271365\n",
      "Iteration 2342 - Grad. Norm.: 0.0007929225231028461 Norm. Diff.: 0.003965809011867263 tk: 5 x_norm: 22.577008921672164\n",
      "Iteration 2343 - Grad. Norm.: 0.0007926834143649369 Norm. Diff.: 0.003964612615514242 tk: 5 x_norm: 22.580379460277516\n",
      "Iteration 2344 - Grad. Norm.: 0.0007924444759701566 Norm. Diff.: 0.003963417071824359 tk: 5 x_norm: 22.58374896182422\n",
      "Iteration 2345 - Grad. Norm.: 0.0007922057077292122 Norm. Diff.: 0.003962222379850701 tk: 5 x_norm: 22.587117427048256\n",
      "Iteration 2346 - Grad. Norm.: 0.0007919671094530942 Norm. Diff.: 0.003961028538646189 tk: 5 x_norm: 22.59048485668476\n",
      "Iteration 2347 - Grad. Norm.: 0.0007917286809530772 Norm. Diff.: 0.003959835547265392 tk: 5 x_norm: 22.593851251468084\n",
      "Iteration 2348 - Grad. Norm.: 0.0007914904220407192 Norm. Diff.: 0.003958643404765139 tk: 5 x_norm: 22.59721661213174\n",
      "Iteration 2349 - Grad. Norm.: 0.0007912523325278605 Norm. Diff.: 0.003957452110203679 tk: 5 x_norm: 22.600580939408438\n",
      "Iteration 2350 - Grad. Norm.: 0.0007910144122266236 Norm. Diff.: 0.003956261662639508 tk: 5 x_norm: 22.60394423403008\n",
      "Iteration 2351 - Grad. Norm.: 0.000790776660949413 Norm. Diff.: 0.00395507206113307 tk: 5 x_norm: 22.607306496727748\n",
      "Iteration 2352 - Grad. Norm.: 0.0007905390785089134 Norm. Diff.: 0.003953883304746831 tk: 5 x_norm: 22.610667728231718\n",
      "Iteration 2353 - Grad. Norm.: 0.0007903016647180903 Norm. Diff.: 0.003952695392544572 tk: 5 x_norm: 22.614027929271458\n",
      "Iteration 2354 - Grad. Norm.: 0.0007900644193901885 Norm. Diff.: 0.003951508323590358 tk: 5 x_norm: 22.61738710057563\n",
      "Iteration 2355 - Grad. Norm.: 0.0007898273423387344 Norm. Diff.: 0.0039503220969510245 tk: 5 x_norm: 22.620745242872083\n",
      "Iteration 2356 - Grad. Norm.: 0.0007895904333775306 Norm. Diff.: 0.003949136711693694 tk: 5 x_norm: 22.62410235688787\n",
      "Iteration 2357 - Grad. Norm.: 0.000789353692320659 Norm. Diff.: 0.003947952166887583 tk: 5 x_norm: 22.627458443349234\n",
      "Iteration 2358 - Grad. Norm.: 0.0007891171189824799 Norm. Diff.: 0.003946768461603306 tk: 5 x_norm: 22.630813502981617\n",
      "Iteration 2359 - Grad. Norm.: 0.0007888807131776297 Norm. Diff.: 0.003945585594912481 tk: 5 x_norm: 22.634167536509658\n",
      "Iteration 2360 - Grad. Norm.: 0.0007886444747210241 Norm. Diff.: 0.003944403565888068 tk: 5 x_norm: 22.637520544657207\n",
      "Iteration 2361 - Grad. Norm.: 0.0007884084034278503 Norm. Diff.: 0.003943222373604958 tk: 5 x_norm: 22.64087252814729\n",
      "Iteration 2362 - Grad. Norm.: 0.0007881724991135753 Norm. Diff.: 0.003942042017139203 tk: 5 x_norm: 22.644223487702167\n",
      "Iteration 2363 - Grad. Norm.: 0.0007879367615939404 Norm. Diff.: 0.003940862495567859 tk: 5 x_norm: 22.647573424043273\n",
      "Iteration 2364 - Grad. Norm.: 0.0007877011906849585 Norm. Diff.: 0.0039396838079700175 tk: 5 x_norm: 22.65092233789127\n",
      "Iteration 2365 - Grad. Norm.: 0.0007874657862029213 Norm. Diff.: 0.003938505953424802 tk: 5 x_norm: 22.654270229966013\n",
      "Iteration 2366 - Grad. Norm.: 0.0007872305479643911 Norm. Diff.: 0.00393732893101467 tk: 5 x_norm: 22.657617100986567\n",
      "Iteration 2367 - Grad. Norm.: 0.0007869954757862021 Norm. Diff.: 0.003936152739822087 tk: 5 x_norm: 22.660962951671202\n",
      "Iteration 2368 - Grad. Norm.: 0.0007867605694854646 Norm. Diff.: 0.003934977378931082 tk: 5 x_norm: 22.664307782737403\n",
      "Iteration 2369 - Grad. Norm.: 0.0007865258288795584 Norm. Diff.: 0.003933802847427301 tk: 5 x_norm: 22.66765159490187\n",
      "Iteration 2370 - Grad. Norm.: 0.0007862912537861346 Norm. Diff.: 0.0039326291443976735 tk: 5 x_norm: 22.670994388880498\n",
      "Iteration 2371 - Grad. Norm.: 0.0007860568440231161 Norm. Diff.: 0.003931456268930612 tk: 5 x_norm: 22.674336165388407\n",
      "Iteration 2372 - Grad. Norm.: 0.0007858225994086961 Norm. Diff.: 0.00393028422011523 tk: 5 x_norm: 22.677676925139934\n",
      "Iteration 2373 - Grad. Norm.: 0.0007855885197613373 Norm. Diff.: 0.003929112997043508 tk: 5 x_norm: 22.68101666884862\n",
      "Iteration 2374 - Grad. Norm.: 0.0007853546048997718 Norm. Diff.: 0.0039279425988070485 tk: 5 x_norm: 22.684355397227232\n",
      "Iteration 2375 - Grad. Norm.: 0.0007851208546430021 Norm. Diff.: 0.003926773024498765 tk: 5 x_norm: 22.68769311098775\n",
      "Iteration 2376 - Grad. Norm.: 0.0007848872688102954 Norm. Diff.: 0.003925604273215072 tk: 5 x_norm: 22.691029810841382\n",
      "Iteration 2377 - Grad. Norm.: 0.0007846538472211906 Norm. Diff.: 0.00392443634405141 tk: 5 x_norm: 22.694365497498538\n",
      "Iteration 2378 - Grad. Norm.: 0.0007844205896954927 Norm. Diff.: 0.003923269236105956 tk: 5 x_norm: 22.69770017166886\n",
      "Iteration 2379 - Grad. Norm.: 0.0007841874960532716 Norm. Diff.: 0.003922102948477285 tk: 5 x_norm: 22.70103383406122\n",
      "Iteration 2380 - Grad. Norm.: 0.0007839545661148661 Norm. Diff.: 0.003920937480266487 tk: 5 x_norm: 22.704366485383698\n",
      "Iteration 2381 - Grad. Norm.: 0.0007837217997008787 Norm. Diff.: 0.003919772830574391 tk: 5 x_norm: 22.707698126343608\n",
      "Iteration 2382 - Grad. Norm.: 0.0007834891966321796 Norm. Diff.: 0.003918608998504565 tk: 5 x_norm: 22.71102875764748\n",
      "Iteration 2383 - Grad. Norm.: 0.0007832567567299013 Norm. Diff.: 0.003917445983161057 tk: 5 x_norm: 22.71435838000109\n",
      "Iteration 2384 - Grad. Norm.: 0.0007830244798154425 Norm. Diff.: 0.0039162837836496074 tk: 5 x_norm: 22.71768699410942\n",
      "Iteration 2385 - Grad. Norm.: 0.0007827923657104648 Norm. Diff.: 0.003915122399077185 tk: 5 x_norm: 22.721014600676696\n",
      "Iteration 2386 - Grad. Norm.: 0.0007825604142368928 Norm. Diff.: 0.003913961828552447 tk: 5 x_norm: 22.72434120040637\n",
      "Iteration 2387 - Grad. Norm.: 0.0007823286252169135 Norm. Diff.: 0.0039128020711845434 tk: 5 x_norm: 22.727666794001124\n",
      "Iteration 2388 - Grad. Norm.: 0.0007820969984729773 Norm. Diff.: 0.0039116431260841815 tk: 5 x_norm: 22.73099138216288\n",
      "Iteration 2389 - Grad. Norm.: 0.0007818655338277974 Norm. Diff.: 0.003910484992364869 tk: 5 x_norm: 22.734314965592773\n",
      "Iteration 2390 - Grad. Norm.: 0.0007816342311043452 Norm. Diff.: 0.003909327669138917 tk: 5 x_norm: 22.737637544991205\n",
      "Iteration 2391 - Grad. Norm.: 0.0007814030901258544 Norm. Diff.: 0.00390817115552192 tk: 5 x_norm: 22.74095912105778\n",
      "Iteration 2392 - Grad. Norm.: 0.0007811721107158212 Norm. Diff.: 0.003907015450629224 tk: 5 x_norm: 22.744279694491365\n",
      "Iteration 2393 - Grad. Norm.: 0.0007809412926979974 Norm. Diff.: 0.003905860553579017 tk: 5 x_norm: 22.74759926599005\n",
      "Iteration 2394 - Grad. Norm.: 0.0007807106358963964 Norm. Diff.: 0.0039047064634897244 tk: 5 x_norm: 22.75091783625118\n",
      "Iteration 2395 - Grad. Norm.: 0.0007804801401352911 Norm. Diff.: 0.0039035531794819095 tk: 5 x_norm: 22.75423540597132\n",
      "Iteration 2396 - Grad. Norm.: 0.0007802498052392114 Norm. Diff.: 0.0039024007006767617 tk: 5 x_norm: 22.757551975846294\n",
      "Iteration 2397 - Grad. Norm.: 0.0007800196310329456 Norm. Diff.: 0.0039012490261960907 tk: 5 x_norm: 22.760867546571152\n",
      "Iteration 2398 - Grad. Norm.: 0.0007797896173415401 Norm. Diff.: 0.003900098155164801 tk: 5 x_norm: 22.764182118840207\n",
      "Iteration 2399 - Grad. Norm.: 0.0007795597639902974 Norm. Diff.: 0.00389894808670777 tk: 5 x_norm: 22.767495693347016\n",
      "Iteration 2400 - Grad. Norm.: 0.0007793300708047731 Norm. Diff.: 0.003897798819951391 tk: 5 x_norm: 22.770808270784354\n",
      "Iteration 2401 - Grad. Norm.: 0.0007791005376107867 Norm. Diff.: 0.0038966503540239397 tk: 5 x_norm: 22.77411985184428\n",
      "Iteration 2402 - Grad. Norm.: 0.0007788711642344058 Norm. Diff.: 0.0038955026880538933 tk: 5 x_norm: 22.777430437218072\n",
      "Iteration 2403 - Grad. Norm.: 0.0007786419505019553 Norm. Diff.: 0.0038943558211718033 tk: 5 x_norm: 22.780740027596284\n",
      "Iteration 2404 - Grad. Norm.: 0.0007784128962400165 Norm. Diff.: 0.0038932097525096934 tk: 5 x_norm: 22.784048623668692\n",
      "Iteration 2405 - Grad. Norm.: 0.0007781840012754203 Norm. Diff.: 0.0038920644812000327 tk: 5 x_norm: 22.78735622612435\n",
      "Iteration 2406 - Grad. Norm.: 0.0007779552654352566 Norm. Diff.: 0.003890920006377396 tk: 5 x_norm: 22.79066283565155\n",
      "Iteration 2407 - Grad. Norm.: 0.0007777266885468636 Norm. Diff.: 0.003889776327176285 tk: 5 x_norm: 22.79396845293783\n",
      "Iteration 2408 - Grad. Norm.: 0.0007774982704378345 Norm. Diff.: 0.003888633442733987 tk: 5 x_norm: 22.797273078670003\n",
      "Iteration 2409 - Grad. Norm.: 0.0007772700109360147 Norm. Diff.: 0.0038874913521892078 tk: 5 x_norm: 22.800576713534134\n",
      "Iteration 2410 - Grad. Norm.: 0.0007770419098694997 Norm. Diff.: 0.003886350054680317 tk: 5 x_norm: 22.803879358215532\n",
      "Iteration 2411 - Grad. Norm.: 0.0007768139670666374 Norm. Diff.: 0.0038852095493472575 tk: 5 x_norm: 22.807181013398775\n",
      "Iteration 2412 - Grad. Norm.: 0.0007765861823560247 Norm. Diff.: 0.003884069835333305 tk: 5 x_norm: 22.810481679767697\n",
      "Iteration 2413 - Grad. Norm.: 0.0007763585555665122 Norm. Diff.: 0.0038829309117801836 tk: 5 x_norm: 22.813781358005397\n",
      "Iteration 2414 - Grad. Norm.: 0.0007761310865271966 Norm. Diff.: 0.003881792777832455 tk: 5 x_norm: 22.817080048794224\n",
      "Iteration 2415 - Grad. Norm.: 0.000775903775067425 Norm. Diff.: 0.0038806554326359715 tk: 5 x_norm: 22.820377752815798\n",
      "Iteration 2416 - Grad. Norm.: 0.0007756766210167945 Norm. Diff.: 0.003879518875337085 tk: 5 x_norm: 22.823674470751005\n",
      "Iteration 2417 - Grad. Norm.: 0.0007754496242051485 Norm. Diff.: 0.0038783831050838574 tk: 5 x_norm: 22.826970203279995\n",
      "Iteration 2418 - Grad. Norm.: 0.0007752227844625794 Norm. Diff.: 0.003877248121025741 tk: 5 x_norm: 22.830264951082178\n",
      "Iteration 2419 - Grad. Norm.: 0.000774996101619428 Norm. Diff.: 0.0038761139223128706 tk: 5 x_norm: 22.833558714836233\n",
      "Iteration 2420 - Grad. Norm.: 0.0007747695755062792 Norm. Diff.: 0.0038749805080973143 tk: 5 x_norm: 22.836851495220113\n",
      "Iteration 2421 - Grad. Norm.: 0.0007745432059539676 Norm. Diff.: 0.00387384787753156 tk: 5 x_norm: 22.840143292911026\n",
      "Iteration 2422 - Grad. Norm.: 0.0007743169927935718 Norm. Diff.: 0.003872716029769769 tk: 5 x_norm: 22.843434108585463\n",
      "Iteration 2423 - Grad. Norm.: 0.0007740909358564166 Norm. Diff.: 0.003871584963968045 tk: 5 x_norm: 22.846723942919187\n",
      "Iteration 2424 - Grad. Norm.: 0.0007738650349740707 Norm. Diff.: 0.003870454679282187 tk: 5 x_norm: 22.85001279658723\n",
      "Iteration 2425 - Grad. Norm.: 0.0007736392899783502 Norm. Diff.: 0.0038693251748703685 tk: 5 x_norm: 22.853300670263877\n",
      "Iteration 2426 - Grad. Norm.: 0.0007734137007013133 Norm. Diff.: 0.0038681964498916174 tk: 5 x_norm: 22.856587564622732\n",
      "Iteration 2427 - Grad. Norm.: 0.0007731882669752623 Norm. Diff.: 0.0038670685035065615 tk: 5 x_norm: 22.85987348033664\n",
      "Iteration 2428 - Grad. Norm.: 0.0007729629886327422 Norm. Diff.: 0.0038659413348765253 tk: 5 x_norm: 22.863158418077717\n",
      "Iteration 2429 - Grad. Norm.: 0.0007727378655065421 Norm. Diff.: 0.003864814943163587 tk: 5 x_norm: 22.866442378517387\n",
      "Iteration 2430 - Grad. Norm.: 0.0007725128974296923 Norm. Diff.: 0.0038636893275326746 tk: 5 x_norm: 22.869725362326335\n",
      "Iteration 2431 - Grad. Norm.: 0.0007722880842354668 Norm. Diff.: 0.0038625644871484754 tk: 5 x_norm: 22.873007370174523\n",
      "Iteration 2432 - Grad. Norm.: 0.0007720634257573777 Norm. Diff.: 0.003861440421177212 tk: 5 x_norm: 22.876288402731195\n",
      "Iteration 2433 - Grad. Norm.: 0.0007718389218291825 Norm. Diff.: 0.003860317128786806 tk: 5 x_norm: 22.87956846066489\n",
      "Iteration 2434 - Grad. Norm.: 0.0007716145722848756 Norm. Diff.: 0.0038591946091461205 tk: 5 x_norm: 22.882847544643404\n",
      "Iteration 2435 - Grad. Norm.: 0.0007713903769586943 Norm. Diff.: 0.00385807286142444 tk: 5 x_norm: 22.88612565533384\n",
      "Iteration 2436 - Grad. Norm.: 0.0007711663356851131 Norm. Diff.: 0.0038569518847936654 tk: 5 x_norm: 22.88940279340258\n",
      "Iteration 2437 - Grad. Norm.: 0.0007709424482988479 Norm. Diff.: 0.003855831678425535 tk: 5 x_norm: 22.892678959515287\n",
      "Iteration 2438 - Grad. Norm.: 0.0007707187146348525 Norm. Diff.: 0.003854712241494333 tk: 5 x_norm: 22.895954154336916\n",
      "Iteration 2439 - Grad. Norm.: 0.0007704951345283176 Norm. Diff.: 0.0038535935731743133 tk: 5 x_norm: 22.899228378531703\n",
      "Iteration 2440 - Grad. Norm.: 0.0007702717078146746 Norm. Diff.: 0.0038524756726415255 tk: 5 x_norm: 22.90250163276318\n",
      "Iteration 2441 - Grad. Norm.: 0.000770048434329591 Norm. Diff.: 0.00385135853907344 tk: 5 x_norm: 22.905773917694166\n",
      "Iteration 2442 - Grad. Norm.: 0.0007698253139089702 Norm. Diff.: 0.003850242171647979 tk: 5 x_norm: 22.90904523398677\n",
      "Iteration 2443 - Grad. Norm.: 0.0007696023463889559 Norm. Diff.: 0.00384912656954479 tk: 5 x_norm: 22.9123155823024\n",
      "Iteration 2444 - Grad. Norm.: 0.0007693795316059232 Norm. Diff.: 0.0038480117319447953 tk: 5 x_norm: 22.915584963301754\n",
      "Iteration 2445 - Grad. Norm.: 0.0007691568693964848 Norm. Diff.: 0.003846897658029867 tk: 5 x_norm: 22.918853377644815\n",
      "Iteration 2446 - Grad. Norm.: 0.0007689343595974925 Norm. Diff.: 0.0038457843469823913 tk: 5 x_norm: 22.922120825990874\n",
      "Iteration 2447 - Grad. Norm.: 0.0007687120020460262 Norm. Diff.: 0.0038446717979872974 tk: 5 x_norm: 22.925387308998502\n",
      "Iteration 2448 - Grad. Norm.: 0.0007684897965794042 Norm. Diff.: 0.0038435600102301746 tk: 5 x_norm: 22.928652827325596\n",
      "Iteration 2449 - Grad. Norm.: 0.0007682677430351797 Norm. Diff.: 0.0038424489828969167 tk: 5 x_norm: 22.93191738162932\n",
      "Iteration 2450 - Grad. Norm.: 0.000768045841251137 Norm. Diff.: 0.003841338715176104 tk: 5 x_norm: 22.93518097256615\n",
      "Iteration 2451 - Grad. Norm.: 0.0007678240910652952 Norm. Diff.: 0.0038402292062557956 tk: 5 x_norm: 22.938443600791867\n",
      "Iteration 2452 - Grad. Norm.: 0.0007676024923159048 Norm. Diff.: 0.003839120455326404 tk: 5 x_norm: 22.941705266961552\n",
      "Iteration 2453 - Grad. Norm.: 0.0007673810448414497 Norm. Diff.: 0.0038380124615794713 tk: 5 x_norm: 22.944965971729577\n",
      "Iteration 2454 - Grad. Norm.: 0.0007671597484806448 Norm. Diff.: 0.003836905224207018 tk: 5 x_norm: 22.94822571574963\n",
      "Iteration 2455 - Grad. Norm.: 0.0007669386030724368 Norm. Diff.: 0.003835798742403198 tk: 5 x_norm: 22.951484499674695\n",
      "Iteration 2456 - Grad. Norm.: 0.0007667176084560042 Norm. Diff.: 0.0038346930153623426 tk: 5 x_norm: 22.954742324157067\n",
      "Iteration 2457 - Grad. Norm.: 0.0007664967644707549 Norm. Diff.: 0.0038335880422800984 tk: 5 x_norm: 22.957999189848348\n",
      "Iteration 2458 - Grad. Norm.: 0.0007662760709563274 Norm. Diff.: 0.003832483822353496 tk: 5 x_norm: 22.961255097399444\n",
      "Iteration 2459 - Grad. Norm.: 0.0007660555277525911 Norm. Diff.: 0.0038313803547816226 tk: 5 x_norm: 22.964510047460568\n",
      "Iteration 2460 - Grad. Norm.: 0.000765835134699642 Norm. Diff.: 0.003830277638762955 tk: 5 x_norm: 22.967764040681246\n",
      "Iteration 2461 - Grad. Norm.: 0.0007656148916378074 Norm. Diff.: 0.0038291756734980505 tk: 5 x_norm: 22.97101707771031\n",
      "Iteration 2462 - Grad. Norm.: 0.0007653947984076424 Norm. Diff.: 0.0038280744581889914 tk: 5 x_norm: 22.97426915919591\n",
      "Iteration 2463 - Grad. Norm.: 0.0007651748548499296 Norm. Diff.: 0.0038269739920384536 tk: 5 x_norm: 22.977520285785502\n",
      "Iteration 2464 - Grad. Norm.: 0.0007649550608056807 Norm. Diff.: 0.003825874274249749 tk: 5 x_norm: 22.98077045812585\n",
      "Iteration 2465 - Grad. Norm.: 0.0007647354161161334 Norm. Diff.: 0.00382477530402853 tk: 5 x_norm: 22.984019676863053\n",
      "Iteration 2466 - Grad. Norm.: 0.0007645159206227514 Norm. Diff.: 0.003823677080580829 tk: 5 x_norm: 22.9872679426425\n",
      "Iteration 2467 - Grad. Norm.: 0.0007642965741672278 Norm. Diff.: 0.0038225796031139854 tk: 5 x_norm: 22.990515256108917\n",
      "Iteration 2468 - Grad. Norm.: 0.0007640773765914773 Norm. Diff.: 0.003821482870836352 tk: 5 x_norm: 22.99376161790633\n",
      "Iteration 2469 - Grad. Norm.: 0.0007638583277376451 Norm. Diff.: 0.0038203868829571833 tk: 5 x_norm: 22.997007028678105\n",
      "Iteration 2470 - Grad. Norm.: 0.0007636394274480987 Norm. Diff.: 0.003819291638688494 tk: 5 x_norm: 23.000251489066898\n",
      "Iteration 2471 - Grad. Norm.: 0.0007634206755654301 Norm. Diff.: 0.0038181971372406058 tk: 5 x_norm: 23.003494999714714\n",
      "Iteration 2472 - Grad. Norm.: 0.0007632020719324565 Norm. Diff.: 0.003817103377827278 tk: 5 x_norm: 23.006737561262852\n",
      "Iteration 2473 - Grad. Norm.: 0.0007629836163922192 Norm. Diff.: 0.003816010359662701 tk: 5 x_norm: 23.009979174351965\n",
      "Iteration 2474 - Grad. Norm.: 0.0007627653087879825 Norm. Diff.: 0.0038149180819613193 tk: 5 x_norm: 23.013219839621996\n",
      "Iteration 2475 - Grad. Norm.: 0.0007625471489632344 Norm. Diff.: 0.0038138265439400607 tk: 5 x_norm: 23.016459557712228\n",
      "Iteration 2476 - Grad. Norm.: 0.0007623291367616865 Norm. Diff.: 0.0038127357448160862 tk: 5 x_norm: 23.019698329261278\n",
      "Iteration 2477 - Grad. Norm.: 0.0007621112720272701 Norm. Diff.: 0.003811645683808393 tk: 5 x_norm: 23.022936154907068\n",
      "Iteration 2478 - Grad. Norm.: 0.0007618935546041391 Norm. Diff.: 0.0038105563601365505 tk: 5 x_norm: 23.026173035286867\n",
      "Iteration 2479 - Grad. Norm.: 0.0007616759843366717 Norm. Diff.: 0.0038094677730210738 tk: 5 x_norm: 23.02940897103726\n",
      "Iteration 2480 - Grad. Norm.: 0.0007614585610694639 Norm. Diff.: 0.0038083799216832967 tk: 5 x_norm: 23.032643962794165\n",
      "Iteration 2481 - Grad. Norm.: 0.0007612412846473345 Norm. Diff.: 0.0038072928053473768 tk: 5 x_norm: 23.03587801119282\n",
      "Iteration 2482 - Grad. Norm.: 0.0007610241549153215 Norm. Diff.: 0.003806206423236816 tk: 5 x_norm: 23.03911111686781\n",
      "Iteration 2483 - Grad. Norm.: 0.0007608071717186828 Norm. Diff.: 0.0038051207745768453 tk: 5 x_norm: 23.042343280453046\n",
      "Iteration 2484 - Grad. Norm.: 0.0007605903349028976 Norm. Diff.: 0.0038040358585935065 tk: 5 x_norm: 23.04557450258177\n",
      "Iteration 2485 - Grad. Norm.: 0.000760373644313661 Norm. Diff.: 0.003802951674514468 tk: 5 x_norm: 23.04880478388655\n",
      "Iteration 2486 - Grad. Norm.: 0.0007601570997968896 Norm. Diff.: 0.0038018682215682988 tk: 5 x_norm: 23.052034124999306\n",
      "Iteration 2487 - Grad. Norm.: 0.0007599407011987174 Norm. Diff.: 0.0038007854989844376 tk: 5 x_norm: 23.055262526551275\n",
      "Iteration 2488 - Grad. Norm.: 0.0007597244483654965 Norm. Diff.: 0.003799703505993611 tk: 5 x_norm: 23.05848998917304\n",
      "Iteration 2489 - Grad. Norm.: 0.0007595083411437951 Norm. Diff.: 0.003798622241827474 tk: 5 x_norm: 23.061716513494524\n",
      "Iteration 2490 - Grad. Norm.: 0.000759292379380402 Norm. Diff.: 0.003797541705719011 tk: 5 x_norm: 23.064942100144982\n",
      "Iteration 2491 - Grad. Norm.: 0.0007590765629223192 Norm. Diff.: 0.0037964618969020653 tk: 5 x_norm: 23.068166749753022\n",
      "Iteration 2492 - Grad. Norm.: 0.0007588608916167662 Norm. Diff.: 0.0037953828146118475 tk: 5 x_norm: 23.071390462946564\n",
      "Iteration 2493 - Grad. Norm.: 0.0007586453653111783 Norm. Diff.: 0.003794304458083912 tk: 5 x_norm: 23.0746132403529\n",
      "Iteration 2494 - Grad. Norm.: 0.0007584299838532088 Norm. Diff.: 0.0037932268265557486 tk: 5 x_norm: 23.077835082598636\n",
      "Iteration 2495 - Grad. Norm.: 0.0007582147470907225 Norm. Diff.: 0.003792149919266091 tk: 5 x_norm: 23.081055990309753\n",
      "Iteration 2496 - Grad. Norm.: 0.0007579996548718016 Norm. Diff.: 0.0037910737354535057 tk: 5 x_norm: 23.08427596411155\n",
      "Iteration 2497 - Grad. Norm.: 0.0007577847070447404 Norm. Diff.: 0.003789998274358985 tk: 5 x_norm: 23.087495004628682\n",
      "Iteration 2498 - Grad. Norm.: 0.0007575699034580512 Norm. Diff.: 0.003788923535223793 tk: 5 x_norm: 23.090713112485147\n",
      "Iteration 2499 - Grad. Norm.: 0.0007573552439604555 Norm. Diff.: 0.003787849517290481 tk: 5 x_norm: 23.093930288304293\n",
      "Iteration 2500 - Grad. Norm.: 0.0007571407284008905 Norm. Diff.: 0.003786776219802481 tk: 5 x_norm: 23.097146532708805\n",
      "Iteration 2501 - Grad. Norm.: 0.000756926356628505 Norm. Diff.: 0.0037857036420044917 tk: 5 x_norm: 23.100361846320737\n",
      "Iteration 2502 - Grad. Norm.: 0.000756712128492663 Norm. Diff.: 0.0037846317831427205 tk: 5 x_norm: 23.103576229761458\n",
      "Iteration 2503 - Grad. Norm.: 0.000756498043842937 Norm. Diff.: 0.0037835606424633543 tk: 5 x_norm: 23.10678968365174\n",
      "Iteration 2504 - Grad. Norm.: 0.0007562841025291145 Norm. Diff.: 0.0037824902192145644 tk: 5 x_norm: 23.110002208611657\n",
      "Iteration 2505 - Grad. Norm.: 0.0007560703044011918 Norm. Diff.: 0.0037814205126453187 tk: 5 x_norm: 23.11321380526066\n",
      "Iteration 2506 - Grad. Norm.: 0.0007558566493093767 Norm. Diff.: 0.003780351522006207 tk: 5 x_norm: 23.116424474217546\n",
      "Iteration 2507 - Grad. Norm.: 0.0007556431371040903 Norm. Diff.: 0.0037792832465467045 tk: 5 x_norm: 23.11963421610047\n",
      "Iteration 2508 - Grad. Norm.: 0.0007554297676359602 Norm. Diff.: 0.003778215685520823 tk: 5 x_norm: 23.122843031526937\n",
      "Iteration 2509 - Grad. Norm.: 0.0007552165407558253 Norm. Diff.: 0.0037771488381797102 tk: 5 x_norm: 23.126050921113812\n",
      "Iteration 2510 - Grad. Norm.: 0.0007550034563147348 Norm. Diff.: 0.003776082703779319 tk: 5 x_norm: 23.12925788547732\n",
      "Iteration 2511 - Grad. Norm.: 0.0007547905141639458 Norm. Diff.: 0.0037750172815736237 tk: 5 x_norm: 23.132463925233033\n",
      "Iteration 2512 - Grad. Norm.: 0.0007545777141549256 Norm. Diff.: 0.0037739525708195575 tk: 5 x_norm: 23.135669040995893\n",
      "Iteration 2513 - Grad. Norm.: 0.0007543650561393491 Norm. Diff.: 0.003772888570774599 tk: 5 x_norm: 23.1388732333802\n",
      "Iteration 2514 - Grad. Norm.: 0.0007541525399690979 Norm. Diff.: 0.0037718252806966863 tk: 5 x_norm: 23.1420765029996\n",
      "Iteration 2515 - Grad. Norm.: 0.0007539401654962621 Norm. Diff.: 0.0037707626998459065 tk: 5 x_norm: 23.14527885046713\n",
      "Iteration 2516 - Grad. Norm.: 0.0007537279325731407 Norm. Diff.: 0.003769700827481267 tk: 5 x_norm: 23.148480276395148\n",
      "Iteration 2517 - Grad. Norm.: 0.0007535158410522376 Norm. Diff.: 0.0037686396628659165 tk: 5 x_norm: 23.15168078139542\n",
      "Iteration 2518 - Grad. Norm.: 0.0007533038907862636 Norm. Diff.: 0.0037675792052611584 tk: 5 x_norm: 23.15488036607904\n",
      "Iteration 2519 - Grad. Norm.: 0.0007530920816281367 Norm. Diff.: 0.003766519453931404 tk: 5 x_norm: 23.158079031056495\n",
      "Iteration 2520 - Grad. Norm.: 0.0007528804134309788 Norm. Diff.: 0.0037654604081408397 tk: 5 x_norm: 23.161276776937612\n",
      "Iteration 2521 - Grad. Norm.: 0.0007526688860481192 Norm. Diff.: 0.003764402067154693 tk: 5 x_norm: 23.164473604331604\n",
      "Iteration 2522 - Grad. Norm.: 0.0007524574993330908 Norm. Diff.: 0.003763344430240705 tk: 5 x_norm: 23.167669513847045\n",
      "Iteration 2523 - Grad. Norm.: 0.0007522462531396315 Norm. Diff.: 0.003762287496665507 tk: 5 x_norm: 23.17086450609187\n",
      "Iteration 2524 - Grad. Norm.: 0.0007520351473216839 Norm. Diff.: 0.00376123126569831 tk: 5 x_norm: 23.1740585816734\n",
      "Iteration 2525 - Grad. Norm.: 0.0007518241817333944 Norm. Diff.: 0.003760175736608332 tk: 5 x_norm: 23.17725174119832\n",
      "Iteration 2526 - Grad. Norm.: 0.0007516133562291125 Norm. Diff.: 0.0037591209086670577 tk: 5 x_norm: 23.180443985272674\n",
      "Iteration 2527 - Grad. Norm.: 0.0007514026706633928 Norm. Diff.: 0.003758066781145579 tk: 5 x_norm: 23.183635314501892\n",
      "Iteration 2528 - Grad. Norm.: 0.0007511921248909898 Norm. Diff.: 0.0037570133533173407 tk: 5 x_norm: 23.18682572949077\n",
      "Iteration 2529 - Grad. Norm.: 0.0007509817187668633 Norm. Diff.: 0.003755960624455038 tk: 5 x_norm: 23.190015230843493\n",
      "Iteration 2530 - Grad. Norm.: 0.0007507714521461735 Norm. Diff.: 0.0037549085938339984 tk: 5 x_norm: 23.193203819163593\n",
      "Iteration 2531 - Grad. Norm.: 0.0007505613248842821 Norm. Diff.: 0.003753857260730729 tk: 5 x_norm: 23.196391495053994\n",
      "Iteration 2532 - Grad. Norm.: 0.0007503513368367551 Norm. Diff.: 0.0037528066244213345 tk: 5 x_norm: 23.199578259117004\n",
      "Iteration 2533 - Grad. Norm.: 0.0007501414878593552 Norm. Diff.: 0.0037517566841838573 tk: 5 x_norm: 23.202764111954302\n",
      "Iteration 2534 - Grad. Norm.: 0.0007499317778080494 Norm. Diff.: 0.0037507074392963574 tk: 5 x_norm: 23.205949054166936\n",
      "Iteration 2535 - Grad. Norm.: 0.0007497222065390057 Norm. Diff.: 0.0037496588890403495 tk: 5 x_norm: 23.20913308635534\n",
      "Iteration 2536 - Grad. Norm.: 0.0007495127739085869 Norm. Diff.: 0.003748611032694841 tk: 5 x_norm: 23.212316209119336\n",
      "Iteration 2537 - Grad. Norm.: 0.0007493034797733611 Norm. Diff.: 0.00374756386954276 tk: 5 x_norm: 23.215498423058108\n",
      "Iteration 2538 - Grad. Norm.: 0.0007490943239900925 Norm. Diff.: 0.003746517398866938 tk: 5 x_norm: 23.218679728770244\n",
      "Iteration 2539 - Grad. Norm.: 0.0007488853064157457 Norm. Diff.: 0.00374547161995046 tk: 5 x_norm: 23.221860126853695\n",
      "Iteration 2540 - Grad. Norm.: 0.0007486764269074829 Norm. Diff.: 0.0037444265320789698 tk: 5 x_norm: 23.225039617905807\n",
      "Iteration 2541 - Grad. Norm.: 0.0007484676853226667 Norm. Diff.: 0.0037433821345372966 tk: 5 x_norm: 23.228218202523312\n",
      "Iteration 2542 - Grad. Norm.: 0.0007482590815188538 Norm. Diff.: 0.003742338426613528 tk: 5 x_norm: 23.231395881302316\n",
      "Iteration 2543 - Grad. Norm.: 0.0007480506153538013 Norm. Diff.: 0.003741295407594238 tk: 5 x_norm: 23.23457265483832\n",
      "Iteration 2544 - Grad. Norm.: 0.0007478422866854645 Norm. Diff.: 0.0037402530767690822 tk: 5 x_norm: 23.237748523726214\n",
      "Iteration 2545 - Grad. Norm.: 0.0007476340953719925 Norm. Diff.: 0.003739211433427376 tk: 5 x_norm: 23.240923488560263\n",
      "Iteration 2546 - Grad. Norm.: 0.0007474260412717331 Norm. Diff.: 0.003738170476859989 tk: 5 x_norm: 23.244097549934132\n",
      "Iteration 2547 - Grad. Norm.: 0.0007472181242432288 Norm. Diff.: 0.0037371302063590353 tk: 5 x_norm: 23.247270708440873\n",
      "Iteration 2548 - Grad. Norm.: 0.0007470103441452197 Norm. Diff.: 0.003736090621216545 tk: 5 x_norm: 23.250442964672924\n",
      "Iteration 2549 - Grad. Norm.: 0.0007468027008366393 Norm. Diff.: 0.0037350517207259872 tk: 5 x_norm: 23.253614319222123\n",
      "Iteration 2550 - Grad. Norm.: 0.0007465951941766185 Norm. Diff.: 0.003734013504183161 tk: 5 x_norm: 23.256784772679705\n",
      "Iteration 2551 - Grad. Norm.: 0.0007463878240244816 Norm. Diff.: 0.0037329759708833684 tk: 5 x_norm: 23.259954325636265\n",
      "Iteration 2552 - Grad. Norm.: 0.0007461805902397467 Norm. Diff.: 0.0037319391201222113 tk: 5 x_norm: 23.263122978681825\n",
      "Iteration 2553 - Grad. Norm.: 0.000745973492682128 Norm. Diff.: 0.0037309029511990127 tk: 5 x_norm: 23.266290732405793\n",
      "Iteration 2554 - Grad. Norm.: 0.000745766531211532 Norm. Diff.: 0.00372986746341064 tk: 5 x_norm: 23.269457587396968\n",
      "Iteration 2555 - Grad. Norm.: 0.0007455597056880592 Norm. Diff.: 0.003728832656057571 tk: 5 x_norm: 23.272623544243544\n",
      "Iteration 2556 - Grad. Norm.: 0.000745353015972003 Norm. Diff.: 0.0037277985284404564 tk: 5 x_norm: 23.275788603533123\n",
      "Iteration 2557 - Grad. Norm.: 0.0007451464619238496 Norm. Diff.: 0.003726765079860356 tk: 5 x_norm: 23.27895276585269\n",
      "Iteration 2558 - Grad. Norm.: 0.0007449400434042786 Norm. Diff.: 0.003725732309619242 tk: 5 x_norm: 23.28211603178864\n",
      "Iteration 2559 - Grad. Norm.: 0.0007447337602741588 Norm. Diff.: 0.0037247002170214386 tk: 5 x_norm: 23.285278401926767\n",
      "Iteration 2560 - Grad. Norm.: 0.0007445276123945544 Norm. Diff.: 0.0037236688013708615 tk: 5 x_norm: 23.288439876852255\n",
      "Iteration 2561 - Grad. Norm.: 0.0007443215996267191 Norm. Diff.: 0.0037226380619729805 tk: 5 x_norm: 23.2916004571497\n",
      "Iteration 2562 - Grad. Norm.: 0.0007441157218320976 Norm. Diff.: 0.0037216079981333893 tk: 5 x_norm: 23.29476014340309\n",
      "Iteration 2563 - Grad. Norm.: 0.0007439099788723254 Norm. Diff.: 0.0037205786091603858 tk: 5 x_norm: 23.297918936195842\n",
      "Iteration 2564 - Grad. Norm.: 0.0007437043706092296 Norm. Diff.: 0.0037195498943615973 tk: 5 x_norm: 23.301076836110735\n",
      "Iteration 2565 - Grad. Norm.: 0.0007434988969048257 Norm. Diff.: 0.003718521853046281 tk: 5 x_norm: 23.304233843729982\n",
      "Iteration 2566 - Grad. Norm.: 0.0007432935576213203 Norm. Diff.: 0.0037174944845242124 tk: 5 x_norm: 23.30738995963519\n",
      "Iteration 2567 - Grad. Norm.: 0.0007430883526211079 Norm. Diff.: 0.0037164677881065876 tk: 5 x_norm: 23.310545184407392\n",
      "Iteration 2568 - Grad. Norm.: 0.000742883281766775 Norm. Diff.: 0.003715441763105239 tk: 5 x_norm: 23.313699518626997\n",
      "Iteration 2569 - Grad. Norm.: 0.0007426783449210935 Norm. Diff.: 0.0037144164088340845 tk: 5 x_norm: 23.31685296287384\n",
      "Iteration 2570 - Grad. Norm.: 0.0007424735419470253 Norm. Diff.: 0.00371339172460549 tk: 5 x_norm: 23.32000551772716\n",
      "Iteration 2571 - Grad. Norm.: 0.0007422688727077206 Norm. Diff.: 0.0037123677097353155 tk: 5 x_norm: 23.323157183765613\n",
      "Iteration 2572 - Grad. Norm.: 0.0007420643370665179 Norm. Diff.: 0.0037113443635388914 tk: 5 x_norm: 23.32630796156726\n",
      "Iteration 2573 - Grad. Norm.: 0.000741859934886941 Norm. Diff.: 0.0037103216853325554 tk: 5 x_norm: 23.329457851709556\n",
      "Iteration 2574 - Grad. Norm.: 0.000741655666032703 Norm. Diff.: 0.003709299674435073 tk: 5 x_norm: 23.3326068547694\n",
      "Iteration 2575 - Grad. Norm.: 0.0007414515303677025 Norm. Diff.: 0.003708278330163623 tk: 5 x_norm: 23.33575497132309\n",
      "Iteration 2576 - Grad. Norm.: 0.000741247527756025 Norm. Diff.: 0.003707257651838692 tk: 5 x_norm: 23.338902201946325\n",
      "Iteration 2577 - Grad. Norm.: 0.0007410436580619431 Norm. Diff.: 0.003706237638780113 tk: 5 x_norm: 23.342048547214237\n",
      "Iteration 2578 - Grad. Norm.: 0.0007408399211499153 Norm. Diff.: 0.0037052182903097534 tk: 5 x_norm: 23.34519400770136\n",
      "Iteration 2579 - Grad. Norm.: 0.0007406363168845805 Norm. Diff.: 0.0037041996057497802 tk: 5 x_norm: 23.348338583981654\n",
      "Iteration 2580 - Grad. Norm.: 0.0007404328451307715 Norm. Diff.: 0.00370318158442314 tk: 5 x_norm: 23.351482276628484\n",
      "Iteration 2581 - Grad. Norm.: 0.0007402295057535002 Norm. Diff.: 0.0037021642256540627 tk: 5 x_norm: 23.354625086214643\n",
      "Iteration 2582 - Grad. Norm.: 0.0007400262986179639 Norm. Diff.: 0.0037011475287676105 tk: 5 x_norm: 23.35776701331234\n",
      "Iteration 2583 - Grad. Norm.: 0.0007398232235895449 Norm. Diff.: 0.0037001314930898395 tk: 5 x_norm: 23.3609080584932\n",
      "Iteration 2584 - Grad. Norm.: 0.0007396202805338082 Norm. Diff.: 0.0036991161179478547 tk: 5 x_norm: 23.364048222328275\n",
      "Iteration 2585 - Grad. Norm.: 0.000739417469316504 Norm. Diff.: 0.0036981014026689165 tk: 5 x_norm: 23.367187505388024\n",
      "Iteration 2586 - Grad. Norm.: 0.0007392147898035653 Norm. Diff.: 0.0036970873465825213 tk: 5 x_norm: 23.370325908242346\n",
      "Iteration 2587 - Grad. Norm.: 0.0007390122418611076 Norm. Diff.: 0.003696073949017704 tk: 5 x_norm: 23.373463431460536\n",
      "Iteration 2588 - Grad. Norm.: 0.0007388098253554304 Norm. Diff.: 0.003695061209305805 tk: 5 x_norm: 23.37660007561135\n",
      "Iteration 2589 - Grad. Norm.: 0.000738607540153013 Norm. Diff.: 0.0036940491267769254 tk: 5 x_norm: 23.37973584126293\n",
      "Iteration 2590 - Grad. Norm.: 0.0007384053861205175 Norm. Diff.: 0.0036930377007648517 tk: 5 x_norm: 23.38287072898286\n",
      "Iteration 2591 - Grad. Norm.: 0.0007382033631247903 Norm. Diff.: 0.003692026930602494 tk: 5 x_norm: 23.38600473933816\n",
      "Iteration 2592 - Grad. Norm.: 0.0007380014710328566 Norm. Diff.: 0.003691016815623979 tk: 5 x_norm: 23.389137872895255\n",
      "Iteration 2593 - Grad. Norm.: 0.0007377997097119224 Norm. Diff.: 0.003690007355164561 tk: 5 x_norm: 23.39227013022002\n",
      "Iteration 2594 - Grad. Norm.: 0.0007375980790293767 Norm. Diff.: 0.0036889985485594216 tk: 5 x_norm: 23.395401511877733\n",
      "Iteration 2595 - Grad. Norm.: 0.0007373965788527873 Norm. Diff.: 0.0036879903951468054 tk: 5 x_norm: 23.39853201843311\n",
      "Iteration 2596 - Grad. Norm.: 0.0007371952090499026 Norm. Diff.: 0.003686982894263761 tk: 5 x_norm: 23.401661650450308\n",
      "Iteration 2597 - Grad. Norm.: 0.00073699396948865 Norm. Diff.: 0.0036859760452496973 tk: 5 x_norm: 23.404790408492897\n",
      "Iteration 2598 - Grad. Norm.: 0.0007367928600371379 Norm. Diff.: 0.0036849698474433223 tk: 5 x_norm: 23.4079182931239\n",
      "Iteration 2599 - Grad. Norm.: 0.0007365918805636525 Norm. Diff.: 0.0036839643001857552 tk: 5 x_norm: 23.411045304905745\n",
      "Iteration 2600 - Grad. Norm.: 0.0007363910309366609 Norm. Diff.: 0.0036829594028183316 tk: 5 x_norm: 23.414171444400303\n",
      "Iteration 2601 - Grad. Norm.: 0.0007361903110248068 Norm. Diff.: 0.0036819551546836424 tk: 5 x_norm: 23.417296712168902\n",
      "Iteration 2602 - Grad. Norm.: 0.0007359897206969135 Norm. Diff.: 0.0036809515551240535 tk: 5 x_norm: 23.420421108772256\n",
      "Iteration 2603 - Grad. Norm.: 0.0007357892598219798 Norm. Diff.: 0.003679948603484568 tk: 5 x_norm: 23.42354463477056\n",
      "Iteration 2604 - Grad. Norm.: 0.0007355889282691861 Norm. Diff.: 0.0036789462991099696 tk: 5 x_norm: 23.42666729072342\n",
      "Iteration 2605 - Grad. Norm.: 0.0007353887259078883 Norm. Diff.: 0.003677944641345671 tk: 5 x_norm: 23.42978907718988\n",
      "Iteration 2606 - Grad. Norm.: 0.0007351886526076182 Norm. Diff.: 0.0036769436295392265 tk: 5 x_norm: 23.432909994728426\n",
      "Iteration 2607 - Grad. Norm.: 0.0007349887082380862 Norm. Diff.: 0.0036759432630378854 tk: 5 x_norm: 23.43603004389699\n",
      "Iteration 2608 - Grad. Norm.: 0.0007347888926691771 Norm. Diff.: 0.003674943541190324 tk: 5 x_norm: 23.43914922525293\n",
      "Iteration 2609 - Grad. Norm.: 0.0007345892057709554 Norm. Diff.: 0.0036739444633456827 tk: 5 x_norm: 23.442267539353043\n",
      "Iteration 2610 - Grad. Norm.: 0.0007343896474136574 Norm. Diff.: 0.003672946028854632 tk: 5 x_norm: 23.44538498675356\n",
      "Iteration 2611 - Grad. Norm.: 0.0007341902174676984 Norm. Diff.: 0.003671948237068131 tk: 5 x_norm: 23.448501568010187\n",
      "Iteration 2612 - Grad. Norm.: 0.000733990915803666 Norm. Diff.: 0.003670951087338474 tk: 5 x_norm: 23.45161728367804\n",
      "Iteration 2613 - Grad. Norm.: 0.0007337917422923247 Norm. Diff.: 0.0036699545790182145 tk: 5 x_norm: 23.454732134311676\n",
      "Iteration 2614 - Grad. Norm.: 0.0007335926968046143 Norm. Diff.: 0.003668958711461557 tk: 5 x_norm: 23.457846120465117\n",
      "Iteration 2615 - Grad. Norm.: 0.0007333937792116475 Norm. Diff.: 0.0036679634840231746 tk: 5 x_norm: 23.460959242691803\n",
      "Iteration 2616 - Grad. Norm.: 0.0007331949893847091 Norm. Diff.: 0.003666968896058362 tk: 5 x_norm: 23.464071501544655\n",
      "Iteration 2617 - Grad. Norm.: 0.0007329963271952623 Norm. Diff.: 0.0036659749469236326 tk: 5 x_norm: 23.467182897575995\n",
      "Iteration 2618 - Grad. Norm.: 0.0007327977925149406 Norm. Diff.: 0.0036649816359760564 tk: 5 x_norm: 23.470293431337627\n",
      "Iteration 2619 - Grad. Norm.: 0.0007325993852155532 Norm. Diff.: 0.0036639889625748614 tk: 5 x_norm: 23.473403103380786\n",
      "Iteration 2620 - Grad. Norm.: 0.0007324011051690789 Norm. Diff.: 0.0036629969260779235 tk: 5 x_norm: 23.476511914256157\n",
      "Iteration 2621 - Grad. Norm.: 0.0007322029522476713 Norm. Diff.: 0.00366200552584534 tk: 5 x_norm: 23.47961986451387\n",
      "Iteration 2622 - Grad. Norm.: 0.0007320049263236557 Norm. Diff.: 0.003661014761238372 tk: 5 x_norm: 23.48272695470352\n",
      "Iteration 2623 - Grad. Norm.: 0.0007318070272695299 Norm. Diff.: 0.003660024631618229 tk: 5 x_norm: 23.48583318537413\n",
      "Iteration 2624 - Grad. Norm.: 0.000731609254957962 Norm. Diff.: 0.0036590351363475987 tk: 5 x_norm: 23.48893855707418\n",
      "Iteration 2625 - Grad. Norm.: 0.0007314116092617944 Norm. Diff.: 0.0036580462747897373 tk: 5 x_norm: 23.492043070351627\n",
      "Iteration 2626 - Grad. Norm.: 0.0007312140900540362 Norm. Diff.: 0.0036570580463085272 tk: 5 x_norm: 23.495146725753838\n",
      "Iteration 2627 - Grad. Norm.: 0.0007310166972078728 Norm. Diff.: 0.0036560704502701514 tk: 5 x_norm: 23.498249523827667\n",
      "Iteration 2628 - Grad. Norm.: 0.0007308194305966553 Norm. Diff.: 0.0036550834860397063 tk: 5 x_norm: 23.5013514651194\n",
      "Iteration 2629 - Grad. Norm.: 0.0007306222900939087 Norm. Diff.: 0.0036540971529833125 tk: 5 x_norm: 23.504452550174797\n",
      "Iteration 2630 - Grad. Norm.: 0.0007304252755733255 Norm. Diff.: 0.0036531114504695966 tk: 5 x_norm: 23.50755277953905\n",
      "Iteration 2631 - Grad. Norm.: 0.0007302283869087679 Norm. Diff.: 0.0036521263778667404 tk: 5 x_norm: 23.51065215375683\n",
      "Iteration 2632 - Grad. Norm.: 0.0007300316239742705 Norm. Diff.: 0.0036511419345438057 tk: 5 x_norm: 23.513750673372247\n",
      "Iteration 2633 - Grad. Norm.: 0.0007298349866440325 Norm. Diff.: 0.0036501581198716015 tk: 5 x_norm: 23.51684833892888\n",
      "Iteration 2634 - Grad. Norm.: 0.0007296384747924267 Norm. Diff.: 0.0036491749332199837 tk: 5 x_norm: 23.519945150969765\n",
      "Iteration 2635 - Grad. Norm.: 0.0007294420882939895 Norm. Diff.: 0.0036481923739620464 tk: 5 x_norm: 23.523041110037386\n",
      "Iteration 2636 - Grad. Norm.: 0.00072924582702343 Norm. Diff.: 0.0036472104414699653 tk: 5 x_norm: 23.5261362166737\n",
      "Iteration 2637 - Grad. Norm.: 0.0007290496908556231 Norm. Diff.: 0.003646229135117176 tk: 5 x_norm: 23.529230471420124\n",
      "Iteration 2638 - Grad. Norm.: 0.0007288536796656116 Norm. Diff.: 0.0036452484542781895 tk: 5 x_norm: 23.532323874817518\n",
      "Iteration 2639 - Grad. Norm.: 0.000728657793328606 Norm. Diff.: 0.0036442683983280142 tk: 5 x_norm: 23.535416427406226\n",
      "Iteration 2640 - Grad. Norm.: 0.0007284620317199824 Norm. Diff.: 0.003643288966643046 tk: 5 x_norm: 23.538508129726043\n",
      "Iteration 2641 - Grad. Norm.: 0.0007282663947152872 Norm. Diff.: 0.003642310158600076 tk: 5 x_norm: 23.54159898231623\n",
      "Iteration 2642 - Grad. Norm.: 0.0007280708821902301 Norm. Diff.: 0.003641331973576484 tk: 5 x_norm: 23.544688985715513\n",
      "Iteration 2643 - Grad. Norm.: 0.0007278754940206883 Norm. Diff.: 0.003640354410951068 tk: 5 x_norm: 23.547778140462086\n",
      "Iteration 2644 - Grad. Norm.: 0.0007276802300827046 Norm. Diff.: 0.003639377470103556 tk: 5 x_norm: 23.550866447093586\n",
      "Iteration 2645 - Grad. Norm.: 0.0007274850902524894 Norm. Diff.: 0.0036384011504133735 tk: 5 x_norm: 23.553953906147154\n",
      "Iteration 2646 - Grad. Norm.: 0.0007272900744064154 Norm. Diff.: 0.00363742545126274 tk: 5 x_norm: 23.557040518159372\n",
      "Iteration 2647 - Grad. Norm.: 0.0007270951824210225 Norm. Diff.: 0.00363645037203196 tk: 5 x_norm: 23.56012628366629\n",
      "Iteration 2648 - Grad. Norm.: 0.0007269004141730157 Norm. Diff.: 0.003635475912105039 tk: 5 x_norm: 23.563211203203437\n",
      "Iteration 2649 - Grad. Norm.: 0.0007267057695392633 Norm. Diff.: 0.003634502070865185 tk: 5 x_norm: 23.5662952773058\n",
      "Iteration 2650 - Grad. Norm.: 0.0007265112483967988 Norm. Diff.: 0.003633528847696341 tk: 5 x_norm: 23.569378506507853\n",
      "Iteration 2651 - Grad. Norm.: 0.0007263168506228189 Norm. Diff.: 0.0036325562419839306 tk: 5 x_norm: 23.57246089134352\n",
      "Iteration 2652 - Grad. Norm.: 0.0007261225760946867 Norm. Diff.: 0.003631584253113917 tk: 5 x_norm: 23.575542432346204\n",
      "Iteration 2653 - Grad. Norm.: 0.0007259284246899249 Norm. Diff.: 0.0036306128804735297 tk: 5 x_norm: 23.578623130048783\n",
      "Iteration 2654 - Grad. Norm.: 0.0007257343962862221 Norm. Diff.: 0.003629642123449365 tk: 5 x_norm: 23.58170298498361\n",
      "Iteration 2655 - Grad. Norm.: 0.0007255404907614291 Norm. Diff.: 0.0036286719814310796 tk: 5 x_norm: 23.584781997682505\n",
      "Iteration 2656 - Grad. Norm.: 0.0007253467079935609 Norm. Diff.: 0.0036277024538070757 tk: 5 x_norm: 23.58786016867676\n",
      "Iteration 2657 - Grad. Norm.: 0.0007251530478607904 Norm. Diff.: 0.0036267335399675768 tk: 5 x_norm: 23.590937498497148\n",
      "Iteration 2658 - Grad. Norm.: 0.0007249595102414584 Norm. Diff.: 0.0036257652393042045 tk: 5 x_norm: 23.59401398767391\n",
      "Iteration 2659 - Grad. Norm.: 0.0007247660950140632 Norm. Diff.: 0.003624797551207106 tk: 5 x_norm: 23.597089636736786\n",
      "Iteration 2660 - Grad. Norm.: 0.0007245728020572678 Norm. Diff.: 0.003623830475070485 tk: 5 x_norm: 23.600164446214947\n",
      "Iteration 2661 - Grad. Norm.: 0.000724379631249893 Norm. Diff.: 0.0036228640102862427 tk: 5 x_norm: 23.603238416637094\n",
      "Iteration 2662 - Grad. Norm.: 0.0007241865824709256 Norm. Diff.: 0.00362189815624935 tk: 5 x_norm: 23.606311548531366\n",
      "Iteration 2663 - Grad. Norm.: 0.0007239936555995086 Norm. Diff.: 0.0036209329123546856 tk: 5 x_norm: 23.609383842425405\n",
      "Iteration 2664 - Grad. Norm.: 0.0007238008505149471 Norm. Diff.: 0.0036199682779974557 tk: 5 x_norm: 23.612455298846314\n",
      "Iteration 2665 - Grad. Norm.: 0.0007236081670967075 Norm. Diff.: 0.0036190042525746755 tk: 5 x_norm: 23.615525918320706\n",
      "Iteration 2666 - Grad. Norm.: 0.0007234156052244141 Norm. Diff.: 0.0036180408354834874 tk: 5 x_norm: 23.618595701374634\n",
      "Iteration 2667 - Grad. Norm.: 0.0007232231647778527 Norm. Diff.: 0.0036170780261222243 tk: 5 x_norm: 23.621664648533663\n",
      "Iteration 2668 - Grad. Norm.: 0.0007230308456369687 Norm. Diff.: 0.0036161158238893257 tk: 5 x_norm: 23.624732760322836\n",
      "Iteration 2669 - Grad. Norm.: 0.0007228386476818658 Norm. Diff.: 0.003615154228184765 tk: 5 x_norm: 23.627800037266674\n",
      "Iteration 2670 - Grad. Norm.: 0.000722646570792805 Norm. Diff.: 0.0036141932384092996 tk: 5 x_norm: 23.630866479889164\n",
      "Iteration 2671 - Grad. Norm.: 0.0007224546148502098 Norm. Diff.: 0.0036132328539640224 tk: 5 x_norm: 23.633932088713813\n",
      "Iteration 2672 - Grad. Norm.: 0.0007222627797346593 Norm. Diff.: 0.0036122730742510407 tk: 5 x_norm: 23.636996864263597\n",
      "Iteration 2673 - Grad. Norm.: 0.0007220710653268914 Norm. Diff.: 0.003611313898673351 tk: 5 x_norm: 23.640060807060966\n",
      "Iteration 2674 - Grad. Norm.: 0.0007218794715078018 Norm. Diff.: 0.003610355326634512 tk: 5 x_norm: 23.643123917627875\n",
      "Iteration 2675 - Grad. Norm.: 0.0007216879981584434 Norm. Diff.: 0.0036093973575389683 tk: 5 x_norm: 23.646186196485754\n",
      "Iteration 2676 - Grad. Norm.: 0.000721496645160028 Norm. Diff.: 0.00360843999079199 tk: 5 x_norm: 23.64924764415553\n",
      "Iteration 2677 - Grad. Norm.: 0.0007213054123939223 Norm. Diff.: 0.003607483225800167 tk: 5 x_norm: 23.652308261157607\n",
      "Iteration 2678 - Grad. Norm.: 0.0007211142997416531 Norm. Diff.: 0.0036065270619695436 tk: 5 x_norm: 23.655368048011887\n",
      "Iteration 2679 - Grad. Norm.: 0.0007209233070848988 Norm. Diff.: 0.0036055714987080828 tk: 5 x_norm: 23.65842700523776\n",
      "Iteration 2680 - Grad. Norm.: 0.0007207324343054989 Norm. Diff.: 0.0036046165354241995 tk: 5 x_norm: 23.66148513335411\n",
      "Iteration 2681 - Grad. Norm.: 0.0007205416812854459 Norm. Diff.: 0.003603662171527538 tk: 5 x_norm: 23.664542432879298\n",
      "Iteration 2682 - Grad. Norm.: 0.0007203510479068888 Norm. Diff.: 0.003602708406427047 tk: 5 x_norm: 23.667598904331207\n",
      "Iteration 2683 - Grad. Norm.: 0.0007201605340521334 Norm. Diff.: 0.0036017552395344325 tk: 5 x_norm: 23.670654548227162\n",
      "Iteration 2684 - Grad. Norm.: 0.0007199701396036395 Norm. Diff.: 0.00360080267026069 tk: 5 x_norm: 23.673709365084044\n",
      "Iteration 2685 - Grad. Norm.: 0.0007197798644440217 Norm. Diff.: 0.003599850698018454 tk: 5 x_norm: 23.676763355418185\n",
      "Iteration 2686 - Grad. Norm.: 0.0007195897084560497 Norm. Diff.: 0.0035988993222198975 tk: 5 x_norm: 23.679816519745412\n",
      "Iteration 2687 - Grad. Norm.: 0.0007193996715226484 Norm. Diff.: 0.003597948542280279 tk: 5 x_norm: 23.68286885858107\n",
      "Iteration 2688 - Grad. Norm.: 0.0007192097535268966 Norm. Diff.: 0.003596998357613118 tk: 5 x_norm: 23.685920372439984\n",
      "Iteration 2689 - Grad. Norm.: 0.0007190199543520254 Norm. Diff.: 0.0035960487676344782 tk: 5 x_norm: 23.688971061836483\n",
      "Iteration 2690 - Grad. Norm.: 0.0007188302738814225 Norm. Diff.: 0.003595099771760105 tk: 5 x_norm: 23.69202092728439\n",
      "Iteration 2691 - Grad. Norm.: 0.000718640711998628 Norm. Diff.: 0.0035941513694068734 tk: 5 x_norm: 23.695069969297016\n",
      "Iteration 2692 - Grad. Norm.: 0.0007184512685873319 Norm. Diff.: 0.003593203559993135 tk: 5 x_norm: 23.69811818838719\n",
      "Iteration 2693 - Grad. Norm.: 0.0007182619435313831 Norm. Diff.: 0.0035922563429366754 tk: 5 x_norm: 23.701165585067233\n",
      "Iteration 2694 - Grad. Norm.: 0.000718072736714779 Norm. Diff.: 0.0035913097176568697 tk: 5 x_norm: 23.704212159848957\n",
      "Iteration 2695 - Grad. Norm.: 0.0007178836480216702 Norm. Diff.: 0.003590363683573874 tk: 5 x_norm: 23.70725791324368\n",
      "Iteration 2696 - Grad. Norm.: 0.0007176946773363612 Norm. Diff.: 0.003589418240108373 tk: 5 x_norm: 23.710302845762243\n",
      "Iteration 2697 - Grad. Norm.: 0.0007175058245433064 Norm. Diff.: 0.003588473386681956 tk: 5 x_norm: 23.713346957914933\n",
      "Iteration 2698 - Grad. Norm.: 0.0007173170895271125 Norm. Diff.: 0.003587529122716971 tk: 5 x_norm: 23.716390250211607\n",
      "Iteration 2699 - Grad. Norm.: 0.0007171284721725385 Norm. Diff.: 0.003586585447635755 tk: 5 x_norm: 23.71943272316157\n",
      "Iteration 2700 - Grad. Norm.: 0.0007169399723644935 Norm. Diff.: 0.0035856423608625204 tk: 5 x_norm: 23.722474377273674\n",
      "Iteration 2701 - Grad. Norm.: 0.0007167515899880382 Norm. Diff.: 0.003584699861822472 tk: 5 x_norm: 23.725515213056237\n",
      "Iteration 2702 - Grad. Norm.: 0.0007165633249283833 Norm. Diff.: 0.003583757949940095 tk: 5 x_norm: 23.728555231017122\n",
      "Iteration 2703 - Grad. Norm.: 0.0007163751770708919 Norm. Diff.: 0.0035828166246419674 tk: 5 x_norm: 23.73159443166366\n",
      "Iteration 2704 - Grad. Norm.: 0.0007161871463010742 Norm. Diff.: 0.0035818758853544373 tk: 5 x_norm: 23.734632815502714\n",
      "Iteration 2705 - Grad. Norm.: 0.0007159992325045931 Norm. Diff.: 0.0035809357315056824 tk: 5 x_norm: 23.737670383040648\n",
      "Iteration 2706 - Grad. Norm.: 0.00071581143556726 Norm. Diff.: 0.003579996162522852 tk: 5 x_norm: 23.740707134783317\n",
      "Iteration 2707 - Grad. Norm.: 0.0007156237553750364 Norm. Diff.: 0.0035790571778361036 tk: 5 x_norm: 23.743743071236107\n",
      "Iteration 2708 - Grad. Norm.: 0.0007154361918140314 Norm. Diff.: 0.0035781187768751245 tk: 5 x_norm: 23.74677819290391\n",
      "Iteration 2709 - Grad. Norm.: 0.0007152487447705044 Norm. Diff.: 0.0035771809590701238 tk: 5 x_norm: 23.749812500291124\n",
      "Iteration 2710 - Grad. Norm.: 0.0007150614141308643 Norm. Diff.: 0.0035762437238528915 tk: 5 x_norm: 23.752845993901644\n",
      "Iteration 2711 - Grad. Norm.: 0.0007148741997816672 Norm. Diff.: 0.003575307070654365 tk: 5 x_norm: 23.755878674238893\n",
      "Iteration 2712 - Grad. Norm.: 0.0007146871016096174 Norm. Diff.: 0.003574370998908359 tk: 5 x_norm: 23.758910541805815\n",
      "Iteration 2713 - Grad. Norm.: 0.0007145001195015689 Norm. Diff.: 0.0035734355080480106 tk: 5 x_norm: 23.761941597104826\n",
      "Iteration 2714 - Grad. Norm.: 0.0007143132533445212 Norm. Diff.: 0.0035725005975076013 tk: 5 x_norm: 23.764971840637905\n",
      "Iteration 2715 - Grad. Norm.: 0.0007141265030256213 Norm. Diff.: 0.003571566266722359 tk: 5 x_norm: 23.768001272906503\n",
      "Iteration 2716 - Grad. Norm.: 0.0007139398684321669 Norm. Diff.: 0.0035706325151278733 tk: 5 x_norm: 23.77102989441161\n",
      "Iteration 2717 - Grad. Norm.: 0.0007137533494515993 Norm. Diff.: 0.0035696993421609467 tk: 5 x_norm: 23.77405770565373\n",
      "Iteration 2718 - Grad. Norm.: 0.0007135669459715062 Norm. Diff.: 0.0035687667472580216 tk: 5 x_norm: 23.77708470713286\n",
      "Iteration 2719 - Grad. Norm.: 0.0007133806578796249 Norm. Diff.: 0.0035678347298574095 tk: 5 x_norm: 23.780110899348553\n",
      "Iteration 2720 - Grad. Norm.: 0.0007131944850638375 Norm. Diff.: 0.003566903289398018 tk: 5 x_norm: 23.783136282799838\n",
      "Iteration 2721 - Grad. Norm.: 0.0007130084274121702 Norm. Diff.: 0.0035659724253191507 tk: 5 x_norm: 23.786160857985273\n",
      "Iteration 2722 - Grad. Norm.: 0.0007128224848127997 Norm. Diff.: 0.003565042137061048 tk: 5 x_norm: 23.78918462540296\n",
      "Iteration 2723 - Grad. Norm.: 0.0007126366571540443 Norm. Diff.: 0.0035641124240638443 tk: 5 x_norm: 23.79220758555049\n",
      "Iteration 2724 - Grad. Norm.: 0.000712450944324368 Norm. Diff.: 0.0035631832857702683 tk: 5 x_norm: 23.795229738924967\n",
      "Iteration 2725 - Grad. Norm.: 0.0007122653462123815 Norm. Diff.: 0.0035622547216218356 tk: 5 x_norm: 23.79825108602305\n",
      "Iteration 2726 - Grad. Norm.: 0.0007120798627068401 Norm. Diff.: 0.003561326731061995 tk: 5 x_norm: 23.8012716273409\n",
      "Iteration 2727 - Grad. Norm.: 0.0007118944936966434 Norm. Diff.: 0.003560399313534307 tk: 5 x_norm: 23.804291363374194\n",
      "Iteration 2728 - Grad. Norm.: 0.0007117092390708342 Norm. Diff.: 0.0035594724684830854 tk: 5 x_norm: 23.807310294618127\n",
      "Iteration 2729 - Grad. Norm.: 0.0007115240987186019 Norm. Diff.: 0.0035585461953539636 tk: 5 x_norm: 23.81032842156743\n",
      "Iteration 2730 - Grad. Norm.: 0.0007113390725292786 Norm. Diff.: 0.0035576204935933043 tk: 5 x_norm: 23.81334574471635\n",
      "Iteration 2731 - Grad. Norm.: 0.0007111541603923398 Norm. Diff.: 0.0035566953626462888 tk: 5 x_norm: 23.816362264558666\n",
      "Iteration 2732 - Grad. Norm.: 0.000710969362197404 Norm. Diff.: 0.0035557708019618166 tk: 5 x_norm: 23.81937798158767\n",
      "Iteration 2733 - Grad. Norm.: 0.0007107846778342347 Norm. Diff.: 0.0035548468109872326 tk: 5 x_norm: 23.822392896296186\n",
      "Iteration 2734 - Grad. Norm.: 0.0007106001071927378 Norm. Diff.: 0.0035539233891710266 tk: 5 x_norm: 23.82540700917656\n",
      "Iteration 2735 - Grad. Norm.: 0.0007104156501629603 Norm. Diff.: 0.0035530005359636694 tk: 5 x_norm: 23.828420320720657\n",
      "Iteration 2736 - Grad. Norm.: 0.0007102313066350946 Norm. Diff.: 0.003552078250814838 tk: 5 x_norm: 23.831432831419892\n",
      "Iteration 2737 - Grad. Norm.: 0.0007100470764994726 Norm. Diff.: 0.003551156533175321 tk: 5 x_norm: 23.83444454176518\n",
      "Iteration 2738 - Grad. Norm.: 0.0007098629596465708 Norm. Diff.: 0.003550235382497554 tk: 5 x_norm: 23.837455452246985\n",
      "Iteration 2739 - Grad. Norm.: 0.000709678955967005 Norm. Diff.: 0.0035493147982328796 tk: 5 x_norm: 23.840465563355284\n",
      "Iteration 2740 - Grad. Norm.: 0.0007094950653515355 Norm. Diff.: 0.0035483947798349205 tk: 5 x_norm: 23.843474875579595\n",
      "Iteration 2741 - Grad. Norm.: 0.0007093112876910613 Norm. Diff.: 0.00354747532675747 tk: 5 x_norm: 23.846483389408956\n",
      "Iteration 2742 - Grad. Norm.: 0.0007091276228766245 Norm. Diff.: 0.003546556438455325 tk: 5 x_norm: 23.849491105331946\n",
      "Iteration 2743 - Grad. Norm.: 0.0007089440707994064 Norm. Diff.: 0.0035456381143831443 tk: 5 x_norm: 23.852498023836663\n",
      "Iteration 2744 - Grad. Norm.: 0.0007087606313507313 Norm. Diff.: 0.0035447203539966353 tk: 5 x_norm: 23.855504145410762\n",
      "Iteration 2745 - Grad. Norm.: 0.0007085773044220617 Norm. Diff.: 0.003543803156753911 tk: 5 x_norm: 23.858509470541396\n",
      "Iteration 2746 - Grad. Norm.: 0.0007083940899050012 Norm. Diff.: 0.0035428865221104728 tk: 5 x_norm: 23.861513999715267\n",
      "Iteration 2747 - Grad. Norm.: 0.0007082109876912943 Norm. Diff.: 0.003541970449524771 tk: 5 x_norm: 23.864517733418605\n",
      "Iteration 2748 - Grad. Norm.: 0.0007080279976728238 Norm. Diff.: 0.003541054938456497 tk: 5 x_norm: 23.867520672137193\n",
      "Iteration 2749 - Grad. Norm.: 0.000707845119741614 Norm. Diff.: 0.0035401399883640983 tk: 5 x_norm: 23.870522816356328\n",
      "Iteration 2750 - Grad. Norm.: 0.000707662353789826 Norm. Diff.: 0.003539225598708077 tk: 5 x_norm: 23.873524166560845\n",
      "Iteration 2751 - Grad. Norm.: 0.0007074796997097616 Norm. Diff.: 0.003538311768948878 tk: 5 x_norm: 23.87652472323513\n",
      "Iteration 2752 - Grad. Norm.: 0.0007072971573938622 Norm. Diff.: 0.0035373984985491366 tk: 5 x_norm: 23.879524486863094\n",
      "Iteration 2753 - Grad. Norm.: 0.0007071147267347067 Norm. Diff.: 0.0035364857869694655 tk: 5 x_norm: 23.882523457928173\n",
      "Iteration 2754 - Grad. Norm.: 0.0007069324076250115 Norm. Diff.: 0.0035355736336734845 tk: 5 x_norm: 23.88552163691336\n",
      "Iteration 2755 - Grad. Norm.: 0.0007067501999576343 Norm. Diff.: 0.0035346620381250604 tk: 5 x_norm: 23.88851902430118\n",
      "Iteration 2756 - Grad. Norm.: 0.0007065681036255681 Norm. Diff.: 0.003533750999788296 tk: 5 x_norm: 23.891515620573703\n",
      "Iteration 2757 - Grad. Norm.: 0.0007063861185219433 Norm. Diff.: 0.0035328405181279357 tk: 5 x_norm: 23.894511426212528\n",
      "Iteration 2758 - Grad. Norm.: 0.0007062042445400317 Norm. Diff.: 0.00353193059260952 tk: 5 x_norm: 23.897506441698802\n",
      "Iteration 2759 - Grad. Norm.: 0.0007060224815732369 Norm. Diff.: 0.003531021222699928 tk: 5 x_norm: 23.900500667513203\n",
      "Iteration 2760 - Grad. Norm.: 0.0007058408295151045 Norm. Diff.: 0.0035301124078663615 tk: 5 x_norm: 23.90349410413595\n",
      "Iteration 2761 - Grad. Norm.: 0.000705659288259315 Norm. Diff.: 0.0035292041475755796 tk: 5 x_norm: 23.906486752046835\n",
      "Iteration 2762 - Grad. Norm.: 0.0007054778576996849 Norm. Diff.: 0.003528296441296589 tk: 5 x_norm: 23.909478611725145\n",
      "Iteration 2763 - Grad. Norm.: 0.0007052965377301679 Norm. Diff.: 0.0035273892884981717 tk: 5 x_norm: 23.912469683649743\n",
      "Iteration 2764 - Grad. Norm.: 0.0007051153282448539 Norm. Diff.: 0.0035264826886509085 tk: 5 x_norm: 23.91545996829902\n",
      "Iteration 2765 - Grad. Norm.: 0.0007049342291379692 Norm. Diff.: 0.0035255766412244168 tk: 5 x_norm: 23.91844946615092\n",
      "Iteration 2766 - Grad. Norm.: 0.0007047532403038761 Norm. Diff.: 0.0035246711456897047 tk: 5 x_norm: 23.92143817768293\n",
      "Iteration 2767 - Grad. Norm.: 0.0007045723616370706 Norm. Diff.: 0.0035237662015191445 tk: 5 x_norm: 23.924426103372085\n",
      "Iteration 2768 - Grad. Norm.: 0.0007043915930321857 Norm. Diff.: 0.0035228618081854226 tk: 5 x_norm: 23.92741324369496\n",
      "Iteration 2769 - Grad. Norm.: 0.0007042109343839893 Norm. Diff.: 0.0035219579651607443 tk: 5 x_norm: 23.93039959912767\n",
      "Iteration 2770 - Grad. Norm.: 0.000704030385587385 Norm. Diff.: 0.003521054671919572 tk: 5 x_norm: 23.9333851701459\n",
      "Iteration 2771 - Grad. Norm.: 0.0007038499465374091 Norm. Diff.: 0.0035201519279367743 tk: 5 x_norm: 23.93636995722486\n",
      "Iteration 2772 - Grad. Norm.: 0.0007036696171292334 Norm. Diff.: 0.00351924973268708 tk: 5 x_norm: 23.93935396083931\n",
      "Iteration 2773 - Grad. Norm.: 0.0007034893972581665 Norm. Diff.: 0.003518348085646246 tk: 5 x_norm: 23.94233718146359\n",
      "Iteration 2774 - Grad. Norm.: 0.0007033092868196448 Norm. Diff.: 0.003517446986290568 tk: 5 x_norm: 23.945319619571542\n",
      "Iteration 2775 - Grad. Norm.: 0.0007031292857092461 Norm. Diff.: 0.003516546434098237 tk: 5 x_norm: 23.948301275636595\n",
      "Iteration 2776 - Grad. Norm.: 0.0007029493938226757 Norm. Diff.: 0.003515646428546261 tk: 5 x_norm: 23.951282150131707\n",
      "Iteration 2777 - Grad. Norm.: 0.0007027696110557756 Norm. Diff.: 0.003514746969113379 tk: 5 x_norm: 23.954262243529403\n",
      "Iteration 2778 - Grad. Norm.: 0.000702589937304521 Norm. Diff.: 0.003513848055278899 tk: 5 x_norm: 23.95724155630175\n",
      "Iteration 2779 - Grad. Norm.: 0.0007024103724650177 Norm. Diff.: 0.0035129496865227887 tk: 5 x_norm: 23.960220088920373\n",
      "Iteration 2780 - Grad. Norm.: 0.0007022309164335072 Norm. Diff.: 0.003512051862325038 tk: 5 x_norm: 23.96319784185644\n",
      "Iteration 2781 - Grad. Norm.: 0.0007020515691063621 Norm. Diff.: 0.0035111545821678056 tk: 5 x_norm: 23.96617481558069\n",
      "Iteration 2782 - Grad. Norm.: 0.0007018723303800875 Norm. Diff.: 0.0035102578455316886 tk: 5 x_norm: 23.969151010563394\n",
      "Iteration 2783 - Grad. Norm.: 0.0007016932001513203 Norm. Diff.: 0.003509361651900369 tk: 5 x_norm: 23.97212642727439\n",
      "Iteration 2784 - Grad. Norm.: 0.0007015141783168299 Norm. Diff.: 0.0035084660007563885 tk: 5 x_norm: 23.975101066183083\n",
      "Iteration 2785 - Grad. Norm.: 0.0007013352647735173 Norm. Diff.: 0.0035075708915839423 tk: 5 x_norm: 23.97807492775841\n",
      "Iteration 2786 - Grad. Norm.: 0.0007011564594184142 Norm. Diff.: 0.003506676323867704 tk: 5 x_norm: 23.981048012468886\n",
      "Iteration 2787 - Grad. Norm.: 0.000700977762148686 Norm. Diff.: 0.003505782297091985 tk: 5 x_norm: 23.98402032078256\n",
      "Iteration 2788 - Grad. Norm.: 0.000700799172861626 Norm. Diff.: 0.0035048888107435503 tk: 5 x_norm: 23.986991853167066\n",
      "Iteration 2789 - Grad. Norm.: 0.0007006206914546608 Norm. Diff.: 0.003503995864308167 tk: 5 x_norm: 23.989962610089567\n",
      "Iteration 2790 - Grad. Norm.: 0.0007004423178253459 Norm. Diff.: 0.003503103457273453 tk: 5 x_norm: 23.992932592016807\n",
      "Iteration 2791 - Grad. Norm.: 0.0007002640518713699 Norm. Diff.: 0.003502211589126485 tk: 5 x_norm: 23.995901799415083\n",
      "Iteration 2792 - Grad. Norm.: 0.0007000858934905481 Norm. Diff.: 0.003501320259356811 tk: 5 x_norm: 23.99887023275025\n",
      "Iteration 2793 - Grad. Norm.: 0.0006999078425808288 Norm. Diff.: 0.003500429467452677 tk: 5 x_norm: 24.001837892487725\n",
      "Iteration 2794 - Grad. Norm.: 0.0006997298990402892 Norm. Diff.: 0.0034995392129041243 tk: 5 x_norm: 24.004804779092478\n",
      "Iteration 2795 - Grad. Norm.: 0.0006995520627671349 Norm. Diff.: 0.003498649495201492 tk: 5 x_norm: 24.007770893029047\n",
      "Iteration 2796 - Grad. Norm.: 0.0006993743336597033 Norm. Diff.: 0.0034977603138355738 tk: 5 x_norm: 24.010736234761538\n",
      "Iteration 2797 - Grad. Norm.: 0.0006991967116164591 Norm. Diff.: 0.003496871668298162 tk: 5 x_norm: 24.013700804753615\n",
      "Iteration 2798 - Grad. Norm.: 0.0006990191965359964 Norm. Diff.: 0.0034959835580822534 tk: 5 x_norm: 24.016664603468502\n",
      "Iteration 2799 - Grad. Norm.: 0.0006988417883170395 Norm. Diff.: 0.00349509598267988 tk: 5 x_norm: 24.019627631368984\n",
      "Iteration 2800 - Grad. Norm.: 0.0006986644868584394 Norm. Diff.: 0.003494208941585204 tk: 5 x_norm: 24.022589888917423\n",
      "Iteration 2801 - Grad. Norm.: 0.0006984872920591762 Norm. Diff.: 0.003493322434292122 tk: 5 x_norm: 24.025551376575734\n",
      "Iteration 2802 - Grad. Norm.: 0.0006983102038183587 Norm. Diff.: 0.003492436460295884 tk: 5 x_norm: 24.028512094805397\n",
      "Iteration 2803 - Grad. Norm.: 0.0006981332220352246 Norm. Diff.: 0.0034915510190918144 tk: 5 x_norm: 24.031472044067467\n",
      "Iteration 2804 - Grad. Norm.: 0.0006979563466091363 Norm. Diff.: 0.0034906661101762352 tk: 5 x_norm: 24.03443122482256\n",
      "Iteration 2805 - Grad. Norm.: 0.0006977795774395865 Norm. Diff.: 0.0034897817330454186 tk: 5 x_norm: 24.037389637530868\n",
      "Iteration 2806 - Grad. Norm.: 0.0006976029144261941 Norm. Diff.: 0.0034888978871978247 tk: 5 x_norm: 24.040347282652128\n",
      "Iteration 2807 - Grad. Norm.: 0.0006974263574687065 Norm. Diff.: 0.0034880145721310676 tk: 5 x_norm: 24.04330416064567\n",
      "Iteration 2808 - Grad. Norm.: 0.0006972499064669955 Norm. Diff.: 0.0034871317873434895 tk: 5 x_norm: 24.04626027197037\n",
      "Iteration 2809 - Grad. Norm.: 0.0006970735613210633 Norm. Diff.: 0.003486249532335148 tk: 5 x_norm: 24.049215617084705\n",
      "Iteration 2810 - Grad. Norm.: 0.0006968973219310358 Norm. Diff.: 0.003485367806605014 tk: 5 x_norm: 24.05217019644669\n",
      "Iteration 2811 - Grad. Norm.: 0.000696721188197166 Norm. Diff.: 0.0034844866096552162 tk: 5 x_norm: 24.055124010513925\n",
      "Iteration 2812 - Grad. Norm.: 0.000696545160019834 Norm. Diff.: 0.003483605940985623 tk: 5 x_norm: 24.058077059743567\n",
      "Iteration 2813 - Grad. Norm.: 0.0006963692372995448 Norm. Diff.: 0.003482725800099007 tk: 5 x_norm: 24.061029344592377\n",
      "Iteration 2814 - Grad. Norm.: 0.00069619341993693 Norm. Diff.: 0.0034818461864978343 tk: 5 x_norm: 24.063980865516655\n",
      "Iteration 2815 - Grad. Norm.: 0.0006960177078327459 Norm. Diff.: 0.003480967099684691 tk: 5 x_norm: 24.066931622972294\n",
      "Iteration 2816 - Grad. Norm.: 0.0006958421008878749 Norm. Diff.: 0.0034800885391638196 tk: 5 x_norm: 24.069881617414737\n",
      "Iteration 2817 - Grad. Norm.: 0.0006956665990033252 Norm. Diff.: 0.003479210504439389 tk: 5 x_norm: 24.072830849299027\n",
      "Iteration 2818 - Grad. Norm.: 0.0006954912020802286 Norm. Diff.: 0.003478332995016689 tk: 5 x_norm: 24.075779319079775\n",
      "Iteration 2819 - Grad. Norm.: 0.0006953159100198429 Norm. Diff.: 0.0034774560104008263 tk: 5 x_norm: 24.078727027211148\n",
      "Iteration 2820 - Grad. Norm.: 0.0006951407227235487 Norm. Diff.: 0.0034765795500991837 tk: 5 x_norm: 24.081673974146906\n",
      "Iteration 2821 - Grad. Norm.: 0.0006949656400928536 Norm. Diff.: 0.00347570361361752 tk: 5 x_norm: 24.08462016034038\n",
      "Iteration 2822 - Grad. Norm.: 0.0006947906620293867 Norm. Diff.: 0.0034748282004640873 tk: 5 x_norm: 24.087565586244484\n",
      "Iteration 2823 - Grad. Norm.: 0.0006946157884349044 Norm. Diff.: 0.0034739533101468497 tk: 5 x_norm: 24.090510252311688\n",
      "Iteration 2824 - Grad. Norm.: 0.0006944410192112837 Norm. Diff.: 0.0034730789421744544 tk: 5 x_norm: 24.093454158994067\n",
      "Iteration 2825 - Grad. Norm.: 0.0006942663542605266 Norm. Diff.: 0.003472205096056458 tk: 5 x_norm: 24.09639730674326\n",
      "Iteration 2826 - Grad. Norm.: 0.0006940917934847596 Norm. Diff.: 0.0034713317713024393 tk: 5 x_norm: 24.099339696010475\n",
      "Iteration 2827 - Grad. Norm.: 0.0006939173367862304 Norm. Diff.: 0.003470458967424091 tk: 5 x_norm: 24.102281327246523\n",
      "Iteration 2828 - Grad. Norm.: 0.0006937429840673108 Norm. Diff.: 0.003469586683930864 tk: 5 x_norm: 24.105222200901768\n",
      "Iteration 2829 - Grad. Norm.: 0.0006935687352304954 Norm. Diff.: 0.003468714920336495 tk: 5 x_norm: 24.10816231742618\n",
      "Iteration 2830 - Grad. Norm.: 0.0006933945901784021 Norm. Diff.: 0.0034678436761520874 tk: 5 x_norm: 24.111101677269282\n",
      "Iteration 2831 - Grad. Norm.: 0.0006932205488137699 Norm. Diff.: 0.0034669729508921532 tk: 5 x_norm: 24.114040280880204\n",
      "Iteration 2832 - Grad. Norm.: 0.0006930466110394604 Norm. Diff.: 0.0034661027440687883 tk: 5 x_norm: 24.116978128707633\n",
      "Iteration 2833 - Grad. Norm.: 0.000692872776758459 Norm. Diff.: 0.003465233055197355 tk: 5 x_norm: 24.11991522119987\n",
      "Iteration 2834 - Grad. Norm.: 0.0006926990458738705 Norm. Diff.: 0.003464363883792405 tk: 5 x_norm: 24.122851558804772\n",
      "Iteration 2835 - Grad. Norm.: 0.0006925254182889226 Norm. Diff.: 0.0034634952293691474 tk: 5 x_norm: 24.125787141969777\n",
      "Iteration 2836 - Grad. Norm.: 0.000692351893906966 Norm. Diff.: 0.003462627091444084 tk: 5 x_norm: 24.128721971141925\n",
      "Iteration 2837 - Grad. Norm.: 0.00069217847263147 Norm. Diff.: 0.003461759469534785 tk: 5 x_norm: 24.131656046767844\n",
      "Iteration 2838 - Grad. Norm.: 0.0006920051543660257 Norm. Diff.: 0.003460892363157114 tk: 5 x_norm: 24.13458936929371\n",
      "Iteration 2839 - Grad. Norm.: 0.0006918319390143469 Norm. Diff.: 0.003460025771830259 tk: 5 x_norm: 24.13752193916532\n",
      "Iteration 2840 - Grad. Norm.: 0.000691658826480267 Norm. Diff.: 0.003459159695071452 tk: 5 x_norm: 24.140453756828073\n",
      "Iteration 2841 - Grad. Norm.: 0.0006914858166677385 Norm. Diff.: 0.003458294132401146 tk: 5 x_norm: 24.143384822726887\n",
      "Iteration 2842 - Grad. Norm.: 0.0006913129094808368 Norm. Diff.: 0.0034574290833385684 tk: 5 x_norm: 24.146315137306324\n",
      "Iteration 2843 - Grad. Norm.: 0.0006911401048237553 Norm. Diff.: 0.003456564547404409 tk: 5 x_norm: 24.149244701010524\n",
      "Iteration 2844 - Grad. Norm.: 0.0006909674026008107 Norm. Diff.: 0.0034557005241186768 tk: 5 x_norm: 24.152173514283188\n",
      "Iteration 2845 - Grad. Norm.: 0.0006907948027164362 Norm. Diff.: 0.0034548370130037267 tk: 5 x_norm: 24.155101577567653\n",
      "Iteration 2846 - Grad. Norm.: 0.0006906223050751844 Norm. Diff.: 0.003453974013582099 tk: 5 x_norm: 24.158028891306795\n",
      "Iteration 2847 - Grad. Norm.: 0.00069044990958173 Norm. Diff.: 0.0034531115253757863 tk: 5 x_norm: 24.16095545594311\n",
      "Iteration 2848 - Grad. Norm.: 0.0006902776161408654 Norm. Diff.: 0.003452249547908567 tk: 5 x_norm: 24.16388127191868\n",
      "Iteration 2849 - Grad. Norm.: 0.0006901054246575028 Norm. Diff.: 0.003451388080704328 tk: 5 x_norm: 24.166806339675162\n",
      "Iteration 2850 - Grad. Norm.: 0.0006899333350366719 Norm. Diff.: 0.003450527123287457 tk: 5 x_norm: 24.169730659653826\n",
      "Iteration 2851 - Grad. Norm.: 0.0006897613471835226 Norm. Diff.: 0.003449666675183422 tk: 5 x_norm: 24.17265423229552\n",
      "Iteration 2852 - Grad. Norm.: 0.0006895894610033222 Norm. Diff.: 0.003448806735917706 tk: 5 x_norm: 24.175577058040687\n",
      "Iteration 2853 - Grad. Norm.: 0.0006894176764014573 Norm. Diff.: 0.0034479473050166376 tk: 5 x_norm: 24.178499137329357\n",
      "Iteration 2854 - Grad. Norm.: 0.0006892459932834316 Norm. Diff.: 0.0034470883820073993 tk: 5 x_norm: 24.181420470601164\n",
      "Iteration 2855 - Grad. Norm.: 0.0006890744115548681 Norm. Diff.: 0.003446229966417134 tk: 5 x_norm: 24.184341058295328\n",
      "Iteration 2856 - Grad. Norm.: 0.0006889029311215059 Norm. Diff.: 0.0034453720577744904 tk: 5 x_norm: 24.18726090085067\n",
      "Iteration 2857 - Grad. Norm.: 0.0006887315518892034 Norm. Diff.: 0.003444514655607644 tk: 5 x_norm: 24.19017999870559\n",
      "Iteration 2858 - Grad. Norm.: 0.0006885602737639349 Norm. Diff.: 0.003443657759446101 tk: 5 x_norm: 24.193098352298104\n",
      "Iteration 2859 - Grad. Norm.: 0.0006883890966517931 Norm. Diff.: 0.0034428013688197943 tk: 5 x_norm: 24.196015962065815\n",
      "Iteration 2860 - Grad. Norm.: 0.0006882180204589874 Norm. Diff.: 0.003441945483259266 tk: 5 x_norm: 24.198932828445905\n",
      "Iteration 2861 - Grad. Norm.: 0.0006880470450918431 Norm. Diff.: 0.003441090102294765 tk: 5 x_norm: 24.201848951875185\n",
      "Iteration 2862 - Grad. Norm.: 0.000687876170456804 Norm. Diff.: 0.00344023522545914 tk: 5 x_norm: 24.20476433279004\n",
      "Iteration 2863 - Grad. Norm.: 0.0006877053964604287 Norm. Diff.: 0.003439380852284202 tk: 5 x_norm: 24.207678971626457\n",
      "Iteration 2864 - Grad. Norm.: 0.0006875347230093936 Norm. Diff.: 0.0034385269823021306 tk: 5 x_norm: 24.21059286882003\n",
      "Iteration 2865 - Grad. Norm.: 0.0006873641500104893 Norm. Diff.: 0.003437673615046977 tk: 5 x_norm: 24.213506024805937\n",
      "Iteration 2866 - Grad. Norm.: 0.0006871936773706247 Norm. Diff.: 0.0034368207500524604 tk: 5 x_norm: 24.216418440018966\n",
      "Iteration 2867 - Grad. Norm.: 0.0006870233049968229 Norm. Diff.: 0.0034359683868533187 tk: 5 x_norm: 24.21933011489351\n",
      "Iteration 2868 - Grad. Norm.: 0.0006868530327962225 Norm. Diff.: 0.003435116524984158 tk: 5 x_norm: 24.222241049863538\n",
      "Iteration 2869 - Grad. Norm.: 0.0006866828606760788 Norm. Diff.: 0.0034342651639809583 tk: 5 x_norm: 24.225151245362643\n",
      "Iteration 2870 - Grad. Norm.: 0.0006865127885437616 Norm. Diff.: 0.0034334143033805864 tk: 5 x_norm: 24.228060701824013\n",
      "Iteration 2871 - Grad. Norm.: 0.0006863428163067552 Norm. Diff.: 0.003432563942718663 tk: 5 x_norm: 24.230969419680438\n",
      "Iteration 2872 - Grad. Norm.: 0.0006861729438726585 Norm. Diff.: 0.0034317140815337366 tk: 5 x_norm: 24.233877399364307\n",
      "Iteration 2873 - Grad. Norm.: 0.0006860031711491884 Norm. Diff.: 0.0034308647193629846 tk: 5 x_norm: 24.236784641307604\n",
      "Iteration 2874 - Grad. Norm.: 0.000685833498044172 Norm. Diff.: 0.003430015855745824 tk: 5 x_norm: 24.239691145941936\n",
      "Iteration 2875 - Grad. Norm.: 0.0006856639244655525 Norm. Diff.: 0.0034291674902206964 tk: 5 x_norm: 24.242596913698492\n",
      "Iteration 2876 - Grad. Norm.: 0.0006854944503213885 Norm. Diff.: 0.003428319622328006 tk: 5 x_norm: 24.245501945008094\n",
      "Iteration 2877 - Grad. Norm.: 0.0006853250755198501 Norm. Diff.: 0.0034274722516071335 tk: 5 x_norm: 24.248406240301136\n",
      "Iteration 2878 - Grad. Norm.: 0.0006851557999692251 Norm. Diff.: 0.003426625377599285 tk: 5 x_norm: 24.251309800007633\n",
      "Iteration 2879 - Grad. Norm.: 0.0006849866235779093 Norm. Diff.: 0.003425778999845773 tk: 5 x_norm: 24.25421262455721\n",
      "Iteration 2880 - Grad. Norm.: 0.0006848175462544167 Norm. Diff.: 0.0034249331178896297 tk: 5 x_norm: 24.257114714379078\n",
      "Iteration 2881 - Grad. Norm.: 0.0006846485679073743 Norm. Diff.: 0.0034240877312719806 tk: 5 x_norm: 24.260016069902086\n",
      "Iteration 2882 - Grad. Norm.: 0.0006844796884455186 Norm. Diff.: 0.0034232428395369148 tk: 5 x_norm: 24.262916691554665\n",
      "Iteration 2883 - Grad. Norm.: 0.0006843109077777021 Norm. Diff.: 0.0034223984422277897 tk: 5 x_norm: 24.26581657976486\n",
      "Iteration 2884 - Grad. Norm.: 0.0006841422258128901 Norm. Diff.: 0.003421554538888391 tk: 5 x_norm: 24.268715734960335\n",
      "Iteration 2885 - Grad. Norm.: 0.0006839736424601594 Norm. Diff.: 0.0034207111290645467 tk: 5 x_norm: 24.271614157568333\n",
      "Iteration 2886 - Grad. Norm.: 0.0006838051576287 Norm. Diff.: 0.003419868212300718 tk: 5 x_norm: 24.27451184801574\n",
      "Iteration 2887 - Grad. Norm.: 0.0006836367712278127 Norm. Diff.: 0.003419025788143548 tk: 5 x_norm: 24.277408806729046\n",
      "Iteration 2888 - Grad. Norm.: 0.0006834684831669113 Norm. Diff.: 0.0034181838561389405 tk: 5 x_norm: 24.280305034134322\n",
      "Iteration 2889 - Grad. Norm.: 0.0006833002933555243 Norm. Diff.: 0.0034173424158346747 tk: 5 x_norm: 24.28320053065729\n",
      "Iteration 2890 - Grad. Norm.: 0.0006831322017032866 Norm. Diff.: 0.003416501466777601 tk: 5 x_norm: 24.286095296723243\n",
      "Iteration 2891 - Grad. Norm.: 0.0006829642081199473 Norm. Diff.: 0.0034156610085163703 tk: 5 x_norm: 24.28898933275712\n",
      "Iteration 2892 - Grad. Norm.: 0.000682796312515369 Norm. Diff.: 0.0034148210405995543 tk: 5 x_norm: 24.291882639183445\n",
      "Iteration 2893 - Grad. Norm.: 0.0006826285147995225 Norm. Diff.: 0.0034139815625767477 tk: 5 x_norm: 24.294775216426377\n",
      "Iteration 2894 - Grad. Norm.: 0.0006824608148824896 Norm. Diff.: 0.0034131425739977934 tk: 5 x_norm: 24.297667064909678\n",
      "Iteration 2895 - Grad. Norm.: 0.0006822932126744646 Norm. Diff.: 0.0034123040744127634 tk: 5 x_norm: 24.30055818505672\n",
      "Iteration 2896 - Grad. Norm.: 0.0006821257080857526 Norm. Diff.: 0.0034114660633721874 tk: 5 x_norm: 24.303448577290485\n",
      "Iteration 2897 - Grad. Norm.: 0.0006819583010267677 Norm. Diff.: 0.003410628540428623 tk: 5 x_norm: 24.306338242033583\n",
      "Iteration 2898 - Grad. Norm.: 0.0006817909914080354 Norm. Diff.: 0.003409791505133982 tk: 5 x_norm: 24.309227179708227\n",
      "Iteration 2899 - Grad. Norm.: 0.0006816237791401918 Norm. Diff.: 0.003408954957040029 tk: 5 x_norm: 24.312115390736256\n",
      "Iteration 2900 - Grad. Norm.: 0.0006814566641339816 Norm. Diff.: 0.0034081188957011043 tk: 5 x_norm: 24.31500287553912\n",
      "Iteration 2901 - Grad. Norm.: 0.0006812896463002612 Norm. Diff.: 0.003407283320669971 tk: 5 x_norm: 24.317889634537867\n",
      "Iteration 2902 - Grad. Norm.: 0.0006811227255499948 Norm. Diff.: 0.003406448231501301 tk: 5 x_norm: 24.320775668153203\n",
      "Iteration 2903 - Grad. Norm.: 0.000680955901794257 Norm. Diff.: 0.003405613627749893 tk: 5 x_norm: 24.3236609768054\n",
      "Iteration 2904 - Grad. Norm.: 0.0006807891749442323 Norm. Diff.: 0.0034047795089710516 tk: 5 x_norm: 24.326545560914397\n",
      "Iteration 2905 - Grad. Norm.: 0.0006806225449112142 Norm. Diff.: 0.00340394587472126 tk: 5 x_norm: 24.32942942089972\n",
      "Iteration 2906 - Grad. Norm.: 0.000680456011606604 Norm. Diff.: 0.00340311272455602 tk: 5 x_norm: 24.33231255718053\n",
      "Iteration 2907 - Grad. Norm.: 0.0006802895749419131 Norm. Diff.: 0.0034022800580328252 tk: 5 x_norm: 24.33519497017558\n",
      "Iteration 2908 - Grad. Norm.: 0.000680123234828762 Norm. Diff.: 0.003401447874709692 tk: 5 x_norm: 24.338076660303273\n",
      "Iteration 2909 - Grad. Norm.: 0.0006799569911788783 Norm. Diff.: 0.0034006161741437853 tk: 5 x_norm: 24.34095762798162\n",
      "Iteration 2910 - Grad. Norm.: 0.0006797908439040975 Norm. Diff.: 0.0033997849558942378 tk: 5 x_norm: 24.34383787362826\n",
      "Iteration 2911 - Grad. Norm.: 0.0006796247929163667 Norm. Diff.: 0.0033989542195206383 tk: 5 x_norm: 24.34671739766043\n",
      "Iteration 2912 - Grad. Norm.: 0.0006794588381277373 Norm. Diff.: 0.0033981239645819107 tk: 5 x_norm: 24.34959620049502\n",
      "Iteration 2913 - Grad. Norm.: 0.00067929297945037 Norm. Diff.: 0.0033972941906389815 tk: 5 x_norm: 24.352474282548517\n",
      "Iteration 2914 - Grad. Norm.: 0.0006791272167965348 Norm. Diff.: 0.003396464897252079 tk: 5 x_norm: 24.35535164423704\n",
      "Iteration 2915 - Grad. Norm.: 0.0006789615500786054 Norm. Diff.: 0.0033956360839826312 tk: 5 x_norm: 24.35822828597633\n",
      "Iteration 2916 - Grad. Norm.: 0.0006787959792090666 Norm. Diff.: 0.00339480775039286 tk: 5 x_norm: 24.361104208181757\n",
      "Iteration 2917 - Grad. Norm.: 0.0006786305041005084 Norm. Diff.: 0.0033939798960453465 tk: 5 x_norm: 24.363979411268303\n",
      "Iteration 2918 - Grad. Norm.: 0.0006784651246656288 Norm. Diff.: 0.003393152520502443 tk: 5 x_norm: 24.36685389565058\n",
      "Iteration 2919 - Grad. Norm.: 0.0006782998408172326 Norm. Diff.: 0.0033923256233278345 tk: 5 x_norm: 24.36972766174283\n",
      "Iteration 2920 - Grad. Norm.: 0.0006781346524682295 Norm. Diff.: 0.003391499204086166 tk: 5 x_norm: 24.37260070995891\n",
      "Iteration 2921 - Grad. Norm.: 0.0006779695595316383 Norm. Diff.: 0.003390673262341219 tk: 5 x_norm: 24.37547304071231\n",
      "Iteration 2922 - Grad. Norm.: 0.000677804561920583 Norm. Diff.: 0.00338984779765845 tk: 5 x_norm: 24.37834465441615\n",
      "Iteration 2923 - Grad. Norm.: 0.000677639659548294 Norm. Diff.: 0.003389022809603023 tk: 5 x_norm: 24.381215551483155\n",
      "Iteration 2924 - Grad. Norm.: 0.0006774748523281076 Norm. Diff.: 0.0033881982977413154 tk: 5 x_norm: 24.384085732325705\n",
      "Iteration 2925 - Grad. Norm.: 0.0006773101401734658 Norm. Diff.: 0.003387374261640388 tk: 5 x_norm: 24.386955197355796\n",
      "Iteration 2926 - Grad. Norm.: 0.000677145522997917 Norm. Diff.: 0.0033865507008674217 tk: 5 x_norm: 24.389823946985025\n",
      "Iteration 2927 - Grad. Norm.: 0.000676981000715116 Norm. Diff.: 0.0033857276149895222 tk: 5 x_norm: 24.39269198162468\n",
      "Iteration 2928 - Grad. Norm.: 0.0006768165732388198 Norm. Diff.: 0.0033849050035754473 tk: 5 x_norm: 24.395559301685616\n",
      "Iteration 2929 - Grad. Norm.: 0.0006766522404828941 Norm. Diff.: 0.003384082866194112 tk: 5 x_norm: 24.398425907578343\n",
      "Iteration 2930 - Grad. Norm.: 0.0006764880023613076 Norm. Diff.: 0.0033832612024143273 tk: 5 x_norm: 24.401291799713004\n",
      "Iteration 2931 - Grad. Norm.: 0.0006763238587881356 Norm. Diff.: 0.0033824400118063415 tk: 5 x_norm: 24.40415697849936\n",
      "Iteration 2932 - Grad. Norm.: 0.000676159809677557 Norm. Diff.: 0.003381619293940794 tk: 5 x_norm: 24.407021444346828\n",
      "Iteration 2933 - Grad. Norm.: 0.0006759958549438557 Norm. Diff.: 0.0033807990483879003 tk: 5 x_norm: 24.409885197664426\n",
      "Iteration 2934 - Grad. Norm.: 0.0006758319945014187 Norm. Diff.: 0.0033799792747191255 tk: 5 x_norm: 24.412748238860804\n",
      "Iteration 2935 - Grad. Norm.: 0.0006756682282647409 Norm. Diff.: 0.003379159972507091 tk: 5 x_norm: 24.41561056834427\n",
      "Iteration 2936 - Grad. Norm.: 0.0006755045561484173 Norm. Diff.: 0.0033783411413237274 tk: 5 x_norm: 24.41847218652275\n",
      "Iteration 2937 - Grad. Norm.: 0.0006753409780671487 Norm. Diff.: 0.003377522780742131 tk: 5 x_norm: 24.421333093803792\n",
      "Iteration 2938 - Grad. Norm.: 0.0006751774939357396 Norm. Diff.: 0.0033767048903358744 tk: 5 x_norm: 24.424193290594598\n",
      "Iteration 2939 - Grad. Norm.: 0.0006750141036691 Norm. Diff.: 0.0033758874696786624 tk: 5 x_norm: 24.427052777301988\n",
      "Iteration 2940 - Grad. Norm.: 0.0006748508071822403 Norm. Diff.: 0.0033750705183454997 tk: 5 x_norm: 24.42991155433242\n",
      "Iteration 2941 - Grad. Norm.: 0.0006746876043902761 Norm. Diff.: 0.0033742540359112034 tk: 5 x_norm: 24.43276962209199\n",
      "Iteration 2942 - Grad. Norm.: 0.0006745244952084249 Norm. Diff.: 0.0033734380219511157 tk: 5 x_norm: 24.435626980986434\n",
      "Iteration 2943 - Grad. Norm.: 0.0006743614795520086 Norm. Diff.: 0.0033726224760420613 tk: 5 x_norm: 24.4384836314211\n",
      "Iteration 2944 - Grad. Norm.: 0.0006741985573364527 Norm. Diff.: 0.0033718073977600563 tk: 5 x_norm: 24.441339573801006\n",
      "Iteration 2945 - Grad. Norm.: 0.0006740357284772824 Norm. Diff.: 0.0033709927866820305 tk: 5 x_norm: 24.444194808530778\n",
      "Iteration 2946 - Grad. Norm.: 0.0006738729928901284 Norm. Diff.: 0.0033701786423866063 tk: 5 x_norm: 24.4470493360147\n",
      "Iteration 2947 - Grad. Norm.: 0.0006737103504907226 Norm. Diff.: 0.0033693649644505616 tk: 5 x_norm: 24.449903156656674\n",
      "Iteration 2948 - Grad. Norm.: 0.0006735478011948994 Norm. Diff.: 0.0033685517524536116 tk: 5 x_norm: 24.452756270860245\n",
      "Iteration 2949 - Grad. Norm.: 0.000673385344918595 Norm. Diff.: 0.0033677390059744772 tk: 5 x_norm: 24.455608679028614\n",
      "Iteration 2950 - Grad. Norm.: 0.0006732229815778477 Norm. Diff.: 0.0033669267245931005 tk: 5 x_norm: 24.458460381564596\n",
      "Iteration 2951 - Grad. Norm.: 0.0006730607110887991 Norm. Diff.: 0.0033661149078892593 tk: 5 x_norm: 24.46131137887065\n",
      "Iteration 2952 - Grad. Norm.: 0.0006728985333676893 Norm. Diff.: 0.003365303555444089 tk: 5 x_norm: 24.4641616713489\n",
      "Iteration 2953 - Grad. Norm.: 0.0006727364483308636 Norm. Diff.: 0.003364492666838505 tk: 5 x_norm: 24.467011259401072\n",
      "Iteration 2954 - Grad. Norm.: 0.0006725744558947648 Norm. Diff.: 0.0033636822416542858 tk: 5 x_norm: 24.46986014342857\n",
      "Iteration 2955 - Grad. Norm.: 0.0006724125559759407 Norm. Diff.: 0.003362872279473564 tk: 5 x_norm: 24.472708323832386\n",
      "Iteration 2956 - Grad. Norm.: 0.0006722507484910364 Norm. Diff.: 0.0033620627798795822 tk: 5 x_norm: 24.47555580101322\n",
      "Iteration 2957 - Grad. Norm.: 0.000672089033356802 Norm. Diff.: 0.003361253742455171 tk: 5 x_norm: 24.47840257537136\n",
      "Iteration 2958 - Grad. Norm.: 0.0006719274104900844 Norm. Diff.: 0.003360445166783901 tk: 5 x_norm: 24.481248647306757\n",
      "Iteration 2959 - Grad. Norm.: 0.0006717658798078338 Norm. Diff.: 0.0033596370524506024 tk: 5 x_norm: 24.484094017219018\n",
      "Iteration 2960 - Grad. Norm.: 0.000671604441227101 Norm. Diff.: 0.00335882939903948 tk: 5 x_norm: 24.486938685507365\n",
      "Iteration 2961 - Grad. Norm.: 0.0006714430946650336 Norm. Diff.: 0.0033580222061356945 tk: 5 x_norm: 24.489782652570682\n",
      "Iteration 2962 - Grad. Norm.: 0.000671281840038883 Norm. Diff.: 0.003357215473325402 tk: 5 x_norm: 24.492625918807484\n",
      "Iteration 2963 - Grad. Norm.: 0.0006711206772659995 Norm. Diff.: 0.0033564092001945084 tk: 5 x_norm: 24.49546848461595\n",
      "Iteration 2964 - Grad. Norm.: 0.0006709596062638339 Norm. Diff.: 0.0033556033863301605 tk: 5 x_norm: 24.49831035039389\n",
      "Iteration 2965 - Grad. Norm.: 0.000670798626949934 Norm. Diff.: 0.0033547980313190407 tk: 5 x_norm: 24.50115151653875\n",
      "Iteration 2966 - Grad. Norm.: 0.0006706377392419495 Norm. Diff.: 0.003353993134749477 tk: 5 x_norm: 24.50399198344765\n",
      "Iteration 2967 - Grad. Norm.: 0.0006704769430576302 Norm. Diff.: 0.0033531886962098697 tk: 5 x_norm: 24.50683175151732\n",
      "Iteration 2968 - Grad. Norm.: 0.0006703162383148227 Norm. Diff.: 0.003352384715288239 tk: 5 x_norm: 24.50967082114416\n",
      "Iteration 2969 - Grad. Norm.: 0.000670155624931475 Norm. Diff.: 0.003351581191574056 tk: 5 x_norm: 24.512509192724224\n",
      "Iteration 2970 - Grad. Norm.: 0.0006699951028256328 Norm. Diff.: 0.003350778124657288 tk: 5 x_norm: 24.515346866653186\n",
      "Iteration 2971 - Grad. Norm.: 0.0006698346719154402 Norm. Diff.: 0.003349975514128355 tk: 5 x_norm: 24.518183843326383\n",
      "Iteration 2972 - Grad. Norm.: 0.0006696743321191408 Norm. Diff.: 0.0033491733595773497 tk: 5 x_norm: 24.521020123138815\n",
      "Iteration 2973 - Grad. Norm.: 0.000669514083355077 Norm. Diff.: 0.0033483716605957337 tk: 5 x_norm: 24.523855706485094\n",
      "Iteration 2974 - Grad. Norm.: 0.0006693539255416883 Norm. Diff.: 0.003347570416775534 tk: 5 x_norm: 24.526690593759515\n",
      "Iteration 2975 - Grad. Norm.: 0.0006691938585975137 Norm. Diff.: 0.0033467696277083903 tk: 5 x_norm: 24.52952478535601\n",
      "Iteration 2976 - Grad. Norm.: 0.0006690338824411889 Norm. Diff.: 0.003345969292987227 tk: 5 x_norm: 24.532358281668156\n",
      "Iteration 2977 - Grad. Norm.: 0.0006688739969914489 Norm. Diff.: 0.0033451694122060734 tk: 5 x_norm: 24.53519108308919\n",
      "Iteration 2978 - Grad. Norm.: 0.0006687142021671253 Norm. Diff.: 0.0033443699849572033 tk: 5 x_norm: 24.538023190011987\n",
      "Iteration 2979 - Grad. Norm.: 0.0006685544978871481 Norm. Diff.: 0.0033435710108357416 tk: 5 x_norm: 24.54085460282908\n",
      "Iteration 2980 - Grad. Norm.: 0.0006683948840705452 Norm. Diff.: 0.003342772489435634 tk: 5 x_norm: 24.543685321932657\n",
      "Iteration 2981 - Grad. Norm.: 0.0006682353606364412 Norm. Diff.: 0.0033419744203528954 tk: 5 x_norm: 24.546515347714564\n",
      "Iteration 2982 - Grad. Norm.: 0.0006680759275040572 Norm. Diff.: 0.003341176803182163 tk: 5 x_norm: 24.54934468056627\n",
      "Iteration 2983 - Grad. Norm.: 0.0006679165845927116 Norm. Diff.: 0.0033403796375204133 tk: 5 x_norm: 24.55217332087893\n",
      "Iteration 2984 - Grad. Norm.: 0.0006677573318218207 Norm. Diff.: 0.0033395829229634693 tk: 5 x_norm: 24.555001269043338\n",
      "Iteration 2985 - Grad. Norm.: 0.0006675981691108968 Norm. Diff.: 0.0033387866591091404 tk: 5 x_norm: 24.557828525449946\n",
      "Iteration 2986 - Grad. Norm.: 0.0006674390963795493 Norm. Diff.: 0.0033379908455545364 tk: 5 x_norm: 24.560655090488847\n",
      "Iteration 2987 - Grad. Norm.: 0.0006672801135474838 Norm. Diff.: 0.003337195481897823 tk: 5 x_norm: 24.5634809645498\n",
      "Iteration 2988 - Grad. Norm.: 0.0006671212205345014 Norm. Diff.: 0.0033364005677375347 tk: 5 x_norm: 24.566306148022218\n",
      "Iteration 2989 - Grad. Norm.: 0.0006669624172605008 Norm. Diff.: 0.0033356061026723937 tk: 5 x_norm: 24.56913064129518\n",
      "Iteration 2990 - Grad. Norm.: 0.0006668037036454755 Norm. Diff.: 0.0033348120863022266 tk: 5 x_norm: 24.5719544447574\n",
      "Iteration 2991 - Grad. Norm.: 0.0006666450796095153 Norm. Diff.: 0.0033340185182273306 tk: 5 x_norm: 24.574777558797237\n",
      "Iteration 2992 - Grad. Norm.: 0.0006664865450728069 Norm. Diff.: 0.0033332253980473225 tk: 5 x_norm: 24.577599983802756\n",
      "Iteration 2993 - Grad. Norm.: 0.0006663280999556302 Norm. Diff.: 0.003332432725364361 tk: 5 x_norm: 24.580421720161638\n",
      "Iteration 2994 - Grad. Norm.: 0.000666169744178363 Norm. Diff.: 0.003331640499778184 tk: 5 x_norm: 24.583242768261233\n",
      "Iteration 2995 - Grad. Norm.: 0.0006660114776614773 Norm. Diff.: 0.0033308487208918423 tk: 5 x_norm: 24.586063128488544\n",
      "Iteration 2996 - Grad. Norm.: 0.000665853300325539 Norm. Diff.: 0.003330057388307186 tk: 5 x_norm: 24.58888280123024\n",
      "Iteration 2997 - Grad. Norm.: 0.0006656952120912116 Norm. Diff.: 0.0033292665016276296 tk: 5 x_norm: 24.591701786872648\n",
      "Iteration 2998 - Grad. Norm.: 0.0006655372128792518 Norm. Diff.: 0.0033284760604561114 tk: 5 x_norm: 24.594520085801744\n",
      "Iteration 2999 - Grad. Norm.: 0.0006653793026105117 Norm. Diff.: 0.0033276860643962933 tk: 5 x_norm: 24.597337698403177\n",
      "Iteration 3000 - Grad. Norm.: 0.0006652214812059375 Norm. Diff.: 0.0033268965130525854 tk: 5 x_norm: 24.600154625062242\n",
      "Iteration 3001 - Grad. Norm.: 0.0006650637485865706 Norm. Diff.: 0.0033261074060300165 tk: 5 x_norm: 24.602970866163915\n",
      "Iteration 3002 - Grad. Norm.: 0.0006649061046735458 Norm. Diff.: 0.003325318742932945 tk: 5 x_norm: 24.605786422092798\n",
      "Iteration 3003 - Grad. Norm.: 0.0006647485493880929 Norm. Diff.: 0.003324530523367602 tk: 5 x_norm: 24.60860129323319\n",
      "Iteration 3004 - Grad. Norm.: 0.0006645910826515354 Norm. Diff.: 0.003323742746940487 tk: 5 x_norm: 24.61141547996903\n",
      "Iteration 3005 - Grad. Norm.: 0.000664433704385291 Norm. Diff.: 0.0033229554132578536 tk: 5 x_norm: 24.614228982683926\n",
      "Iteration 3006 - Grad. Norm.: 0.0006642764145108693 Norm. Diff.: 0.0033221685219267543 tk: 5 x_norm: 24.61704180176115\n",
      "Iteration 3007 - Grad. Norm.: 0.0006641192129498783 Norm. Diff.: 0.0033213820725540508 tk: 5 x_norm: 24.61985393758363\n",
      "Iteration 3008 - Grad. Norm.: 0.0006639620996240137 Norm. Diff.: 0.0033205960647493212 tk: 5 x_norm: 24.622665390533975\n",
      "Iteration 3009 - Grad. Norm.: 0.0006638050744550677 Norm. Diff.: 0.003319810498119881 tk: 5 x_norm: 24.62547616099442\n",
      "Iteration 3010 - Grad. Norm.: 0.0006636481373649263 Norm. Diff.: 0.003319025372275653 tk: 5 x_norm: 24.628286249346903\n",
      "Iteration 3011 - Grad. Norm.: 0.0006634912882755653 Norm. Diff.: 0.0033182406868246484 tk: 5 x_norm: 24.631095655973002\n",
      "Iteration 3012 - Grad. Norm.: 0.000663334527109058 Norm. Diff.: 0.003317456441377873 tk: 5 x_norm: 24.633904381253974\n",
      "Iteration 3013 - Grad. Norm.: 0.0006631778537875677 Norm. Diff.: 0.0033166726355453586 tk: 5 x_norm: 24.63671242557073\n",
      "Iteration 3014 - Grad. Norm.: 0.0006630212682333498 Norm. Diff.: 0.0033158892689379425 tk: 5 x_norm: 24.639519789303865\n",
      "Iteration 3015 - Grad. Norm.: 0.0006628647703687536 Norm. Diff.: 0.003315106341166523 tk: 5 x_norm: 24.64232647283361\n",
      "Iteration 3016 - Grad. Norm.: 0.0006627083601162209 Norm. Diff.: 0.0033143238518437527 tk: 5 x_norm: 24.645132476539878\n",
      "Iteration 3017 - Grad. Norm.: 0.0006625520373982841 Norm. Diff.: 0.0033135418005808747 tk: 5 x_norm: 24.647937800802257\n",
      "Iteration 3018 - Grad. Norm.: 0.0006623958021375704 Norm. Diff.: 0.0033127601869911366 tk: 5 x_norm: 24.650742446\n",
      "Iteration 3019 - Grad. Norm.: 0.0006622396542567973 Norm. Diff.: 0.0033119790106875637 tk: 5 x_norm: 24.653546412512007\n",
      "Iteration 3020 - Grad. Norm.: 0.000662083593678773 Norm. Diff.: 0.003311198271284033 tk: 5 x_norm: 24.65634970071687\n",
      "Iteration 3021 - Grad. Norm.: 0.0006619276203263998 Norm. Diff.: 0.0033104179683937896 tk: 5 x_norm: 24.659152310992834\n",
      "Iteration 3022 - Grad. Norm.: 0.00066177173412267 Norm. Diff.: 0.003309638101632061 tk: 5 x_norm: 24.661954243717826\n",
      "Iteration 3023 - Grad. Norm.: 0.0006616159349906695 Norm. Diff.: 0.003308858670613355 tk: 5 x_norm: 24.66475549926943\n",
      "Iteration 3024 - Grad. Norm.: 0.0006614602228535709 Norm. Diff.: 0.0033080796749534905 tk: 5 x_norm: 24.667556078024898\n",
      "Iteration 3025 - Grad. Norm.: 0.0006613045976346432 Norm. Diff.: 0.003307301114267846 tk: 5 x_norm: 24.67035598036116\n",
      "Iteration 3026 - Grad. Norm.: 0.0006611490592572436 Norm. Diff.: 0.003306522988173247 tk: 5 x_norm: 24.673155206654823\n",
      "Iteration 3027 - Grad. Norm.: 0.0006609936076448208 Norm. Diff.: 0.0033057452962864586 tk: 5 x_norm: 24.675953757282144\n",
      "Iteration 3028 - Grad. Norm.: 0.0006608382427209132 Norm. Diff.: 0.003304968038223845 tk: 5 x_norm: 24.678751632619065\n",
      "Iteration 3029 - Grad. Norm.: 0.0006606829644091534 Norm. Diff.: 0.003304191213604538 tk: 5 x_norm: 24.6815488330412\n",
      "Iteration 3030 - Grad. Norm.: 0.0006605277726332586 Norm. Diff.: 0.0033034148220458756 tk: 5 x_norm: 24.684345358923824\n",
      "Iteration 3031 - Grad. Norm.: 0.000660372667317044 Norm. Diff.: 0.003302638863166323 tk: 5 x_norm: 24.687141210641897\n",
      "Iteration 3032 - Grad. Norm.: 0.0006602176483844065 Norm. Diff.: 0.003301863336585052 tk: 5 x_norm: 24.68993638857005\n",
      "Iteration 3033 - Grad. Norm.: 0.0006600627157593396 Norm. Diff.: 0.0033010882419221062 tk: 5 x_norm: 24.692730893082572\n",
      "Iteration 3034 - Grad. Norm.: 0.0006599078693659248 Norm. Diff.: 0.003300313578796779 tk: 5 x_norm: 24.69552472455344\n",
      "Iteration 3035 - Grad. Norm.: 0.0006597531091283315 Norm. Diff.: 0.0032995393468298064 tk: 5 x_norm: 24.69831788335631\n",
      "Iteration 3036 - Grad. Norm.: 0.0006595984349708228 Norm. Diff.: 0.003298765545641908 tk: 5 x_norm: 24.70111036986448\n",
      "Iteration 3037 - Grad. Norm.: 0.0006594438468177471 Norm. Diff.: 0.0032979921748539937 tk: 5 x_norm: 24.703902184450975\n",
      "Iteration 3038 - Grad. Norm.: 0.0006592893445935451 Norm. Diff.: 0.00329721923408839 tk: 5 x_norm: 24.70669332748844\n",
      "Iteration 3039 - Grad. Norm.: 0.0006591349282227463 Norm. Diff.: 0.0032964467229676985 tk: 5 x_norm: 24.709483799349236\n",
      "Iteration 3040 - Grad. Norm.: 0.0006589805976299685 Norm. Diff.: 0.003295674641113953 tk: 5 x_norm: 24.712273600405375\n",
      "Iteration 3041 - Grad. Norm.: 0.0006588263527399191 Norm. Diff.: 0.0032949029881499106 tk: 5 x_norm: 24.715062731028564\n",
      "Iteration 3042 - Grad. Norm.: 0.0006586721934773936 Norm. Diff.: 0.003294131763699565 tk: 5 x_norm: 24.71785119159016\n",
      "Iteration 3043 - Grad. Norm.: 0.0006585181197672792 Norm. Diff.: 0.0032933609673870667 tk: 5 x_norm: 24.720638982461224\n",
      "Iteration 3044 - Grad. Norm.: 0.0006583641315345477 Norm. Diff.: 0.003292590598836512 tk: 5 x_norm: 24.723426104012486\n",
      "Iteration 3045 - Grad. Norm.: 0.0006582102287042616 Norm. Diff.: 0.0032918206576728324 tk: 5 x_norm: 24.726212556614342\n",
      "Iteration 3046 - Grad. Norm.: 0.0006580564112015724 Norm. Diff.: 0.0032910511435210563 tk: 5 x_norm: 24.72899834063688\n",
      "Iteration 3047 - Grad. Norm.: 0.0006579026789517184 Norm. Diff.: 0.0032902820560081264 tk: 5 x_norm: 24.731783456449865\n",
      "Iteration 3048 - Grad. Norm.: 0.0006577490318800273 Norm. Diff.: 0.0032895133947586676 tk: 5 x_norm: 24.734567904422725\n",
      "Iteration 3049 - Grad. Norm.: 0.0006575954699119134 Norm. Diff.: 0.003288745159400154 tk: 5 x_norm: 24.737351684924583\n",
      "Iteration 3050 - Grad. Norm.: 0.0006574419929728806 Norm. Diff.: 0.0032879773495596096 tk: 5 x_norm: 24.74013479832424\n",
      "Iteration 3051 - Grad. Norm.: 0.0006572886009885185 Norm. Diff.: 0.0032872099648640425 tk: 5 x_norm: 24.74291724499018\n",
      "Iteration 3052 - Grad. Norm.: 0.0006571352938845057 Norm. Diff.: 0.003286443004942593 tk: 5 x_norm: 24.745699025290556\n",
      "Iteration 3053 - Grad. Norm.: 0.000656982071586609 Norm. Diff.: 0.003285676469422324 tk: 5 x_norm: 24.748480139593195\n",
      "Iteration 3054 - Grad. Norm.: 0.0006568289340206801 Norm. Diff.: 0.003284910357933152 tk: 5 x_norm: 24.75126058826563\n",
      "Iteration 3055 - Grad. Norm.: 0.0006566758811126602 Norm. Diff.: 0.003284144670103226 tk: 5 x_norm: 24.754040371675057\n",
      "Iteration 3056 - Grad. Norm.: 0.0006565229127885771 Norm. Diff.: 0.003283379405563725 tk: 5 x_norm: 24.75681949018837\n",
      "Iteration 3057 - Grad. Norm.: 0.000656370028974546 Norm. Diff.: 0.003282614563942763 tk: 5 x_norm: 24.759597944172107\n",
      "Iteration 3058 - Grad. Norm.: 0.0006562172295967667 Norm. Diff.: 0.003281850144872648 tk: 5 x_norm: 24.76237573399254\n",
      "Iteration 3059 - Grad. Norm.: 0.000656064514581528 Norm. Diff.: 0.0032810861479836907 tk: 5 x_norm: 24.765152860015583\n",
      "Iteration 3060 - Grad. Norm.: 0.0006559118838552052 Norm. Diff.: 0.0032803225729075465 tk: 5 x_norm: 24.767929322606868\n",
      "Iteration 3061 - Grad. Norm.: 0.000655759337344259 Norm. Diff.: 0.0032795594192758055 tk: 5 x_norm: 24.77070512213167\n",
      "Iteration 3062 - Grad. Norm.: 0.0006556068749752366 Norm. Diff.: 0.0032787966867214463 tk: 5 x_norm: 24.773480258954983\n",
      "Iteration 3063 - Grad. Norm.: 0.0006554544966747724 Norm. Diff.: 0.0032780343748760902 tk: 5 x_norm: 24.77625473344147\n",
      "Iteration 3064 - Grad. Norm.: 0.0006553022023695867 Norm. Diff.: 0.0032772724833737975 tk: 5 x_norm: 24.77902854595548\n",
      "Iteration 3065 - Grad. Norm.: 0.0006551499919864838 Norm. Diff.: 0.003276511011848169 tk: 5 x_norm: 24.78180169686104\n",
      "Iteration 3066 - Grad. Norm.: 0.0006549978654523574 Norm. Diff.: 0.0032757499599324613 tk: 5 x_norm: 24.784574186521876\n",
      "Iteration 3067 - Grad. Norm.: 0.0006548458226941844 Norm. Diff.: 0.003274989327262034 tk: 5 x_norm: 24.7873460153014\n",
      "Iteration 3068 - Grad. Norm.: 0.0006546938636390264 Norm. Diff.: 0.0032742291134708634 tk: 5 x_norm: 24.790117183562693\n",
      "Iteration 3069 - Grad. Norm.: 0.0006545419882140342 Norm. Diff.: 0.003273469318195242 tk: 5 x_norm: 24.79288769166854\n",
      "Iteration 3070 - Grad. Norm.: 0.0006543901963464399 Norm. Diff.: 0.003272709941070203 tk: 5 x_norm: 24.795657539981406\n",
      "Iteration 3071 - Grad. Norm.: 0.0006542384879635632 Norm. Diff.: 0.003271950981732349 tk: 5 x_norm: 24.79842672886344\n",
      "Iteration 3072 - Grad. Norm.: 0.0006540868629928083 Norm. Diff.: 0.003271192439817789 tk: 5 x_norm: 24.80119525867648\n",
      "Iteration 3073 - Grad. Norm.: 0.0006539353213616658 Norm. Diff.: 0.003270434314964192 tk: 5 x_norm: 24.803963129782062\n",
      "Iteration 3074 - Grad. Norm.: 0.0006537838629977078 Norm. Diff.: 0.0032696766068085075 tk: 5 x_norm: 24.806730342541403\n",
      "Iteration 3075 - Grad. Norm.: 0.0006536324878285931 Norm. Diff.: 0.0032689193149886774 tk: 5 x_norm: 24.8094968973154\n",
      "Iteration 3076 - Grad. Norm.: 0.0006534811957820666 Norm. Diff.: 0.003268162439142962 tk: 5 x_norm: 24.812262794464655\n",
      "Iteration 3077 - Grad. Norm.: 0.0006533299867859554 Norm. Diff.: 0.003267405978910285 tk: 5 x_norm: 24.81502803434944\n",
      "Iteration 3078 - Grad. Norm.: 0.0006531788607681715 Norm. Diff.: 0.0032666499339297273 tk: 5 x_norm: 24.817792617329747\n",
      "Iteration 3079 - Grad. Norm.: 0.0006530278176567118 Norm. Diff.: 0.003265894303840919 tk: 5 x_norm: 24.820556543765218\n",
      "Iteration 3080 - Grad. Norm.: 0.0006528768573796571 Norm. Diff.: 0.003265139088283351 tk: 5 x_norm: 24.823319814015225\n",
      "Iteration 3081 - Grad. Norm.: 0.0006527259798651717 Norm. Diff.: 0.0032643842868984602 tk: 5 x_norm: 24.826082428438813\n",
      "Iteration 3082 - Grad. Norm.: 0.000652575185041504 Norm. Diff.: 0.0032636298993258617 tk: 5 x_norm: 24.82884438739471\n",
      "Iteration 3083 - Grad. Norm.: 0.000652424472836987 Norm. Diff.: 0.0032628759252075583 tk: 5 x_norm: 24.83160569124134\n",
      "Iteration 3084 - Grad. Norm.: 0.000652273843180035 Norm. Diff.: 0.0032621223641849106 tk: 5 x_norm: 24.83436634033684\n",
      "Iteration 3085 - Grad. Norm.: 0.000652123295999149 Norm. Diff.: 0.003261369215900466 tk: 5 x_norm: 24.837126335038995\n",
      "Iteration 3086 - Grad. Norm.: 0.0006519728312229107 Norm. Diff.: 0.003260616479995847 tk: 5 x_norm: 24.83988567570535\n",
      "Iteration 3087 - Grad. Norm.: 0.0006518224487799877 Norm. Diff.: 0.003259864156114572 tk: 5 x_norm: 24.842644362693058\n",
      "Iteration 3088 - Grad. Norm.: 0.0006516721485991277 Norm. Diff.: 0.0032591122439000436 tk: 5 x_norm: 24.84540239635905\n",
      "Iteration 3089 - Grad. Norm.: 0.0006515219306091634 Norm. Diff.: 0.0032583607429958112 tk: 5 x_norm: 24.848159777059887\n",
      "Iteration 3090 - Grad. Norm.: 0.0006513717947390098 Norm. Diff.: 0.0032576096530457957 tk: 5 x_norm: 24.850916505151854\n",
      "Iteration 3091 - Grad. Norm.: 0.0006512217409176654 Norm. Diff.: 0.0032568589736949767 tk: 5 x_norm: 24.853672580990928\n",
      "Iteration 3092 - Grad. Norm.: 0.000651071769074211 Norm. Diff.: 0.003256108704588061 tk: 5 x_norm: 24.856428004932777\n",
      "Iteration 3093 - Grad. Norm.: 0.0006509218791378084 Norm. Diff.: 0.0032553588453710187 tk: 5 x_norm: 24.859182777332762\n",
      "Iteration 3094 - Grad. Norm.: 0.0006507720710377048 Norm. Diff.: 0.0032546093956890313 tk: 5 x_norm: 24.861936898545945\n",
      "Iteration 3095 - Grad. Norm.: 0.0006506223447032272 Norm. Diff.: 0.0032538603551885985 tk: 5 x_norm: 24.864690368927082\n",
      "Iteration 3096 - Grad. Norm.: 0.000650472700063786 Norm. Diff.: 0.0032531117235164954 tk: 5 x_norm: 24.86744318883063\n",
      "Iteration 3097 - Grad. Norm.: 0.0006503231370488728 Norm. Diff.: 0.003252363500318908 tk: 5 x_norm: 24.870195358610726\n",
      "Iteration 3098 - Grad. Norm.: 0.0006501736555880619 Norm. Diff.: 0.003251615685244597 tk: 5 x_norm: 24.872946878621228\n",
      "Iteration 3099 - Grad. Norm.: 0.0006500242556110108 Norm. Diff.: 0.003250868277940632 tk: 5 x_norm: 24.875697749215664\n",
      "Iteration 3100 - Grad. Norm.: 0.0006498749370474551 Norm. Diff.: 0.003250121278055141 tk: 5 x_norm: 24.87844797074729\n",
      "Iteration 3101 - Grad. Norm.: 0.0006497256998272154 Norm. Diff.: 0.0032493746852375435 tk: 5 x_norm: 24.881197543569026\n",
      "Iteration 3102 - Grad. Norm.: 0.0006495765438801919 Norm. Diff.: 0.003248628499136241 tk: 5 x_norm: 24.883946468033525\n",
      "Iteration 3103 - Grad. Norm.: 0.0006494274691363671 Norm. Diff.: 0.0032478827194009313 tk: 5 x_norm: 24.886694744493113\n",
      "Iteration 3104 - Grad. Norm.: 0.0006492784755258043 Norm. Diff.: 0.003247137345681944 tk: 5 x_norm: 24.889442373299833\n",
      "Iteration 3105 - Grad. Norm.: 0.000649129562978648 Norm. Diff.: 0.0032463923776291388 tk: 5 x_norm: 24.89218935480541\n",
      "Iteration 3106 - Grad. Norm.: 0.0006489807314251229 Norm. Diff.: 0.003245647814893557 tk: 5 x_norm: 24.894935689361287\n",
      "Iteration 3107 - Grad. Norm.: 0.0006488319807955368 Norm. Diff.: 0.0032449036571257717 tk: 5 x_norm: 24.897681377318584\n",
      "Iteration 3108 - Grad. Norm.: 0.0006486833110202766 Norm. Diff.: 0.0032441599039776 tk: 5 x_norm: 24.900426419028157\n",
      "Iteration 3109 - Grad. Norm.: 0.0006485347220298097 Norm. Diff.: 0.003243416555101446 tk: 5 x_norm: 24.903170814840518\n",
      "Iteration 3110 - Grad. Norm.: 0.0006483862137546856 Norm. Diff.: 0.0032426736101488713 tk: 5 x_norm: 24.905914565105913\n",
      "Iteration 3111 - Grad. Norm.: 0.000648237786125532 Norm. Diff.: 0.003241931068773601 tk: 5 x_norm: 24.90865767017428\n",
      "Iteration 3112 - Grad. Norm.: 0.0006480894390730584 Norm. Diff.: 0.003241188930627894 tk: 5 x_norm: 24.911400130395265\n",
      "Iteration 3113 - Grad. Norm.: 0.0006479411725280542 Norm. Diff.: 0.0032404471953654873 tk: 5 x_norm: 24.9141419461182\n",
      "Iteration 3114 - Grad. Norm.: 0.0006477929864213897 Norm. Diff.: 0.0032397058626402564 tk: 5 x_norm: 24.91688311769214\n",
      "Iteration 3115 - Grad. Norm.: 0.000647644880684013 Norm. Diff.: 0.003238964932107056 tk: 5 x_norm: 24.919623645465826\n",
      "Iteration 3116 - Grad. Norm.: 0.0006474968552469544 Norm. Diff.: 0.003238224403420209 tk: 5 x_norm: 24.9223635297877\n",
      "Iteration 3117 - Grad. Norm.: 0.000647348910041322 Norm. Diff.: 0.0032374842762346416 tk: 5 x_norm: 24.92510277100593\n",
      "Iteration 3118 - Grad. Norm.: 0.0006472010449983063 Norm. Diff.: 0.0032367445502066933 tk: 5 x_norm: 24.927841369468368\n",
      "Iteration 3119 - Grad. Norm.: 0.0006470532600491738 Norm. Diff.: 0.003236005224991655 tk: 5 x_norm: 24.930579325522576\n",
      "Iteration 3120 - Grad. Norm.: 0.0006469055551252731 Norm. Diff.: 0.0032352663002459927 tk: 5 x_norm: 24.933316639515823\n",
      "Iteration 3121 - Grad. Norm.: 0.0006467579301580305 Norm. Diff.: 0.003234527775626468 tk: 5 x_norm: 24.936053311795074\n",
      "Iteration 3122 - Grad. Norm.: 0.000646610385078953 Norm. Diff.: 0.0032337896507902138 tk: 5 x_norm: 24.93878934270703\n",
      "Iteration 3123 - Grad. Norm.: 0.0006464629198196233 Norm. Diff.: 0.0032330519253948573 tk: 5 x_norm: 24.94152473259804\n",
      "Iteration 3124 - Grad. Norm.: 0.0006463155343117092 Norm. Diff.: 0.003232314599097951 tk: 5 x_norm: 24.94425948181422\n",
      "Iteration 3125 - Grad. Norm.: 0.00064616822848695 Norm. Diff.: 0.003231577671558467 tk: 5 x_norm: 24.946993590701346\n",
      "Iteration 3126 - Grad. Norm.: 0.0006460210022771702 Norm. Diff.: 0.0032308411424347384 tk: 5 x_norm: 24.94972705960493\n",
      "Iteration 3127 - Grad. Norm.: 0.0006458738556142682 Norm. Diff.: 0.003230105011385964 tk: 5 x_norm: 24.952459888870184\n",
      "Iteration 3128 - Grad. Norm.: 0.0006457267884302233 Norm. Diff.: 0.003229369278071285 tk: 5 x_norm: 24.95519207884202\n",
      "Iteration 3129 - Grad. Norm.: 0.000645579800657093 Norm. Diff.: 0.0032286339421511703 tk: 5 x_norm: 24.957923629865057\n",
      "Iteration 3130 - Grad. Norm.: 0.0006454328922270123 Norm. Diff.: 0.003227899003285515 tk: 5 x_norm: 24.960654542283628\n",
      "Iteration 3131 - Grad. Norm.: 0.0006452860630721942 Norm. Diff.: 0.0032271644611348753 tk: 5 x_norm: 24.96338481644178\n",
      "Iteration 3132 - Grad. Norm.: 0.0006451393131249313 Norm. Diff.: 0.003226430315361033 tk: 5 x_norm: 24.96611445268326\n",
      "Iteration 3133 - Grad. Norm.: 0.0006449926423175924 Norm. Diff.: 0.003225696565624719 tk: 5 x_norm: 24.96884345135153\n",
      "Iteration 3134 - Grad. Norm.: 0.0006448460505826263 Norm. Diff.: 0.0032249632115880023 tk: 5 x_norm: 24.971571812789737\n",
      "Iteration 3135 - Grad. Norm.: 0.0006446995378525553 Norm. Diff.: 0.003224230252913016 tk: 5 x_norm: 24.974299537340777\n",
      "Iteration 3136 - Grad. Norm.: 0.0006445531040599856 Norm. Diff.: 0.0032234976892628955 tk: 5 x_norm: 24.97702662534723\n",
      "Iteration 3137 - Grad. Norm.: 0.0006444067491375948 Norm. Diff.: 0.003222765520299987 tk: 5 x_norm: 24.979753077151397\n",
      "Iteration 3138 - Grad. Norm.: 0.0006442604730181404 Norm. Diff.: 0.0032220337456878158 tk: 5 x_norm: 24.982478893095283\n",
      "Iteration 3139 - Grad. Norm.: 0.0006441142756344585 Norm. Diff.: 0.003221302365091015 tk: 5 x_norm: 24.98520407352061\n",
      "Iteration 3140 - Grad. Norm.: 0.0006439681569194609 Norm. Diff.: 0.0032205713781722997 tk: 5 x_norm: 24.9879286187688\n",
      "Iteration 3141 - Grad. Norm.: 0.0006438221168061354 Norm. Diff.: 0.003219840784597133 tk: 5 x_norm: 24.990652529181006\n",
      "Iteration 3142 - Grad. Norm.: 0.0006436761552275496 Norm. Diff.: 0.003219110584030538 tk: 5 x_norm: 24.99337580509808\n",
      "Iteration 3143 - Grad. Norm.: 0.0006435302721168453 Norm. Diff.: 0.0032183807761376857 tk: 5 x_norm: 24.99609844686058\n",
      "Iteration 3144 - Grad. Norm.: 0.0006433844674072424 Norm. Diff.: 0.003217651360584026 tk: 5 x_norm: 24.99882045480879\n",
      "Iteration 3145 - Grad. Norm.: 0.0006432387410320365 Norm. Diff.: 0.0032169223370359865 tk: 5 x_norm: 25.001541829282704\n",
      "Iteration 3146 - Grad. Norm.: 0.0006430930929246007 Norm. Diff.: 0.003216193705160112 tk: 5 x_norm: 25.004262570622025\n",
      "Iteration 3147 - Grad. Norm.: 0.0006429475230183834 Norm. Diff.: 0.003215465464623017 tk: 5 x_norm: 25.00698267916617\n",
      "Iteration 3148 - Grad. Norm.: 0.0006428020312469109 Norm. Diff.: 0.003214737615092096 tk: 5 x_norm: 25.009702155254285\n",
      "Iteration 3149 - Grad. Norm.: 0.0006426566175437846 Norm. Diff.: 0.003214010156234627 tk: 5 x_norm: 25.012420999225196\n",
      "Iteration 3150 - Grad. Norm.: 0.0006425112818426809 Norm. Diff.: 0.003213283087718781 tk: 5 x_norm: 25.015139211417477\n",
      "Iteration 3151 - Grad. Norm.: 0.0006423660240773548 Norm. Diff.: 0.0032125564092134887 tk: 5 x_norm: 25.017856792169407\n",
      "Iteration 3152 - Grad. Norm.: 0.000642220844181634 Norm. Diff.: 0.0032118301203868434 tk: 5 x_norm: 25.020573741818964\n",
      "Iteration 3153 - Grad. Norm.: 0.0006420757420894253 Norm. Diff.: 0.0032111042209080507 tk: 5 x_norm: 25.02329006070389\n",
      "Iteration 3154 - Grad. Norm.: 0.0006419307177347082 Norm. Diff.: 0.003210378710447157 tk: 5 x_norm: 25.02600574916156\n",
      "Iteration 3155 - Grad. Norm.: 0.0006417857710515398 Norm. Diff.: 0.003209653588673453 tk: 5 x_norm: 25.028720807529147\n",
      "Iteration 3156 - Grad. Norm.: 0.0006416409019740512 Norm. Diff.: 0.003208928855257575 tk: 5 x_norm: 25.031435236143505\n",
      "Iteration 3157 - Grad. Norm.: 0.0006414961104364495 Norm. Diff.: 0.0032082045098701345 tk: 5 x_norm: 25.0341490353412\n",
      "Iteration 3158 - Grad. Norm.: 0.0006413513963730171 Norm. Diff.: 0.0032074805521822365 tk: 5 x_norm: 25.036862205458526\n",
      "Iteration 3159 - Grad. Norm.: 0.000641206759718112 Norm. Diff.: 0.0032067569818647244 tk: 5 x_norm: 25.03957474683149\n",
      "Iteration 3160 - Grad. Norm.: 0.0006410622004061649 Norm. Diff.: 0.0032060337985908354 tk: 5 x_norm: 25.042286659795817\n",
      "Iteration 3161 - Grad. Norm.: 0.0006409177183716843 Norm. Diff.: 0.0032053110020306918 tk: 5 x_norm: 25.04499794468696\n",
      "Iteration 3162 - Grad. Norm.: 0.0006407733135492514 Norm. Diff.: 0.0032045885918584333 tk: 5 x_norm: 25.047708601840064\n",
      "Iteration 3163 - Grad. Norm.: 0.0006406289858735234 Norm. Diff.: 0.0032038665677459766 tk: 5 x_norm: 25.050418631590027\n",
      "Iteration 3164 - Grad. Norm.: 0.0006404847352792314 Norm. Diff.: 0.003203144929367782 tk: 5 x_norm: 25.05312803427145\n",
      "Iteration 3165 - Grad. Norm.: 0.0006403405617011809 Norm. Diff.: 0.0032024236763960514 tk: 5 x_norm: 25.055836810218647\n",
      "Iteration 3166 - Grad. Norm.: 0.0006401964650742522 Norm. Diff.: 0.003201702808505917 tk: 5 x_norm: 25.058544959765655\n",
      "Iteration 3167 - Grad. Norm.: 0.0006400524453333993 Norm. Diff.: 0.0032009823253711473 tk: 5 x_norm: 25.061252483246243\n",
      "Iteration 3168 - Grad. Norm.: 0.0006399085024136506 Norm. Diff.: 0.0032002622266669883 tk: 5 x_norm: 25.063959380993886\n",
      "Iteration 3169 - Grad. Norm.: 0.0006397646362501092 Norm. Diff.: 0.003199542512068232 tk: 5 x_norm: 25.066665653341794\n",
      "Iteration 3170 - Grad. Norm.: 0.0006396208467779512 Norm. Diff.: 0.0031988231812506472 tk: 5 x_norm: 25.06937130062288\n",
      "Iteration 3171 - Grad. Norm.: 0.0006394771339324258 Norm. Diff.: 0.0031981042338898153 tk: 5 x_norm: 25.072076323169796\n",
      "Iteration 3172 - Grad. Norm.: 0.0006393334976488587 Norm. Diff.: 0.0031973856696621136 tk: 5 x_norm: 25.074780721314898\n",
      "Iteration 3173 - Grad. Norm.: 0.0006391899378626463 Norm. Diff.: 0.003196667488244423 tk: 5 x_norm: 25.077484495390287\n",
      "Iteration 3174 - Grad. Norm.: 0.0006390464545092612 Norm. Diff.: 0.00319594968931313 tk: 5 x_norm: 25.08018764572776\n",
      "Iteration 3175 - Grad. Norm.: 0.0006389030475242461 Norm. Diff.: 0.0031952322725463432 tk: 5 x_norm: 25.082890172658868\n",
      "Iteration 3176 - Grad. Norm.: 0.0006387597168432204 Norm. Diff.: 0.0031945152376211604 tk: 5 x_norm: 25.085592076514843\n",
      "Iteration 3177 - Grad. Norm.: 0.000638616462401873 Norm. Diff.: 0.003193798584216175 tk: 5 x_norm: 25.088293357626682\n",
      "Iteration 3178 - Grad. Norm.: 0.0006384732841359716 Norm. Diff.: 0.003193082312009435 tk: 5 x_norm: 25.09099401632508\n",
      "Iteration 3179 - Grad. Norm.: 0.00063833018198135 Norm. Diff.: 0.0031923664206798376 tk: 5 x_norm: 25.093694052940474\n",
      "Iteration 3180 - Grad. Norm.: 0.0006381871558739205 Norm. Diff.: 0.0031916509099064873 tk: 5 x_norm: 25.096393467803008\n",
      "Iteration 3181 - Grad. Norm.: 0.0006380442057496641 Norm. Diff.: 0.0031909357793698453 tk: 5 x_norm: 25.099092261242554\n",
      "Iteration 3182 - Grad. Norm.: 0.0006379013315446377 Norm. Diff.: 0.0031902210287482777 tk: 5 x_norm: 25.10179043358871\n",
      "Iteration 3183 - Grad. Norm.: 0.0006377585331949696 Norm. Diff.: 0.003189506657723381 tk: 5 x_norm: 25.104487985170817\n",
      "Iteration 3184 - Grad. Norm.: 0.0006376158106368601 Norm. Diff.: 0.003188792665974828 tk: 5 x_norm: 25.107184916317923\n",
      "Iteration 3185 - Grad. Norm.: 0.0006374731638065817 Norm. Diff.: 0.0031880790531842135 tk: 5 x_norm: 25.109881227358795\n",
      "Iteration 3186 - Grad. Norm.: 0.000637330592640481 Norm. Diff.: 0.0031873658190326804 tk: 5 x_norm: 25.112576918621944\n",
      "Iteration 3187 - Grad. Norm.: 0.0006371880970749743 Norm. Diff.: 0.0031866529632023966 tk: 5 x_norm: 25.115271990435588\n",
      "Iteration 3188 - Grad. Norm.: 0.0006370456770465513 Norm. Diff.: 0.0031859404853747902 tk: 5 x_norm: 25.1179664431277\n",
      "Iteration 3189 - Grad. Norm.: 0.0006369033324917739 Norm. Diff.: 0.0031852283852326214 tk: 5 x_norm: 25.120660277025948\n",
      "Iteration 3190 - Grad. Norm.: 0.0006367610633472759 Norm. Diff.: 0.003184516662458851 tk: 5 x_norm: 25.123353492457763\n",
      "Iteration 3191 - Grad. Norm.: 0.0006366188695497634 Norm. Diff.: 0.003183805316736146 tk: 5 x_norm: 25.12604608975026\n",
      "Iteration 3192 - Grad. Norm.: 0.0006364767510360104 Norm. Diff.: 0.0031830943477488367 tk: 5 x_norm: 25.128738069230323\n",
      "Iteration 3193 - Grad. Norm.: 0.0006363347077428681 Norm. Diff.: 0.0031823837551800778 tk: 5 x_norm: 25.131429431224532\n",
      "Iteration 3194 - Grad. Norm.: 0.0006361927396072547 Norm. Diff.: 0.003181673538714569 tk: 5 x_norm: 25.134120176059227\n",
      "Iteration 3195 - Grad. Norm.: 0.000636050846566163 Norm. Diff.: 0.0031809636980364192 tk: 5 x_norm: 25.136810304060454\n",
      "Iteration 3196 - Grad. Norm.: 0.0006359090285566549 Norm. Diff.: 0.0031802542328311333 tk: 5 x_norm: 25.13949981555399\n",
      "Iteration 3197 - Grad. Norm.: 0.0006357672855158637 Norm. Diff.: 0.003179545142783326 tk: 5 x_norm: 25.14218871086535\n",
      "Iteration 3198 - Grad. Norm.: 0.0006356256173809953 Norm. Diff.: 0.0031788364275792307 tk: 5 x_norm: 25.14487699031978\n",
      "Iteration 3199 - Grad. Norm.: 0.0006354840240893251 Norm. Diff.: 0.0031781280869048645 tk: 5 x_norm: 25.147564654242228\n",
      "Iteration 3200 - Grad. Norm.: 0.0006353425055781992 Norm. Diff.: 0.0031774201204467847 tk: 5 x_norm: 25.150251702957423\n",
      "Iteration 3201 - Grad. Norm.: 0.0006352010617850365 Norm. Diff.: 0.0031767125278907593 tk: 5 x_norm: 25.15293813678978\n",
      "Iteration 3202 - Grad. Norm.: 0.000635059692647324 Norm. Diff.: 0.003176005308925506 tk: 5 x_norm: 25.155623956063476\n",
      "Iteration 3203 - Grad. Norm.: 0.0006349183981026209 Norm. Diff.: 0.003175298463236496 tk: 5 x_norm: 25.158309161102395\n",
      "Iteration 3204 - Grad. Norm.: 0.0006347771780885569 Norm. Diff.: 0.003174591990512803 tk: 5 x_norm: 25.160993752230166\n",
      "Iteration 3205 - Grad. Norm.: 0.0006346360325428294 Norm. Diff.: 0.003173885890442988 tk: 5 x_norm: 25.16367772977015\n",
      "Iteration 3206 - Grad. Norm.: 0.000634494961403211 Norm. Diff.: 0.0031731801627140764 tk: 5 x_norm: 25.16636109404543\n",
      "Iteration 3207 - Grad. Norm.: 0.0006343539646075409 Norm. Diff.: 0.0031724748070160887 tk: 5 x_norm: 25.169043845378845\n",
      "Iteration 3208 - Grad. Norm.: 0.0006342130420937284 Norm. Diff.: 0.003171769823037784 tk: 5 x_norm: 25.171725984092934\n",
      "Iteration 3209 - Grad. Norm.: 0.0006340721937997553 Norm. Diff.: 0.0031710652104685023 tk: 5 x_norm: 25.17440751050998\n",
      "Iteration 3210 - Grad. Norm.: 0.0006339314196636697 Norm. Diff.: 0.003170360968998797 tk: 5 x_norm: 25.17708842495203\n",
      "Iteration 3211 - Grad. Norm.: 0.0006337907196235931 Norm. Diff.: 0.0031696570983185198 tk: 5 x_norm: 25.17976872774082\n",
      "Iteration 3212 - Grad. Norm.: 0.000633650093617713 Norm. Diff.: 0.003168953598118201 tk: 5 x_norm: 25.18244841919785\n",
      "Iteration 3213 - Grad. Norm.: 0.0006335095415842912 Norm. Diff.: 0.003168250468088747 tk: 5 x_norm: 25.185127499644352\n",
      "Iteration 3214 - Grad. Norm.: 0.0006333690634616547 Norm. Diff.: 0.0031675477079213658 tk: 5 x_norm: 25.187805969401264\n",
      "Iteration 3215 - Grad. Norm.: 0.0006332286591882019 Norm. Diff.: 0.003166845317308334 tk: 5 x_norm: 25.1904838287893\n",
      "Iteration 3216 - Grad. Norm.: 0.0006330883287023994 Norm. Diff.: 0.0031661432959410553 tk: 5 x_norm: 25.193161078128867\n",
      "Iteration 3217 - Grad. Norm.: 0.0006329480719427841 Norm. Diff.: 0.0031654416435121235 tk: 5 x_norm: 25.19583771774015\n",
      "Iteration 3218 - Grad. Norm.: 0.000632807888847962 Norm. Diff.: 0.003164740359713674 tk: 5 x_norm: 25.19851374794305\n",
      "Iteration 3219 - Grad. Norm.: 0.0006326677793566077 Norm. Diff.: 0.0031640394442398125 tk: 5 x_norm: 25.201189169057194\n",
      "Iteration 3220 - Grad. Norm.: 0.0006325277434074651 Norm. Diff.: 0.0031633388967832296 tk: 5 x_norm: 25.203863981401966\n",
      "Iteration 3221 - Grad. Norm.: 0.0006323877809393452 Norm. Diff.: 0.003162638717037227 tk: 5 x_norm: 25.206538185296463\n",
      "Iteration 3222 - Grad. Norm.: 0.00063224789189113 Norm. Diff.: 0.003161938904696867 tk: 5 x_norm: 25.209211781059548\n",
      "Iteration 3223 - Grad. Norm.: 0.0006321080762017701 Norm. Diff.: 0.003161239459455766 tk: 5 x_norm: 25.211884769009785\n",
      "Iteration 3224 - Grad. Norm.: 0.0006319683338102827 Norm. Diff.: 0.0031605403810090046 tk: 5 x_norm: 25.214557149465517\n",
      "Iteration 3225 - Grad. Norm.: 0.0006318286646557543 Norm. Diff.: 0.003159841669051225 tk: 5 x_norm: 25.217228922744784\n",
      "Iteration 3226 - Grad. Norm.: 0.0006316890686773403 Norm. Diff.: 0.003159143323278433 tk: 5 x_norm: 25.21990008916541\n",
      "Iteration 3227 - Grad. Norm.: 0.0006315495458142648 Norm. Diff.: 0.003158445343386573 tk: 5 x_norm: 25.222570649044908\n",
      "Iteration 3228 - Grad. Norm.: 0.0006314100960058176 Norm. Diff.: 0.003157747729071665 tk: 5 x_norm: 25.225240602700563\n",
      "Iteration 3229 - Grad. Norm.: 0.0006312707191913599 Norm. Diff.: 0.00315705048002914 tk: 5 x_norm: 25.227909950449398\n",
      "Iteration 3230 - Grad. Norm.: 0.0006311314153103182 Norm. Diff.: 0.0031563535959568344 tk: 5 x_norm: 25.230578692608155\n",
      "Iteration 3231 - Grad. Norm.: 0.0006309921843021891 Norm. Diff.: 0.003155657076551614 tk: 5 x_norm: 25.23324682949333\n",
      "Iteration 3232 - Grad. Norm.: 0.000630853026106533 Norm. Diff.: 0.003154960921511037 tk: 5 x_norm: 25.23591436142116\n",
      "Iteration 3233 - Grad. Norm.: 0.0006307139406629838 Norm. Diff.: 0.0031542651305325924 tk: 5 x_norm: 25.238581288707607\n",
      "Iteration 3234 - Grad. Norm.: 0.0006305749279112377 Norm. Diff.: 0.0031535697033151545 tk: 5 x_norm: 25.24124761166841\n",
      "Iteration 3235 - Grad. Norm.: 0.0006304359877910616 Norm. Diff.: 0.003152874639555875 tk: 5 x_norm: 25.243913330619005\n",
      "Iteration 3236 - Grad. Norm.: 0.0006302971202422883 Norm. Diff.: 0.0031521799389550896 tk: 5 x_norm: 25.2465784458746\n",
      "Iteration 3237 - Grad. Norm.: 0.0006301583252048187 Norm. Diff.: 0.0031514856012115153 tk: 5 x_norm: 25.249242957750116\n",
      "Iteration 3238 - Grad. Norm.: 0.0006300196026186212 Norm. Diff.: 0.003150791626024118 tk: 5 x_norm: 25.251906866560255\n",
      "Iteration 3239 - Grad. Norm.: 0.0006298809524237296 Norm. Diff.: 0.0031500980130932882 tk: 5 x_norm: 25.254570172619417\n",
      "Iteration 3240 - Grad. Norm.: 0.0006297423745602463 Norm. Diff.: 0.0031494047621186795 tk: 5 x_norm: 25.257232876241787\n",
      "Iteration 3241 - Grad. Norm.: 0.0006296038689683405 Norm. Diff.: 0.0031487118728012495 tk: 5 x_norm: 25.259894977741258\n",
      "Iteration 3242 - Grad. Norm.: 0.0006294654355882465 Norm. Diff.: 0.003148019344841901 tk: 5 x_norm: 25.26255647743148\n",
      "Iteration 3243 - Grad. Norm.: 0.000629327074360268 Norm. Diff.: 0.0031473271779415423 tk: 5 x_norm: 25.265217375625845\n",
      "Iteration 3244 - Grad. Norm.: 0.0006291887852247748 Norm. Diff.: 0.0031466353718013606 tk: 5 x_norm: 25.267877672637496\n",
      "Iteration 3245 - Grad. Norm.: 0.0006290505681222 Norm. Diff.: 0.0031459439261238217 tk: 5 x_norm: 25.27053736877931\n",
      "Iteration 3246 - Grad. Norm.: 0.0006289124229930486 Norm. Diff.: 0.003145252840611094 tk: 5 x_norm: 25.273196464363913\n",
      "Iteration 3247 - Grad. Norm.: 0.0006287743497778872 Norm. Diff.: 0.0031445621149654456 tk: 5 x_norm: 25.275854959703665\n",
      "Iteration 3248 - Grad. Norm.: 0.0006286363484173514 Norm. Diff.: 0.0031438717488895627 tk: 5 x_norm: 25.278512855110677\n",
      "Iteration 3249 - Grad. Norm.: 0.0006284984188521412 Norm. Diff.: 0.0031431817420869883 tk: 5 x_norm: 25.28117015089682\n",
      "Iteration 3250 - Grad. Norm.: 0.0006283605610230257 Norm. Diff.: 0.0031424920942607626 tk: 5 x_norm: 25.283826847373682\n",
      "Iteration 3251 - Grad. Norm.: 0.0006282227748708359 Norm. Diff.: 0.00314180280511514 tk: 5 x_norm: 25.286482944852626\n",
      "Iteration 3252 - Grad. Norm.: 0.0006280850603364715 Norm. Diff.: 0.00314111387435432 tk: 5 x_norm: 25.289138443644735\n",
      "Iteration 3253 - Grad. Norm.: 0.0006279474173608978 Norm. Diff.: 0.0031404253016823172 tk: 5 x_norm: 25.29179334406085\n",
      "Iteration 3254 - Grad. Norm.: 0.000627809845885145 Norm. Diff.: 0.003139737086804631 tk: 5 x_norm: 25.294447646411555\n",
      "Iteration 3255 - Grad. Norm.: 0.0006276723458503085 Norm. Diff.: 0.003139049229425439 tk: 5 x_norm: 25.2971013510072\n",
      "Iteration 3256 - Grad. Norm.: 0.0006275349171975513 Norm. Diff.: 0.0031383617292514683 tk: 5 x_norm: 25.29975445815783\n",
      "Iteration 3257 - Grad. Norm.: 0.0006273975598681007 Norm. Diff.: 0.00313767458598777 tk: 5 x_norm: 25.302406968173308\n",
      "Iteration 3258 - Grad. Norm.: 0.0006272602738032483 Norm. Diff.: 0.003136987799340676 tk: 5 x_norm: 25.305058881363184\n",
      "Iteration 3259 - Grad. Norm.: 0.0006271230589443522 Norm. Diff.: 0.0031363013690161386 tk: 5 x_norm: 25.30771019803679\n",
      "Iteration 3260 - Grad. Norm.: 0.000626985915232835 Norm. Diff.: 0.0031356152947218776 tk: 5 x_norm: 25.310360918503193\n",
      "Iteration 3261 - Grad. Norm.: 0.000626848842610187 Norm. Diff.: 0.0031349295761640573 tk: 5 x_norm: 25.313011043071214\n",
      "Iteration 3262 - Grad. Norm.: 0.0006267118410179587 Norm. Diff.: 0.00313424421305065 tk: 5 x_norm: 25.315660572049413\n",
      "Iteration 3263 - Grad. Norm.: 0.0006265749103977696 Norm. Diff.: 0.00313355920508984 tk: 5 x_norm: 25.318309505746104\n",
      "Iteration 3264 - Grad. Norm.: 0.0006264380506913029 Norm. Diff.: 0.003132874551988535 tk: 5 x_norm: 25.32095784446937\n",
      "Iteration 3265 - Grad. Norm.: 0.0006263012618403052 Norm. Diff.: 0.0031321902534567347 tk: 5 x_norm: 25.323605588527\n",
      "Iteration 3266 - Grad. Norm.: 0.0006261645437865892 Norm. Diff.: 0.003131506309201325 tk: 5 x_norm: 25.326252738226565\n",
      "Iteration 3267 - Grad. Norm.: 0.0006260278964720326 Norm. Diff.: 0.003130822718932467 tk: 5 x_norm: 25.328899293875384\n",
      "Iteration 3268 - Grad. Norm.: 0.0006258913198385755 Norm. Diff.: 0.0031301394823601398 tk: 5 x_norm: 25.331545255780515\n",
      "Iteration 3269 - Grad. Norm.: 0.0006257548138282248 Norm. Diff.: 0.0031294565991929297 tk: 5 x_norm: 25.334190624248777\n",
      "Iteration 3270 - Grad. Norm.: 0.0006256183783830494 Norm. Diff.: 0.003128774069141273 tk: 5 x_norm: 25.33683539958674\n",
      "Iteration 3271 - Grad. Norm.: 0.0006254820134451837 Norm. Diff.: 0.0031280918919152413 tk: 5 x_norm: 25.339479582100697\n",
      "Iteration 3272 - Grad. Norm.: 0.0006253457189568271 Norm. Diff.: 0.0031274100672258227 tk: 5 x_norm: 25.342123172096734\n",
      "Iteration 3273 - Grad. Norm.: 0.0006252094948602412 Norm. Diff.: 0.0031267285947840693 tk: 5 x_norm: 25.344766169880668\n",
      "Iteration 3274 - Grad. Norm.: 0.0006250733410977526 Norm. Diff.: 0.003126047474300966 tk: 5 x_norm: 25.34740857575806\n",
      "Iteration 3275 - Grad. Norm.: 0.0006249372576117515 Norm. Diff.: 0.0031253667054886858 tk: 5 x_norm: 25.35005039003424\n",
      "Iteration 3276 - Grad. Norm.: 0.0006248012443446915 Norm. Diff.: 0.0031246862880589255 tk: 5 x_norm: 25.352691613014283\n",
      "Iteration 3277 - Grad. Norm.: 0.0006246653012390906 Norm. Diff.: 0.0031240062217235062 tk: 5 x_norm: 25.355332245003016\n",
      "Iteration 3278 - Grad. Norm.: 0.0006245294282375307 Norm. Diff.: 0.003123326506195352 tk: 5 x_norm: 25.357972286305017\n",
      "Iteration 3279 - Grad. Norm.: 0.0006243936252826553 Norm. Diff.: 0.0031226471411875583 tk: 5 x_norm: 25.360611737224616\n",
      "Iteration 3280 - Grad. Norm.: 0.0006242578923171733 Norm. Diff.: 0.00312196812641326 tk: 5 x_norm: 25.36325059806591\n",
      "Iteration 3281 - Grad. Norm.: 0.0006241222292838553 Norm. Diff.: 0.003121289461585633 tk: 5 x_norm: 25.365888869132732\n",
      "Iteration 3282 - Grad. Norm.: 0.0006239866361255369 Norm. Diff.: 0.00312061114641933 tk: 5 x_norm: 25.36852655072869\n",
      "Iteration 3283 - Grad. Norm.: 0.0006238511127851162 Norm. Diff.: 0.003119933180627481 tk: 5 x_norm: 25.37116364315711\n",
      "Iteration 3284 - Grad. Norm.: 0.0006237156592055535 Norm. Diff.: 0.003119255563925346 tk: 5 x_norm: 25.373800146721113\n",
      "Iteration 3285 - Grad. Norm.: 0.0006235802753298728 Norm. Diff.: 0.0031185782960278597 tk: 5 x_norm: 25.376436061723552\n",
      "Iteration 3286 - Grad. Norm.: 0.0006234449611011619 Norm. Diff.: 0.0031179013766494193 tk: 5 x_norm: 25.379071388467054\n",
      "Iteration 3287 - Grad. Norm.: 0.0006233097164625685 Norm. Diff.: 0.0031172248055057255 tk: 5 x_norm: 25.381706127253967\n",
      "Iteration 3288 - Grad. Norm.: 0.0006231745413573062 Norm. Diff.: 0.0031165485823129177 tk: 5 x_norm: 25.38434027838642\n",
      "Iteration 3289 - Grad. Norm.: 0.0006230394357286508 Norm. Diff.: 0.0031158727067865503 tk: 5 x_norm: 25.386973842166313\n",
      "Iteration 3290 - Grad. Norm.: 0.000622904399519939 Norm. Diff.: 0.0031151971786432505 tk: 5 x_norm: 25.38960681889526\n",
      "Iteration 3291 - Grad. Norm.: 0.0006227694326745707 Norm. Diff.: 0.0031145219975996685 tk: 5 x_norm: 25.392239208874667\n",
      "Iteration 3292 - Grad. Norm.: 0.0006226345351360088 Norm. Diff.: 0.0031138471633731903 tk: 5 x_norm: 25.394871012405687\n",
      "Iteration 3293 - Grad. Norm.: 0.0006224997068477771 Norm. Diff.: 0.0031131726756801472 tk: 5 x_norm: 25.397502229789215\n",
      "Iteration 3294 - Grad. Norm.: 0.0006223649477534631 Norm. Diff.: 0.0031124985342388554 tk: 5 x_norm: 25.40013286132592\n",
      "Iteration 3295 - Grad. Norm.: 0.0006222302577967158 Norm. Diff.: 0.0031118247387671234 tk: 5 x_norm: 25.402762907316227\n",
      "Iteration 3296 - Grad. Norm.: 0.0006220956369212466 Norm. Diff.: 0.003111151288983593 tk: 5 x_norm: 25.405392368060316\n",
      "Iteration 3297 - Grad. Norm.: 0.0006219610850708287 Norm. Diff.: 0.003110478184606396 tk: 5 x_norm: 25.40802124385812\n",
      "Iteration 3298 - Grad. Norm.: 0.0006218266021892965 Norm. Diff.: 0.0031098054253539554 tk: 5 x_norm: 25.410649535009345\n",
      "Iteration 3299 - Grad. Norm.: 0.0006216921882205465 Norm. Diff.: 0.003109133010946427 tk: 5 x_norm: 25.41327724181344\n",
      "Iteration 3300 - Grad. Norm.: 0.0006215578431085375 Norm. Diff.: 0.0031084609411026433 tk: 5 x_norm: 25.415904364569613\n",
      "Iteration 3301 - Grad. Norm.: 0.000621423566797289 Norm. Diff.: 0.003107789215542741 tk: 5 x_norm: 25.41853090357684\n",
      "Iteration 3302 - Grad. Norm.: 0.0006212893592308832 Norm. Diff.: 0.0031071178339866752 tk: 5 x_norm: 25.421156859133863\n",
      "Iteration 3303 - Grad. Norm.: 0.000621155220353463 Norm. Diff.: 0.003106446796154638 tk: 5 x_norm: 25.423782231539153\n",
      "Iteration 3304 - Grad. Norm.: 0.0006210211501092325 Norm. Diff.: 0.003105776101767393 tk: 5 x_norm: 25.426407021090988\n",
      "Iteration 3305 - Grad. Norm.: 0.0006208871484424574 Norm. Diff.: 0.003105105750546461 tk: 5 x_norm: 25.429031228087364\n",
      "Iteration 3306 - Grad. Norm.: 0.0006207532152974647 Norm. Diff.: 0.0031044357422120965 tk: 5 x_norm: 25.431654852826046\n",
      "Iteration 3307 - Grad. Norm.: 0.0006206193506186421 Norm. Diff.: 0.0031037660764873104 tk: 5 x_norm: 25.434277895604584\n",
      "Iteration 3308 - Grad. Norm.: 0.0006204855543504395 Norm. Diff.: 0.00310309675309343 tk: 5 x_norm: 25.436900356720272\n",
      "Iteration 3309 - Grad. Norm.: 0.000620351826437365 Norm. Diff.: 0.003102427771752219 tk: 5 x_norm: 25.439522236470147\n",
      "Iteration 3310 - Grad. Norm.: 0.0006202181668239908 Norm. Diff.: 0.0031017591321866843 tk: 5 x_norm: 25.442143535151047\n",
      "Iteration 3311 - Grad. Norm.: 0.0006200845754549481 Norm. Diff.: 0.003101090834120098 tk: 5 x_norm: 25.444764253059535\n",
      "Iteration 3312 - Grad. Norm.: 0.0006199510522749291 Norm. Diff.: 0.003100422877274505 tk: 5 x_norm: 25.44738439049196\n",
      "Iteration 3313 - Grad. Norm.: 0.0006198175972286859 Norm. Diff.: 0.0030997552613746 tk: 5 x_norm: 25.450003947744424\n",
      "Iteration 3314 - Grad. Norm.: 0.0006196842102610343 Norm. Diff.: 0.003099087986143561 tk: 5 x_norm: 25.452622925112784\n",
      "Iteration 3315 - Grad. Norm.: 0.0006195508913168457 Norm. Diff.: 0.0030984210513048884 tk: 5 x_norm: 25.45524132289268\n",
      "Iteration 3316 - Grad. Norm.: 0.0006194176403410566 Norm. Diff.: 0.0030977544565841324 tk: 5 x_norm: 25.457859141379497\n",
      "Iteration 3317 - Grad. Norm.: 0.0006192844572786591 Norm. Diff.: 0.0030970882017051205 tk: 5 x_norm: 25.460476380868393\n",
      "Iteration 3318 - Grad. Norm.: 0.000619151342074708 Norm. Diff.: 0.003096422286393267 tk: 5 x_norm: 25.463093041654282\n",
      "Iteration 3319 - Grad. Norm.: 0.0006190182946743207 Norm. Diff.: 0.0030957567103735463 tk: 5 x_norm: 25.465709124031846\n",
      "Iteration 3320 - Grad. Norm.: 0.0006188853150226699 Norm. Diff.: 0.00309509147337169 tk: 5 x_norm: 25.468324628295534\n",
      "Iteration 3321 - Grad. Norm.: 0.000618752403064991 Norm. Diff.: 0.003094426575113511 tk: 5 x_norm: 25.47093955473956\n",
      "Iteration 3322 - Grad. Norm.: 0.0006186195587465789 Norm. Diff.: 0.0030937620153249175 tk: 5 x_norm: 25.473553903657887\n",
      "Iteration 3323 - Grad. Norm.: 0.0006184867820127882 Norm. Diff.: 0.0030930977937327236 tk: 5 x_norm: 25.476167675344268\n",
      "Iteration 3324 - Grad. Norm.: 0.0006183540728090331 Norm. Diff.: 0.0030924339100639295 tk: 5 x_norm: 25.478780870092198\n",
      "Iteration 3325 - Grad. Norm.: 0.0006182214310807869 Norm. Diff.: 0.0030917703640452117 tk: 5 x_norm: 25.481393488194957\n",
      "Iteration 3326 - Grad. Norm.: 0.0006180888567735834 Norm. Diff.: 0.0030911071554038843 tk: 5 x_norm: 25.484005529945573\n",
      "Iteration 3327 - Grad. Norm.: 0.0006179563498330155 Norm. Diff.: 0.003090444283867877 tk: 5 x_norm: 25.48661699563685\n",
      "Iteration 3328 - Grad. Norm.: 0.0006178239102047359 Norm. Diff.: 0.00308978174916506 tk: 5 x_norm: 25.489227885561355\n",
      "Iteration 3329 - Grad. Norm.: 0.0006176915378344552 Norm. Diff.: 0.0030891195510235683 tk: 5 x_norm: 25.49183820001143\n",
      "Iteration 3330 - Grad. Norm.: 0.0006175592326679446 Norm. Diff.: 0.003088457689172328 tk: 5 x_norm: 25.494447939279162\n",
      "Iteration 3331 - Grad. Norm.: 0.000617426994651034 Norm. Diff.: 0.003087796163339428 tk: 5 x_norm: 25.497057103656434\n",
      "Iteration 3332 - Grad. Norm.: 0.000617294823729613 Norm. Diff.: 0.003087134973255272 tk: 5 x_norm: 25.49966569343487\n",
      "Iteration 3333 - Grad. Norm.: 0.0006171627198496296 Norm. Diff.: 0.00308647411864785 tk: 5 x_norm: 25.502273708905882\n",
      "Iteration 3334 - Grad. Norm.: 0.0006170306829570902 Norm. Diff.: 0.0030858135992478937 tk: 5 x_norm: 25.504881150360635\n",
      "Iteration 3335 - Grad. Norm.: 0.0006168987129980602 Norm. Diff.: 0.0030851534147854683 tk: 5 x_norm: 25.507488018090065\n",
      "Iteration 3336 - Grad. Norm.: 0.0006167668099186648 Norm. Diff.: 0.003084493564990382 tk: 5 x_norm: 25.510094312384876\n",
      "Iteration 3337 - Grad. Norm.: 0.0006166349736650864 Norm. Diff.: 0.003083834049593424 tk: 5 x_norm: 25.512700033535555\n",
      "Iteration 3338 - Grad. Norm.: 0.0006165032041835679 Norm. Diff.: 0.0030831748683256884 tk: 5 x_norm: 25.515305181832343\n",
      "Iteration 3339 - Grad. Norm.: 0.0006163715014204089 Norm. Diff.: 0.0030825160209178044 tk: 5 x_norm: 25.517909757565235\n",
      "Iteration 3340 - Grad. Norm.: 0.0006162398653219678 Norm. Diff.: 0.0030818575071018136 tk: 5 x_norm: 25.520513761024027\n",
      "Iteration 3341 - Grad. Norm.: 0.0006161082958346619 Norm. Diff.: 0.00308119932660995 tk: 5 x_norm: 25.523117192498276\n",
      "Iteration 3342 - Grad. Norm.: 0.0006159767929049672 Norm. Diff.: 0.0030805414791735186 tk: 5 x_norm: 25.525720052277286\n",
      "Iteration 3343 - Grad. Norm.: 0.0006158453564794165 Norm. Diff.: 0.0030798839645247533 tk: 5 x_norm: 25.52832234065016\n",
      "Iteration 3344 - Grad. Norm.: 0.0006157139865046009 Norm. Diff.: 0.0030792267823973305 tk: 5 x_norm: 25.530924057905757\n",
      "Iteration 3345 - Grad. Norm.: 0.0006155826829271713 Norm. Diff.: 0.003078569932523251 tk: 5 x_norm: 25.533525204332708\n",
      "Iteration 3346 - Grad. Norm.: 0.0006154514456938342 Norm. Diff.: 0.0030779134146357843 tk: 5 x_norm: 25.536125780219407\n",
      "Iteration 3347 - Grad. Norm.: 0.0006153202747513555 Norm. Diff.: 0.003077257228469368 tk: 5 x_norm: 25.53872578585403\n",
      "Iteration 3348 - Grad. Norm.: 0.0006151891700465587 Norm. Diff.: 0.0030766013737566294 tk: 5 x_norm: 25.541325221524534\n",
      "Iteration 3349 - Grad. Norm.: 0.0006150581315263249 Norm. Diff.: 0.0030759458502329475 tk: 5 x_norm: 25.543924087518622\n",
      "Iteration 3350 - Grad. Norm.: 0.0006149271591375927 Norm. Diff.: 0.0030752906576312885 tk: 5 x_norm: 25.546522384123772\n",
      "Iteration 3351 - Grad. Norm.: 0.0006147962528273574 Norm. Diff.: 0.003074635795688217 tk: 5 x_norm: 25.549120111627268\n",
      "Iteration 3352 - Grad. Norm.: 0.0006146654125426747 Norm. Diff.: 0.0030739812641369696 tk: 5 x_norm: 25.55171727031612\n",
      "Iteration 3353 - Grad. Norm.: 0.0006145346382306539 Norm. Diff.: 0.0030733270627130425 tk: 5 x_norm: 25.55431386047714\n",
      "Iteration 3354 - Grad. Norm.: 0.0006144039298384643 Norm. Diff.: 0.003072673191153195 tk: 5 x_norm: 25.55690988239691\n",
      "Iteration 3355 - Grad. Norm.: 0.0006142732873133313 Norm. Diff.: 0.003072019649192509 tk: 5 x_norm: 25.559505336361763\n",
      "Iteration 3356 - Grad. Norm.: 0.0006141427106025375 Norm. Diff.: 0.003071366436566635 tk: 5 x_norm: 25.562100222657836\n",
      "Iteration 3357 - Grad. Norm.: 0.0006140121996534245 Norm. Diff.: 0.0030707135530127004 tk: 5 x_norm: 25.56469454157101\n",
      "Iteration 3358 - Grad. Norm.: 0.0006138817544133872 Norm. Diff.: 0.0030700609982668883 tk: 5 x_norm: 25.567288293386966\n",
      "Iteration 3359 - Grad. Norm.: 0.0006137513748298805 Norm. Diff.: 0.0030694087720670245 tk: 5 x_norm: 25.569881478391153\n",
      "Iteration 3360 - Grad. Norm.: 0.0006136210608504157 Norm. Diff.: 0.003068756874149436 tk: 5 x_norm: 25.57247409686878\n",
      "Iteration 3361 - Grad. Norm.: 0.0006134908124225603 Norm. Diff.: 0.003068105304252098 tk: 5 x_norm: 25.575066149104835\n",
      "Iteration 3362 - Grad. Norm.: 0.0006133606294939382 Norm. Diff.: 0.0030674540621129704 tk: 5 x_norm: 25.57765763538409\n",
      "Iteration 3363 - Grad. Norm.: 0.0006132305120122311 Norm. Diff.: 0.003066803147469559 tk: 5 x_norm: 25.580248555991076\n",
      "Iteration 3364 - Grad. Norm.: 0.0006131004599251755 Norm. Diff.: 0.003066152560061459 tk: 5 x_norm: 25.582838911210125\n",
      "Iteration 3365 - Grad. Norm.: 0.000612970473180566 Norm. Diff.: 0.0030655022996260053 tk: 5 x_norm: 25.58542870132532\n",
      "Iteration 3366 - Grad. Norm.: 0.000612840551726254 Norm. Diff.: 0.003064852365902617 tk: 5 x_norm: 25.588017926620527\n",
      "Iteration 3367 - Grad. Norm.: 0.0006127106955101453 Norm. Diff.: 0.003064202758631278 tk: 5 x_norm: 25.590606587379384\n",
      "Iteration 3368 - Grad. Norm.: 0.000612580904480203 Norm. Diff.: 0.0030635534775506545 tk: 5 x_norm: 25.593194683885326\n",
      "Iteration 3369 - Grad. Norm.: 0.0006124511785844456 Norm. Diff.: 0.003062904522401022 tk: 5 x_norm: 25.59578221642154\n",
      "Iteration 3370 - Grad. Norm.: 0.0006123215177709507 Norm. Diff.: 0.0030622558929221657 tk: 5 x_norm: 25.59836918527099\n",
      "Iteration 3371 - Grad. Norm.: 0.0006121919219878483 Norm. Diff.: 0.0030616075888546795 tk: 5 x_norm: 25.60095559071644\n",
      "Iteration 3372 - Grad. Norm.: 0.0006120623911833258 Norm. Diff.: 0.0030609596099394273 tk: 5 x_norm: 25.6035414330404\n",
      "Iteration 3373 - Grad. Norm.: 0.0006119329253056269 Norm. Diff.: 0.0030603119559166046 tk: 5 x_norm: 25.606126712525192\n",
      "Iteration 3374 - Grad. Norm.: 0.0006118035243030503 Norm. Diff.: 0.0030596646265279547 tk: 5 x_norm: 25.608711429452875\n",
      "Iteration 3375 - Grad. Norm.: 0.0006116741881239501 Norm. Diff.: 0.003059017621515455 tk: 5 x_norm: 25.611295584105328\n",
      "Iteration 3376 - Grad. Norm.: 0.0006115449167167385 Norm. Diff.: 0.003058370940619787 tk: 5 x_norm: 25.61387917676417\n",
      "Iteration 3377 - Grad. Norm.: 0.0006114157100298801 Norm. Diff.: 0.003057724583583687 tk: 5 x_norm: 25.616462207710818\n",
      "Iteration 3378 - Grad. Norm.: 0.0006112865680118974 Norm. Diff.: 0.0030570785501493085 tk: 5 x_norm: 25.61904467722648\n",
      "Iteration 3379 - Grad. Norm.: 0.0006111574906113676 Norm. Diff.: 0.0030564328400595107 tk: 5 x_norm: 25.621626585592104\n",
      "Iteration 3380 - Grad. Norm.: 0.0006110284777769213 Norm. Diff.: 0.0030557874530570727 tk: 5 x_norm: 25.624207933088467\n",
      "Iteration 3381 - Grad. Norm.: 0.0006108995294572487 Norm. Diff.: 0.0030551423888845342 tk: 5 x_norm: 25.62678871999608\n",
      "Iteration 3382 - Grad. Norm.: 0.0006107706456010906 Norm. Diff.: 0.0030544976472863788 tk: 5 x_norm: 25.629368946595257\n",
      "Iteration 3383 - Grad. Norm.: 0.0006106418261572454 Norm. Diff.: 0.0030538532280054154 tk: 5 x_norm: 25.63194861316609\n",
      "Iteration 3384 - Grad. Norm.: 0.0006105130710745672 Norm. Diff.: 0.0030532091307863087 tk: 5 x_norm: 25.634527719988444\n",
      "Iteration 3385 - Grad. Norm.: 0.0006103843803019628 Norm. Diff.: 0.0030525653553728593 tk: 5 x_norm: 25.637106267341977\n",
      "Iteration 3386 - Grad. Norm.: 0.0006102557537883963 Norm. Diff.: 0.003051921901509862 tk: 5 x_norm: 25.639684255506094\n",
      "Iteration 3387 - Grad. Norm.: 0.0006101271914828846 Norm. Diff.: 0.003051278768941945 tk: 5 x_norm: 25.642261684760037\n",
      "Iteration 3388 - Grad. Norm.: 0.0006099986933345014 Norm. Diff.: 0.0030506359574146024 tk: 5 x_norm: 25.644838555382776\n",
      "Iteration 3389 - Grad. Norm.: 0.0006098702592923731 Norm. Diff.: 0.0030499934666725933 tk: 5 x_norm: 25.647414867653087\n",
      "Iteration 3390 - Grad. Norm.: 0.0006097418893056818 Norm. Diff.: 0.00304935129646198 tk: 5 x_norm: 25.649990621849525\n",
      "Iteration 3391 - Grad. Norm.: 0.0006096135833236646 Norm. Diff.: 0.0030487094465287573 tk: 5 x_norm: 25.652565818250416\n",
      "Iteration 3392 - Grad. Norm.: 0.0006094853412956119 Norm. Diff.: 0.00304806791661834 tk: 5 x_norm: 25.6551404571339\n",
      "Iteration 3393 - Grad. Norm.: 0.0006093571631708689 Norm. Diff.: 0.003047426706478183 tk: 5 x_norm: 25.657714538777853\n",
      "Iteration 3394 - Grad. Norm.: 0.0006092290488988353 Norm. Diff.: 0.003046785815854133 tk: 5 x_norm: 25.660288063459955\n",
      "Iteration 3395 - Grad. Norm.: 0.0006091009984289658 Norm. Diff.: 0.0030461452444943173 tk: 5 x_norm: 25.662861031457684\n",
      "Iteration 3396 - Grad. Norm.: 0.0006089730117107687 Norm. Diff.: 0.0030455049921449726 tk: 5 x_norm: 25.66543344304828\n",
      "Iteration 3397 - Grad. Norm.: 0.0006088450886938046 Norm. Diff.: 0.0030448650585538097 tk: 5 x_norm: 25.668005298508763\n",
      "Iteration 3398 - Grad. Norm.: 0.0006087172293276908 Norm. Diff.: 0.00304422544346927 tk: 5 x_norm: 25.670576598115954\n",
      "Iteration 3399 - Grad. Norm.: 0.0006085894335620985 Norm. Diff.: 0.0030435861466381925 tk: 5 x_norm: 25.673147342146446\n",
      "Iteration 3400 - Grad. Norm.: 0.0006084617013467512 Norm. Diff.: 0.0030429471678107586 tk: 5 x_norm: 25.675717530876618\n",
      "Iteration 3401 - Grad. Norm.: 0.0006083340326314268 Norm. Diff.: 0.0030423085067338555 tk: 5 x_norm: 25.67828716458263\n",
      "Iteration 3402 - Grad. Norm.: 0.0006082064273659578 Norm. Diff.: 0.0030416701631572436 tk: 5 x_norm: 25.680856243540436\n",
      "Iteration 3403 - Grad. Norm.: 0.0006080788855002275 Norm. Diff.: 0.0030410321368296 tk: 5 x_norm: 25.68342476802576\n",
      "Iteration 3404 - Grad. Norm.: 0.0006079514069841773 Norm. Diff.: 0.003040394427500955 tk: 5 x_norm: 25.685992738314127\n",
      "Iteration 3405 - Grad. Norm.: 0.0006078239917677989 Norm. Diff.: 0.003039757034920775 tk: 5 x_norm: 25.68856015468082\n",
      "Iteration 3406 - Grad. Norm.: 0.0006076966398011388 Norm. Diff.: 0.003039119958838751 tk: 5 x_norm: 25.691127017400945\n",
      "Iteration 3407 - Grad. Norm.: 0.0006075693510342961 Norm. Diff.: 0.003038483199005777 tk: 5 x_norm: 25.693693326749358\n",
      "Iteration 3408 - Grad. Norm.: 0.0006074421254174243 Norm. Diff.: 0.003037846755171504 tk: 5 x_norm: 25.696259083000733\n",
      "Iteration 3409 - Grad. Norm.: 0.0006073149629007282 Norm. Diff.: 0.0030372106270869586 tk: 5 x_norm: 25.698824286429485\n",
      "Iteration 3410 - Grad. Norm.: 0.0006071878634344687 Norm. Diff.: 0.00303657481450365 tk: 5 x_norm: 25.70138893730987\n",
      "Iteration 3411 - Grad. Norm.: 0.0006070608269689565 Norm. Diff.: 0.0030359393171723145 tk: 5 x_norm: 25.703953035915877\n",
      "Iteration 3412 - Grad. Norm.: 0.0006069338534545585 Norm. Diff.: 0.0030353041348447954 tk: 5 x_norm: 25.706516582521324\n",
      "Iteration 3413 - Grad. Norm.: 0.0006068069428416921 Norm. Diff.: 0.003034669267272645 tk: 5 x_norm: 25.709079577399795\n",
      "Iteration 3414 - Grad. Norm.: 0.0006066800950808298 Norm. Diff.: 0.0030340347142087457 tk: 5 x_norm: 25.711642020824655\n",
      "Iteration 3415 - Grad. Norm.: 0.0006065533101224939 Norm. Diff.: 0.0030334004754037913 tk: 5 x_norm: 25.714203913069078\n",
      "Iteration 3416 - Grad. Norm.: 0.0006064265879172627 Norm. Diff.: 0.003032766550612643 tk: 5 x_norm: 25.716765254406\n",
      "Iteration 3417 - Grad. Norm.: 0.0006062999284157662 Norm. Diff.: 0.00303213293958625 tk: 5 x_norm: 25.719326045108165\n",
      "Iteration 3418 - Grad. Norm.: 0.000606173331568685 Norm. Diff.: 0.003031499642078707 tk: 5 x_norm: 25.721886285448097\n",
      "Iteration 3419 - Grad. Norm.: 0.0006060467973267551 Norm. Diff.: 0.003030866657843488 tk: 5 x_norm: 25.7244459756981\n",
      "Iteration 3420 - Grad. Norm.: 0.0006059203256407632 Norm. Diff.: 0.0030302339866337554 tk: 5 x_norm: 25.72700511613028\n",
      "Iteration 3421 - Grad. Norm.: 0.0006057939164615499 Norm. Diff.: 0.003029601628203818 tk: 5 x_norm: 25.729563707016524\n",
      "Iteration 3422 - Grad. Norm.: 0.0006056675697400061 Norm. Diff.: 0.0030289695823076533 tk: 5 x_norm: 25.732121748628508\n",
      "Iteration 3423 - Grad. Norm.: 0.0006055412854270767 Norm. Diff.: 0.0030283378487002744 tk: 5 x_norm: 25.7346792412377\n",
      "Iteration 3424 - Grad. Norm.: 0.000605415063473758 Norm. Diff.: 0.003027706427135452 tk: 5 x_norm: 25.73723618511535\n",
      "Iteration 3425 - Grad. Norm.: 0.000605288903831098 Norm. Diff.: 0.00302707531736861 tk: 5 x_norm: 25.739792580532505\n",
      "Iteration 3426 - Grad. Norm.: 0.0006051628064501997 Norm. Diff.: 0.0030264445191553507 tk: 5 x_norm: 25.742348427760003\n",
      "Iteration 3427 - Grad. Norm.: 0.0006050367712822139 Norm. Diff.: 0.0030258140322508295 tk: 5 x_norm: 25.744903727068454\n",
      "Iteration 3428 - Grad. Norm.: 0.0006049107982783449 Norm. Diff.: 0.0030251838564113328 tk: 5 x_norm: 25.747458478728287\n",
      "Iteration 3429 - Grad. Norm.: 0.0006047848873898498 Norm. Diff.: 0.0030245539913920805 tk: 5 x_norm: 25.750012683009693\n",
      "Iteration 3430 - Grad. Norm.: 0.0006046590385680371 Norm. Diff.: 0.0030239244369493416 tk: 5 x_norm: 25.752566340182675\n",
      "Iteration 3431 - Grad. Norm.: 0.0006045332517642672 Norm. Diff.: 0.0030232951928402195 tk: 5 x_norm: 25.75511945051701\n",
      "Iteration 3432 - Grad. Norm.: 0.0006044075269299518 Norm. Diff.: 0.0030226662588211536 tk: 5 x_norm: 25.75767201428229\n",
      "Iteration 3433 - Grad. Norm.: 0.0006042818640165529 Norm. Diff.: 0.003022037634649962 tk: 5 x_norm: 25.76022403174786\n",
      "Iteration 3434 - Grad. Norm.: 0.0006041562629755855 Norm. Diff.: 0.0030214093200828375 tk: 5 x_norm: 25.76277550318288\n",
      "Iteration 3435 - Grad. Norm.: 0.0006040307237586174 Norm. Diff.: 0.003020781314878075 tk: 5 x_norm: 25.765326428856323\n",
      "Iteration 3436 - Grad. Norm.: 0.0006039052463172641 Norm. Diff.: 0.003020153618793023 tk: 5 x_norm: 25.767876809036903\n",
      "Iteration 3437 - Grad. Norm.: 0.0006037798306031968 Norm. Diff.: 0.0030195262315863758 tk: 5 x_norm: 25.77042664399317\n",
      "Iteration 3438 - Grad. Norm.: 0.0006036544765681341 Norm. Diff.: 0.003018899153015791 tk: 5 x_norm: 25.772975933993436\n",
      "Iteration 3439 - Grad. Norm.: 0.0006035291841638474 Norm. Diff.: 0.0030182723828406444 tk: 5 x_norm: 25.775524679305835\n",
      "Iteration 3440 - Grad. Norm.: 0.0006034039533421594 Norm. Diff.: 0.003017645920819176 tk: 5 x_norm: 25.778072880198263\n",
      "Iteration 3441 - Grad. Norm.: 0.000603278784054944 Norm. Diff.: 0.0030170197667108937 tk: 5 x_norm: 25.780620536938436\n",
      "Iteration 3442 - Grad. Norm.: 0.0006031536762541261 Norm. Diff.: 0.0030163939202746196 tk: 5 x_norm: 25.78316764979384\n",
      "Iteration 3443 - Grad. Norm.: 0.0006030286298916792 Norm. Diff.: 0.003015768381270675 tk: 5 x_norm: 25.785714219031767\n",
      "Iteration 3444 - Grad. Norm.: 0.0006029036449196308 Norm. Diff.: 0.003015143149458339 tk: 5 x_norm: 25.788260244919304\n",
      "Iteration 3445 - Grad. Norm.: 0.0006027787212900587 Norm. Diff.: 0.003014518224597901 tk: 5 x_norm: 25.790805727723328\n",
      "Iteration 3446 - Grad. Norm.: 0.0006026538589550892 Norm. Diff.: 0.003013893606450177 tk: 5 x_norm: 25.793350667710502\n",
      "Iteration 3447 - Grad. Norm.: 0.0006025290578669005 Norm. Diff.: 0.003013269294775495 tk: 5 x_norm: 25.795895065147306\n",
      "Iteration 3448 - Grad. Norm.: 0.0006024043179777234 Norm. Diff.: 0.003012645289334487 tk: 5 x_norm: 25.798438920299986\n",
      "Iteration 3449 - Grad. Norm.: 0.0006022796392398361 Norm. Diff.: 0.003012021589888584 tk: 5 x_norm: 25.800982233434603\n",
      "Iteration 3450 - Grad. Norm.: 0.0006021550216055683 Norm. Diff.: 0.0030113981961990047 tk: 5 x_norm: 25.803525004816997\n",
      "Iteration 3451 - Grad. Norm.: 0.0006020304650273 Norm. Diff.: 0.0030107751080279 tk: 5 x_norm: 25.80606723471282\n",
      "Iteration 3452 - Grad. Norm.: 0.0006019059694574624 Norm. Diff.: 0.003010152325136452 tk: 5 x_norm: 25.808608923387503\n",
      "Iteration 3453 - Grad. Norm.: 0.0006017815348485364 Norm. Diff.: 0.0030095298472873786 tk: 5 x_norm: 25.811150071106297\n",
      "Iteration 3454 - Grad. Norm.: 0.0006016571611530525 Norm. Diff.: 0.0030089076742427835 tk: 5 x_norm: 25.813690678134222\n",
      "Iteration 3455 - Grad. Norm.: 0.0006015328483235925 Norm. Diff.: 0.003008285805765239 tk: 5 x_norm: 25.8162307447361\n",
      "Iteration 3456 - Grad. Norm.: 0.0006014085963127867 Norm. Diff.: 0.0030076642416178474 tk: 5 x_norm: 25.818770271176565\n",
      "Iteration 3457 - Grad. Norm.: 0.0006012844050733167 Norm. Diff.: 0.0030070429815640784 tk: 5 x_norm: 25.821309257720024\n",
      "Iteration 3458 - Grad. Norm.: 0.0006011602745579132 Norm. Diff.: 0.003006422025366602 tk: 5 x_norm: 25.823847704630694\n",
      "Iteration 3459 - Grad. Norm.: 0.0006010362047193575 Norm. Diff.: 0.003005801372789536 tk: 5 x_norm: 25.826385612172594\n",
      "Iteration 3460 - Grad. Norm.: 0.0006009121955104803 Norm. Diff.: 0.003005181023596771 tk: 5 x_norm: 25.828922980609526\n",
      "Iteration 3461 - Grad. Norm.: 0.0006007882468841609 Norm. Diff.: 0.0030045609775523983 tk: 5 x_norm: 25.831459810205097\n",
      "Iteration 3462 - Grad. Norm.: 0.0006006643587933291 Norm. Diff.: 0.003003941234420933 tk: 5 x_norm: 25.833996101222716\n",
      "Iteration 3463 - Grad. Norm.: 0.0006005405311909676 Norm. Diff.: 0.0030033217939666804 tk: 5 x_norm: 25.83653185392558\n",
      "Iteration 3464 - Grad. Norm.: 0.0006004167640301031 Norm. Diff.: 0.003002702655954666 tk: 5 x_norm: 25.83906706857669\n",
      "Iteration 3465 - Grad. Norm.: 0.0006002930572638136 Norm. Diff.: 0.0030020838201504207 tk: 5 x_norm: 25.841601745438833\n",
      "Iteration 3466 - Grad. Norm.: 0.000600169410845228 Norm. Diff.: 0.003001465286319141 tk: 5 x_norm: 25.844135884774623\n",
      "Iteration 3467 - Grad. Norm.: 0.000600045824727524 Norm. Diff.: 0.0030008470542259363 tk: 5 x_norm: 25.846669486846434\n",
      "Iteration 3468 - Grad. Norm.: 0.0005999222988639264 Norm. Diff.: 0.003000229123637543 tk: 5 x_norm: 25.849202551916466\n",
      "Iteration 3469 - Grad. Norm.: 0.0005997988332077141 Norm. Diff.: 0.00299961149431969 tk: 5 x_norm: 25.851735080246726\n",
      "Iteration 3470 - Grad. Norm.: 0.0005996754277122086 Norm. Diff.: 0.0029989941660387215 tk: 5 x_norm: 25.854267072098978\n",
      "Iteration 3471 - Grad. Norm.: 0.0005995520823307858 Norm. Diff.: 0.0029983771385612137 tk: 5 x_norm: 25.856798527734824\n",
      "Iteration 3472 - Grad. Norm.: 0.0005994287970168681 Norm. Diff.: 0.002997760411653763 tk: 5 x_norm: 25.859329447415654\n",
      "Iteration 3473 - Grad. Norm.: 0.0005993055717239262 Norm. Diff.: 0.002997143985084112 tk: 5 x_norm: 25.861859831402654\n",
      "Iteration 3474 - Grad. Norm.: 0.0005991824064054835 Norm. Diff.: 0.002996527858619632 tk: 5 x_norm: 25.86438967995682\n",
      "Iteration 3475 - Grad. Norm.: 0.000599059301015107 Norm. Diff.: 0.0029959120320275866 tk: 5 x_norm: 25.86691899333892\n",
      "Iteration 3476 - Grad. Norm.: 0.0005989362555064172 Norm. Diff.: 0.0029952965050754907 tk: 5 x_norm: 25.86944777180958\n",
      "Iteration 3477 - Grad. Norm.: 0.0005988132698330793 Norm. Diff.: 0.0029946812775321066 tk: 5 x_norm: 25.871976015629148\n",
      "Iteration 3478 - Grad. Norm.: 0.0005986903439488092 Norm. Diff.: 0.002994066349165249 tk: 5 x_norm: 25.874503725057842\n",
      "Iteration 3479 - Grad. Norm.: 0.0005985674778073717 Norm. Diff.: 0.0029934517197439986 tk: 5 x_norm: 25.87703090035565\n",
      "Iteration 3480 - Grad. Norm.: 0.0005984446713625793 Norm. Diff.: 0.002992837389036645 tk: 5 x_norm: 25.879557541782358\n",
      "Iteration 3481 - Grad. Norm.: 0.0005983219245682927 Norm. Diff.: 0.0029922233568129117 tk: 5 x_norm: 25.882083649597554\n",
      "Iteration 3482 - Grad. Norm.: 0.0005981992373784225 Norm. Diff.: 0.002991609622841445 tk: 5 x_norm: 25.884609224060647\n",
      "Iteration 3483 - Grad. Norm.: 0.0005980766097469243 Norm. Diff.: 0.002990996186892281 tk: 5 x_norm: 25.887134265430827\n",
      "Iteration 3484 - Grad. Norm.: 0.0005979540416278062 Norm. Diff.: 0.002990383048734695 tk: 5 x_norm: 25.889658773967106\n",
      "Iteration 3485 - Grad. Norm.: 0.0005978315329751206 Norm. Diff.: 0.0029897702081391393 tk: 5 x_norm: 25.89218274992827\n",
      "Iteration 3486 - Grad. Norm.: 0.0005977090837429711 Norm. Diff.: 0.0029891576648756533 tk: 5 x_norm: 25.894706193572926\n",
      "Iteration 3487 - Grad. Norm.: 0.0005975866938855071 Norm. Diff.: 0.0029885454187147894 tk: 5 x_norm: 25.897229105159482\n",
      "Iteration 3488 - Grad. Norm.: 0.0005974643633569273 Norm. Diff.: 0.0029879334694275744 tk: 5 x_norm: 25.899751484946158\n",
      "Iteration 3489 - Grad. Norm.: 0.0005973420921114776 Norm. Diff.: 0.0029873218167846306 tk: 5 x_norm: 25.902273333190955\n",
      "Iteration 3490 - Grad. Norm.: 0.0005972198801034531 Norm. Diff.: 0.0029867104605575926 tk: 5 x_norm: 25.904794650151686\n",
      "Iteration 3491 - Grad. Norm.: 0.0005970977272871948 Norm. Diff.: 0.002986099400517199 tk: 5 x_norm: 25.90731543608598\n",
      "Iteration 3492 - Grad. Norm.: 0.0005969756336170921 Norm. Diff.: 0.002985488636435677 tk: 5 x_norm: 25.90983569125126\n",
      "Iteration 3493 - Grad. Norm.: 0.0005968535990475826 Norm. Diff.: 0.0029848781680856815 tk: 5 x_norm: 25.912355415904745\n",
      "Iteration 3494 - Grad. Norm.: 0.0005967316235331515 Norm. Diff.: 0.002984267995238007 tk: 5 x_norm: 25.91487461030347\n",
      "Iteration 3495 - Grad. Norm.: 0.0005966097070283311 Norm. Diff.: 0.002983658117665712 tk: 5 x_norm: 25.917393274704267\n",
      "Iteration 3496 - Grad. Norm.: 0.000596487849487701 Norm. Diff.: 0.0029830485351416657 tk: 5 x_norm: 25.919911409363788\n",
      "Iteration 3497 - Grad. Norm.: 0.0005963660508658885 Norm. Diff.: 0.0029824392474383835 tk: 5 x_norm: 25.92242901453846\n",
      "Iteration 3498 - Grad. Norm.: 0.000596244311117569 Norm. Diff.: 0.0029818302543296407 tk: 5 x_norm: 25.924946090484536\n",
      "Iteration 3499 - Grad. Norm.: 0.0005961226301974639 Norm. Diff.: 0.0029812215555878804 tk: 5 x_norm: 25.927462637458078\n",
      "Iteration 3500 - Grad. Norm.: 0.0005960010080603423 Norm. Diff.: 0.0029806131509871963 tk: 5 x_norm: 25.929978655714947\n",
      "Iteration 3501 - Grad. Norm.: 0.0005958794446610216 Norm. Diff.: 0.0029800050403014345 tk: 5 x_norm: 25.9324941455108\n",
      "Iteration 3502 - Grad. Norm.: 0.0005957579399543638 Norm. Diff.: 0.002979397223305207 tk: 5 x_norm: 25.93500910710111\n",
      "Iteration 3503 - Grad. Norm.: 0.0005956364938952816 Norm. Diff.: 0.002978789699771975 tk: 5 x_norm: 25.937523540741157\n",
      "Iteration 3504 - Grad. Norm.: 0.0005955151064387311 Norm. Diff.: 0.002978182469476598 tk: 5 x_norm: 25.94003744668602\n",
      "Iteration 3505 - Grad. Norm.: 0.0005953937775397168 Norm. Diff.: 0.0029775755321933477 tk: 5 x_norm: 25.942550825190587\n",
      "Iteration 3506 - Grad. Norm.: 0.0005952725071532908 Norm. Diff.: 0.0029769688876989725 tk: 5 x_norm: 25.945063676509555\n",
      "Iteration 3507 - Grad. Norm.: 0.0005951512952345514 Norm. Diff.: 0.002976362535766498 tk: 5 x_norm: 25.94757600089743\n",
      "Iteration 3508 - Grad. Norm.: 0.0005950301417386424 Norm. Diff.: 0.0029757564761727097 tk: 5 x_norm: 25.950087798608518\n",
      "Iteration 3509 - Grad. Norm.: 0.0005949090466207569 Norm. Diff.: 0.0029751507086934114 tk: 5 x_norm: 25.952599069896934\n",
      "Iteration 3510 - Grad. Norm.: 0.0005947880098361315 Norm. Diff.: 0.0029745452331036595 tk: 5 x_norm: 25.955109815016606\n",
      "Iteration 3511 - Grad. Norm.: 0.0005946670313400525 Norm. Diff.: 0.002973940049180924 tk: 5 x_norm: 25.95762003422126\n",
      "Iteration 3512 - Grad. Norm.: 0.0005945461110878515 Norm. Diff.: 0.002973335156700225 tk: 5 x_norm: 25.960129727764432\n",
      "Iteration 3513 - Grad. Norm.: 0.000594425249034905 Norm. Diff.: 0.0029727305554391715 tk: 5 x_norm: 25.962638895899477\n",
      "Iteration 3514 - Grad. Norm.: 0.0005943044451366385 Norm. Diff.: 0.0029721262451747714 tk: 5 x_norm: 25.965147538879545\n",
      "Iteration 3515 - Grad. Norm.: 0.0005941836993485222 Norm. Diff.: 0.002971522225682891 tk: 5 x_norm: 25.967655656957604\n",
      "Iteration 3516 - Grad. Norm.: 0.0005940630116260711 Norm. Diff.: 0.0029709184967427146 tk: 5 x_norm: 25.970163250386417\n",
      "Iteration 3517 - Grad. Norm.: 0.0005939423819248513 Norm. Diff.: 0.0029703150581302357 tk: 5 x_norm: 25.97267031941857\n",
      "Iteration 3518 - Grad. Norm.: 0.0005938218102004688 Norm. Diff.: 0.002969711909623844 tk: 5 x_norm: 25.975176864306448\n",
      "Iteration 3519 - Grad. Norm.: 0.000593701296408582 Norm. Diff.: 0.002969109051002175 tk: 5 x_norm: 25.97768288530225\n",
      "Iteration 3520 - Grad. Norm.: 0.0005935808405048898 Norm. Diff.: 0.0029685064820426394 tk: 5 x_norm: 25.98018838265799\n",
      "Iteration 3521 - Grad. Norm.: 0.0005934604424451403 Norm. Diff.: 0.0029679042025246207 tk: 5 x_norm: 25.982693356625482\n",
      "Iteration 3522 - Grad. Norm.: 0.0005933401021851255 Norm. Diff.: 0.0029673022122255624 tk: 5 x_norm: 25.985197807456345\n",
      "Iteration 3523 - Grad. Norm.: 0.0005932198196806873 Norm. Diff.: 0.0029667005109257545 tk: 5 x_norm: 25.987701735402023\n",
      "Iteration 3524 - Grad. Norm.: 0.0005930995948877073 Norm. Diff.: 0.002966099098403544 tk: 5 x_norm: 25.99020514071376\n",
      "Iteration 3525 - Grad. Norm.: 0.0005929794277621171 Norm. Diff.: 0.002965497974438898 tk: 5 x_norm: 25.992708023642614\n",
      "Iteration 3526 - Grad. Norm.: 0.0005928593182598929 Norm. Diff.: 0.0029648971388103696 tk: 5 x_norm: 25.995210384439456\n",
      "Iteration 3527 - Grad. Norm.: 0.0005927392663370578 Norm. Diff.: 0.002964296591299347 tk: 5 x_norm: 25.997712223354952\n",
      "Iteration 3528 - Grad. Norm.: 0.0005926192719496766 Norm. Diff.: 0.0029636963316853216 tk: 5 x_norm: 26.000213540639603\n",
      "Iteration 3529 - Grad. Norm.: 0.0005924993350538646 Norm. Diff.: 0.002963096359748355 tk: 5 x_norm: 26.0027143365437\n",
      "Iteration 3530 - Grad. Norm.: 0.0005923794556057786 Norm. Diff.: 0.002962496675269279 tk: 5 x_norm: 26.005214611317356\n",
      "Iteration 3531 - Grad. Norm.: 0.0005922596335616224 Norm. Diff.: 0.002961897278028832 tk: 5 x_norm: 26.007714365210507\n",
      "Iteration 3532 - Grad. Norm.: 0.0005921398688776458 Norm. Diff.: 0.0029612981678081365 tk: 5 x_norm: 26.010213598472863\n",
      "Iteration 3533 - Grad. Norm.: 0.0005920201615101422 Norm. Diff.: 0.0029606993443882287 tk: 5 x_norm: 26.01271231135399\n",
      "Iteration 3534 - Grad. Norm.: 0.00059190051141545 Norm. Diff.: 0.002960100807550921 tk: 5 x_norm: 26.015210504103244\n",
      "Iteration 3535 - Grad. Norm.: 0.0005917809185499567 Norm. Diff.: 0.0029595025570773644 tk: 5 x_norm: 26.017708176969776\n",
      "Iteration 3536 - Grad. Norm.: 0.0005916613828700889 Norm. Diff.: 0.0029589045927496294 tk: 5 x_norm: 26.020205330202593\n",
      "Iteration 3537 - Grad. Norm.: 0.0005915419043323229 Norm. Diff.: 0.0029583069143502925 tk: 5 x_norm: 26.022701964050476\n",
      "Iteration 3538 - Grad. Norm.: 0.0005914224828931783 Norm. Diff.: 0.002957709521661508 tk: 5 x_norm: 26.02519807876204\n",
      "Iteration 3539 - Grad. Norm.: 0.0005913031185092192 Norm. Diff.: 0.002957112414466006 tk: 5 x_norm: 26.0276936745857\n",
      "Iteration 3540 - Grad. Norm.: 0.0005911838111370546 Norm. Diff.: 0.0029565155925460845 tk: 5 x_norm: 26.030188751769696\n",
      "Iteration 3541 - Grad. Norm.: 0.0005910645607333395 Norm. Diff.: 0.0029559190556855365 tk: 5 x_norm: 26.03268331056207\n",
      "Iteration 3542 - Grad. Norm.: 0.0005909453672547734 Norm. Diff.: 0.002955322803666723 tk: 5 x_norm: 26.035177351210685\n",
      "Iteration 3543 - Grad. Norm.: 0.0005908262306580985 Norm. Diff.: 0.00295472683627363 tk: 5 x_norm: 26.03767087396322\n",
      "Iteration 3544 - Grad. Norm.: 0.0005907071509001036 Norm. Diff.: 0.0029541311532902182 tk: 5 x_norm: 26.04016387906715\n",
      "Iteration 3545 - Grad. Norm.: 0.0005905881279376212 Norm. Diff.: 0.0029535357545005425 tk: 5 x_norm: 26.0426563667698\n",
      "Iteration 3546 - Grad. Norm.: 0.0005904691617275292 Norm. Diff.: 0.002952940639688273 tk: 5 x_norm: 26.045148337318277\n",
      "Iteration 3547 - Grad. Norm.: 0.0005903502522267485 Norm. Diff.: 0.002952345808637668 tk: 5 x_norm: 26.047639790959504\n",
      "Iteration 3548 - Grad. Norm.: 0.0005902313993922461 Norm. Diff.: 0.0029517512611336176 tk: 5 x_norm: 26.05013072794024\n",
      "Iteration 3549 - Grad. Norm.: 0.0005901126031810317 Norm. Diff.: 0.0029511569969614313 tk: 5 x_norm: 26.052621148507033\n",
      "Iteration 3550 - Grad. Norm.: 0.0005899938635501606 Norm. Diff.: 0.0029505630159051234 tk: 5 x_norm: 26.055111052906277\n",
      "Iteration 3551 - Grad. Norm.: 0.0005898751804567323 Norm. Diff.: 0.0029499693177506624 tk: 5 x_norm: 26.05760044138415\n",
      "Iteration 3552 - Grad. Norm.: 0.0005897565538578884 Norm. Diff.: 0.002949375902283389 tk: 5 x_norm: 26.060089314186666\n",
      "Iteration 3553 - Grad. Norm.: 0.0005896379837108169 Norm. Diff.: 0.0029487827692897617 tk: 5 x_norm: 26.06257767155964\n",
      "Iteration 3554 - Grad. Norm.: 0.000589519469972749 Norm. Diff.: 0.002948189918554369 tk: 5 x_norm: 26.06506551374872\n",
      "Iteration 3555 - Grad. Norm.: 0.0005894010126009605 Norm. Diff.: 0.002947597349863921 tk: 5 x_norm: 26.067552840999358\n",
      "Iteration 3556 - Grad. Norm.: 0.0005892826115527697 Norm. Diff.: 0.002947005063005037 tk: 5 x_norm: 26.070039653556822\n",
      "Iteration 3557 - Grad. Norm.: 0.0005891642667855408 Norm. Diff.: 0.0029464130577639253 tk: 5 x_norm: 26.0725259516662\n",
      "Iteration 3558 - Grad. Norm.: 0.0005890459782566792 Norm. Diff.: 0.0029458213339271532 tk: 5 x_norm: 26.075011735572406\n",
      "Iteration 3559 - Grad. Norm.: 0.000588927745923637 Norm. Diff.: 0.0029452298912835823 tk: 5 x_norm: 26.07749700552014\n",
      "Iteration 3560 - Grad. Norm.: 0.0005888095697439077 Norm. Diff.: 0.0029446387296184155 tk: 5 x_norm: 26.07998176175396\n",
      "Iteration 3561 - Grad. Norm.: 0.0005886914496750295 Norm. Diff.: 0.0029440478487196484 tk: 5 x_norm: 26.082466004518214\n",
      "Iteration 3562 - Grad. Norm.: 0.0005885733856745841 Norm. Diff.: 0.0029434572483752644 tk: 5 x_norm: 26.08494973405707\n",
      "Iteration 3563 - Grad. Norm.: 0.0005884553777001974 Norm. Diff.: 0.002942866928372808 tk: 5 x_norm: 26.087432950614517\n",
      "Iteration 3564 - Grad. Norm.: 0.0005883374257095367 Norm. Diff.: 0.002942276888500992 tk: 5 x_norm: 26.08991565443437\n",
      "Iteration 3565 - Grad. Norm.: 0.0005882195296603148 Norm. Diff.: 0.0029416871285477117 tk: 5 x_norm: 26.092397845760253\n",
      "Iteration 3566 - Grad. Norm.: 0.0005881016895102879 Norm. Diff.: 0.002941097648301581 tk: 5 x_norm: 26.094879524835605\n",
      "Iteration 3567 - Grad. Norm.: 0.0005879839052172533 Norm. Diff.: 0.0029405084475514313 tk: 5 x_norm: 26.097360691903695\n",
      "Iteration 3568 - Grad. Norm.: 0.0005878661767390538 Norm. Diff.: 0.002939919526086364 tk: 5 x_norm: 26.099841347207594\n",
      "Iteration 3569 - Grad. Norm.: 0.0005877485040335747 Norm. Diff.: 0.0029393308836952207 tk: 5 x_norm: 26.1023214909902\n",
      "Iteration 3570 - Grad. Norm.: 0.000587630887058744 Norm. Diff.: 0.002938742520167727 tk: 5 x_norm: 26.10480112349424\n",
      "Iteration 3571 - Grad. Norm.: 0.0005875133257725339 Norm. Diff.: 0.0029381544352940344 tk: 5 x_norm: 26.10728024496225\n",
      "Iteration 3572 - Grad. Norm.: 0.0005873958201329584 Norm. Diff.: 0.002937566628862859 tk: 5 x_norm: 26.109758855636585\n",
      "Iteration 3573 - Grad. Norm.: 0.0005872783700980745 Norm. Diff.: 0.0029369791006647553 tk: 5 x_norm: 26.112236955759418\n",
      "Iteration 3574 - Grad. Norm.: 0.0005871609756259849 Norm. Diff.: 0.0029363918504904077 tk: 5 x_norm: 26.114714545572745\n",
      "Iteration 3575 - Grad. Norm.: 0.0005870436366748311 Norm. Diff.: 0.0029358048781298364 tk: 5 x_norm: 26.117191625318373\n",
      "Iteration 3576 - Grad. Norm.: 0.0005869263532027992 Norm. Diff.: 0.0029352181833744765 tk: 5 x_norm: 26.119668195237946\n",
      "Iteration 3577 - Grad. Norm.: 0.000586809125168118 Norm. Diff.: 0.0029346317660142434 tk: 5 x_norm: 26.122144255572916\n",
      "Iteration 3578 - Grad. Norm.: 0.0005866919525290605 Norm. Diff.: 0.0029340456258405007 tk: 5 x_norm: 26.12461980656456\n",
      "Iteration 3579 - Grad. Norm.: 0.0005865748352439402 Norm. Diff.: 0.0029334597626455793 tk: 5 x_norm: 26.12709484845398\n",
      "Iteration 3580 - Grad. Norm.: 0.0005864577732711137 Norm. Diff.: 0.0029328741762198692 tk: 5 x_norm: 26.129569381482074\n",
      "Iteration 3581 - Grad. Norm.: 0.0005863407665689807 Norm. Diff.: 0.0029322888663555775 tk: 5 x_norm: 26.13204340588959\n",
      "Iteration 3582 - Grad. Norm.: 0.0005862238150959832 Norm. Diff.: 0.002931703832845188 tk: 5 x_norm: 26.134516921917086\n",
      "Iteration 3583 - Grad. Norm.: 0.000586106918810605 Norm. Diff.: 0.0029311190754802165 tk: 5 x_norm: 26.136989929804944\n",
      "Iteration 3584 - Grad. Norm.: 0.0005859900776713742 Norm. Diff.: 0.0029305345940531975 tk: 5 x_norm: 26.13946242979336\n",
      "Iteration 3585 - Grad. Norm.: 0.0005858732916368596 Norm. Diff.: 0.002929950388357236 tk: 5 x_norm: 26.141934422122365\n",
      "Iteration 3586 - Grad. Norm.: 0.0005857565606656709 Norm. Diff.: 0.0029293664581843877 tk: 5 x_norm: 26.144405907031786\n",
      "Iteration 3587 - Grad. Norm.: 0.000585639884716464 Norm. Diff.: 0.002928782803328516 tk: 5 x_norm: 26.146876884761298\n",
      "Iteration 3588 - Grad. Norm.: 0.0005855232637479339 Norm. Diff.: 0.002928199423582774 tk: 5 x_norm: 26.149347355550393\n",
      "Iteration 3589 - Grad. Norm.: 0.0005854066977188172 Norm. Diff.: 0.002927616318739996 tk: 5 x_norm: 26.15181731963838\n",
      "Iteration 3590 - Grad. Norm.: 0.0005852901865878959 Norm. Diff.: 0.002927033488593969 tk: 5 x_norm: 26.15428677726439\n",
      "Iteration 3591 - Grad. Norm.: 0.0005851737303139901 Norm. Diff.: 0.0029264509329394246 tk: 5 x_norm: 26.15675572866738\n",
      "Iteration 3592 - Grad. Norm.: 0.0005850573288559654 Norm. Diff.: 0.0029258686515700716 tk: 5 x_norm: 26.159224174086134\n",
      "Iteration 3593 - Grad. Norm.: 0.0005849409821727268 Norm. Diff.: 0.002925286644279924 tk: 5 x_norm: 26.161692113759237\n",
      "Iteration 3594 - Grad. Norm.: 0.0005848246902232217 Norm. Diff.: 0.002924704910863791 tk: 5 x_norm: 26.164159547925134\n",
      "Iteration 3595 - Grad. Norm.: 0.0005847084529664398 Norm. Diff.: 0.002924123451116124 tk: 5 x_norm: 26.16662647682206\n",
      "Iteration 3596 - Grad. Norm.: 0.0005845922703614124 Norm. Diff.: 0.002923542264831947 tk: 5 x_norm: 26.16909290068808\n",
      "Iteration 3597 - Grad. Norm.: 0.0005844761423672125 Norm. Diff.: 0.0029229613518071745 tk: 5 x_norm: 26.171558819761106\n",
      "Iteration 3598 - Grad. Norm.: 0.000584360068942955 Norm. Diff.: 0.0029223807118357245 tk: 5 x_norm: 26.17402423427885\n",
      "Iteration 3599 - Grad. Norm.: 0.0005842440500477953 Norm. Diff.: 0.0029218003447152355 tk: 5 x_norm: 26.176489144478865\n",
      "Iteration 3600 - Grad. Norm.: 0.0005841280856409308 Norm. Diff.: 0.00292122025023914 tk: 5 x_norm: 26.178953550598496\n",
      "Iteration 3601 - Grad. Norm.: 0.0005840121756816019 Norm. Diff.: 0.0029206404282047286 tk: 5 x_norm: 26.181417452874957\n",
      "Iteration 3602 - Grad. Norm.: 0.0005838963201290879 Norm. Diff.: 0.002920060878407773 tk: 5 x_norm: 26.183880851545254\n",
      "Iteration 3603 - Grad. Norm.: 0.0005837805189427117 Norm. Diff.: 0.0029194816006455687 tk: 5 x_norm: 26.186343746846237\n",
      "Iteration 3604 - Grad. Norm.: 0.0005836647720818357 Norm. Diff.: 0.0029189025947135264 tk: 5 x_norm: 26.188806139014563\n",
      "Iteration 3605 - Grad. Norm.: 0.0005835490795058648 Norm. Diff.: 0.002918323860408961 tk: 5 x_norm: 26.19126802828672\n",
      "Iteration 3606 - Grad. Norm.: 0.0005834334411742443 Norm. Diff.: 0.002917745397529075 tk: 5 x_norm: 26.193729414899042\n",
      "Iteration 3607 - Grad. Norm.: 0.0005833178570464626 Norm. Diff.: 0.0029171672058711817 tk: 5 x_norm: 26.196190299087657\n",
      "Iteration 3608 - Grad. Norm.: 0.0005832023270820458 Norm. Diff.: 0.002916589285231961 tk: 5 x_norm: 26.19865068108854\n",
      "Iteration 3609 - Grad. Norm.: 0.0005830868512405643 Norm. Diff.: 0.002916011635410082 tk: 5 x_norm: 26.201110561137483\n",
      "Iteration 3610 - Grad. Norm.: 0.0005829714294816278 Norm. Diff.: 0.0029154342562026174 tk: 5 x_norm: 26.20356993947011\n",
      "Iteration 3611 - Grad. Norm.: 0.0005828560617648858 Norm. Diff.: 0.0029148571474081745 tk: 5 x_norm: 26.206028816321858\n",
      "Iteration 3612 - Grad. Norm.: 0.0005827407480500322 Norm. Diff.: 0.002914280308824331 tk: 5 x_norm: 26.208487191928015\n",
      "Iteration 3613 - Grad. Norm.: 0.0005826254882967993 Norm. Diff.: 0.002913703740250159 tk: 5 x_norm: 26.210945066523664\n",
      "Iteration 3614 - Grad. Norm.: 0.0005825102824649601 Norm. Diff.: 0.00291312744148397 tk: 5 x_norm: 26.21340244034375\n",
      "Iteration 3615 - Grad. Norm.: 0.0005823951305143301 Norm. Diff.: 0.00291255141232487 tk: 5 x_norm: 26.215859313623\n",
      "Iteration 3616 - Grad. Norm.: 0.0005822800324047628 Norm. Diff.: 0.0029119756525714567 tk: 5 x_norm: 26.21831568659602\n",
      "Iteration 3617 - Grad. Norm.: 0.0005821649880961539 Norm. Diff.: 0.002911400162024219 tk: 5 x_norm: 26.2207715594972\n",
      "Iteration 3618 - Grad. Norm.: 0.0005820499975484417 Norm. Diff.: 0.002910824940480642 tk: 5 x_norm: 26.22322693256079\n",
      "Iteration 3619 - Grad. Norm.: 0.0005819350607216004 Norm. Diff.: 0.0029102499877423586 tk: 5 x_norm: 26.225681806020834\n",
      "Iteration 3620 - Grad. Norm.: 0.0005818201775756484 Norm. Diff.: 0.0029096753036080706 tk: 5 x_norm: 26.22813618011124\n",
      "Iteration 3621 - Grad. Norm.: 0.0005817053480706431 Norm. Diff.: 0.0029091008878784274 tk: 5 x_norm: 26.23059005506572\n",
      "Iteration 3622 - Grad. Norm.: 0.0005815905721666834 Norm. Diff.: 0.002908526740352997 tk: 5 x_norm: 26.233043431117814\n",
      "Iteration 3623 - Grad. Norm.: 0.0005814758498239071 Norm. Diff.: 0.002907952860833571 tk: 5 x_norm: 26.235496308500906\n",
      "Iteration 3624 - Grad. Norm.: 0.0005813611810024925 Norm. Diff.: 0.002907379249119489 tk: 5 x_norm: 26.23794868744819\n",
      "Iteration 3625 - Grad. Norm.: 0.000581246565662659 Norm. Diff.: 0.00290680590501266 tk: 5 x_norm: 26.240400568192698\n",
      "Iteration 3626 - Grad. Norm.: 0.0005811320037646659 Norm. Diff.: 0.002906232828313433 tk: 5 x_norm: 26.242851950967307\n",
      "Iteration 3627 - Grad. Norm.: 0.000581017495268812 Norm. Diff.: 0.002905660018823383 tk: 5 x_norm: 26.245302836004686\n",
      "Iteration 3628 - Grad. Norm.: 0.0005809030401354374 Norm. Diff.: 0.002905087476344207 tk: 5 x_norm: 26.247753223537373\n",
      "Iteration 3629 - Grad. Norm.: 0.0005807886383249199 Norm. Diff.: 0.0029045152006771753 tk: 5 x_norm: 26.250203113797696\n",
      "Iteration 3630 - Grad. Norm.: 0.0005806742897976802 Norm. Diff.: 0.0029039431916246606 tk: 5 x_norm: 26.252652507017842\n",
      "Iteration 3631 - Grad. Norm.: 0.0005805599945141783 Norm. Diff.: 0.002903371448988433 tk: 5 x_norm: 26.255101403429823\n",
      "Iteration 3632 - Grad. Norm.: 0.0005804457524349106 Norm. Diff.: 0.0029027999725707364 tk: 5 x_norm: 26.25754980326548\n",
      "Iteration 3633 - Grad. Norm.: 0.0005803315635204177 Norm. Diff.: 0.002902228762174639 tk: 5 x_norm: 26.25999770675646\n",
      "Iteration 3634 - Grad. Norm.: 0.0005802174277312797 Norm. Diff.: 0.0029016578176020587 tk: 5 x_norm: 26.262445114134284\n",
      "Iteration 3635 - Grad. Norm.: 0.0005801033450281131 Norm. Diff.: 0.0029010871386564944 tk: 5 x_norm: 26.264892025630264\n",
      "Iteration 3636 - Grad. Norm.: 0.0005799893153715759 Norm. Diff.: 0.0029005167251406434 tk: 5 x_norm: 26.267338441475562\n",
      "Iteration 3637 - Grad. Norm.: 0.0005798753387223673 Norm. Diff.: 0.0028999465768581338 tk: 5 x_norm: 26.269784361901173\n",
      "Iteration 3638 - Grad. Norm.: 0.0005797614150412239 Norm. Diff.: 0.0028993766936117812 tk: 5 x_norm: 26.272229787137906\n",
      "Iteration 3639 - Grad. Norm.: 0.000579647544288922 Norm. Diff.: 0.0028988070752058908 tk: 5 x_norm: 26.27467471741643\n",
      "Iteration 3640 - Grad. Norm.: 0.0005795337264262784 Norm. Diff.: 0.0028982377214449378 tk: 5 x_norm: 26.27711915296721\n",
      "Iteration 3641 - Grad. Norm.: 0.0005794199614141496 Norm. Diff.: 0.0028976686321312427 tk: 5 x_norm: 26.279563094020563\n",
      "Iteration 3642 - Grad. Norm.: 0.0005793062492134302 Norm. Diff.: 0.0028970998070709762 tk: 5 x_norm: 26.28200654080664\n",
      "Iteration 3643 - Grad. Norm.: 0.0005791925897850547 Norm. Diff.: 0.0028965312460674103 tk: 5 x_norm: 26.28444949355541\n",
      "Iteration 3644 - Grad. Norm.: 0.0005790789830899966 Norm. Diff.: 0.0028959629489252892 tk: 5 x_norm: 26.28689195249669\n",
      "Iteration 3645 - Grad. Norm.: 0.0005789654290892691 Norm. Diff.: 0.0028953949154500724 tk: 5 x_norm: 26.289333917860112\n",
      "Iteration 3646 - Grad. Norm.: 0.0005788519277439245 Norm. Diff.: 0.0028948271454465433 tk: 5 x_norm: 26.291775389875166\n",
      "Iteration 3647 - Grad. Norm.: 0.0005787384790150539 Norm. Diff.: 0.00289425963871927 tk: 5 x_norm: 26.294216368771142\n",
      "Iteration 3648 - Grad. Norm.: 0.0005786250828637878 Norm. Diff.: 0.002893692395075233 tk: 5 x_norm: 26.296656854777176\n",
      "Iteration 3649 - Grad. Norm.: 0.0005785117392512959 Norm. Diff.: 0.0028931254143186274 tk: 5 x_norm: 26.299096848122243\n",
      "Iteration 3650 - Grad. Norm.: 0.0005783984481387861 Norm. Diff.: 0.002892558696256606 tk: 5 x_norm: 26.301536349035157\n",
      "Iteration 3651 - Grad. Norm.: 0.0005782852094875056 Norm. Diff.: 0.002891992240693931 tk: 5 x_norm: 26.303975357744545\n",
      "Iteration 3652 - Grad. Norm.: 0.0005781720232587411 Norm. Diff.: 0.002891426047437736 tk: 5 x_norm: 26.306413874478874\n",
      "Iteration 3653 - Grad. Norm.: 0.0005780588894138174 Norm. Diff.: 0.002890860116293558 tk: 5 x_norm: 26.30885189946645\n",
      "Iteration 3654 - Grad. Norm.: 0.0005779458079140983 Norm. Diff.: 0.002890294447069093 tk: 5 x_norm: 26.311289432935414\n",
      "Iteration 3655 - Grad. Norm.: 0.0005778327787209865 Norm. Diff.: 0.0028897290395704074 tk: 5 x_norm: 26.31372647511374\n",
      "Iteration 3656 - Grad. Norm.: 0.0005777198017959225 Norm. Diff.: 0.002889163893605154 tk: 5 x_norm: 26.316163026229216\n",
      "Iteration 3657 - Grad. Norm.: 0.0005776068771003878 Norm. Diff.: 0.0028885990089797292 tk: 5 x_norm: 26.3185990865095\n",
      "Iteration 3658 - Grad. Norm.: 0.0005774940045959 Norm. Diff.: 0.0028880343855019522 tk: 5 x_norm: 26.321034656182057\n",
      "Iteration 3659 - Grad. Norm.: 0.000577381184244016 Norm. Diff.: 0.002887470022979593 tk: 5 x_norm: 26.323469735474188\n",
      "Iteration 3660 - Grad. Norm.: 0.0005772684160063312 Norm. Diff.: 0.0028869059212199384 tk: 5 x_norm: 26.325904324613038\n",
      "Iteration 3661 - Grad. Norm.: 0.0005771556998444803 Norm. Diff.: 0.002886342080031722 tk: 5 x_norm: 26.32833842382559\n",
      "Iteration 3662 - Grad. Norm.: 0.0005770430357201348 Norm. Diff.: 0.0028857784992220984 tk: 5 x_norm: 26.33077203333865\n",
      "Iteration 3663 - Grad. Norm.: 0.0005769304235950061 Norm. Diff.: 0.002885215178600591 tk: 5 x_norm: 26.333205153378856\n",
      "Iteration 3664 - Grad. Norm.: 0.0005768178634308436 Norm. Diff.: 0.0028846521179749663 tk: 5 x_norm: 26.335637784172715\n",
      "Iteration 3665 - Grad. Norm.: 0.0005767053551894333 Norm. Diff.: 0.002884089317154295 tk: 5 x_norm: 26.338069925946524\n",
      "Iteration 3666 - Grad. Norm.: 0.0005765928988326011 Norm. Diff.: 0.0028835267759469104 tk: 5 x_norm: 26.340501578926432\n",
      "Iteration 3667 - Grad. Norm.: 0.0005764804943222118 Norm. Diff.: 0.0028829644941630013 tk: 5 x_norm: 26.34293274333844\n",
      "Iteration 3668 - Grad. Norm.: 0.000576368141620166 Norm. Diff.: 0.0028824024716111404 tk: 5 x_norm: 26.345363419408372\n",
      "Iteration 3669 - Grad. Norm.: 0.000576255840688403 Norm. Diff.: 0.0028818407081008597 tk: 5 x_norm: 26.347793607361876\n",
      "Iteration 3670 - Grad. Norm.: 0.0005761435914889029 Norm. Diff.: 0.0028812792034419617 tk: 5 x_norm: 26.350223307424464\n",
      "Iteration 3671 - Grad. Norm.: 0.0005760313939836792 Norm. Diff.: 0.0028807179574444042 tk: 5 x_norm: 26.35265251982145\n",
      "Iteration 3672 - Grad. Norm.: 0.000575919248134787 Norm. Diff.: 0.0028801569699185244 tk: 5 x_norm: 26.355081244778017\n",
      "Iteration 3673 - Grad. Norm.: 0.0005758071539043165 Norm. Diff.: 0.00287959624067374 tk: 5 x_norm: 26.35750948251917\n",
      "Iteration 3674 - Grad. Norm.: 0.0005756951112543985 Norm. Diff.: 0.0028790357695216663 tk: 5 x_norm: 26.35993723326975\n",
      "Iteration 3675 - Grad. Norm.: 0.0005755831201472008 Norm. Diff.: 0.0028784755562717527 tk: 5 x_norm: 26.362364497254436\n",
      "Iteration 3676 - Grad. Norm.: 0.0005754711805449264 Norm. Diff.: 0.002877915600736096 tk: 5 x_norm: 26.364791274697744\n",
      "Iteration 3677 - Grad. Norm.: 0.0005753592924098186 Norm. Diff.: 0.002877355902724516 tk: 5 x_norm: 26.367217565824028\n",
      "Iteration 3678 - Grad. Norm.: 0.0005752474557041583 Norm. Diff.: 0.0028767964620488302 tk: 5 x_norm: 26.36964337085749\n",
      "Iteration 3679 - Grad. Norm.: 0.0005751356703902627 Norm. Diff.: 0.002876237278520664 tk: 5 x_norm: 26.37206869002214\n",
      "Iteration 3680 - Grad. Norm.: 0.000575023936430488 Norm. Diff.: 0.002875678351951223 tk: 5 x_norm: 26.374493523541858\n",
      "Iteration 3681 - Grad. Norm.: 0.0005749122537872263 Norm. Diff.: 0.0028751196821527472 tk: 5 x_norm: 26.37691787164035\n",
      "Iteration 3682 - Grad. Norm.: 0.0005748006224229071 Norm. Diff.: 0.002874561268936346 tk: 5 x_norm: 26.379341734541164\n",
      "Iteration 3683 - Grad. Norm.: 0.0005746890423000009 Norm. Diff.: 0.002874003112114619 tk: 5 x_norm: 26.381765112467665\n",
      "Iteration 3684 - Grad. Norm.: 0.00057457751338101 Norm. Diff.: 0.0028734452114999257 tk: 5 x_norm: 26.384188005643086\n",
      "Iteration 3685 - Grad. Norm.: 0.0005744660356284781 Norm. Diff.: 0.0028728875669051094 tk: 5 x_norm: 26.386610414290477\n",
      "Iteration 3686 - Grad. Norm.: 0.0005743546090049843 Norm. Diff.: 0.002872330178142443 tk: 5 x_norm: 26.38903233863275\n",
      "Iteration 3687 - Grad. Norm.: 0.0005742432334731468 Norm. Diff.: 0.002871773045024544 tk: 5 x_norm: 26.391453778892625\n",
      "Iteration 3688 - Grad. Norm.: 0.0005741319089956183 Norm. Diff.: 0.0028712161673657864 tk: 5 x_norm: 26.393874735292684\n",
      "Iteration 3689 - Grad. Norm.: 0.0005740206355350898 Norm. Diff.: 0.0028706595449780672 tk: 5 x_norm: 26.39629520805535\n",
      "Iteration 3690 - Grad. Norm.: 0.0005739094130542907 Norm. Diff.: 0.0028701031776754734 tk: 5 x_norm: 26.398715197402865\n",
      "Iteration 3691 - Grad. Norm.: 0.0005737982415159861 Norm. Diff.: 0.002869547065271379 tk: 5 x_norm: 26.401134703557325\n",
      "Iteration 3692 - Grad. Norm.: 0.000573687120882978 Norm. Diff.: 0.0028689912075799888 tk: 5 x_norm: 26.40355372674066\n",
      "Iteration 3693 - Grad. Norm.: 0.000573576051118105 Norm. Diff.: 0.002868435604414724 tk: 5 x_norm: 26.405972267174665\n",
      "Iteration 3694 - Grad. Norm.: 0.000573465032184243 Norm. Diff.: 0.0028678802555903715 tk: 5 x_norm: 26.408390325080926\n",
      "Iteration 3695 - Grad. Norm.: 0.0005733540640443065 Norm. Diff.: 0.0028673251609212884 tk: 5 x_norm: 26.410807900680915\n",
      "Iteration 3696 - Grad. Norm.: 0.0005732431466612445 Norm. Diff.: 0.002866770320221487 tk: 5 x_norm: 26.41322499419591\n",
      "Iteration 3697 - Grad. Norm.: 0.0005731322799980429 Norm. Diff.: 0.00286621573330625 tk: 5 x_norm: 26.415641605847068\n",
      "Iteration 3698 - Grad. Norm.: 0.0005730214640177264 Norm. Diff.: 0.0028656613999900843 tk: 5 x_norm: 26.418057735855342\n",
      "Iteration 3699 - Grad. Norm.: 0.0005729106986833528 Norm. Diff.: 0.0028651073200886296 tk: 5 x_norm: 26.42047338444156\n",
      "Iteration 3700 - Grad. Norm.: 0.0005727999839580206 Norm. Diff.: 0.0028645534934171575 tk: 5 x_norm: 26.42288855182638\n",
      "Iteration 3701 - Grad. Norm.: 0.0005726893198048608 Norm. Diff.: 0.0028639999197901003 tk: 5 x_norm: 26.42530323823028\n",
      "Iteration 3702 - Grad. Norm.: 0.000572578706187045 Norm. Diff.: 0.0028634465990242794 tk: 5 x_norm: 26.42771744387363\n",
      "Iteration 3703 - Grad. Norm.: 0.0005724681430677781 Norm. Diff.: 0.0028628935309351925 tk: 5 x_norm: 26.430131168976594\n",
      "Iteration 3704 - Grad. Norm.: 0.0005723576304103036 Norm. Diff.: 0.002862340715338854 tk: 5 x_norm: 26.4325444137592\n",
      "Iteration 3705 - Grad. Norm.: 0.0005722471681778987 Norm. Diff.: 0.002861788152051537 tk: 5 x_norm: 26.434957178441305\n",
      "Iteration 3706 - Grad. Norm.: 0.0005721367563338803 Norm. Diff.: 0.0028612358408894706 tk: 5 x_norm: 26.437369463242618\n",
      "Iteration 3707 - Grad. Norm.: 0.0005720263948415987 Norm. Diff.: 0.0028606837816695842 tk: 5 x_norm: 26.439781268382692\n",
      "Iteration 3708 - Grad. Norm.: 0.0005719160836644432 Norm. Diff.: 0.002860131974208439 tk: 5 x_norm: 26.442192594080918\n",
      "Iteration 3709 - Grad. Norm.: 0.0005718058227658365 Norm. Diff.: 0.002859580418322425 tk: 5 x_norm: 26.444603440556513\n",
      "Iteration 3710 - Grad. Norm.: 0.0005716956121092393 Norm. Diff.: 0.002859029113829122 tk: 5 x_norm: 26.447013808028572\n",
      "Iteration 3711 - Grad. Norm.: 0.0005715854516581479 Norm. Diff.: 0.002858478060546209 tk: 5 x_norm: 26.449423696716007\n",
      "Iteration 3712 - Grad. Norm.: 0.000571475341376094 Norm. Diff.: 0.0028579272582907114 tk: 5 x_norm: 26.451833106837576\n",
      "Iteration 3713 - Grad. Norm.: 0.000571365281226648 Norm. Diff.: 0.002857376706880431 tk: 5 x_norm: 26.454242038611884\n",
      "Iteration 3714 - Grad. Norm.: 0.0005712552711734115 Norm. Diff.: 0.002856826406133278 tk: 5 x_norm: 26.45665049225738\n",
      "Iteration 3715 - Grad. Norm.: 0.0005711453111800268 Norm. Diff.: 0.002856276355867177 tk: 5 x_norm: 26.459058467992353\n",
      "Iteration 3716 - Grad. Norm.: 0.0005710354012101694 Norm. Diff.: 0.0028557265559000207 tk: 5 x_norm: 26.461465966034943\n",
      "Iteration 3717 - Grad. Norm.: 0.0005709255412275513 Norm. Diff.: 0.0028551770060506634 tk: 5 x_norm: 26.463872986603114\n",
      "Iteration 3718 - Grad. Norm.: 0.0005708157311959212 Norm. Diff.: 0.002854627706137593 tk: 5 x_norm: 26.466279529914704\n",
      "Iteration 3719 - Grad. Norm.: 0.0005707059710790622 Norm. Diff.: 0.0028540786559794005 tk: 5 x_norm: 26.468685596187367\n",
      "Iteration 3720 - Grad. Norm.: 0.0005705962608407938 Norm. Diff.: 0.002853529855395604 tk: 5 x_norm: 26.471091185638613\n",
      "Iteration 3721 - Grad. Norm.: 0.0005704866004449702 Norm. Diff.: 0.0028529813042038657 tk: 5 x_norm: 26.4734962984858\n",
      "Iteration 3722 - Grad. Norm.: 0.0005703769898554834 Norm. Diff.: 0.002852433002224554 tk: 5 x_norm: 26.475900934946125\n",
      "Iteration 3723 - Grad. Norm.: 0.000570267429036259 Norm. Diff.: 0.0028518849492773723 tk: 5 x_norm: 26.47830509523662\n",
      "Iteration 3724 - Grad. Norm.: 0.0005701579179512585 Norm. Diff.: 0.002851337145181173 tk: 5 x_norm: 26.480708779574194\n",
      "Iteration 3725 - Grad. Norm.: 0.0005700484565644806 Norm. Diff.: 0.0028507895897562506 tk: 5 x_norm: 26.483111988175562\n",
      "Iteration 3726 - Grad. Norm.: 0.0005699390448399565 Norm. Diff.: 0.002850242282822131 tk: 5 x_norm: 26.48551472125731\n",
      "Iteration 3727 - Grad. Norm.: 0.0005698296827417544 Norm. Diff.: 0.002849695224199832 tk: 5 x_norm: 26.48791697903586\n",
      "Iteration 3728 - Grad. Norm.: 0.0005697203702339798 Norm. Diff.: 0.00284914841370888 tk: 5 x_norm: 26.49031876172747\n",
      "Iteration 3729 - Grad. Norm.: 0.0005696111072807692 Norm. Diff.: 0.002848601851169915 tk: 5 x_norm: 26.492720069548255\n",
      "Iteration 3730 - Grad. Norm.: 0.0005695018938462988 Norm. Diff.: 0.00284805553640392 tk: 5 x_norm: 26.495120902714184\n",
      "Iteration 3731 - Grad. Norm.: 0.000569392729894776 Norm. Diff.: 0.002847509469231716 tk: 5 x_norm: 26.49752126144105\n",
      "Iteration 3732 - Grad. Norm.: 0.0005692836153904462 Norm. Diff.: 0.0028469636494740796 tk: 5 x_norm: 26.499921145944512\n",
      "Iteration 3733 - Grad. Norm.: 0.0005691745502975892 Norm. Diff.: 0.0028464180769521667 tk: 5 x_norm: 26.50232055644007\n",
      "Iteration 3734 - Grad. Norm.: 0.0005690655345805208 Norm. Diff.: 0.0028458727514881397 tk: 5 x_norm: 26.50471949314306\n",
      "Iteration 3735 - Grad. Norm.: 0.0005689565682035896 Norm. Diff.: 0.0028453276729027625 tk: 5 x_norm: 26.50711795626866\n",
      "Iteration 3736 - Grad. Norm.: 0.0005688476511311811 Norm. Diff.: 0.002844782841017952 tk: 5 x_norm: 26.509515946031915\n",
      "Iteration 3737 - Grad. Norm.: 0.0005687387833277142 Norm. Diff.: 0.002844238255656112 tk: 5 x_norm: 26.511913462647712\n",
      "Iteration 3738 - Grad. Norm.: 0.0005686299647576461 Norm. Diff.: 0.002843693916638561 tk: 5 x_norm: 26.514310506330784\n",
      "Iteration 3739 - Grad. Norm.: 0.0005685211953854642 Norm. Diff.: 0.002843149823788078 tk: 5 x_norm: 26.51670707729569\n",
      "Iteration 3740 - Grad. Norm.: 0.000568412475175694 Norm. Diff.: 0.0028426059769275603 tk: 5 x_norm: 26.519103175756868\n",
      "Iteration 3741 - Grad. Norm.: 0.0005683038040928948 Norm. Diff.: 0.0028420623758782567 tk: 5 x_norm: 26.521498801928576\n",
      "Iteration 3742 - Grad. Norm.: 0.0005681951821016618 Norm. Diff.: 0.0028415190204647595 tk: 5 x_norm: 26.523893956024942\n",
      "Iteration 3743 - Grad. Norm.: 0.0005680866091666217 Norm. Diff.: 0.0028409759105084476 tk: 5 x_norm: 26.526288638259928\n",
      "Iteration 3744 - Grad. Norm.: 0.0005679780852524391 Norm. Diff.: 0.0028404330458329796 tk: 5 x_norm: 26.52868284884734\n",
      "Iteration 3745 - Grad. Norm.: 0.0005678696103238124 Norm. Diff.: 0.002839890426262105 tk: 5 x_norm: 26.53107658800085\n",
      "Iteration 3746 - Grad. Norm.: 0.0005677611843454744 Norm. Diff.: 0.0028393480516189203 tk: 5 x_norm: 26.53346985593396\n",
      "Iteration 3747 - Grad. Norm.: 0.0005676528072821921 Norm. Diff.: 0.0028388059217274906 tk: 5 x_norm: 26.53586265286003\n",
      "Iteration 3748 - Grad. Norm.: 0.0005675444790987671 Norm. Diff.: 0.0028382640364108553 tk: 5 x_norm: 26.538254978992263\n",
      "Iteration 3749 - Grad. Norm.: 0.0005674361997600365 Norm. Diff.: 0.002837722395493653 tk: 5 x_norm: 26.540646834543715\n",
      "Iteration 3750 - Grad. Norm.: 0.0005673279692308706 Norm. Diff.: 0.0028371809988002707 tk: 5 x_norm: 26.543038219727283\n",
      "Iteration 3751 - Grad. Norm.: 0.0005672197874761743 Norm. Diff.: 0.00283663984615419 tk: 5 x_norm: 26.545429134755725\n",
      "Iteration 3752 - Grad. Norm.: 0.0005671116544608868 Norm. Diff.: 0.00283609893738086 tk: 5 x_norm: 26.547819579841633\n",
      "Iteration 3753 - Grad. Norm.: 0.0005670035701499821 Norm. Diff.: 0.0028355582723044704 tk: 5 x_norm: 26.550209555197466\n",
      "Iteration 3754 - Grad. Norm.: 0.0005668955345084683 Norm. Diff.: 0.0028350178507498157 tk: 5 x_norm: 26.552599061035515\n",
      "Iteration 3755 - Grad. Norm.: 0.0005667875475013876 Norm. Diff.: 0.0028344776725425847 tk: 5 x_norm: 26.554988097567925\n",
      "Iteration 3756 - Grad. Norm.: 0.0005666796090938162 Norm. Diff.: 0.0028339377375070623 tk: 5 x_norm: 26.5573766650067\n",
      "Iteration 3757 - Grad. Norm.: 0.0005665717192508651 Norm. Diff.: 0.002833398045468901 tk: 5 x_norm: 26.55976476356368\n",
      "Iteration 3758 - Grad. Norm.: 0.0005664638779376776 Norm. Diff.: 0.00283285859625403 tk: 5 x_norm: 26.56215239345057\n",
      "Iteration 3759 - Grad. Norm.: 0.0005663560851194333 Norm. Diff.: 0.00283231938968853 tk: 5 x_norm: 26.564539554878905\n",
      "Iteration 3760 - Grad. Norm.: 0.0005662483407613452 Norm. Diff.: 0.0028317804255970007 tk: 5 x_norm: 26.566926248060085\n",
      "Iteration 3761 - Grad. Norm.: 0.0005661406448286583 Norm. Diff.: 0.0028312417038070348 tk: 5 x_norm: 26.569312473205365\n",
      "Iteration 3762 - Grad. Norm.: 0.0005660329972866549 Norm. Diff.: 0.0028307032241433362 tk: 5 x_norm: 26.571698230525833\n",
      "Iteration 3763 - Grad. Norm.: 0.0005659253981006479 Norm. Diff.: 0.0028301649864331375 tk: 5 x_norm: 26.574083520232442\n",
      "Iteration 3764 - Grad. Norm.: 0.0005658178472359862 Norm. Diff.: 0.002829626990503451 tk: 5 x_norm: 26.576468342535975\n",
      "Iteration 3765 - Grad. Norm.: 0.0005657103446580519 Norm. Diff.: 0.0028290892361802393 tk: 5 x_norm: 26.578852697647097\n",
      "Iteration 3766 - Grad. Norm.: 0.0005656028903322599 Norm. Diff.: 0.0028285517232902587 tk: 5 x_norm: 26.58123658577631\n",
      "Iteration 3767 - Grad. Norm.: 0.0005654954842240601 Norm. Diff.: 0.002828014451661258 tk: 5 x_norm: 26.583620007133955\n",
      "Iteration 3768 - Grad. Norm.: 0.0005653881262989357 Norm. Diff.: 0.002827477421119983 tk: 5 x_norm: 26.586002961930227\n",
      "Iteration 3769 - Grad. Norm.: 0.0005652808165224043 Norm. Diff.: 0.002826940631494974 tk: 5 x_norm: 26.58838545037519\n",
      "Iteration 3770 - Grad. Norm.: 0.0005651735548600146 Norm. Diff.: 0.0028264040826118915 tk: 5 x_norm: 26.590767472678753\n",
      "Iteration 3771 - Grad. Norm.: 0.0005650663412773521 Norm. Diff.: 0.002825867774300388 tk: 5 x_norm: 26.593149029050657\n",
      "Iteration 3772 - Grad. Norm.: 0.000564959175740032 Norm. Diff.: 0.0028253317063864965 tk: 5 x_norm: 26.595530119700527\n",
      "Iteration 3773 - Grad. Norm.: 0.0005648520582137073 Norm. Diff.: 0.002824795878700149 tk: 5 x_norm: 26.59791074483782\n",
      "Iteration 3774 - Grad. Norm.: 0.0005647449886640617 Norm. Diff.: 0.0028242602910684826 tk: 5 x_norm: 26.60029090467183\n",
      "Iteration 3775 - Grad. Norm.: 0.0005646379670568121 Norm. Diff.: 0.002823724943320272 tk: 5 x_norm: 26.60267059941175\n",
      "Iteration 3776 - Grad. Norm.: 0.00056453099335771 Norm. Diff.: 0.0028231898352844673 tk: 5 x_norm: 26.605049829266573\n",
      "Iteration 3777 - Grad. Norm.: 0.00056442406753254 Norm. Diff.: 0.002822654966788799 tk: 5 x_norm: 26.607428594445178\n",
      "Iteration 3778 - Grad. Norm.: 0.0005643171895471193 Norm. Diff.: 0.0028221203376625646 tk: 5 x_norm: 26.60980689515628\n",
      "Iteration 3779 - Grad. Norm.: 0.0005642103593672983 Norm. Diff.: 0.0028215859477357646 tk: 5 x_norm: 26.61218473160847\n",
      "Iteration 3780 - Grad. Norm.: 0.0005641035769589614 Norm. Diff.: 0.0028210517968367426 tk: 5 x_norm: 26.614562104010158\n",
      "Iteration 3781 - Grad. Norm.: 0.0005639968422880257 Norm. Diff.: 0.002820517884794831 tk: 5 x_norm: 26.616939012569635\n",
      "Iteration 3782 - Grad. Norm.: 0.0005638901553204404 Norm. Diff.: 0.0028199842114402384 tk: 5 x_norm: 26.619315457495034\n",
      "Iteration 3783 - Grad. Norm.: 0.0005637835160221905 Norm. Diff.: 0.002819450776602225 tk: 5 x_norm: 26.621691438994336\n",
      "Iteration 3784 - Grad. Norm.: 0.0005636769243592912 Norm. Diff.: 0.002818917580110824 tk: 5 x_norm: 26.624066957275392\n",
      "Iteration 3785 - Grad. Norm.: 0.0005635703802977922 Norm. Diff.: 0.002818384621796171 tk: 5 x_norm: 26.626442012545883\n",
      "Iteration 3786 - Grad. Norm.: 0.0005634638838037749 Norm. Diff.: 0.00281785190148867 tk: 5 x_norm: 26.62881660501337\n",
      "Iteration 3787 - Grad. Norm.: 0.000563357434843355 Norm. Diff.: 0.002817319419018974 tk: 5 x_norm: 26.631190734885248\n",
      "Iteration 3788 - Grad. Norm.: 0.0005632510333826799 Norm. Diff.: 0.002816787174216783 tk: 5 x_norm: 26.633564402368776\n",
      "Iteration 3789 - Grad. Norm.: 0.0005631446793879311 Norm. Diff.: 0.002816255166913497 tk: 5 x_norm: 26.63593760767106\n",
      "Iteration 3790 - Grad. Norm.: 0.000563038372825321 Norm. Diff.: 0.0028157233969397038 tk: 5 x_norm: 26.638310350999067\n",
      "Iteration 3791 - Grad. Norm.: 0.0005629321136610964 Norm. Diff.: 0.002815191864126508 tk: 5 x_norm: 26.64068263255962\n",
      "Iteration 3792 - Grad. Norm.: 0.0005628259018615369 Norm. Diff.: 0.0028146605683053087 tk: 5 x_norm: 26.643054452559387\n",
      "Iteration 3793 - Grad. Norm.: 0.0005627197373929538 Norm. Diff.: 0.00281412950930776 tk: 5 x_norm: 26.645425811204902\n",
      "Iteration 3794 - Grad. Norm.: 0.0005626136202216899 Norm. Diff.: 0.0028135986869648882 tk: 5 x_norm: 26.647796708702547\n",
      "Iteration 3795 - Grad. Norm.: 0.0005625075503141241 Norm. Diff.: 0.0028130681011081884 tk: 5 x_norm: 26.65016714525856\n",
      "Iteration 3796 - Grad. Norm.: 0.0005624015276366641 Norm. Diff.: 0.002812537751570438 tk: 5 x_norm: 26.652537121079032\n",
      "Iteration 3797 - Grad. Norm.: 0.000562295552155753 Norm. Diff.: 0.002812007638183658 tk: 5 x_norm: 26.654906636369912\n",
      "Iteration 3798 - Grad. Norm.: 0.0005621896238378633 Norm. Diff.: 0.002811477760778871 tk: 5 x_norm: 26.657275691337006\n",
      "Iteration 3799 - Grad. Norm.: 0.0005620837426495047 Norm. Diff.: 0.0028109481191895807 tk: 5 x_norm: 26.65964428618598\n",
      "Iteration 3800 - Grad. Norm.: 0.0005619779085572129 Norm. Diff.: 0.0028104187132474436 tk: 5 x_norm: 26.66201242112234\n",
      "Iteration 3801 - Grad. Norm.: 0.0005618721215275608 Norm. Diff.: 0.0028098895427859003 tk: 5 x_norm: 26.66438009635146\n",
      "Iteration 3802 - Grad. Norm.: 0.0005617663815271535 Norm. Diff.: 0.002809360607637834 tk: 5 x_norm: 26.66674731207858\n",
      "Iteration 3803 - Grad. Norm.: 0.0005616606885226246 Norm. Diff.: 0.002808831907635997 tk: 5 x_norm: 26.66911406850877\n",
      "Iteration 3804 - Grad. Norm.: 0.0005615550424806433 Norm. Diff.: 0.0028083034426129557 tk: 5 x_norm: 26.671480365846968\n",
      "Iteration 3805 - Grad. Norm.: 0.0005614494433679098 Norm. Diff.: 0.002807775212403359 tk: 5 x_norm: 26.673846204297977\n",
      "Iteration 3806 - Grad. Norm.: 0.0005613438911511576 Norm. Diff.: 0.0028072472168395495 tk: 5 x_norm: 26.67621158406645\n",
      "Iteration 3807 - Grad. Norm.: 0.0005612383857971501 Norm. Diff.: 0.0028067194557557552 tk: 5 x_norm: 26.678576505356897\n",
      "Iteration 3808 - Grad. Norm.: 0.0005611329272726848 Norm. Diff.: 0.0028061919289856154 tk: 5 x_norm: 26.680940968373687\n",
      "Iteration 3809 - Grad. Norm.: 0.0005610275155445903 Norm. Diff.: 0.0028056646363630714 tk: 5 x_norm: 26.683304973321036\n",
      "Iteration 3810 - Grad. Norm.: 0.0005609221505797266 Norm. Diff.: 0.0028051375777231125 tk: 5 x_norm: 26.685668520403038\n",
      "Iteration 3811 - Grad. Norm.: 0.0005608168323449868 Norm. Diff.: 0.0028046107528988196 tk: 5 x_norm: 26.688031609823614\n",
      "Iteration 3812 - Grad. Norm.: 0.0005607115608072951 Norm. Diff.: 0.002804084161725287 tk: 5 x_norm: 26.69039424178657\n",
      "Iteration 3813 - Grad. Norm.: 0.0005606063359336102 Norm. Diff.: 0.002803557804036562 tk: 5 x_norm: 26.69275641649556\n",
      "Iteration 3814 - Grad. Norm.: 0.0005605011576909172 Norm. Diff.: 0.002803031679668021 tk: 5 x_norm: 26.695118134154082\n",
      "Iteration 3815 - Grad. Norm.: 0.0005603960260462375 Norm. Diff.: 0.0028025057884547267 tk: 5 x_norm: 26.69747939496552\n",
      "Iteration 3816 - Grad. Norm.: 0.0005602909409666229 Norm. Diff.: 0.002801980130231448 tk: 5 x_norm: 26.6998401991331\n",
      "Iteration 3817 - Grad. Norm.: 0.0005601859024191576 Norm. Diff.: 0.002801454704833086 tk: 5 x_norm: 26.702200546859892\n",
      "Iteration 3818 - Grad. Norm.: 0.0005600809103709558 Norm. Diff.: 0.0028009295120956664 tk: 5 x_norm: 26.70456043834885\n",
      "Iteration 3819 - Grad. Norm.: 0.0005599759647891655 Norm. Diff.: 0.0028004045518544084 tk: 5 x_norm: 26.706919873802768\n",
      "Iteration 3820 - Grad. Norm.: 0.0005598710656409642 Norm. Diff.: 0.002799879823946063 tk: 5 x_norm: 26.709278853424312\n",
      "Iteration 3821 - Grad. Norm.: 0.0005597662128935618 Norm. Diff.: 0.0027993553282049054 tk: 5 x_norm: 26.711637377416\n",
      "Iteration 3822 - Grad. Norm.: 0.0005596614065142012 Norm. Diff.: 0.0027988310644675085 tk: 5 x_norm: 26.7139954459802\n",
      "Iteration 3823 - Grad. Norm.: 0.000559556646470154 Norm. Diff.: 0.0027983070325710516 tk: 5 x_norm: 26.716353059319157\n",
      "Iteration 3824 - Grad. Norm.: 0.000559451932728725 Norm. Diff.: 0.0027977832323511265 tk: 5 x_norm: 26.71871021763496\n",
      "Iteration 3825 - Grad. Norm.: 0.0005593472652572511 Norm. Diff.: 0.002797259663643429 tk: 5 x_norm: 26.721066921129562\n",
      "Iteration 3826 - Grad. Norm.: 0.0005592426440230978 Norm. Diff.: 0.00279673632628653 tk: 5 x_norm: 26.723423170004796\n",
      "Iteration 3827 - Grad. Norm.: 0.000559138068993665 Norm. Diff.: 0.0027962132201152594 tk: 5 x_norm: 26.725778964462304\n",
      "Iteration 3828 - Grad. Norm.: 0.0005590335401363833 Norm. Diff.: 0.0027956903449681794 tk: 5 x_norm: 26.72813430470363\n",
      "Iteration 3829 - Grad. Norm.: 0.0005589290574187125 Norm. Diff.: 0.002795167700682058 tk: 5 x_norm: 26.730489190930175\n",
      "Iteration 3830 - Grad. Norm.: 0.0005588246208081456 Norm. Diff.: 0.0027946452870936745 tk: 5 x_norm: 26.732843623343182\n",
      "Iteration 3831 - Grad. Norm.: 0.0005587202302722056 Norm. Diff.: 0.002794123104040643 tk: 5 x_norm: 26.73519760214376\n",
      "Iteration 3832 - Grad. Norm.: 0.0005586158857784479 Norm. Diff.: 0.002793601151361171 tk: 5 x_norm: 26.737551127532885\n",
      "Iteration 3833 - Grad. Norm.: 0.0005585115872944584 Norm. Diff.: 0.0027930794288918977 tk: 5 x_norm: 26.739904199711383\n",
      "Iteration 3834 - Grad. Norm.: 0.0005584073347878536 Norm. Diff.: 0.0027925579364724016 tk: 5 x_norm: 26.74225681887996\n",
      "Iteration 3835 - Grad. Norm.: 0.0005583031282262823 Norm. Diff.: 0.002792036673939227 tk: 5 x_norm: 26.744608985239157\n",
      "Iteration 3836 - Grad. Norm.: 0.0005581989675774212 Norm. Diff.: 0.00279151564113147 tk: 5 x_norm: 26.746960698989383\n",
      "Iteration 3837 - Grad. Norm.: 0.0005580948528089829 Norm. Diff.: 0.0027909948378872593 tk: 5 x_norm: 26.74931196033093\n",
      "Iteration 3838 - Grad. Norm.: 0.0005579907838887067 Norm. Diff.: 0.0027904742640447104 tk: 5 x_norm: 26.751662769463916\n",
      "Iteration 3839 - Grad. Norm.: 0.0005578867607843651 Norm. Diff.: 0.0027899539194436466 tk: 5 x_norm: 26.75401312658834\n",
      "Iteration 3840 - Grad. Norm.: 0.000557782783463761 Norm. Diff.: 0.002789433803922005 tk: 5 x_norm: 26.756363031904066\n",
      "Iteration 3841 - Grad. Norm.: 0.0005576788518947259 Norm. Diff.: 0.0027889139173188225 tk: 5 x_norm: 26.758712485610804\n",
      "Iteration 3842 - Grad. Norm.: 0.0005575749660451259 Norm. Diff.: 0.00278839425947394 tk: 5 x_norm: 26.761061487908144\n",
      "Iteration 3843 - Grad. Norm.: 0.0005574711258828546 Norm. Diff.: 0.0027878748302258634 tk: 5 x_norm: 26.76341003899552\n",
      "Iteration 3844 - Grad. Norm.: 0.0005573673313758387 Norm. Diff.: 0.0027873556294143345 tk: 5 x_norm: 26.765758139072236\n",
      "Iteration 3845 - Grad. Norm.: 0.0005572635824920336 Norm. Diff.: 0.0027868366568793612 tk: 5 x_norm: 26.76810578833745\n",
      "Iteration 3846 - Grad. Norm.: 0.000557159879199427 Norm. Diff.: 0.00278631791246016 tk: 5 x_norm: 26.7704529869902\n",
      "Iteration 3847 - Grad. Norm.: 0.0005570562214660352 Norm. Diff.: 0.0027857993959973367 tk: 5 x_norm: 26.772799735229373\n",
      "Iteration 3848 - Grad. Norm.: 0.0005569526092599068 Norm. Diff.: 0.0027852811073301696 tk: 5 x_norm: 26.775146033253712\n",
      "Iteration 3849 - Grad. Norm.: 0.0005568490425491212 Norm. Diff.: 0.002784763046299521 tk: 5 x_norm: 26.777491881261845\n",
      "Iteration 3850 - Grad. Norm.: 0.0005567455213017859 Norm. Diff.: 0.002784245212745867 tk: 5 x_norm: 26.779837279452227\n",
      "Iteration 3851 - Grad. Norm.: 0.0005566420454860412 Norm. Diff.: 0.00278372760650907 tk: 5 x_norm: 26.782182228023217\n",
      "Iteration 3852 - Grad. Norm.: 0.0005565386150700571 Norm. Diff.: 0.0027832102274299034 tk: 5 x_norm: 26.784526727173002\n",
      "Iteration 3853 - Grad. Norm.: 0.0005564352300220331 Norm. Diff.: 0.0027826930753503108 tk: 5 x_norm: 26.786870777099654\n",
      "Iteration 3854 - Grad. Norm.: 0.0005563318903102017 Norm. Diff.: 0.0027821761501102254 tk: 5 x_norm: 26.78921437800109\n",
      "Iteration 3855 - Grad. Norm.: 0.0005562285959028212 Norm. Diff.: 0.00278165945155109 tk: 5 x_norm: 26.791557530075117\n",
      "Iteration 3856 - Grad. Norm.: 0.0005561253467681839 Norm. Diff.: 0.0027811429795141195 tk: 5 x_norm: 26.79390023351937\n",
      "Iteration 3857 - Grad. Norm.: 0.0005560221428746113 Norm. Diff.: 0.0027806267338409347 tk: 5 x_norm: 26.796242488531377\n",
      "Iteration 3858 - Grad. Norm.: 0.0005559189841904547 Norm. Diff.: 0.0027801107143731124 tk: 5 x_norm: 26.798584295308512\n",
      "Iteration 3859 - Grad. Norm.: 0.0005558158706840958 Norm. Diff.: 0.002779594920952319 tk: 5 x_norm: 26.800925654048022\n",
      "Iteration 3860 - Grad. Norm.: 0.0005557128023239467 Norm. Diff.: 0.0027790793534204776 tk: 5 x_norm: 26.803266564947016\n",
      "Iteration 3861 - Grad. Norm.: 0.0005556097790784484 Norm. Diff.: 0.002778564011619764 tk: 5 x_norm: 26.80560702820246\n",
      "Iteration 3862 - Grad. Norm.: 0.0005555068009160749 Norm. Diff.: 0.002778048895392207 tk: 5 x_norm: 26.80794704401119\n",
      "Iteration 3863 - Grad. Norm.: 0.0005554038678053248 Norm. Diff.: 0.0027775340045802337 tk: 5 x_norm: 26.810286612569914\n",
      "Iteration 3864 - Grad. Norm.: 0.0005553009797147332 Norm. Diff.: 0.0027770193390264882 tk: 5 x_norm: 26.812625734075194\n",
      "Iteration 3865 - Grad. Norm.: 0.0005551981366128603 Norm. Diff.: 0.0027765048985736876 tk: 5 x_norm: 26.81496440872345\n",
      "Iteration 3866 - Grad. Norm.: 0.0005550953384682984 Norm. Diff.: 0.0027759906830643103 tk: 5 x_norm: 26.817302636710973\n",
      "Iteration 3867 - Grad. Norm.: 0.0005549925852496684 Norm. Diff.: 0.0027754766923417966 tk: 5 x_norm: 26.819640418233927\n",
      "Iteration 3868 - Grad. Norm.: 0.0005548898769256226 Norm. Diff.: 0.0027749629262484375 tk: 5 x_norm: 26.82197775348834\n",
      "Iteration 3869 - Grad. Norm.: 0.0005547872134648425 Norm. Diff.: 0.0027744493846279137 tk: 5 x_norm: 26.824314642670092\n",
      "Iteration 3870 - Grad. Norm.: 0.0005546845948360368 Norm. Diff.: 0.002773936067324433 tk: 5 x_norm: 26.826651085974934\n",
      "Iteration 3871 - Grad. Norm.: 0.000554582021007949 Norm. Diff.: 0.0027734229741803156 tk: 5 x_norm: 26.828987083598477\n",
      "Iteration 3872 - Grad. Norm.: 0.0005544794919493484 Norm. Diff.: 0.002772910105039816 tk: 5 x_norm: 26.831322635736225\n",
      "Iteration 3873 - Grad. Norm.: 0.0005543770076290344 Norm. Diff.: 0.002772397459746617 tk: 5 x_norm: 26.833657742583505\n",
      "Iteration 3874 - Grad. Norm.: 0.0005542745680158374 Norm. Diff.: 0.0027718850381449577 tk: 5 x_norm: 26.835992404335535\n",
      "Iteration 3875 - Grad. Norm.: 0.0005541721730786172 Norm. Diff.: 0.0027713728400792503 tk: 5 x_norm: 26.838326621187402\n",
      "Iteration 3876 - Grad. Norm.: 0.0005540698227862606 Norm. Diff.: 0.0027708608653933117 tk: 5 x_norm: 26.840660393334044\n",
      "Iteration 3877 - Grad. Norm.: 0.0005539675171076878 Norm. Diff.: 0.002770349113931266 tk: 5 x_norm: 26.842993720970274\n",
      "Iteration 3878 - Grad. Norm.: 0.0005538652560118462 Norm. Diff.: 0.0027698375855389036 tk: 5 x_norm: 26.845326604290772\n",
      "Iteration 3879 - Grad. Norm.: 0.0005537630394677117 Norm. Diff.: 0.002769326280059204 tk: 5 x_norm: 26.847659043490072\n",
      "Iteration 3880 - Grad. Norm.: 0.0005536608674442923 Norm. Diff.: 0.002768815197338619 tk: 5 x_norm: 26.849991038762596\n",
      "Iteration 3881 - Grad. Norm.: 0.0005535587399106238 Norm. Diff.: 0.0027683043372215125 tk: 5 x_norm: 26.85232259030261\n",
      "Iteration 3882 - Grad. Norm.: 0.0005534566568357713 Norm. Diff.: 0.002767793699552983 tk: 5 x_norm: 26.85465369830426\n",
      "Iteration 3883 - Grad. Norm.: 0.0005533546181888284 Norm. Diff.: 0.002767283284178814 tk: 5 x_norm: 26.85698436296156\n",
      "Iteration 3884 - Grad. Norm.: 0.0005532526239389209 Norm. Diff.: 0.0027667730909444 tk: 5 x_norm: 26.859314584468372\n",
      "Iteration 3885 - Grad. Norm.: 0.0005531506740552007 Norm. Diff.: 0.002766263119694688 tk: 5 x_norm: 26.861644363018453\n",
      "Iteration 3886 - Grad. Norm.: 0.0005530487685068498 Norm. Diff.: 0.0027657533702757134 tk: 5 x_norm: 26.86397369880541\n",
      "Iteration 3887 - Grad. Norm.: 0.0005529469072630808 Norm. Diff.: 0.002765243842534519 tk: 5 x_norm: 26.866302592022716\n",
      "Iteration 3888 - Grad. Norm.: 0.0005528450902931325 Norm. Diff.: 0.0027647345363154482 tk: 5 x_norm: 26.868631042863708\n",
      "Iteration 3889 - Grad. Norm.: 0.0005527433175662764 Norm. Diff.: 0.002764225451465642 tk: 5 x_norm: 26.870959051521616\n",
      "Iteration 3890 - Grad. Norm.: 0.00055264158905181 Norm. Diff.: 0.002763716587831601 tk: 5 x_norm: 26.87328661818951\n",
      "Iteration 3891 - Grad. Norm.: 0.0005525399047190619 Norm. Diff.: 0.0027632079452588197 tk: 5 x_norm: 26.875613743060338\n",
      "Iteration 3892 - Grad. Norm.: 0.0005524382645373881 Norm. Diff.: 0.0027626995235955185 tk: 5 x_norm: 26.87794042632691\n",
      "Iteration 3893 - Grad. Norm.: 0.0005523366684761743 Norm. Diff.: 0.0027621913226869234 tk: 5 x_norm: 26.880266668181914\n",
      "Iteration 3894 - Grad. Norm.: 0.0005522351165048354 Norm. Diff.: 0.0027616833423808962 tk: 5 x_norm: 26.882592468817904\n",
      "Iteration 3895 - Grad. Norm.: 0.0005521336085928147 Norm. Diff.: 0.0027611755825240492 tk: 5 x_norm: 26.88491782842729\n",
      "Iteration 3896 - Grad. Norm.: 0.0005520321447095845 Norm. Diff.: 0.002760668042964133 tk: 5 x_norm: 26.88724274720236\n",
      "Iteration 3897 - Grad. Norm.: 0.0005519307248246467 Norm. Diff.: 0.002760160723547946 tk: 5 x_norm: 26.889567225335288\n",
      "Iteration 3898 - Grad. Norm.: 0.0005518293489075293 Norm. Diff.: 0.0027596536241233285 tk: 5 x_norm: 26.89189126301807\n",
      "Iteration 3899 - Grad. Norm.: 0.0005517280169277924 Norm. Diff.: 0.002759146744537239 tk: 5 x_norm: 26.89421486044262\n",
      "Iteration 3900 - Grad. Norm.: 0.0005516267288550229 Norm. Diff.: 0.0027586400846389392 tk: 5 x_norm: 26.896538017800687\n",
      "Iteration 3901 - Grad. Norm.: 0.0005515254846588373 Norm. Diff.: 0.0027581336442750997 tk: 5 x_norm: 26.89886073528391\n",
      "Iteration 3902 - Grad. Norm.: 0.0005514242843088797 Norm. Diff.: 0.0027576274232937225 tk: 5 x_norm: 26.90118301308378\n",
      "Iteration 3903 - Grad. Norm.: 0.0005513231277748244 Norm. Diff.: 0.0027571214215440986 tk: 5 x_norm: 26.90350485139168\n",
      "Iteration 3904 - Grad. Norm.: 0.0005512220150263714 Norm. Diff.: 0.0027566156388738852 tk: 5 x_norm: 26.90582625039884\n",
      "Iteration 3905 - Grad. Norm.: 0.0005511209460332527 Norm. Diff.: 0.002756110075132 tk: 5 x_norm: 26.90814721029636\n",
      "Iteration 3906 - Grad. Norm.: 0.0005510199207652267 Norm. Diff.: 0.0027556047301662183 tk: 5 x_norm: 26.91046773127523\n",
      "Iteration 3907 - Grad. Norm.: 0.0005509189391920809 Norm. Diff.: 0.0027550996038260543 tk: 5 x_norm: 26.912787813526283\n",
      "Iteration 3908 - Grad. Norm.: 0.0005508180012836308 Norm. Diff.: 0.002754594695960421 tk: 5 x_norm: 26.915107457240254\n",
      "Iteration 3909 - Grad. Norm.: 0.0005507171070097207 Norm. Diff.: 0.002754090006417999 tk: 5 x_norm: 26.917426662607713\n",
      "Iteration 3910 - Grad. Norm.: 0.0005506162563402232 Norm. Diff.: 0.0027535855350486068 tk: 5 x_norm: 26.919745429819116\n",
      "Iteration 3911 - Grad. Norm.: 0.0005505154492450393 Norm. Diff.: 0.002753081281701077 tk: 5 x_norm: 26.9220637590648\n",
      "Iteration 3912 - Grad. Norm.: 0.0005504146856940986 Norm. Diff.: 0.0027525772462251015 tk: 5 x_norm: 26.924381650534958\n",
      "Iteration 3913 - Grad. Norm.: 0.000550313965657358 Norm. Diff.: 0.0027520734284704894 tk: 5 x_norm: 26.926699104419658\n",
      "Iteration 3914 - Grad. Norm.: 0.0005502132891048028 Norm. Diff.: 0.002751569828286798 tk: 5 x_norm: 26.929016120908834\n",
      "Iteration 3915 - Grad. Norm.: 0.0005501126560064487 Norm. Diff.: 0.002751066445523548 tk: 5 x_norm: 26.931332700192293\n",
      "Iteration 3916 - Grad. Norm.: 0.0005500120663323359 Norm. Diff.: 0.0027505632800322805 tk: 5 x_norm: 26.933648842459714\n",
      "Iteration 3917 - Grad. Norm.: 0.0005499115200525362 Norm. Diff.: 0.0027500603316616026 tk: 5 x_norm: 26.935964547900653\n",
      "Iteration 3918 - Grad. Norm.: 0.0005498110171371465 Norm. Diff.: 0.002749557600262849 tk: 5 x_norm: 26.93827981670453\n",
      "Iteration 3919 - Grad. Norm.: 0.0005497105575562938 Norm. Diff.: 0.0027490550856857188 tk: 5 x_norm: 26.94059464906063\n",
      "Iteration 3920 - Grad. Norm.: 0.0005496101412801335 Norm. Diff.: 0.0027485527877810787 tk: 5 x_norm: 26.94290904515811\n",
      "Iteration 3921 - Grad. Norm.: 0.0005495097682788465 Norm. Diff.: 0.0027480507064004634 tk: 5 x_norm: 26.94522300518603\n",
      "Iteration 3922 - Grad. Norm.: 0.0005494094385226448 Norm. Diff.: 0.0027475488413943134 tk: 5 x_norm: 26.947536529333277\n",
      "Iteration 3923 - Grad. Norm.: 0.0005493091519817653 Norm. Diff.: 0.0027470471926132915 tk: 5 x_norm: 26.949849617788633\n",
      "Iteration 3924 - Grad. Norm.: 0.0005492089086264754 Norm. Diff.: 0.002746545759908681 tk: 5 x_norm: 26.952162270740732\n",
      "Iteration 3925 - Grad. Norm.: 0.0005491087084270685 Norm. Diff.: 0.0027460445431325246 tk: 5 x_norm: 26.954474488378118\n",
      "Iteration 3926 - Grad. Norm.: 0.0005490085513538668 Norm. Diff.: 0.0027455435421352044 tk: 5 x_norm: 26.95678627088918\n",
      "Iteration 3927 - Grad. Norm.: 0.0005489084373772205 Norm. Diff.: 0.0027450427567694267 tk: 5 x_norm: 26.959097618462167\n",
      "Iteration 3928 - Grad. Norm.: 0.0005488083664675068 Norm. Diff.: 0.0027445421868859893 tk: 5 x_norm: 26.961408531285237\n",
      "Iteration 3929 - Grad. Norm.: 0.0005487083385951308 Norm. Diff.: 0.002744041832337272 tk: 5 x_norm: 26.963719009546374\n",
      "Iteration 3930 - Grad. Norm.: 0.0005486083537305259 Norm. Diff.: 0.0027435416929758156 tk: 5 x_norm: 26.966029053433488\n",
      "Iteration 3931 - Grad. Norm.: 0.0005485084118441526 Norm. Diff.: 0.002743041768652506 tk: 5 x_norm: 26.96833866313431\n",
      "Iteration 3932 - Grad. Norm.: 0.0005484085129065 Norm. Diff.: 0.002742542059220812 tk: 5 x_norm: 26.970647838836484\n",
      "Iteration 3933 - Grad. Norm.: 0.0005483086568880825 Norm. Diff.: 0.0027420425645324356 tk: 5 x_norm: 26.972956580727498\n",
      "Iteration 3934 - Grad. Norm.: 0.0005482088437594448 Norm. Diff.: 0.0027415432844404967 tk: 5 x_norm: 26.97526488899473\n",
      "Iteration 3935 - Grad. Norm.: 0.0005481090734911579 Norm. Diff.: 0.0027410442187971486 tk: 5 x_norm: 26.977572763825425\n",
      "Iteration 3936 - Grad. Norm.: 0.0005480093460538202 Norm. Diff.: 0.002740545367455564 tk: 5 x_norm: 26.9798802054067\n",
      "Iteration 3937 - Grad. Norm.: 0.0005479096614180577 Norm. Diff.: 0.002740046730268791 tk: 5 x_norm: 26.982187213925553\n",
      "Iteration 3938 - Grad. Norm.: 0.0005478100195545236 Norm. Diff.: 0.002739548307090197 tk: 5 x_norm: 26.98449378956884\n",
      "Iteration 3939 - Grad. Norm.: 0.0005477104204338988 Norm. Diff.: 0.0027390500977722077 tk: 5 x_norm: 26.9867999325233\n",
      "Iteration 3940 - Grad. Norm.: 0.0005476108640268925 Norm. Diff.: 0.0027385521021694227 tk: 5 x_norm: 26.98910564297556\n",
      "Iteration 3941 - Grad. Norm.: 0.0005475113503042396 Norm. Diff.: 0.0027380543201346833 tk: 5 x_norm: 26.991410921112088\n",
      "Iteration 3942 - Grad. Norm.: 0.000547411879236703 Norm. Diff.: 0.002737556751521455 tk: 5 x_norm: 26.993715767119255\n",
      "Iteration 3943 - Grad. Norm.: 0.000547312450795074 Norm. Diff.: 0.002737059396183662 tk: 5 x_norm: 26.99602018118329\n",
      "Iteration 3944 - Grad. Norm.: 0.0005472130649501686 Norm. Diff.: 0.002736562253975282 tk: 5 x_norm: 26.9983241634903\n",
      "Iteration 3945 - Grad. Norm.: 0.0005471137216728323 Norm. Diff.: 0.0027360653247508917 tk: 5 x_norm: 27.00062771422627\n",
      "Iteration 3946 - Grad. Norm.: 0.0005470144209339375 Norm. Diff.: 0.0027355686083640396 tk: 5 x_norm: 27.00293083357706\n",
      "Iteration 3947 - Grad. Norm.: 0.0005469151627043823 Norm. Diff.: 0.0027350721046694665 tk: 5 x_norm: 27.00523352172839\n",
      "Iteration 3948 - Grad. Norm.: 0.0005468159469550938 Norm. Diff.: 0.0027345758135217716 tk: 5 x_norm: 27.007535778865872\n",
      "Iteration 3949 - Grad. Norm.: 0.0005467167736570243 Norm. Diff.: 0.002734079734775484 tk: 5 x_norm: 27.009837605174997\n",
      "Iteration 3950 - Grad. Norm.: 0.0005466176427811551 Norm. Diff.: 0.0027335838682851056 tk: 5 x_norm: 27.012139000841092\n",
      "Iteration 3951 - Grad. Norm.: 0.0005465185542984936 Norm. Diff.: 0.002733088213905828 tk: 5 x_norm: 27.01443996604941\n",
      "Iteration 3952 - Grad. Norm.: 0.0005464195081800736 Norm. Diff.: 0.002732592771492229 tk: 5 x_norm: 27.016740500985048\n",
      "Iteration 3953 - Grad. Norm.: 0.0005463205043969566 Norm. Diff.: 0.0027320975409002596 tk: 5 x_norm: 27.019040605832988\n",
      "Iteration 3954 - Grad. Norm.: 0.0005462215429202314 Norm. Diff.: 0.002731602521984623 tk: 5 x_norm: 27.021340280778073\n",
      "Iteration 3955 - Grad. Norm.: 0.0005461226237210127 Norm. Diff.: 0.002731107714601407 tk: 5 x_norm: 27.023639526005052\n",
      "Iteration 3956 - Grad. Norm.: 0.0005460237467704428 Norm. Diff.: 0.0027306131186050626 tk: 5 x_norm: 27.02593834169852\n",
      "Iteration 3957 - Grad. Norm.: 0.0005459249120396901 Norm. Diff.: 0.002730118733852023 tk: 5 x_norm: 27.028236728042955\n",
      "Iteration 3958 - Grad. Norm.: 0.0005458261194999511 Norm. Diff.: 0.002729624560198444 tk: 5 x_norm: 27.03053468522272\n",
      "Iteration 3959 - Grad. Norm.: 0.0005457273691224482 Norm. Diff.: 0.0027291305974998384 tk: 5 x_norm: 27.032832213422047\n",
      "Iteration 3960 - Grad. Norm.: 0.0005456286608784292 Norm. Diff.: 0.0027286368456122907 tk: 5 x_norm: 27.03512931282504\n",
      "Iteration 3961 - Grad. Norm.: 0.0005455299947391728 Norm. Diff.: 0.0027281433043921622 tk: 5 x_norm: 27.037425983615684\n",
      "Iteration 3962 - Grad. Norm.: 0.0005454313706759801 Norm. Diff.: 0.0027276499736958357 tk: 5 x_norm: 27.039722225977847\n",
      "Iteration 3963 - Grad. Norm.: 0.0005453327886601797 Norm. Diff.: 0.002727156853379967 tk: 5 x_norm: 27.042018040095254\n",
      "Iteration 3964 - Grad. Norm.: 0.0005452342486631281 Norm. Diff.: 0.00272666394330074 tk: 5 x_norm: 27.04431342615154\n",
      "Iteration 3965 - Grad. Norm.: 0.0005451357506562089 Norm. Diff.: 0.0027261712433155174 tk: 5 x_norm: 27.046608384330163\n",
      "Iteration 3966 - Grad. Norm.: 0.0005450372946108298 Norm. Diff.: 0.0027256787532810925 tk: 5 x_norm: 27.048902914814516\n",
      "Iteration 3967 - Grad. Norm.: 0.0005449388804984272 Norm. Diff.: 0.0027251864730543705 tk: 5 x_norm: 27.05119701778783\n",
      "Iteration 3968 - Grad. Norm.: 0.0005448405082904619 Norm. Diff.: 0.0027246944024923035 tk: 5 x_norm: 27.053490693433226\n",
      "Iteration 3969 - Grad. Norm.: 0.0005447421779584242 Norm. Diff.: 0.0027242025414523957 tk: 5 x_norm: 27.0557839419337\n",
      "Iteration 3970 - Grad. Norm.: 0.0005446438894738281 Norm. Diff.: 0.002723710889792323 tk: 5 x_norm: 27.05807676347213\n",
      "Iteration 3971 - Grad. Norm.: 0.0005445456428082157 Norm. Diff.: 0.0027232194473689373 tk: 5 x_norm: 27.06036915823126\n",
      "Iteration 3972 - Grad. Norm.: 0.0005444474379331539 Norm. Diff.: 0.002722728214041093 tk: 5 x_norm: 27.062661126393728\n",
      "Iteration 3973 - Grad. Norm.: 0.0005443492748202378 Norm. Diff.: 0.0027222371896657 tk: 5 x_norm: 27.064952668142034\n",
      "Iteration 3974 - Grad. Norm.: 0.0005442511534410865 Norm. Diff.: 0.0027217463741013377 tk: 5 x_norm: 27.067243783658558\n",
      "Iteration 3975 - Grad. Norm.: 0.0005441530737673483 Norm. Diff.: 0.0027212557672056797 tk: 5 x_norm: 27.069534473125564\n",
      "Iteration 3976 - Grad. Norm.: 0.0005440550357706947 Norm. Diff.: 0.002720765368836767 tk: 5 x_norm: 27.071824736725198\n",
      "Iteration 3977 - Grad. Norm.: 0.000543957039422826 Norm. Diff.: 0.0027202751788535096 tk: 5 x_norm: 27.074114574639456\n",
      "Iteration 3978 - Grad. Norm.: 0.0005438590846954671 Norm. Diff.: 0.0027197851971140874 tk: 5 x_norm: 27.076403987050245\n",
      "Iteration 3979 - Grad. Norm.: 0.0005437611715603695 Norm. Diff.: 0.002719295423477342 tk: 5 x_norm: 27.078692974139347\n",
      "Iteration 3980 - Grad. Norm.: 0.0005436632999893107 Norm. Diff.: 0.0027188058578016105 tk: 5 x_norm: 27.080981536088395\n",
      "Iteration 3981 - Grad. Norm.: 0.0005435654699540947 Norm. Diff.: 0.0027183164999469264 tk: 5 x_norm: 27.08326967307892\n",
      "Iteration 3982 - Grad. Norm.: 0.0005434676814265512 Norm. Diff.: 0.002717827349770583 tk: 5 x_norm: 27.08555738529234\n",
      "Iteration 3983 - Grad. Norm.: 0.0005433699343785365 Norm. Diff.: 0.002717338407132979 tk: 5 x_norm: 27.08784467290993\n",
      "Iteration 3984 - Grad. Norm.: 0.0005432722287819323 Norm. Diff.: 0.002716849671892808 tk: 5 x_norm: 27.090131536112867\n",
      "Iteration 3985 - Grad. Norm.: 0.0005431745646086455 Norm. Diff.: 0.002716361143909752 tk: 5 x_norm: 27.09241797508218\n",
      "Iteration 3986 - Grad. Norm.: 0.0005430769418306111 Norm. Diff.: 0.0027158728230432462 tk: 5 x_norm: 27.09470398999879\n",
      "Iteration 3987 - Grad. Norm.: 0.0005429793604197891 Norm. Diff.: 0.002715384709153002 tk: 5 x_norm: 27.09698958104351\n",
      "Iteration 3988 - Grad. Norm.: 0.0005428818203481628 Norm. Diff.: 0.002714896802099166 tk: 5 x_norm: 27.099274748397008\n",
      "Iteration 3989 - Grad. Norm.: 0.0005427843215877467 Norm. Diff.: 0.0027144091017408997 tk: 5 x_norm: 27.10155949223985\n",
      "Iteration 3990 - Grad. Norm.: 0.000542686864110576 Norm. Diff.: 0.0027139216079385977 tk: 5 x_norm: 27.103843812752473\n",
      "Iteration 3991 - Grad. Norm.: 0.0005425894478887146 Norm. Diff.: 0.0027134343205527413 tk: 5 x_norm: 27.10612771011519\n",
      "Iteration 3992 - Grad. Norm.: 0.0005424920728942504 Norm. Diff.: 0.002712947239443403 tk: 5 x_norm: 27.108411184508206\n",
      "Iteration 3993 - Grad. Norm.: 0.0005423947390992992 Norm. Diff.: 0.002712460364471467 tk: 5 x_norm: 27.11069423611158\n",
      "Iteration 3994 - Grad. Norm.: 0.000542297446476 Norm. Diff.: 0.0027119736954964832 tk: 5 x_norm: 27.112976865105292\n",
      "Iteration 3995 - Grad. Norm.: 0.0005422001949965208 Norm. Diff.: 0.002711487232379747 tk: 5 x_norm: 27.115259071669172\n",
      "Iteration 3996 - Grad. Norm.: 0.0005421029846330507 Norm. Diff.: 0.002711000974982923 tk: 5 x_norm: 27.11754085598292\n",
      "Iteration 3997 - Grad. Norm.: 0.000542005815357808 Norm. Diff.: 0.0027105149231653755 tk: 5 x_norm: 27.119822218226155\n",
      "Iteration 3998 - Grad. Norm.: 0.0005419086871430362 Norm. Diff.: 0.0027100290767892252 tk: 5 x_norm: 27.122103158578334\n",
      "Iteration 3999 - Grad. Norm.: 0.0005418115999610025 Norm. Diff.: 0.002709543435715191 tk: 5 x_norm: 27.12438367721882\n",
      "Iteration 4000 - Grad. Norm.: 0.0005417145537840015 Norm. Diff.: 0.0027090579998050083 tk: 5 x_norm: 27.126663774326854\n",
      "Iteration 4001 - Grad. Norm.: 0.000541617548584352 Norm. Diff.: 0.0027085727689201903 tk: 5 x_norm: 27.12894345008155\n",
      "Iteration 4002 - Grad. Norm.: 0.0005415205843343999 Norm. Diff.: 0.002708087742922059 tk: 5 x_norm: 27.1312227046619\n",
      "Iteration 4003 - Grad. Norm.: 0.0005414236610065138 Norm. Diff.: 0.0027076029216718278 tk: 5 x_norm: 27.133501538246797\n",
      "Iteration 4004 - Grad. Norm.: 0.0005413267785730914 Norm. Diff.: 0.0027071183050324694 tk: 5 x_norm: 27.13577995101499\n",
      "Iteration 4005 - Grad. Norm.: 0.0005412299370065516 Norm. Diff.: 0.0027066338928653684 tk: 5 x_norm: 27.13805794314512\n",
      "Iteration 4006 - Grad. Norm.: 0.000541133136279342 Norm. Diff.: 0.002706149685032644 tk: 5 x_norm: 27.140335514815714\n",
      "Iteration 4007 - Grad. Norm.: 0.0005410363763639349 Norm. Diff.: 0.0027056656813970684 tk: 5 x_norm: 27.142612666205167\n",
      "Iteration 4008 - Grad. Norm.: 0.0005409396572328264 Norm. Diff.: 0.002705181881819676 tk: 5 x_norm: 27.144889397491763\n",
      "Iteration 4009 - Grad. Norm.: 0.0005408429788585392 Norm. Diff.: 0.0027046982861642136 tk: 5 x_norm: 27.147165708853674\n",
      "最小值: 0.066485\t耗时: 412.120495s\n"
     ]
    }
   ],
   "source": [
    "#* Armijo rule \n",
    "# def armijo_search(f, f_grad, xk, t_hat, alpha, beta, D, isNewton=False, dk=None):\n",
    "#     if isNewton:\n",
    "#         assert dk is not None\n",
    "#     tk = t_hat*1\n",
    "#     grad = f_grad(xk)\n",
    "#     while True:\n",
    "#         if isNewton:\n",
    "#             if np.linalg.norm(xk+tk*dk,ord=2)<=D/2 and f(xk+tk*dk) <= f(xk) + alpha*tk*grad.T@dk:\n",
    "#                 break\n",
    "#         else:\n",
    "#             if f(xk-tk*grad) <= f(xk)-alpha*tk*grad.T@grad:\n",
    "#                 break\n",
    "#         tk *= beta\n",
    "#     return tk\n",
    "\n",
    "def project(x,D):\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    if x_norm <= D/2:\n",
    "        return x\n",
    "    coef = D/2/x_norm\n",
    "    return coef*x\n",
    "\n",
    "#* 投影梯度法\n",
    "def projected_gradient_descent(f, f_grad, x0, D, t_hat=1, epsilon=1e-6, max_iters=10000):\n",
    "    # func_val_record = []\n",
    "    func_val_record = [f(x0)]\n",
    "    # func_val_record = []\n",
    "    grad_norm_record = [np.linalg.norm(f_grad(x0))]\n",
    "    # grad_norm_record = []\n",
    "    xk = x0\n",
    "    xk_norm = np.linalg.norm(xk)\n",
    "    t_s = time()\n",
    "    # for idx in trange(max_iters):\n",
    "    for idx in range(max_iters):\n",
    "        tk = armijo_search(f, f_grad, xk, t_hat=t_hat, alpha=0.1, beta=0.5, D=D)\n",
    "        xk_next = project(xk-tk*f_grad(xk), D)\n",
    "        fval_xk_next = f(xk_next)\n",
    "        grad_xk_next = f_grad(xk_next)\n",
    "        func_val_record.append(fval_xk_next)\n",
    "        grad_norm_next = np.linalg.norm(grad_xk_next,ord=2)\n",
    "        grad_norm_record.append(grad_norm_next)\n",
    "        norm_diff = np.linalg.norm(xk_next-xk)\n",
    "        if norm_diff<=epsilon:\n",
    "            break\n",
    "        else:\n",
    "            print(f'Iteration {idx} - Grad. Norm.:',grad_norm_next, 'Norm. Diff.:',norm_diff,'tk:',tk, 'x_norm:',np.linalg.norm(xk_next))\n",
    "        xk = xk_next\n",
    "    t_e = time()\n",
    "    return xk_next, t_e-t_s, np.array(func_val_record), np.array(grad_norm_record)\n",
    "\n",
    "np.random.seed(1000)\n",
    "init_x = np.zeros(n)+0.005\n",
    "x_opt_pgd, t_pgd, fvals_pgd, grad_norm_pgd = projected_gradient_descent(f=f, f_grad=f_grad, x0=init_x, D=500, t_hat=5, epsilon=1e-4, max_iters=4010)\n",
    "print(f'最小值: {f(x_opt_pgd):>2f}\\t耗时: {t_pgd:>2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008207631426463323"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_opt_pgd)-f(x_opt_ipm_damped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fval_opt = f(x_opt_ipm_damped)\n",
    "fvals_pgd_seq = pd.Series(fvals_pgd-fval_opt, index=np.arange(len(fvals_pgd))+1, name=r'Projected GD')\n",
    "fvals_damped_seq = pd.Series(fvals_damped-fval_opt, index=np.arange(len(fvals_damped))+1, name=r'Newton')\n",
    "fvals_bfgs_seq = pd.Series(fvals_bfgs-fval_opt, index=np.arange(len(fvals_bfgs))+1, name=r'BFGS')\n",
    "plot_multi_seqs([fvals_pgd_seq, fvals_damped_seq, fvals_bfgs_seq], xlabel='Iterations', ylabel=r'Func. residual', title=r'w8a, D=20', xtick_step = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        obj = json.load(f)\n",
    "    return obj\n",
    "\n",
    "def save_as_json_files(objs, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(objs, f)\n",
    "\n",
    "# 保存计算迭代的计算结果\n",
    "results = {\n",
    "    'newton': (fvals_damped.tolist(), t_ipm_damped, x_opt_ipm_damped.tolist()),\n",
    "    'bfgs': (fvals_bfgs.tolist(), t_ipm_bfgs, x_opt_ipm_bfgs.tolist()),\n",
    "    'gd': (fvals_pgd.tolist(), t_pgd, x_opt_pgd.tolist()),\n",
    "}\n",
    "# x_opt_ipm_damped, t_ipm_damped, duality_gaps_damped, fvals_damped\n",
    "# x_opt_ipm_bfgs, t_ipm_bfgs, duality_gaps_bfgs, fvals_bfgs\n",
    "# x_opt_pgd, t_pgd, fvals_pgd, grad_norm_pgd\n",
    "save_as_json_files(results, filename='D_500.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05827782057975089"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_opt_ipm_damped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05827782057975089"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = read_json('D_500.json')\n",
    "f(np.array(res['newton'][2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "734ab24b5d337aa3083f37141e45635523032b38e37867a0b0460a6855b4b5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
