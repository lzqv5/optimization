{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:07<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from libsvm.svmutil import svm_read_problem # https://blog.csdn.net/u013630349/article/details/47323883\n",
    "from time import time\n",
    "\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "norm=np.linalg.norm\n",
    "# import scipy as sp\n",
    "from scipy.linalg import hessenberg\n",
    "def ReadDataSparse(filename):\n",
    "    try:\n",
    "        input = open(filename)\n",
    "    except:\n",
    "        print(\"E: Unable to open file \" + filename)\n",
    "        return False\n",
    "    m = 0  # Number of training examples.\n",
    "    n = 0  # Number of features.\n",
    "    nnz = 0  # Number of nonzero elements.\n",
    "    data = []\n",
    "    buffer = input.readline()\n",
    "    labels = []\n",
    "    while buffer:\n",
    "        m += 1\n",
    "        data.append([])\n",
    "        ss = buffer.strip().split(\" \")\n",
    "        label = float(ss[0])\n",
    "        labels.append(int(label))\n",
    "        for i in range(1, len(ss)):\n",
    "            key_value = ss[i].split(\":\")\n",
    "            key = int(key_value[0])\n",
    "            value = float(key_value[1])\n",
    "            data[-1].append((key - 1, value))\n",
    "            n = max(n, key)\n",
    "            nnz += 1\n",
    "        buffer = input.readline()\n",
    "    input.close()\n",
    "    return data\n",
    "\n",
    "def read_data(path):\n",
    "    b, A = svm_read_problem(path)\n",
    "    rows = len(b)   # 矩阵行数, i.e. sample 数\n",
    "    cols = max([max(row.keys()) if len(row)>0 else 0 for row in A])  # 矩阵列数, i.e. feature 数\n",
    "    b = np.array(b)\n",
    "    A_np = np.zeros((rows,cols))\n",
    "    for r in range(rows):\n",
    "        for c in A[r].keys():\n",
    "            # MatLab 是 1-index, python 则是 0-index\n",
    "            A_np[r,c-1] = A[r][c]\n",
    "    # 清楚全 0 features\n",
    "    effective_row_ids = []\n",
    "    for idx, row in enumerate(A_np):\n",
    "        if   True or np.sum(row) > 1e-3:\n",
    "            effective_row_ids.append(idx)\n",
    "    return b[effective_row_ids], A_np[effective_row_ids]\n",
    "\n",
    "\n",
    "def solve_tridiagonal_system(diag: np.ndarray, subdiag: np.ndarray, tau: float, b: np.ndarray) -> np.ndarray:\n",
    "    n = diag.shape[0]\n",
    "    c = np.zeros(n - 1)\n",
    "    d = np.zeros(n)\n",
    "\n",
    "    c[0] = subdiag[0] / (diag[0] + tau)\n",
    "    d[0] = b[0] / (diag[0] + tau)\n",
    "    for i in range(1, n - 1):\n",
    "        w = diag[i] + tau - subdiag[i - 1] * c[i - 1]\n",
    "        c[i] = subdiag[i] / w\n",
    "        d[i] = (b[i] - subdiag[i - 1] * d[i - 1]) / w\n",
    "    d[n - 1] = (b[n - 1] - subdiag[n - 2] * d[n - 2]) / (diag[n - 1] + tau - subdiag[n - 2] * c[n - 2])\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        d[i] -= c[i] * d[i + 1]\n",
    "\n",
    "    return d\n",
    "\n",
    "2 * np.finfo(float).eps\n",
    "def ss(A, jj):\n",
    "    \"\"\"Subfunction for h_trid.\"\"\"\n",
    "    return np.sqrt(np.sum(A[jj + 1:, jj] ** 2))\n",
    "\n",
    "def h_trid(A):\n",
    "    \"\"\"\n",
    "    H_TRID(A) uses Householder method to form a tridiagonal matrix from A.\n",
    "    Must have a SQUARE SYMMETRIC matrix as the input.\n",
    "    \"\"\"\n",
    "    M, N = A.shape\n",
    "    if M != N or (A != A.T).any():  # This just screens matrices that can't work.\n",
    "        raise ValueError(\"Matrix must be square symmetric only, see help.\")\n",
    "\n",
    "    lngth = len(A)  # Preallocations.\n",
    "    v = np.zeros(lngth)\n",
    "    I = np.eye(lngth)\n",
    "    Aold = A\n",
    "    finalP=np.eye(lngth)\n",
    "    for jj in range(lngth - 2):  # Build each vector j and run the whole procedure.\n",
    "        v[:jj+1] = 0\n",
    "        S = ss(Aold, jj)\n",
    "        v[jj + 1] = np.sqrt(0.5 * (1 + abs(Aold[jj + 1, jj]) / (S+2 * np.finfo(float).eps)))\n",
    "        v[jj + 2:] = Aold[jj + 2:, jj] * np.sign(Aold[jj + 1, jj]) / (2 * v[jj + 1] * S+2 * np.finfo(float).eps )\n",
    "        P = I - 2 * np.outer(v, v)\n",
    "        Anew = P @ Aold @ P\n",
    "        Aold = Anew\n",
    "        finalP=finalP@P\n",
    "    # Anew[abs(Anew) < 5e-14] = 0  # Tolerance.\n",
    "\n",
    "    return Anew,finalP\n",
    "\n",
    "\n",
    "\n",
    "def minimize_quadratic_on_l2_ball(g: np.ndarray, H: np.ndarray, R: float, inner_eps: float) -> np.ndarray:\n",
    "    n = g.shape[0]\n",
    "    # np.savetxt('hess.txt',H)\n",
    "    # print(np.linalg.norm(H))\n",
    "    H_tridiag, Q = hessenberg(H,calc_q=True)\n",
    "    diag = np.diag(H_tridiag)\n",
    "    subdiag = np.diag(H_tridiag, k=-1)\n",
    "    # print(\"Other:\",np.sum(H_tridiag)-np.sum(diag)-np.sum(subdiag)*2,flush=True)\n",
    "    g_ = Q.T.dot(g)\n",
    "\n",
    "    tau = 1.0\n",
    "    S_tau = np.zeros(n)\n",
    "    S_tau_norm = 0.0\n",
    "    phi_tau = 0.0\n",
    "    # print(np.linalg.norm(H_tridiag))\n",
    "    # print(np.linalg.norm(diag),\"\\t\",np.linalg.norm(subdiag),\"\\t\",np.linalg.norm(g_))\n",
    "    N_LINE_SEARCH_ITERS = 100\n",
    "    for i in range(N_LINE_SEARCH_ITERS + 1):\n",
    "        if i == N_LINE_SEARCH_ITERS:\n",
    "            print(\"W: Preliminaty line search iterations exceeded in MinimizeQuadraticOnL2Ball\")\n",
    "            break\n",
    "\n",
    "        S_tau = solve_tridiagonal_system(diag, subdiag, tau, g_)\n",
    "        S_tau_norm = np.linalg.norm(S_tau)\n",
    "        phi_tau = 1.0 / S_tau_norm - 1.0 / R\n",
    "        if phi_tau < inner_eps or tau < inner_eps:\n",
    "            break\n",
    "        tau *= 0.5\n",
    "    # print(\"phi_tau:\",phi_tau)\n",
    "    if phi_tau < -inner_eps:\n",
    "        S_tau_grad = np.zeros(n)\n",
    "        for i in range(N_LINE_SEARCH_ITERS + 1):\n",
    "            if i == N_LINE_SEARCH_ITERS:\n",
    "                print(\"W: 1-D Newton iterations exceeded in MinimizeQuadraticOnL2Ball\")\n",
    "                break\n",
    "\n",
    "            S_tau_grad = solve_tridiagonal_system(diag, subdiag, tau, S_tau)\n",
    "            phi_tau_prime = (1.0 / S_tau_norm**3) * (S_tau.T.dot(S_tau_grad))\n",
    "            tau -= phi_tau / phi_tau_prime\n",
    "\n",
    "            S_tau = solve_tridiagonal_system(diag, subdiag, tau, g_)\n",
    "            S_tau_norm = np.linalg.norm(S_tau)\n",
    "            phi_tau = 1.0 / S_tau_norm - 1.0 / R\n",
    "\n",
    "            if abs(phi_tau) < inner_eps or abs(phi_tau_prime) < inner_eps:\n",
    "                break\n",
    "\n",
    "    return -Q.dot(S_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Sigmoid(t):\n",
    "    return 1.0 / (1 + np.exp(-t))\n",
    "\n",
    "def Pi(k: int) -> int:\n",
    "    k |= (k >> 1)\n",
    "    k |= (k >> 2)\n",
    "    k |= (k >> 4)\n",
    "    k |= (k >> 8)\n",
    "    k |= (k >> 16)\n",
    "    return (k + 1) >> 1\n",
    "\n",
    "def StochasticContractingNewton(params: dict, c_0: float, decrease_gamma: bool, variance_reduction: bool, hessian_variance_reduction: bool, history = None):\n",
    "    params['AT']=params['A'].T\n",
    "    n = params['A'].shape[1]\n",
    "    m = params['A'].shape[0]\n",
    "    inv_m = 1.0 / m\n",
    "    data_accesses = 0\n",
    "\n",
    "    x_k = params['x_0']\n",
    "\n",
    "    A_batch = None\n",
    "    AT_batch = None\n",
    "    A_batch_triplets = []\n",
    "    AT_batch_triplets = []\n",
    "\n",
    "    g_k = np.zeros(n)\n",
    "    H_k = np.zeros((n, n))\n",
    "    v_k = np.zeros(n)\n",
    "\n",
    "    sigma_prime = None\n",
    "    Ax = None\n",
    "    full_grad = None\n",
    "    full_Hess = None\n",
    "    z_k = None\n",
    "\n",
    "    np.random.seed(31415)\n",
    "    obj_indices = np.arange(m)\n",
    "    batch = []\n",
    "\n",
    "    method_name = \"Stochastic Newton\"\n",
    "    if variance_reduction:\n",
    "        method_name += \" (HVR)\" if hessian_variance_reduction else \" (VR)\"\n",
    "    gamma_str = \"gamma_k = \" + str(c_0)\n",
    "    if decrease_gamma:\n",
    "        gamma_str += \" / (3 + k)\"\n",
    "    pbar=tqdm(range(params['n_iters'] ))\n",
    "    # InitDisplay(params, method_name + \", \" + gamma_str)\n",
    "    for k in range(params['n_iters'] ):\n",
    "        to_finish = None\n",
    "        # UpdateHistory(\n",
    "        #     params, start_time, k, data_accesses,\n",
    "        #     lambda: (x_k.norm() > params.R_ + REGION_TOLERERANCE) ? INF : inv_m * ((*params.A_) * x_k).unaryExpr(&Log_one_exp).sum(),\n",
    "        #     &last_logging_time,\n",
    "        #     &last_display_time,\n",
    "        #     history,\n",
    "        #     &to_finish)\n",
    "        if to_finish or (k>=1 and np.linalg.norm(g_k)<params['outer_eps']):\n",
    "            break\n",
    "\n",
    "        if variance_reduction and Pi(k) == k:\n",
    "            Ax = np.matmul(params['A'], x_k)\n",
    "            full_grad = inv_m * (params['A'].T.dot(1 / (1 + np.exp(-Ax))))#+2*params['lambda']*x_k) \n",
    "            if hessian_variance_reduction:\n",
    "                full_Hess = (inv_m) * (params['A'].T.dot(((1 / (1 + np.exp(-Ax))) * (1 - 1 / (1 + np.exp(-Ax))))[:, np.newaxis] * params['A'])) #+ inv_m*2*params['lambda']*np.diag([1.0]*x_k.size)\n",
    "            z_k = x_k\n",
    "            data_accesses += m\n",
    "\n",
    "        k_sqr = (k + 1) * (k + 1)\n",
    "        batch_size = k_sqr if k_sqr < m else m\n",
    "        if batch_size == m:\n",
    "            print(\"W: batch_size equals m\")\n",
    "        np.random.shuffle(obj_indices)\n",
    "        if k!=0:\n",
    "            batch = obj_indices[:batch_size].copy()\n",
    "        else:\n",
    "            batch=[19539]\n",
    "\n",
    "        if decrease_gamma:\n",
    "            gamma_k = c_0 / (3 + k)\n",
    "\n",
    "        if variance_reduction:\n",
    "            g_k = full_grad\n",
    "            if hessian_variance_reduction:\n",
    "                H_k = gamma_k*full_Hess\n",
    "            else:\n",
    "                H_k=np.zeros((n,n))\n",
    "        else:\n",
    "            g_k=np.zeros(n)\n",
    "            H_k=np.zeros((n,n))\n",
    "                \n",
    "        A_batch=np.zeros((batch_size,n))\n",
    "        sigma_prime = np.zeros(batch_size)\n",
    "        for batch_i in range(batch_size):\n",
    "            i = batch[batch_i]\n",
    "            sigma = Sigmoid(params['A'][i, :].dot(x_k))\n",
    "            g_k += (sigma / batch_size) * params['A'][i, :]\n",
    "            data_i = params['data'][i]\n",
    "            for index_value in data_i:\n",
    "                A_batch[batch_i, index_value[0]]=index_value[1]\n",
    "            sigma_prime[batch_i] = sigma * (1 - sigma) * gamma_k / batch_size\n",
    "            if variance_reduction:\n",
    "                sigma_z = Sigmoid(params['A'][i, :].dot(z_k))\n",
    "                g_k -= (sigma_z / batch_size) * params['A'][i, :]\n",
    "                # print(sigma_z,\"\\t\",norm(x_k),\"\\t\",np.sum(params['A'][i, :]))\n",
    "                if hessian_variance_reduction:\n",
    "                    sigma_prime[batch_i] -= sigma_z * (1 - sigma_z) * gamma_k / batch_size\n",
    "        # print(np.linalg.norm(sigma_prime),\"\\t\",(np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k))))))\n",
    "        \n",
    "        data_accesses += batch_size\n",
    "        # g_k+=2*inv_m*params['lambda']*x_k\n",
    "        AT_batch = A_batch.T\n",
    "        H_k += A_batch.T @ np.diag(sigma_prime) @ A_batch # + inv_m*2*params['lambda']*np.diag([1.0]*x_k.size)\n",
    "        norm_g=np.linalg.norm(g_k)\n",
    "        g_k -= H_k @ x_k\n",
    "        v_k = minimize_quadratic_on_l2_ball(g_k, H_k, params['R'], params['inner_eps'])\n",
    "        x_k += gamma_k * (v_k - x_k)\n",
    "        # x_k=-x_k\n",
    "        print('Function value: %.8f / Grad norm: %.8f'%(np.average(np.log(1+np.exp((params['A']@x_k)))),norm_g))\n",
    "        print(x_k[:5],\"\\t\",norm(x_k))\n",
    "        # print()\n",
    "        # pbar.set_description('Function value: %.8f / Grad norm: %.8f'%(np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k)))),norm_g)) # +inv_m*params['lambda']*np.linalg.norm(x_k)**2\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49749 300\n",
      "14358852\n",
      "Function value: 0.23217260 / Grad norm: 0.56253632\n",
      "[0.32482595 0.26790497 0.42314402 0.27637255 0.34434844] \t 10.00000970727117\n",
      "Function value: 1.72237966 / Grad norm: 0.01999596\n",
      "[0.61713195 0.60905421 0.84026918 0.75386319 0.63574987] \t 7.1935933969932915\n",
      "Function value: 0.19739870 / Grad norm: 0.92060543\n",
      "[0.25244415 0.28423075 0.34285351 0.34288074 0.26227689] \t 6.188520328000635\n",
      "Function value: 0.23731381 / Grad norm: 0.84504604\n",
      "[0.16039476 0.16988698 0.17553288 0.19965412 0.13599394] \t 7.652444421650844\n",
      "Function value: 0.18814495 / Grad norm: 0.03612063\n",
      "[0.78078435 0.70205858 1.09636425 0.75982821 0.78485896] \t 5.800635162582487\n",
      "Function value: 0.20939881 / Grad norm: 0.04124280\n",
      "[0.79237902 0.8771177  1.40691057 0.94275575 1.00289238] \t 6.843471304871322\n",
      "Function value: 0.20012670 / Grad norm: 0.04938442\n",
      "[1.01026884 0.90851081 1.47099899 0.97408283 1.04703748] \t 7.7267664875031725\n",
      "Function value: 0.18114985 / Grad norm: 0.07058971\n",
      "[1.05264979 0.86985797 1.4147214  0.93151717 1.01179584] \t 8.222607673145138\n",
      "Function value: 0.17071398 / Grad norm: 0.02183183\n",
      "[0.80009459 0.67443231 1.05943391 0.72804617 0.82239876] \t 7.229097043145119\n",
      "Function value: 0.18089002 / Grad norm: 0.03658000\n",
      "[0.61477443 0.52614225 0.82272512 0.57004686 0.65595888] \t 7.122783083393379\n",
      "Function value: 0.19795743 / Grad norm: 0.04533615\n",
      "[0.48276096 0.42068267 0.65903623 0.47183587 0.5502894 ] \t 7.391097572619172\n",
      "Function value: 0.21298692 / Grad norm: 0.05027886\n",
      "[0.39693313 0.34358081 0.5432256  0.40642772 0.47487127] \t 7.760474117060326\n",
      "Function value: 0.22487576 / Grad norm: 0.05347466\n",
      "[0.34080934 0.28837464 0.48414006 0.3603493  0.42072801] \t 8.121273784449583\n",
      "Function value: 0.23408261 / Grad norm: 0.05594132\n",
      "[0.30679855 0.25387514 0.45933817 0.33091899 0.38894683] \t 8.432022680420081\n",
      "Function value: 0.24116270 / Grad norm: 0.05833031\n",
      "[0.29085539 0.23424438 0.44860326 0.31334318 0.37740489] \t 8.687706392103525\n",
      "Function value: 0.24648000 / Grad norm: 0.06029979\n",
      "[0.28443593 0.22515298 0.45151365 0.3077414  0.38028678] \t 8.895149181775839\n",
      "Function value: 0.19967507 / Grad norm: 0.02313864\n",
      "[0.34598757 0.29197794 0.51040916 0.37867637 0.43020143] \t 6.919869252592907\n",
      "Function value: 0.17597326 / Grad norm: 0.02308226\n",
      "[0.42441335 0.4034968  0.63238166 0.48319972 0.50120187] \t 5.908284815539295\n",
      "Function value: 0.17216807 / Grad norm: 0.02247163\n",
      "[0.52736935 0.47445143 0.77135453 0.60364433 0.55875952] \t 5.76546800090912\n",
      "Function value: 0.17761105 / Grad norm: 0.02180403\n",
      "[0.61635187 0.57523692 0.90636129 0.71449964 0.63152785] \t 6.075960741536829\n",
      "Function value: 0.18265658 / Grad norm: 0.02108530\n",
      "[0.68236112 0.6728407  1.04571035 0.79725346 0.71349107] \t 6.494174801110779\n",
      "Function value: 0.18405563 / Grad norm: 0.02256784\n",
      "[0.74943674 0.75518784 1.1509394  0.86561694 0.76854474] \t 6.898104524045905\n",
      "Function value: 0.18143229 / Grad norm: 0.02580003\n",
      "[0.79178291 0.81336857 1.22978688 0.91369511 0.80701148] \t 7.258039381009922\n",
      "Function value: 0.17662688 / Grad norm: 0.03008088\n",
      "[0.81445176 0.85036279 1.27683385 0.9452261  0.83104394] \t 7.554043830588695\n",
      "Function value: 0.17138755 / Grad norm: 0.03419186\n",
      "[0.82262779 0.8718617  1.30082556 0.95996335 0.84286997] \t 7.788856991213425\n",
      "Function value: 0.16763072 / Grad norm: 0.03792588\n",
      "[0.82343528 0.88107928 1.30854714 0.96529829 0.84510002] \t 7.979992309637947\n",
      "Function value: 0.16504734 / Grad norm: 0.04158716\n",
      "[0.81815232 0.87897254 1.30144694 0.95941876 0.8390493 ] \t 8.133191704550686\n",
      "Function value: 0.16382948 / Grad norm: 0.04459433\n",
      "[0.81064206 0.87291984 1.28669167 0.94905793 0.82889087] \t 8.264631940154828\n",
      "Function value: 0.16360890 / Grad norm: 0.04721146\n",
      "[0.80022666 0.86440849 1.26768879 0.9355801  0.8159882 ] \t 8.375785414693356\n",
      "Function value: 0.16428425 / Grad norm: 0.04941677\n",
      "[0.78864911 0.85360571 1.24619818 0.92058076 0.80273392] \t 8.47225859807213\n",
      "Function value: 0.16559786 / Grad norm: 0.05123604\n",
      "[0.77711853 0.84226203 1.22449496 0.90578922 0.79012273] \t 8.560276755526633\n",
      "Function value: 0.16738003 / Grad norm: 0.05288554\n",
      "[0.76618142 0.8302432  1.20268339 0.8919539  0.77798784] \t 8.641980313337543\n",
      "Function value: 0.16092434 / Grad norm: 0.00932883\n",
      "[0.73872674 0.79880532 1.13797722 0.86158596 0.77621307] \t 8.024526294871956\n",
      "Function value: 0.15845820 / Grad norm: 0.00875708\n",
      "[0.72486431 0.78161206 1.0957601  0.84752026 0.78712043] \t 7.716915151825326\n",
      "Function value: 0.15815231 / Grad norm: 0.00849271\n",
      "[0.72169585 0.77154166 1.06955957 0.84832379 0.81252795] \t 7.6517500581171225\n",
      "Function value: 0.15871391 / Grad norm: 0.00848432\n",
      "[0.71327111 0.76013954 1.04364586 0.84884055 0.82952662] \t 7.673827727163207\n",
      "Function value: 0.15934775 / Grad norm: 0.00907786\n",
      "[0.70641466 0.7488521  1.01836502 0.84662863 0.83854807] \t 7.736415851304425\n",
      "Function value: 0.15965637 / Grad norm: 0.01027166\n",
      "[0.699476   0.73929735 0.99499066 0.84707917 0.84345553] \t 7.827432137612707\n",
      "Function value: 0.15974173 / Grad norm: 0.01183764\n",
      "[0.69245857 0.72935619 0.97560523 0.84639026 0.84593726] \t 7.930335532319987\n",
      "Function value: 0.15988115 / Grad norm: 0.01357270\n",
      "[0.68364758 0.71739816 0.95829894 0.8439582  0.84348165] \t 8.0340805805829\n",
      "Function value: 0.16027983 / Grad norm: 0.01541960\n",
      "[0.67495471 0.70460505 0.94194236 0.83864718 0.83758962] \t 8.125990826563221\n",
      "Function value: 0.16116563 / Grad norm: 0.01709236\n",
      "[0.66586787 0.69127802 0.92537974 0.83112716 0.82879027] \t 8.20771876456505\n",
      "Function value: 0.16254693 / Grad norm: 0.01866179\n",
      "[0.65576701 0.67865254 0.90885058 0.82248263 0.81812904] \t 8.279516522503647\n",
      "Function value: 0.16441807 / Grad norm: 0.02008868\n",
      "[0.64587176 0.6664165  0.89228619 0.81293248 0.80662698] \t 8.342252677141701\n",
      "Function value: 0.16662906 / Grad norm: 0.02143605\n",
      "[0.63703869 0.65456216 0.87653972 0.80315446 0.79540068] \t 8.400943672407442\n",
      "Function value: 0.16902744 / Grad norm: 0.02263773\n",
      "[0.62893503 0.64333985 0.86241637 0.79390243 0.78476853] \t 8.458956405725507\n",
      "Function value: 0.17163393 / Grad norm: 0.02375189\n",
      "[0.62185312 0.63325786 0.84986564 0.78540487 0.77390274] \t 8.511943126235156\n",
      "Function value: 0.17433495 / Grad norm: 0.02479083\n",
      "[0.61564135 0.62392494 0.83928303 0.77748757 0.76367833] \t 8.563421153671325\n",
      "Function value: 0.17710845 / Grad norm: 0.02574671\n",
      "[0.61018973 0.61516327 0.8306034  0.7698168  0.75407283] \t 8.612851308634264\n",
      "Function value: 0.17985388 / Grad norm: 0.02666016\n",
      "[0.60518348 0.60738987 0.82355156 0.76287297 0.74525445] \t 8.661174598650975\n",
      "Function value: 0.18261582 / Grad norm: 0.02754770\n",
      "[0.60067573 0.6003983  0.81750611 0.75667805 0.73724112] \t 8.707435081591264\n",
      "Function value: 0.18534551 / Grad norm: 0.02837213\n",
      "[0.59636194 0.59419375 0.81238445 0.75100993 0.72980009] \t 8.751981913896309\n",
      "Function value: 0.18801630 / Grad norm: 0.02915728\n",
      "[0.59322356 0.58880918 0.80770317 0.74628156 0.72290641] \t 8.79517643485181\n",
      "Function value: 0.19059776 / Grad norm: 0.02986941\n",
      "[0.59073552 0.5842126  0.8039432  0.74232538 0.7167761 ] \t 8.837279551307246\n",
      "Function value: 0.19310486 / Grad norm: 0.03058657\n",
      "[0.58886926 0.58023659 0.8008661  0.73895925 0.71110288] \t 8.87790659191764\n",
      "Function value: 0.19549594 / Grad norm: 0.03124177\n",
      "[0.58764989 0.57736068 0.79867936 0.73644426 0.70612566] \t 8.917671759333233\n",
      "Function value: 0.19778733 / Grad norm: 0.03188807\n",
      "[0.58693131 0.57518101 0.79762711 0.73460379 0.7016996 ] \t 8.956141839410996\n",
      "Function value: 0.19999341 / Grad norm: 0.03248049\n",
      "[0.58679723 0.57364284 0.79728566 0.73323358 0.69766467] \t 8.99319566627858\n",
      "Function value: 0.20209347 / Grad norm: 0.03307546\n",
      "[0.58711986 0.57249052 0.79751748 0.73222448 0.69429773] \t 9.029090058939532\n",
      "Function value: 0.20410537 / Grad norm: 0.03367180\n",
      "[0.58789172 0.57153489 0.79826979 0.73145407 0.69126922] \t 9.063607908522602\n",
      "Function value: 0.20603361 / Grad norm: 0.03423496\n",
      "[0.58892438 0.57097662 0.79971508 0.73143873 0.688717  ] \t 9.096703502098174\n",
      "Function value: 0.20786043 / Grad norm: 0.03478113\n",
      "[0.59023288 0.57078381 0.80143615 0.73155636 0.68652986] \t 9.128704212639615\n",
      "Function value: 0.20958266 / Grad norm: 0.03530066\n",
      "[0.59160132 0.57085689 0.80340252 0.73202135 0.68483157] \t 9.159636911989804\n",
      "Function value: 0.21122394 / Grad norm: 0.03582058\n",
      "[0.5929303  0.5711583  0.80561521 0.73265011 0.68340151] \t 9.18930862090606\n",
      "Function value: 0.19944648 / Grad norm: 0.01999094\n",
      "[0.58108041 0.56121159 0.78815923 0.7172077  0.67223878] \t 8.615102995751926\n",
      "Function value: 0.18932754 / Grad norm: 0.01972527\n",
      "[0.57135967 0.5532793  0.77396706 0.70435996 0.66348666] \t 8.107342551842313\n",
      "Function value: 0.18091628 / Grad norm: 0.01941964\n",
      "[0.56396557 0.54768297 0.76325828 0.69439899 0.65729384] \t 7.664702525833812\n",
      "Function value: 0.17427994 / Grad norm: 0.01906652\n",
      "[0.55915625 0.54480896 0.75653389 0.68785179 0.65356993] \t 7.288699798900281\n",
      "Function value: 0.16947751 / Grad norm: 0.01861716\n",
      "[0.55631279 0.54361862 0.75253037 0.68340654 0.65142231] \t 6.979726795117624\n",
      "Function value: 0.16651012 / Grad norm: 0.01817592\n",
      "[0.55684592 0.54577974 0.75313921 0.6827471  0.65283684] \t 6.742660178959842\n",
      "Function value: 0.16532891 / Grad norm: 0.01764846\n",
      "[0.55919886 0.54957106 0.7561379  0.68455329 0.65611451] \t 6.5738663930389\n",
      "Function value: 0.16572542 / Grad norm: 0.01710810\n",
      "[0.56421374 0.55587459 0.76255574 0.68925881 0.66150866] \t 6.47073184641497\n",
      "Function value: 0.16734869 / Grad norm: 0.01657810\n",
      "[0.57129206 0.56411635 0.77201718 0.69647925 0.66899413] \t 6.428080653429842\n",
      "Function value: 0.16985338 / Grad norm: 0.01607675\n",
      "[0.57917841 0.57336788 0.78284474 0.70472878 0.67729005] \t 6.432604273611994\n",
      "Function value: 0.17261210 / Grad norm: 0.01566318\n",
      "[0.58911394 0.58374601 0.79578424 0.71489397 0.68692506] \t 6.4800156684990196\n",
      "Function value: 0.17540815 / Grad norm: 0.01536417\n",
      "[0.59901909 0.59418645 0.80909104 0.72512773 0.69651325] \t 6.5510491760217535\n",
      "Function value: 0.17790639 / Grad norm: 0.01529054\n",
      "[0.60855738 0.60471009 0.82245338 0.7359783  0.70601256] \t 6.639830978039181\n",
      "Function value: 0.17983727 / Grad norm: 0.01543077\n",
      "[0.61759817 0.61470173 0.83586139 0.74643733 0.71487812] \t 6.736646777856395\n",
      "Function value: 0.18118437 / Grad norm: 0.01581814\n",
      "[0.62621775 0.62430668 0.84828681 0.75619843 0.72320839] \t 6.838881978530984\n",
      "Function value: 0.18193430 / Grad norm: 0.01642042\n",
      "[0.63391642 0.63277908 0.8593059  0.76488989 0.73044629] \t 6.941468815875905\n",
      "Function value: 0.18199402 / Grad norm: 0.01722137\n",
      "[0.64082876 0.64025518 0.86939788 0.77274789 0.73669574] \t 7.0432852733489355\n",
      "Function value: 0.18147223 / Grad norm: 0.01817697\n",
      "[0.64676609 0.64678322 0.87815702 0.77962448 0.7421066 ] \t 7.141761024825499\n",
      "Function value: 0.18049894 / Grad norm: 0.01924284\n",
      "[0.65181266 0.65248369 0.88561918 0.78538371 0.74627191] \t 7.235138299698688\n",
      "Function value: 0.17921952 / Grad norm: 0.02038095\n",
      "[0.65580585 0.65710621 0.89171534 0.79013813 0.74926536] \t 7.322627309823404\n",
      "Function value: 0.17768871 / Grad norm: 0.02152004\n",
      "[0.65906431 0.66087891 0.8966711  0.79380336 0.7514634 ] \t 7.404932347426496\n",
      "Function value: 0.17602579 / Grad norm: 0.02266235\n",
      "[0.66143283 0.66370913 0.90060406 0.79654401 0.75264857] \t 7.48139360148707\n",
      "Function value: 0.17431618 / Grad norm: 0.02379994\n",
      "[0.66296492 0.66570258 0.9034254  0.79829356 0.75293127] \t 7.5523151426778545\n",
      "Function value: 0.17263045 / Grad norm: 0.02487735\n",
      "[0.6638857  0.66705591 0.9054187  0.79919813 0.75253306] \t 7.618302278791443\n",
      "Function value: 0.17100293 / Grad norm: 0.02593581\n",
      "[0.66413909 0.66780558 0.90662329 0.79942058 0.75150158] \t 7.679766026772063\n",
      "Function value: 0.16948048 / Grad norm: 0.02695418\n",
      "[0.66390787 0.66809205 0.90717137 0.7992351  0.74997385] \t 7.737245382157295\n",
      "Function value: 0.16810259 / Grad norm: 0.02794913\n",
      "[0.66326049 0.66793781 0.90706281 0.79856805 0.74795292] \t 7.791336631110255\n",
      "Function value: 0.16686555 / Grad norm: 0.02888924\n",
      "[0.66226324 0.66747095 0.90644265 0.79749285 0.74557945] \t 7.842075410636557\n",
      "Function value: 0.16579049 / Grad norm: 0.02978781\n",
      "[0.66097354 0.66668894 0.90547235 0.7961643  0.74288081] \t 7.890227677457016\n",
      "Function value: 0.16486520 / Grad norm: 0.03064267\n",
      "[0.65948529 0.66566775 0.90412186 0.79464516 0.74001998] \t 7.935896449003071\n",
      "Function value: 0.16408591 / Grad norm: 0.03146700\n",
      "[0.65775025 0.66439191 0.90240806 0.79292652 0.7369954 ] \t 7.979188952067646\n",
      "Function value: 0.16345337 / Grad norm: 0.03224292\n",
      "[0.65590975 0.66289998 0.90049879 0.79111029 0.73384654] \t 8.0208460046104\n",
      "Function value: 0.16295888 / Grad norm: 0.03298997\n",
      "[0.65390476 0.66124387 0.89838865 0.78912972 0.73060124] \t 8.06104180175751\n",
      "Function value: 0.16258956 / Grad norm: 0.03369068\n",
      "[0.65184247 0.65949865 0.89616991 0.78703005 0.72727528] \t 8.099700637401993\n",
      "Function value: 0.16233513 / Grad norm: 0.03437205\n",
      "[0.64972167 0.65768362 0.8938885  0.7848786  0.7239292 ] \t 8.137101711678005\n",
      "Function value: 0.16218610 / Grad norm: 0.03504409\n",
      "[0.64756144 0.6557887  0.89148196 0.78266606 0.72055401] \t 8.173183752518757\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "b, A= read_data('w8a')\n",
    "data = ReadDataSparse('w8a')\n",
    "# b, A = read_data('ijcnn1.test')\n",
    "# b, A = read_data('a9a.test')\n",
    "# b, A = read_data('CINA.test')\n",
    "m,n = A.shape\n",
    "print(m,n)\n",
    "b=-b\n",
    "# b=np.expand_dims(b, axis=1)\n",
    "params=dict()\n",
    "params['data']=data\n",
    "params['A']=-np.multiply(b,A.T).T\n",
    "params['A_o']=A\n",
    "params['b']=b\n",
    "# print(params['A'][0,:])\n",
    "print(np.sum(A==params['A']))\n",
    "params['x_0']=np.zeros(n)\n",
    "c_0 = 3.0\n",
    "params['R']=10\n",
    "params['inner_eps']=1e-7\n",
    "params['outer_eps']=1e-4\n",
    "params['n_iters']=100\n",
    "params['lambda']=0.01\n",
    "history=None\n",
    "decrease_gamma=True\n",
    "vr = True # Variance reduction\n",
    "hessvr = False # Hessian Variance Reduction\n",
    "StochasticContractingNewton(params, c_0, decrease_gamma,vr,hessvr, history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "734ab24b5d337aa3083f37141e45635523032b38e37867a0b0460a6855b4b5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
