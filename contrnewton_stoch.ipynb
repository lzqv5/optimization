{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from libsvm.svmutil import svm_read_problem # https://blog.csdn.net/u013630349/article/details/47323883\n",
    "from time import time\n",
    "\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "norm=np.linalg.norm\n",
    "# import scipy as sp\n",
    "from scipy.linalg import hessenberg\n",
    "def ReadDataSparse(filename):\n",
    "    try:\n",
    "        input = open(filename)\n",
    "    except:\n",
    "        print(\"E: Unable to open file \" + filename)\n",
    "        return False\n",
    "    m = 0  # Number of training examples.\n",
    "    n = 0  # Number of features.\n",
    "    nnz = 0  # Number of nonzero elements.\n",
    "    data = []\n",
    "    buffer = input.readline()\n",
    "    labels = []\n",
    "    while buffer:\n",
    "        m += 1\n",
    "        data.append([])\n",
    "        ss = buffer.strip().split(\" \")\n",
    "        label = float(ss[0])\n",
    "        labels.append(int(label))\n",
    "        for i in range(1, len(ss)):\n",
    "            key_value = ss[i].split(\":\")\n",
    "            key = int(key_value[0])\n",
    "            value = float(key_value[1])\n",
    "            data[-1].append((key - 1, value))\n",
    "            n = max(n, key)\n",
    "            nnz += 1\n",
    "        buffer = input.readline()\n",
    "    input.close()\n",
    "    return data\n",
    "\n",
    "def read_data(path):\n",
    "    b, A = svm_read_problem(path)\n",
    "    rows = len(b)   # 矩阵行数, i.e. sample 数\n",
    "    cols = max([max(row.keys()) if len(row)>0 else 0 for row in A])  # 矩阵列数, i.e. feature 数\n",
    "    b = np.array(b)\n",
    "    A_np = np.zeros((rows,cols))\n",
    "    for r in range(rows):\n",
    "        for c in A[r].keys():\n",
    "            # MatLab 是 1-index, python 则是 0-index\n",
    "            A_np[r,c-1] = A[r][c]\n",
    "    # 清楚全 0 features\n",
    "    effective_row_ids = []\n",
    "    for idx, row in enumerate(A_np):\n",
    "        if   True or np.sum(row) > 1e-3:\n",
    "            effective_row_ids.append(idx)\n",
    "    return b[effective_row_ids], A_np[effective_row_ids]\n",
    "\n",
    "\n",
    "def solve_tridiagonal_system(diag: np.ndarray, subdiag: np.ndarray, tau: float, b: np.ndarray) -> np.ndarray:\n",
    "    n = diag.shape[0]\n",
    "    c = np.zeros(n - 1)\n",
    "    d = np.zeros(n)\n",
    "\n",
    "    c[0] = subdiag[0] / (diag[0] + tau)\n",
    "    d[0] = b[0] / (diag[0] + tau)\n",
    "    for i in range(1, n - 1):\n",
    "        w = diag[i] + tau - subdiag[i - 1] * c[i - 1]\n",
    "        c[i] = subdiag[i] / w\n",
    "        d[i] = (b[i] - subdiag[i - 1] * d[i - 1]) / w\n",
    "    d[n - 1] = (b[n - 1] - subdiag[n - 2] * d[n - 2]) / (diag[n - 1] + tau - subdiag[n - 2] * c[n - 2])\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        d[i] -= c[i] * d[i + 1]\n",
    "\n",
    "    return d\n",
    "\n",
    "2 * np.finfo(float).eps\n",
    "def ss(A, jj):\n",
    "    \"\"\"Subfunction for h_trid.\"\"\"\n",
    "    return np.sqrt(np.sum(A[jj + 1:, jj] ** 2))\n",
    "\n",
    "def h_trid(A):\n",
    "    \"\"\"\n",
    "    H_TRID(A) uses Householder method to form a tridiagonal matrix from A.\n",
    "    Must have a SQUARE SYMMETRIC matrix as the input.\n",
    "    \"\"\"\n",
    "    M, N = A.shape\n",
    "    if M != N or (A != A.T).any():  # This just screens matrices that can't work.\n",
    "        raise ValueError(\"Matrix must be square symmetric only, see help.\")\n",
    "\n",
    "    lngth = len(A)  # Preallocations.\n",
    "    v = np.zeros(lngth)\n",
    "    I = np.eye(lngth)\n",
    "    Aold = A\n",
    "    finalP=np.eye(lngth)\n",
    "    for jj in range(lngth - 2):  # Build each vector j and run the whole procedure.\n",
    "        v[:jj+1] = 0\n",
    "        S = ss(Aold, jj)\n",
    "        v[jj + 1] = np.sqrt(0.5 * (1 + abs(Aold[jj + 1, jj]) / (S+2 * np.finfo(float).eps)))\n",
    "        v[jj + 2:] = Aold[jj + 2:, jj] * np.sign(Aold[jj + 1, jj]) / (2 * v[jj + 1] * S+2 * np.finfo(float).eps )\n",
    "        P = I - 2 * np.outer(v, v)\n",
    "        Anew = P @ Aold @ P\n",
    "        Aold = Anew\n",
    "        finalP=finalP@P\n",
    "    # Anew[abs(Anew) < 5e-14] = 0  # Tolerance.\n",
    "\n",
    "    return Anew,finalP\n",
    "\n",
    "\n",
    "\n",
    "def minimize_quadratic_on_l2_ball(g: np.ndarray, H: np.ndarray, R: float, inner_eps: float) -> np.ndarray:\n",
    "    n = g.shape[0]\n",
    "    # np.savetxt('hess.txt',H)\n",
    "    # print(np.linalg.norm(H))\n",
    "    H_tridiag, Q = hessenberg(H,calc_q=True)\n",
    "    diag = np.diag(H_tridiag)\n",
    "    subdiag = np.diag(H_tridiag, k=-1)\n",
    "    # print(\"Other:\",np.sum(H_tridiag)-np.sum(diag)-np.sum(subdiag)*2,flush=True)\n",
    "    g_ = Q.T.dot(g)\n",
    "\n",
    "    tau = 1.0\n",
    "    S_tau = np.zeros(n)\n",
    "    S_tau_norm = 0.0\n",
    "    phi_tau = 0.0\n",
    "    # print(np.linalg.norm(H_tridiag))\n",
    "    # print(np.linalg.norm(diag),\"\\t\",np.linalg.norm(subdiag),\"\\t\",np.linalg.norm(g_))\n",
    "    N_LINE_SEARCH_ITERS = 100\n",
    "    for i in range(N_LINE_SEARCH_ITERS + 1):\n",
    "        if i == N_LINE_SEARCH_ITERS:\n",
    "            print(\"W: Preliminaty line search iterations exceeded in MinimizeQuadraticOnL2Ball\")\n",
    "            break\n",
    "\n",
    "        S_tau = solve_tridiagonal_system(diag, subdiag, tau, g_)\n",
    "        S_tau_norm = np.linalg.norm(S_tau)\n",
    "        phi_tau = 1.0 / S_tau_norm - 1.0 / R\n",
    "        if phi_tau < inner_eps or tau < inner_eps:\n",
    "            break\n",
    "        tau *= 0.5\n",
    "    # print(\"phi_tau:\",phi_tau)\n",
    "    if phi_tau < -inner_eps:\n",
    "        S_tau_grad = np.zeros(n)\n",
    "        for i in range(N_LINE_SEARCH_ITERS + 1):\n",
    "            if i == N_LINE_SEARCH_ITERS:\n",
    "                print(\"W: 1-D Newton iterations exceeded in MinimizeQuadraticOnL2Ball\")\n",
    "                break\n",
    "\n",
    "            S_tau_grad = solve_tridiagonal_system(diag, subdiag, tau, S_tau)\n",
    "            phi_tau_prime = (1.0 / S_tau_norm**3) * (S_tau.T.dot(S_tau_grad))\n",
    "            tau -= phi_tau / phi_tau_prime\n",
    "\n",
    "            S_tau = solve_tridiagonal_system(diag, subdiag, tau, g_)\n",
    "            S_tau_norm = np.linalg.norm(S_tau)\n",
    "            phi_tau = 1.0 / S_tau_norm - 1.0 / R\n",
    "\n",
    "            if abs(phi_tau) < inner_eps or abs(phi_tau_prime) < inner_eps:\n",
    "                break\n",
    "\n",
    "    return -Q.dot(S_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Sigmoid(t):\n",
    "    # if t>0:\n",
    "    return 1.0 / (1 + np.exp(-t))\n",
    "    # else:\n",
    "    #     return np.exp(t) / (1 + np.exp(t))\n",
    "def Log_one_exp(inner):\n",
    "    if (inner > 0):\n",
    "        return inner + np.log(1 + np.exp(-inner))\n",
    "    else:\n",
    "        return np.log(1 + np.exp(inner))\n",
    "\n",
    "def Pi(k: int) -> int:\n",
    "    k |= (k >> 1)\n",
    "    k |= (k >> 2)\n",
    "    k |= (k >> 4)\n",
    "    k |= (k >> 8)\n",
    "    k |= (k >> 16)\n",
    "    return (k + 1) >> 1\n",
    "\n",
    "def StochasticContractingNewton(params: dict, c_0: float, decrease_gamma: bool, variance_reduction: bool, hessian_variance_reduction: bool, history = None):\n",
    "    params['AT']=params['A'].T\n",
    "    n = params['A'].shape[1]\n",
    "    m = params['A'].shape[0]\n",
    "    inv_m = 1.0 / m\n",
    "    data_accesses = 0\n",
    "\n",
    "    x_k = params['x_0']\n",
    "\n",
    "    A_batch = None\n",
    "    AT_batch = None\n",
    "    A_batch_triplets = []\n",
    "    AT_batch_triplets = []\n",
    "\n",
    "    g_k = np.zeros(n)\n",
    "    H_k = np.zeros((n, n))\n",
    "    v_k = np.zeros(n)\n",
    "\n",
    "    sigma_prime = None\n",
    "    Ax = None\n",
    "    full_grad = None\n",
    "    full_Hess = None\n",
    "    z_k = None\n",
    "\n",
    "    # np.random.seed(31415) # 原代码的随机数，但是由于编程语言差异，在Python中效果并不相同\n",
    "    obj_indices = np.arange(m)\n",
    "    batch = []\n",
    "    norm_g=0\n",
    "    method_name = \"Stochastic Newton\"\n",
    "    if variance_reduction:\n",
    "        method_name += \" (HVR)\" if hessian_variance_reduction else \" (VR)\"\n",
    "    gamma_str = \"gamma_k = \" + str(c_0)\n",
    "    if decrease_gamma:\n",
    "        gamma_str += \" / (3 + k)\"\n",
    "    pbar=tqdm(range(params['n_iters'] ))\n",
    "    # InitDisplay(params, method_name + \", \" + gamma_str)\n",
    "    print('Iteration 0 - Function value: %.8f / Grad norm: %.8f'%(np.average(np.array([Log_one_exp(ax) for ax in params['A']@x_k]))+inv_m*params['lambda']*np.linalg.norm(x_k)**2,norm_g))\n",
    "    for k in range(params['n_iters'] ):\n",
    "        to_finish = None\n",
    "        # UpdateHistory(\n",
    "        #     params, start_time, k, data_accesses,\n",
    "        #     lambda: (x_k.norm() > params.R_ + REGION_TOLERERANCE) ? INF : inv_m * ((*params.A_) * x_k).unaryExpr(&Log_one_exp).sum(),\n",
    "        #     &last_logging_time,\n",
    "        #     &last_display_time,\n",
    "        #     history,\n",
    "        #     &to_finish)\n",
    "        if to_finish or (k>=1 and norm_g<params['outer_eps']):\n",
    "            break\n",
    "\n",
    "        if variance_reduction and Pi(k) == k:\n",
    "            Ax = np.matmul(params['A'], x_k)\n",
    "            full_grad = inv_m * (params['AT']@(np.array([Sigmoid(ax) for ax in Ax]))) \n",
    "            if hessian_variance_reduction:\n",
    "                full_Hess = (inv_m) * (params['AT']@((np.array([Sigmoid(ax) for ax in Ax]) * (1 - np.array([Sigmoid(ax) for ax in Ax])))[:, np.newaxis] * params['A']))\n",
    "            z_k = x_k.copy()\n",
    "            data_accesses += m\n",
    "\n",
    "        k_sqr = (k + 1) * (k + 1)\n",
    "        batch_size = k_sqr if k_sqr < m else m\n",
    "        if batch_size == m:\n",
    "            print(\"W: batch_size equals m\")\n",
    "        np.random.shuffle(obj_indices)\n",
    "        # if k!=0:\n",
    "        batch = obj_indices[:batch_size].copy()\n",
    "        # else:\n",
    "        #     batch=[19539] // 原作者版本的第一个随机数\n",
    "\n",
    "        if decrease_gamma:\n",
    "            gamma_k = c_0 / (3 + k)\n",
    "\n",
    "        if variance_reduction:\n",
    "            g_k = full_grad\n",
    "            if hessian_variance_reduction:\n",
    "                H_k = gamma_k*full_Hess\n",
    "            else:\n",
    "                H_k=np.zeros((n,n))\n",
    "        else:\n",
    "            g_k=np.zeros(n)\n",
    "            H_k=np.zeros((n,n))\n",
    "                \n",
    "        A_batch=np.zeros((batch_size,n))\n",
    "        sigma_prime = np.zeros(batch_size)\n",
    "        \n",
    "        for batch_i in range(batch_size):\n",
    "            i = batch[batch_i]\n",
    "            sigma = Sigmoid(params['A'][i, :].dot(x_k))\n",
    "            g_k += (sigma / batch_size) * params['A'][i, :]\n",
    "            data_i = params['data'][i]\n",
    "            for index_value in data_i:\n",
    "                A_batch[batch_i, index_value[0]]=index_value[1]\n",
    "            sigma_prime[batch_i] = sigma * (1 - sigma) * gamma_k / batch_size\n",
    "            if variance_reduction:\n",
    "                sigma_z = Sigmoid(params['A'][i, :].dot(z_k))\n",
    "                g_k -= (sigma_z / batch_size) * params['A'][i, :]\n",
    "                # print(sigma_z,\"\\t\",norm(x_k),\"\\t\",np.sum(params['A'][i, :]))\n",
    "                if hessian_variance_reduction:\n",
    "                    sigma_prime[batch_i] -= sigma_z * (1 - sigma_z) * gamma_k / batch_size\n",
    "        # print(np.linalg.norm(sigma_prime),\"\\t\",(np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k))))))\n",
    "        \n",
    "        data_accesses += batch_size\n",
    "        g_k+=2*inv_m*params['lambda']*x_k\n",
    "        AT_batch = A_batch.T\n",
    "        H_k += AT_batch @ np.diag(sigma_prime) @ A_batch  + inv_m*2*params['lambda']*np.diag([1.0]*x_k.size)\n",
    "        # print(np.diag(sigma_prime))\n",
    "        norm_g=np.linalg.norm(g_k)\n",
    "        g_k -= H_k @ x_k\n",
    "        v_k = minimize_quadratic_on_l2_ball(g_k, H_k, params['R'], params['inner_eps'])\n",
    "        x_k += gamma_k * (v_k - x_k)\n",
    "        # x_k=-x_k\n",
    "        print(f'Iteration {k+1} - Function value: %.8f / Grad norm: %.8f/ Data access:{data_accesses}'%(np.average(np.array([Log_one_exp(ax) for ax in params['A']@x_k]))+inv_m*params['lambda']*np.linalg.norm(x_k)**2,norm_g))\n",
    "        # print(x_k[:5],\"\\t\",np.max((params['A']@x_k)))\n",
    "        # print()\n",
    "        # pbar.set_description('Function value: %.8f / Grad norm: %.8f'%(np.average(np.log(1+np.exp(-params['b']*(params['A_o']@x_k)))),norm_g)) # +inv_m*params['lambda']*np.linalg.norm(x_k)**2\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-219-f8feeca25872>:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(930)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49749 300\n",
      "14358852\n",
      "Iteration 0 - Function value: 0.69314718 / Grad norm: 0.00000000\n",
      "Iteration 1 - Function value: 1.47403231 / Grad norm: 0.56253632/ Data access:49750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-218-cb4fadb0451a>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 - Function value: 35.42722520 / Grad norm: 0.02418674/ Data access:99503\n",
      "Iteration 3 - Function value: 0.59822403 / Grad norm: 1.12614092/ Data access:149261\n",
      "Iteration 4 - Function value: 1.47926329 / Grad norm: 0.79658398/ Data access:149277\n",
      "Iteration 5 - Function value: 0.62766847 / Grad norm: 0.17332865/ Data access:199051\n",
      "Iteration 6 - Function value: 2.27813599 / Grad norm: 0.29308159/ Data access:199087\n",
      "Iteration 7 - Function value: 1.12132929 / Grad norm: 0.36657319/ Data access:199136\n",
      "Iteration 8 - Function value: 1.77924071 / Grad norm: 0.36285511/ Data access:199200\n",
      "Iteration 9 - Function value: 0.54301159 / Grad norm: 0.17909668/ Data access:249030\n",
      "Iteration 10 - Function value: 0.55968054 / Grad norm: 0.10150626/ Data access:249130\n",
      "Iteration 11 - Function value: 0.87965682 / Grad norm: 0.17131322/ Data access:249251\n",
      "Iteration 12 - Function value: 5.02072679 / Grad norm: 0.26685093/ Data access:249395\n",
      "Iteration 13 - Function value: 2.52568120 / Grad norm: 0.37129569/ Data access:249564\n",
      "Iteration 14 - Function value: 1.21783357 / Grad norm: 0.45605228/ Data access:249760\n",
      "Iteration 15 - Function value: 0.67863529 / Grad norm: 0.47316040/ Data access:249985\n",
      "Iteration 16 - Function value: 0.62111211 / Grad norm: 0.37861020/ Data access:250241\n",
      "Iteration 17 - Function value: 0.34781805 / Grad norm: 0.02319631/ Data access:300279\n",
      "Iteration 18 - Function value: 0.35267962 / Grad norm: 0.02536378/ Data access:300603\n",
      "Iteration 19 - Function value: 0.34614408 / Grad norm: 0.03892448/ Data access:300964\n",
      "Iteration 20 - Function value: 0.55556326 / Grad norm: 0.05037172/ Data access:301364\n",
      "Iteration 21 - Function value: 0.58817682 / Grad norm: 0.07895682/ Data access:301805\n",
      "Iteration 22 - Function value: 0.51209424 / Grad norm: 0.09115605/ Data access:302289\n",
      "Iteration 23 - Function value: 0.49240822 / Grad norm: 0.09427900/ Data access:302818\n",
      "Iteration 24 - Function value: 0.49243727 / Grad norm: 0.08632029/ Data access:303394\n",
      "Iteration 25 - Function value: 0.48802108 / Grad norm: 0.08340579/ Data access:304019\n",
      "Iteration 26 - Function value: 0.48047733 / Grad norm: 0.08124389/ Data access:304695\n",
      "Iteration 27 - Function value: 0.49567982 / Grad norm: 0.08395798/ Data access:305424\n",
      "Iteration 28 - Function value: 0.54030524 / Grad norm: 0.08703137/ Data access:306208\n",
      "Iteration 29 - Function value: 0.61462673 / Grad norm: 0.08934145/ Data access:307049\n",
      "Iteration 30 - Function value: 0.67364692 / Grad norm: 0.08865333/ Data access:307949\n",
      "Iteration 31 - Function value: 0.67469429 / Grad norm: 0.09082678/ Data access:308910\n",
      "Iteration 32 - Function value: 0.66345930 / Grad norm: 0.09716581/ Data access:309934\n",
      "Iteration 33 - Function value: 0.44871676 / Grad norm: 0.02720556/ Data access:360772\n",
      "Iteration 34 - Function value: 0.32560648 / Grad norm: 0.01651393/ Data access:361928\n",
      "Iteration 35 - Function value: 0.29205691 / Grad norm: 0.02183500/ Data access:363153\n",
      "Iteration 36 - Function value: 0.34419954 / Grad norm: 0.01854131/ Data access:364449\n",
      "Iteration 37 - Function value: 0.39001553 / Grad norm: 0.02193940/ Data access:365818\n",
      "Iteration 38 - Function value: 0.42232577 / Grad norm: 0.02929336/ Data access:367262\n",
      "Iteration 39 - Function value: 0.43572523 / Grad norm: 0.03048096/ Data access:368783\n",
      "Iteration 40 - Function value: 0.43743957 / Grad norm: 0.03060878/ Data access:370383\n",
      "Iteration 41 - Function value: 0.44791418 / Grad norm: 0.03139840/ Data access:372064\n",
      "Iteration 42 - Function value: 0.46935956 / Grad norm: 0.03446273/ Data access:373828\n",
      "Iteration 43 - Function value: 0.51538815 / Grad norm: 0.03849323/ Data access:375677\n",
      "Iteration 44 - Function value: 0.56553174 / Grad norm: 0.03703762/ Data access:377613\n",
      "Iteration 45 - Function value: 0.58624443 / Grad norm: 0.03635083/ Data access:379638\n",
      "Iteration 46 - Function value: 0.57436986 / Grad norm: 0.04037303/ Data access:381754\n",
      "Iteration 47 - Function value: 0.57506594 / Grad norm: 0.04135692/ Data access:383963\n",
      "Iteration 48 - Function value: 0.58702883 / Grad norm: 0.04022027/ Data access:386267\n",
      "Iteration 49 - Function value: 0.61055714 / Grad norm: 0.03866140/ Data access:388668\n",
      "Iteration 50 - Function value: 0.64610183 / Grad norm: 0.03861867/ Data access:391168\n",
      "Iteration 51 - Function value: 0.68690113 / Grad norm: 0.03956903/ Data access:393769\n",
      "Iteration 52 - Function value: 0.73045189 / Grad norm: 0.04084581/ Data access:396473\n",
      "Iteration 53 - Function value: 0.77183092 / Grad norm: 0.04095818/ Data access:399282\n",
      "Iteration 54 - Function value: 0.79738985 / Grad norm: 0.04024204/ Data access:402198\n",
      "Iteration 55 - Function value: 0.80846653 / Grad norm: 0.04048731/ Data access:405223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-806d9a8dee63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mvr\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;31m# Variance reduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mhessvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;31m# Hessian Variance Reduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mStochasticContractingNewton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecrease_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhessvr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-218-cb4fadb0451a>\u001b[0m in \u001b[0;36mStochasticContractingNewton\u001b[1;34m(params, c_0, decrease_gamma, variance_reduction, hessian_variance_reduction, history)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mx_k\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma_k\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv_k\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# x_k=-x_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Iteration {k+1} - Function value: %.8f / Grad norm: %.8f/ Data access:{data_accesses}'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLog_one_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0minv_m\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lambda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnorm_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;31m# print(x_k[:5],\"\\t\",np.max((params['A']@x_k)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-218-cb4fadb0451a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mx_k\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma_k\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv_k\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# x_k=-x_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Iteration {k+1} - Function value: %.8f / Grad norm: %.8f/ Data access:{data_accesses}'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLog_one_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0minv_m\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lambda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnorm_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;31m# print(x_k[:5],\"\\t\",np.max((params['A']@x_k)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-218-cb4fadb0451a>\u001b[0m in \u001b[0;36mLog_one_exp\u001b[1;34m(inner)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mPi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "b, A= read_data('w8a')\n",
    "data = ReadDataSparse('w8a')\n",
    "# b, A = read_data('ijcnn1.test')\n",
    "# b, A = read_data('a9a.test')\n",
    "# b, A = read_data('CINA.test')\n",
    "m,n = A.shape\n",
    "print(m,n)\n",
    "b=-b #原论文将第一个label作为1，反之为-1\n",
    "# b=np.expand_dims(b, axis=1)\n",
    "params=dict()\n",
    "params['data']=data\n",
    "params['A']=-np.multiply(b,A.T).T\n",
    "params['A_o']=A\n",
    "params['b']=b\n",
    "# print(params['A'][0,:])\n",
    "print(np.sum(A==params['A']))\n",
    "params['x_0']=np.zeros(n)\n",
    "c_0 = 3.0\n",
    "params['R']=100\n",
    "params['inner_eps']=1e-9\n",
    "params['outer_eps']=1e-4\n",
    "params['n_iters']=100\n",
    "params['lambda']=0.01\n",
    "history=None\n",
    "decrease_gamma=True\n",
    "vr =True # Variance reduction\n",
    "hessvr = False # Hessian Variance Reduction\n",
    "StochasticContractingNewton(params, c_0, decrease_gamma,vr,hessvr, history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "734ab24b5d337aa3083f37141e45635523032b38e37867a0b0460a6855b4b5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
